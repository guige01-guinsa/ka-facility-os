import csv
import hashlib
import html
import hmac
import io
import json
import math
import secrets
import statistics
import string
import time
import zipfile
from collections import deque
from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from datetime import date
from datetime import datetime, timezone
from datetime import timedelta
from os import getenv
from pathlib import Path, PurePosixPath
from threading import Lock
from typing import Annotated, Any, Callable
from urllib import error as url_error
from urllib import request as url_request

from fastapi import APIRouter, Depends, FastAPI, File, Form, HTTPException, Header, Query, Request, UploadFile
from fastapi.responses import HTMLResponse, JSONResponse, Response
from sqlalchemy import delete, func, insert, select, update
from sqlalchemy.exc import SQLAlchemyError

try:
    from redis import Redis
except Exception:  # pragma: no cover - optional dependency
    Redis = None  # type: ignore[assignment]

from app.database import (
    DATABASE_URL,
    adoption_w02_evidence_files,
    adoption_w02_site_runs,
    adoption_w02_tracker_items,
    adoption_w03_evidence_files,
    adoption_w03_site_runs,
    adoption_w03_tracker_items,
    adoption_w04_evidence_files,
    adoption_w04_site_runs,
    adoption_w04_tracker_items,
    adoption_w07_evidence_files,
    adoption_w07_site_runs,
    adoption_w07_tracker_items,
    adoption_w09_evidence_files,
    adoption_w09_site_runs,
    adoption_w09_tracker_items,
    adoption_w10_evidence_files,
    adoption_w10_site_runs,
    adoption_w10_tracker_items,
    adoption_w11_evidence_files,
    adoption_w11_site_runs,
    adoption_w11_tracker_items,
    adoption_w12_evidence_files,
    adoption_w12_site_runs,
    adoption_w12_tracker_items,
    adoption_w13_evidence_files,
    adoption_w13_site_runs,
    adoption_w13_tracker_items,
    adoption_w14_evidence_files,
    adoption_w14_site_runs,
    adoption_w14_tracker_items,
    adoption_w15_evidence_files,
    adoption_w15_site_runs,
    adoption_w15_tracker_items,
    ops_governance_remediation_tracker_items,
    ops_governance_remediation_tracker_runs,
    api_latency_samples,
    alert_deliveries,
    admin_audit_logs,
    admin_tokens,
    admin_users,
    ensure_database,
    get_conn,
    inspections,
    job_runs,
    sla_policies,
    sla_policy_proposals,
    sla_policy_revisions,
    workflow_locks,
    work_order_events,
    work_orders,
)
from app.schemas import (
    AlertRetryRunRequest,
    AlertRetryRunResponse,
    AlertDeliveryRead,
    AdminAuditLogRead,
    AdminTokenIssueRequest,
    AdminTokenIssueResponse,
    AdminTokenRead,
    AdminUserActiveUpdate,
    AdminUserCreate,
    AdminUserRead,
    AuthMeRead,
    DashboardSummaryRead,
    DashboardTrendPoint,
    DashboardTrendsRead,
    InspectionCreate,
    InspectionRead,
    JobRunRead,
    MonthlyReportRead,
    OpsHandoverBriefRead,
    OpsHandoverInspectionRead,
    OpsHandoverWorkOrderRead,
    SlaAlertChannelResult,
    SlaEscalationRunRequest,
    SlaEscalationRunResponse,
    SlaPolicyRead,
    SlaPolicyProposalCreate,
    SlaPolicyProposalDecision,
    SlaPolicyProposalRead,
    SlaPolicyRestoreRequest,
    SlaPolicyRevisionRead,
    SlaPolicyUpdate,
    SlaWhatIfRequest,
    SlaWhatIfResponse,
    W02EvidenceRead,
    W02TrackerCompletionRead,
    W02TrackerCompletionRequest,
    W02TrackerBootstrapRequest,
    W02TrackerBootstrapResponse,
    W02TrackerItemRead,
    W02TrackerItemUpdate,
    W02TrackerOverviewRead,
    W02TrackerReadinessRead,
    W03EvidenceRead,
    W03TrackerCompletionRead,
    W03TrackerCompletionRequest,
    W03TrackerBootstrapRequest,
    W03TrackerBootstrapResponse,
    W03TrackerItemRead,
    W03TrackerItemUpdate,
    W03TrackerOverviewRead,
    W03TrackerReadinessRead,
    W04EvidenceRead,
    W04TrackerCompletionRead,
    W04TrackerCompletionRequest,
    W04TrackerBootstrapRequest,
    W04TrackerBootstrapResponse,
    W04TrackerItemRead,
    W04TrackerItemUpdate,
    W04TrackerOverviewRead,
    W04TrackerReadinessRead,
    W07EvidenceRead,
    W07TrackerBootstrapRequest,
    W07TrackerBootstrapResponse,
    W07TrackerCompletionRead,
    W07TrackerCompletionRequest,
    W07TrackerItemRead,
    W07TrackerItemUpdate,
    W07TrackerOverviewRead,
    W07TrackerReadinessRead,
    W09EvidenceRead,
    W09TrackerBootstrapRequest,
    W09TrackerBootstrapResponse,
    W09TrackerCompletionRead,
    W09TrackerCompletionRequest,
    W09TrackerItemRead,
    W09TrackerItemUpdate,
    W09TrackerOverviewRead,
    W09TrackerReadinessRead,
    W10EvidenceRead,
    W10TrackerBootstrapRequest,
    W10TrackerBootstrapResponse,
    W10TrackerCompletionRead,
    W10TrackerCompletionRequest,
    W10TrackerItemRead,
    W10TrackerItemUpdate,
    W10TrackerOverviewRead,
    W10TrackerReadinessRead,
    W11EvidenceRead,
    W11TrackerBootstrapRequest,
    W11TrackerBootstrapResponse,
    W11TrackerCompletionRead,
    W11TrackerCompletionRequest,
    W11TrackerItemRead,
    W11TrackerItemUpdate,
    W11TrackerOverviewRead,
    W11TrackerReadinessRead,
    W12EvidenceRead,
    W12TrackerBootstrapRequest,
    W12TrackerBootstrapResponse,
    W12TrackerCompletionRead,
    W12TrackerCompletionRequest,
    W12TrackerItemRead,
    W12TrackerItemUpdate,
    W12TrackerOverviewRead,
    W12TrackerReadinessRead,
    W13EvidenceRead,
    W13TrackerBootstrapRequest,
    W13TrackerBootstrapResponse,
    W13TrackerCompletionRead,
    W13TrackerCompletionRequest,
    W13TrackerItemRead,
    W13TrackerItemUpdate,
    W13TrackerOverviewRead,
    W13TrackerReadinessRead,
    W14EvidenceRead,
    W14TrackerBootstrapRequest,
    W14TrackerBootstrapResponse,
    W14TrackerCompletionRead,
    W14TrackerCompletionRequest,
    W14TrackerItemRead,
    W14TrackerItemUpdate,
    W14TrackerOverviewRead,
    W14TrackerReadinessRead,
    W15EvidenceRead,
    W15TrackerBootstrapRequest,
    W15TrackerBootstrapResponse,
    W15TrackerCompletionRead,
    W15TrackerCompletionRequest,
    W15TrackerItemRead,
    W15TrackerItemUpdate,
    W15TrackerOverviewRead,
    W15TrackerReadinessRead,
    W21RemediationTrackerCompletionRead,
    W21RemediationTrackerCompletionRequest,
    W21RemediationTrackerItemRead,
    W21RemediationTrackerItemUpdate,
    W21RemediationTrackerOverviewRead,
    W21RemediationTrackerReadinessRead,
    W21RemediationTrackerSyncRequest,
    W21RemediationTrackerSyncResponse,
    WorkflowLockCreate,
    WorkflowLockDraftUpdate,
    WorkflowLockRead,
    WorkflowLockTransitionRequest,
    WorkOrderAck,
    WorkOrderCancel,
    WorkOrderCommentCreate,
    WorkOrderComplete,
    WorkOrderCreate,
    WorkOrderEventRead,
    WorkOrderReopen,
    WorkOrderRead,
)

def _env_bool(name: str, default: bool) -> bool:
    raw = getenv(name)
    if raw is None:
        return default
    return raw.strip().lower() in {"1", "true", "yes", "on"}


def _env_int(name: str, default: int, *, min_value: int = 0) -> int:
    raw = getenv(name)
    if raw is None:
        return max(default, min_value)
    try:
        value = int(raw.strip())
    except ValueError:
        return max(default, min_value)
    return max(value, min_value)


def _env_float(name: str, default: float, *, min_value: float = 0.0) -> float:
    raw = getenv(name)
    if raw is None:
        return max(default, min_value)
    try:
        value = float(raw.strip())
    except ValueError:
        return max(default, min_value)
    return max(value, min_value)


ADMIN_TOKEN = getenv("ADMIN_TOKEN", "").strip()
ENV_NAME = getenv("ENV", "local").lower()
ALLOW_INSECURE_LOCAL_AUTH = _env_bool("ALLOW_INSECURE_LOCAL_AUTH", True)
ALERT_WEBHOOK_URL = getenv("ALERT_WEBHOOK_URL", "").strip()
ALERT_WEBHOOK_URLS = getenv("ALERT_WEBHOOK_URLS", "").strip()
ALERT_WEBHOOK_TIMEOUT_SEC = float(getenv("ALERT_WEBHOOK_TIMEOUT_SEC", "5"))
ALERT_WEBHOOK_RETRIES = int(getenv("ALERT_WEBHOOK_RETRIES", "3"))
OPS_DAILY_CHECK_ALERT_LEVEL = getenv("OPS_DAILY_CHECK_ALERT_LEVEL", "critical").strip().lower() or "critical"
ALERT_CHANNEL_GUARD_ENABLED = _env_bool("ALERT_CHANNEL_GUARD_ENABLED", True)
ALERT_CHANNEL_GUARD_FAIL_THRESHOLD = _env_int("ALERT_CHANNEL_GUARD_FAIL_THRESHOLD", 3, min_value=1)
ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES = _env_int("ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES", 30, min_value=1)
ALERT_GUARD_RECOVER_MAX_TARGETS = _env_int("ALERT_GUARD_RECOVER_MAX_TARGETS", 30, min_value=1)
ALERT_RETENTION_DAYS = _env_int("ALERT_RETENTION_DAYS", 90, min_value=1)
ALERT_RETENTION_MAX_DELETE = _env_int("ALERT_RETENTION_MAX_DELETE", 5000, min_value=1)
ALERT_RETENTION_ARCHIVE_ENABLED = _env_bool("ALERT_RETENTION_ARCHIVE_ENABLED", True)
ALERT_RETENTION_ARCHIVE_PATH = getenv("ALERT_RETENTION_ARCHIVE_PATH", "data/alert-archives").strip() or "data/alert-archives"
ALERT_MTTR_SLO_ENABLED = _env_bool("ALERT_MTTR_SLO_ENABLED", True)
ALERT_MTTR_SLO_WINDOW_DAYS = _env_int("ALERT_MTTR_SLO_WINDOW_DAYS", 30, min_value=1)
ALERT_MTTR_SLO_THRESHOLD_MINUTES = _env_int("ALERT_MTTR_SLO_THRESHOLD_MINUTES", 45, min_value=1)
ALERT_MTTR_SLO_MIN_INCIDENTS = _env_int("ALERT_MTTR_SLO_MIN_INCIDENTS", 5, min_value=1)
ALERT_MTTR_SLO_AUTO_RECOVER_ENABLED = _env_bool("ALERT_MTTR_SLO_AUTO_RECOVER_ENABLED", True)
ALERT_MTTR_SLO_RECOVER_STATE = getenv("ALERT_MTTR_SLO_RECOVER_STATE", "quarantined").strip().lower() or "quarantined"
ALERT_MTTR_SLO_RECOVER_MAX_TARGETS = _env_int("ALERT_MTTR_SLO_RECOVER_MAX_TARGETS", 30, min_value=1)
ALERT_MTTR_SLO_NOTIFY_ENABLED = _env_bool("ALERT_MTTR_SLO_NOTIFY_ENABLED", True)
ALERT_MTTR_SLO_NOTIFY_EVENT_TYPE = getenv("ALERT_MTTR_SLO_NOTIFY_EVENT_TYPE", "mttr_slo_breach").strip() or "mttr_slo_breach"
ALERT_MTTR_SLO_NOTIFY_COOLDOWN_MINUTES = _env_int("ALERT_MTTR_SLO_NOTIFY_COOLDOWN_MINUTES", 120, min_value=0)
ALERT_MTTR_SLO_TOP_CHANNELS = _env_int("ALERT_MTTR_SLO_TOP_CHANNELS", 15, min_value=1)
API_RATE_LIMIT_ENABLED = _env_bool("API_RATE_LIMIT_ENABLED", True)
API_RATE_LIMIT_WINDOW_SEC = _env_int("API_RATE_LIMIT_WINDOW_SEC", 60, min_value=1)
API_RATE_LIMIT_MAX_PUBLIC = _env_int("API_RATE_LIMIT_MAX_PUBLIC", 120, min_value=1)
API_RATE_LIMIT_MAX_PUBLIC_HEAVY = _env_int("API_RATE_LIMIT_MAX_PUBLIC_HEAVY", 60, min_value=1)
API_RATE_LIMIT_MAX_AUTH = _env_int("API_RATE_LIMIT_MAX_AUTH", 300, min_value=1)
API_RATE_LIMIT_MAX_AUTH_HEAVY = _env_int("API_RATE_LIMIT_MAX_AUTH_HEAVY", 40, min_value=1)
API_RATE_LIMIT_MAX_AUTH_ADMIN = _env_int("API_RATE_LIMIT_MAX_AUTH_ADMIN", 180, min_value=1)
API_RATE_LIMIT_MAX_AUTH_WRITE = _env_int("API_RATE_LIMIT_MAX_AUTH_WRITE", 120, min_value=1)
API_RATE_LIMIT_MAX_AUTH_UPLOAD = _env_int("API_RATE_LIMIT_MAX_AUTH_UPLOAD", 40, min_value=1)
API_RATE_LIMIT_STORE = getenv("API_RATE_LIMIT_STORE", "auto").strip().lower()
API_RATE_LIMIT_REDIS_URL = getenv("API_RATE_LIMIT_REDIS_URL", getenv("REDIS_URL", "")).strip()
API_RATE_LIMIT_REDIS_KEY_PREFIX = getenv("API_RATE_LIMIT_REDIS_KEY_PREFIX", "kaos:ratelimit").strip() or "kaos:ratelimit"
ADMIN_TOKEN_REQUIRE_EXPIRY = _env_bool("ADMIN_TOKEN_REQUIRE_EXPIRY", True)
ADMIN_TOKEN_MAX_TTL_DAYS = _env_int("ADMIN_TOKEN_MAX_TTL_DAYS", 30, min_value=1)
ADMIN_TOKEN_ROTATE_AFTER_DAYS = _env_int("ADMIN_TOKEN_ROTATE_AFTER_DAYS", 45, min_value=1)
ADMIN_TOKEN_ROTATE_WARNING_DAYS = _env_int("ADMIN_TOKEN_ROTATE_WARNING_DAYS", 7, min_value=0)
ADMIN_TOKEN_MAX_IDLE_DAYS = _env_int("ADMIN_TOKEN_MAX_IDLE_DAYS", 30, min_value=1)
ADMIN_TOKEN_MAX_ACTIVE_PER_USER = _env_int("ADMIN_TOKEN_MAX_ACTIVE_PER_USER", 5, min_value=1)
W07_QUALITY_ALERT_ENABLED = _env_bool("W07_QUALITY_ALERT_ENABLED", True)
W07_QUALITY_ALERT_COOLDOWN_MINUTES = _env_int("W07_QUALITY_ALERT_COOLDOWN_MINUTES", 180, min_value=0)
W07_QUALITY_ALERT_MIN_WINDOW_DAYS = _env_int("W07_QUALITY_ALERT_MIN_WINDOW_DAYS", 7, min_value=7)
W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD = float(getenv("W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD", "30"))
W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD = float(getenv("W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD", "95"))
W07_WEEKLY_ARCHIVE_ENABLED = _env_bool("W07_WEEKLY_ARCHIVE_ENABLED", True)
W07_WEEKLY_ARCHIVE_PATH = getenv("W07_WEEKLY_ARCHIVE_PATH", "data/adoption-w07-archives").strip() or "data/adoption-w07-archives"
OPS_DAILY_CHECK_ARCHIVE_ENABLED = _env_bool("OPS_DAILY_CHECK_ARCHIVE_ENABLED", True)
OPS_DAILY_CHECK_ARCHIVE_PATH = (
    getenv("OPS_DAILY_CHECK_ARCHIVE_PATH", "data/ops-daily-check-archives").strip()
    or "data/ops-daily-check-archives"
)
OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS = _env_int("OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS", 60, min_value=1)
OPS_QUALITY_REPORT_ARCHIVE_ENABLED = _env_bool("OPS_QUALITY_REPORT_ARCHIVE_ENABLED", True)
OPS_QUALITY_REPORT_ARCHIVE_PATH = (
    getenv("OPS_QUALITY_REPORT_ARCHIVE_PATH", "data/ops-quality-reports").strip()
    or "data/ops-quality-reports"
)
OPS_QUALITY_REPORT_ARCHIVE_RETENTION_DAYS = _env_int("OPS_QUALITY_REPORT_ARCHIVE_RETENTION_DAYS", 180, min_value=1)
OPS_QUALITY_WEEKLY_STREAK_TARGET = _env_int("OPS_QUALITY_WEEKLY_STREAK_TARGET", 4, min_value=1)
DR_REHEARSAL_ENABLED = _env_bool("DR_REHEARSAL_ENABLED", True)
DR_REHEARSAL_BACKUP_PATH = getenv("DR_REHEARSAL_BACKUP_PATH", "data/dr-rehearsal").strip() or "data/dr-rehearsal"
DR_REHEARSAL_RETENTION_DAYS = _env_int("DR_REHEARSAL_RETENTION_DAYS", 120, min_value=1)
PREFLIGHT_REQUIRED_ENV = {
    value.strip()
    for value in getenv("PREFLIGHT_REQUIRED_ENV", "DATABASE_URL").split(",")
    if value.strip()
}
PREFLIGHT_FAIL_ON_ERROR = _env_bool("PREFLIGHT_FAIL_ON_ERROR", ENV_NAME in {"prod", "production"})
ALERT_NOISE_REVIEW_WINDOW_DAYS = _env_int("ALERT_NOISE_REVIEW_WINDOW_DAYS", 14, min_value=1)
ALERT_NOISE_FALSE_POSITIVE_THRESHOLD_PERCENT = _env_float(
    "ALERT_NOISE_FALSE_POSITIVE_THRESHOLD_PERCENT",
    5.0,
    min_value=0.1,
)
ALERT_NOISE_FALSE_NEGATIVE_THRESHOLD_PERCENT = _env_float(
    "ALERT_NOISE_FALSE_NEGATIVE_THRESHOLD_PERCENT",
    1.0,
    min_value=0.1,
)
EVIDENCE_ALLOWED_CONTENT_TYPES = {
    value.strip().lower()
    for value in getenv(
        "EVIDENCE_ALLOWED_CONTENT_TYPES",
        ",".join(
            [
                "application/pdf",
                "text/plain",
                "text/csv",
                "application/json",
                "image/png",
                "image/jpeg",
                "image/webp",
            ]
        ),
    ).split(",")
    if value.strip()
}
EVIDENCE_STORAGE_BACKEND = getenv("EVIDENCE_STORAGE_BACKEND", "fs").strip().lower() or "fs"
EVIDENCE_STORAGE_PATH = getenv("EVIDENCE_STORAGE_PATH", "data/evidence-objects").strip() or "data/evidence-objects"
EVIDENCE_SCAN_MODE = getenv("EVIDENCE_SCAN_MODE", "basic").strip().lower() or "basic"
EVIDENCE_SCAN_BLOCK_SUSPICIOUS = _env_bool("EVIDENCE_SCAN_BLOCK_SUSPICIOUS", False)
AUDIT_ARCHIVE_SIGNING_KEY = getenv("AUDIT_ARCHIVE_SIGNING_KEY", "").strip()
API_LATENCY_MONITOR_ENABLED = _env_bool("API_LATENCY_MONITOR_ENABLED", True)
API_LATENCY_MONITOR_WINDOW = _env_int("API_LATENCY_MONITOR_WINDOW", 300, min_value=20)
API_LATENCY_MIN_SAMPLES = _env_int("API_LATENCY_MIN_SAMPLES", 8, min_value=1)
API_LATENCY_P95_WARNING_MS = _env_float("API_LATENCY_P95_WARNING_MS", 450.0, min_value=1.0)
API_LATENCY_P95_CRITICAL_MS = _env_float("API_LATENCY_P95_CRITICAL_MS", 900.0, min_value=1.0)
API_LATENCY_PERSIST_ENABLED = _env_bool("API_LATENCY_PERSIST_ENABLED", True)
API_LATENCY_PERSIST_RETENTION_DAYS = _env_int("API_LATENCY_PERSIST_RETENTION_DAYS", 30, min_value=1)
API_LATENCY_PERSIST_PRUNE_INTERVAL = _env_int("API_LATENCY_PERSIST_PRUNE_INTERVAL", 200, min_value=1)
API_BURN_RATE_SHORT_WINDOW_MIN = _env_int("API_BURN_RATE_SHORT_WINDOW_MIN", 5, min_value=1)
API_BURN_RATE_LONG_WINDOW_MIN = _env_int("API_BURN_RATE_LONG_WINDOW_MIN", 60, min_value=1)
API_BURN_RATE_MIN_SAMPLES = _env_int("API_BURN_RATE_MIN_SAMPLES", 8, min_value=1)
API_BURN_RATE_WARNING = _env_float("API_BURN_RATE_WARNING", 2.0, min_value=0.1)
API_BURN_RATE_CRITICAL = _env_float("API_BURN_RATE_CRITICAL", 10.0, min_value=0.1)
API_BURN_RATE_ERROR_SLO_PERCENT = _env_float("API_BURN_RATE_ERROR_SLO_PERCENT", 99.0, min_value=0.1)
API_BURN_RATE_LATENCY_SLO_PERCENT = _env_float("API_BURN_RATE_LATENCY_SLO_PERCENT", 95.0, min_value=0.1)
API_BURN_RATE_SAMPLE_LIMIT = _env_int("API_BURN_RATE_SAMPLE_LIMIT", 1500, min_value=20)
API_LATENCY_TARGETS_RAW = (
    getenv(
        "API_LATENCY_TARGETS",
        "GET /health,GET /meta,GET /api/inspections,GET /api/work-orders,GET /api/ops/dashboard/summary",
    ).strip()
    or "GET /health,GET /meta,GET /api/inspections,GET /api/work-orders,GET /api/ops/dashboard/summary"
)
DEPLOY_SMOKE_RECENT_HOURS = _env_int("DEPLOY_SMOKE_RECENT_HOURS", 48, min_value=1)
DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE = _env_bool("DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE", True)
EVIDENCE_INTEGRITY_SAMPLE_PER_TABLE = _env_int("EVIDENCE_INTEGRITY_SAMPLE_PER_TABLE", 20, min_value=1)
EVIDENCE_INTEGRITY_MAX_ISSUES = _env_int("EVIDENCE_INTEGRITY_MAX_ISSUES", 50, min_value=1)
DEPLOY_CHECKLIST_VERSION = getenv("DEPLOY_CHECKLIST_VERSION", "2026.03.v1").strip() or "2026.03.v1"
GOVERNANCE_GATE_ALLOW_WARNING = _env_bool("GOVERNANCE_GATE_ALLOW_WARNING", True)
GOVERNANCE_GATE_MAX_SECURITY_RISK_LEVEL = (
    getenv("GOVERNANCE_GATE_MAX_SECURITY_RISK_LEVEL", "high").strip().lower() or "high"
)
GOVERNANCE_GATE_REQUIRE_PREFLIGHT_NO_ERROR = _env_bool("GOVERNANCE_GATE_REQUIRE_PREFLIGHT_NO_ERROR", True)
GOVERNANCE_GATE_REQUIRE_RUNBOOK_NO_CRITICAL = _env_bool("GOVERNANCE_GATE_REQUIRE_RUNBOOK_NO_CRITICAL", True)
GOVERNANCE_GATE_REQUIRE_DAILY_CHECK_RECENT = _env_bool("GOVERNANCE_GATE_REQUIRE_DAILY_CHECK_RECENT", False)
GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS = _env_int("GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS", 36, min_value=1)
GOVERNANCE_GATE_REQUIRE_DR_RESTORE_VALID = _env_bool("GOVERNANCE_GATE_REQUIRE_DR_RESTORE_VALID", False)
GOVERNANCE_GATE_DR_MAX_AGE_DAYS = _env_int("GOVERNANCE_GATE_DR_MAX_AGE_DAYS", 35, min_value=1)
GOVERNANCE_GATE_REQUIRE_DEPLOY_SMOKE_BINDING = _env_bool("GOVERNANCE_GATE_REQUIRE_DEPLOY_SMOKE_BINDING", False)
GOVERNANCE_GATE_DEPLOY_SMOKE_MAX_AGE_HOURS = _env_int("GOVERNANCE_GATE_DEPLOY_SMOKE_MAX_AGE_HOURS", 72, min_value=1)
GOVERNANCE_GATE_REQUIRE_WEEKLY_STREAK = _env_bool("GOVERNANCE_GATE_REQUIRE_WEEKLY_STREAK", False)
GOVERNANCE_GATE_SECURITY_DASHBOARD_DAYS = _env_int("GOVERNANCE_GATE_SECURITY_DASHBOARD_DAYS", 30, min_value=7)
SECURITY_HEADERS_BASE: dict[str, str] = {
    "X-Content-Type-Options": "nosniff",
    "X-Frame-Options": "DENY",
    "Referrer-Policy": "no-referrer",
    "Permissions-Policy": "camera=(), microphone=(), geolocation=()",
}
HTML_CSP_POLICY = (
    "default-src 'self'; "
    "img-src 'self' data:; "
    "style-src 'self' 'unsafe-inline'; "
    "script-src 'self' 'unsafe-inline'; "
    "connect-src 'self'; "
    "frame-ancestors 'none'; "
    "base-uri 'self'; "
    "form-action 'self'"
)
_RATE_LIMIT_LOCK = Lock()
_RATE_LIMIT_BUCKETS: dict[str, deque[float]] = {}
_RATE_LIMIT_REDIS: Any = None
_API_LATENCY_LOCK = Lock()
_API_LATENCY_SAMPLES: dict[str, deque[float]] = {}
_API_LATENCY_LAST_SEEN_AT: dict[str, str] = {}
_API_LATENCY_TARGET_KEYS: set[str] = set()
_API_LATENCY_PERSIST_WRITE_COUNT = 0
_PREFLIGHT_LOCK = Lock()
_PREFLIGHT_SNAPSHOT: dict[str, Any] = {}

EVIDENCE_INTEGRITY_TABLES: list[tuple[str, Any]] = [
    ("w02", adoption_w02_evidence_files),
    ("w03", adoption_w03_evidence_files),
    ("w04", adoption_w04_evidence_files),
    ("w07", adoption_w07_evidence_files),
    ("w09", adoption_w09_evidence_files),
    ("w10", adoption_w10_evidence_files),
    ("w11", adoption_w11_evidence_files),
    ("w12", adoption_w12_evidence_files),
    ("w13", adoption_w13_evidence_files),
    ("w14", adoption_w14_evidence_files),
    ("w15", adoption_w15_evidence_files),
]

ROLE_PERMISSION_MAP: dict[str, set[str]] = {
    "owner": {"*"},
    "manager": {
        "inspections:read",
        "inspections:write",
        "work_orders:read",
        "work_orders:write",
        "work_orders:escalate",
        "reports:read",
        "reports:export",
        "workflow_locks:read",
        "workflow_locks:review",
        "workflow_locks:approve",
        "adoption_w02:read",
        "adoption_w02:write",
        "adoption_w03:read",
        "adoption_w03:write",
        "adoption_w04:read",
        "adoption_w04:write",
        "adoption_w05:read",
        "adoption_w05:write",
        "adoption_w06:read",
        "adoption_w06:write",
        "adoption_w07:read",
        "adoption_w07:write",
        "adoption_w08:read",
        "adoption_w08:write",
        "adoption_w09:read",
        "adoption_w09:write",
        "adoption_w10:read",
        "adoption_w10:write",
        "adoption_w11:read",
        "adoption_w11:write",
        "adoption_w12:read",
        "adoption_w12:write",
        "adoption_w13:read",
        "adoption_w13:write",
        "adoption_w14:read",
        "adoption_w14:write",
        "adoption_w15:read",
        "adoption_w15:write",
    },
    "operator": {
        "inspections:read",
        "inspections:write",
        "work_orders:read",
        "work_orders:write",
        "workflow_locks:read",
        "workflow_locks:write",
        "adoption_w02:read",
        "adoption_w02:write",
        "adoption_w03:read",
        "adoption_w03:write",
        "adoption_w04:read",
        "adoption_w04:write",
        "adoption_w05:read",
        "adoption_w05:write",
        "adoption_w06:read",
        "adoption_w06:write",
        "adoption_w07:read",
        "adoption_w07:write",
        "adoption_w08:read",
        "adoption_w08:write",
        "adoption_w09:read",
        "adoption_w09:write",
        "adoption_w10:read",
        "adoption_w10:write",
        "adoption_w11:read",
        "adoption_w11:write",
        "adoption_w12:read",
        "adoption_w12:write",
        "adoption_w13:read",
        "adoption_w13:write",
        "adoption_w14:read",
        "adoption_w14:write",
        "adoption_w15:read",
        "adoption_w15:write",
    },
    "auditor": {
        "inspections:read",
        "work_orders:read",
        "reports:read",
        "reports:export",
        "workflow_locks:read",
        "adoption_w02:read",
        "adoption_w03:read",
        "adoption_w04:read",
        "adoption_w05:read",
        "adoption_w06:read",
        "adoption_w07:read",
        "adoption_w08:read",
        "adoption_w09:read",
        "adoption_w10:read",
        "adoption_w11:read",
        "adoption_w12:read",
        "adoption_w13:read",
        "adoption_w14:read",
        "adoption_w15:read",
    },
}

SLA_DEFAULT_POLICY_KEY = "default"
SLA_SITE_POLICY_PREFIX = "site:"
SLA_DEFAULT_DUE_HOURS: dict[str, int] = {
    "low": 72,
    "medium": 24,
    "high": 8,
    "critical": 2,
}
ALERT_MTTR_SLO_POLICY_KEY = "alert_mttr_slo_default"
ALERT_MTTR_SLO_RECOVER_STATE_SET = {"quarantined", "warning", "all"}
W09_KPI_POLICY_KEY_DEFAULT = "adoption_w09_kpi_policy:default"
W09_KPI_POLICY_KEY_SITE_PREFIX = "adoption_w09_kpi_policy:site:"
W09_KPI_STATUS_GREEN = "green"
W09_KPI_STATUS_YELLOW = "yellow"
W09_KPI_STATUS_RED = "red"
W10_SUPPORT_POLICY_KEY_DEFAULT = "adoption_w10_support_policy:default"
W10_SUPPORT_POLICY_KEY_SITE_PREFIX = "adoption_w10_support_policy:site:"
W10_SUPPORT_STATUS_GREEN = "green"
W10_SUPPORT_STATUS_YELLOW = "yellow"
W10_SUPPORT_STATUS_RED = "red"
W11_READINESS_POLICY_KEY_DEFAULT = "adoption_w11_readiness_policy:default"
W11_READINESS_POLICY_KEY_SITE_PREFIX = "adoption_w11_readiness_policy:site:"
W11_READINESS_STATUS_GREEN = "green"
W11_READINESS_STATUS_YELLOW = "yellow"
W11_READINESS_STATUS_RED = "red"
W12_HANDOFF_POLICY_KEY_DEFAULT = "adoption_w12_handoff_policy:default"
W12_HANDOFF_POLICY_KEY_SITE_PREFIX = "adoption_w12_handoff_policy:site:"
W12_HANDOFF_STATUS_GREEN = "green"
W12_HANDOFF_STATUS_YELLOW = "yellow"
W12_HANDOFF_STATUS_RED = "red"
W13_HANDOFF_POLICY_KEY_DEFAULT = "adoption_w13_handoff_policy:default"
W13_HANDOFF_POLICY_KEY_SITE_PREFIX = "adoption_w13_handoff_policy:site:"
W13_HANDOFF_STATUS_GREEN = "green"
W13_HANDOFF_STATUS_YELLOW = "yellow"
W13_HANDOFF_STATUS_RED = "red"
W14_STABILITY_POLICY_KEY_DEFAULT = "adoption_w14_stability_policy:default"
W14_STABILITY_POLICY_KEY_SITE_PREFIX = "adoption_w14_stability_policy:site:"
W14_STABILITY_STATUS_GREEN = "green"
W14_STABILITY_STATUS_YELLOW = "yellow"
W14_STABILITY_STATUS_RED = "red"
W15_EFFICIENCY_POLICY_KEY_DEFAULT = "adoption_w15_efficiency_policy:default"
W15_EFFICIENCY_POLICY_KEY_SITE_PREFIX = "adoption_w15_efficiency_policy:site:"
W15_EFFICIENCY_STATUS_GREEN = "green"
W15_EFFICIENCY_STATUS_YELLOW = "yellow"
W15_EFFICIENCY_STATUS_RED = "red"
SITE_SCOPE_ALL = "*"
WORK_ORDER_TRANSITIONS: dict[str, set[str]] = {
    "open": {"acked", "completed", "canceled"},
    "acked": {"completed", "canceled"},
    "completed": {"open"},
    "canceled": {"open"},
}
SLA_PROPOSAL_STATUS_PENDING = "pending"
SLA_PROPOSAL_STATUS_APPROVED = "approved"
SLA_PROPOSAL_STATUS_REJECTED = "rejected"
WORKFLOW_LOCK_STATUS_DRAFT = "draft"
WORKFLOW_LOCK_STATUS_REVIEW = "review"
WORKFLOW_LOCK_STATUS_APPROVED = "approved"
WORKFLOW_LOCK_STATUS_LOCKED = "locked"
WORKFLOW_LOCK_STATUS_SET = {
    WORKFLOW_LOCK_STATUS_DRAFT,
    WORKFLOW_LOCK_STATUS_REVIEW,
    WORKFLOW_LOCK_STATUS_APPROVED,
    WORKFLOW_LOCK_STATUS_LOCKED,
}
W02_TRACKER_STATUS_PENDING = "pending"
W02_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W02_TRACKER_STATUS_DONE = "done"
W02_TRACKER_STATUS_BLOCKED = "blocked"
W02_TRACKER_STATUS_SET = {
    W02_TRACKER_STATUS_PENDING,
    W02_TRACKER_STATUS_IN_PROGRESS,
    W02_TRACKER_STATUS_DONE,
    W02_TRACKER_STATUS_BLOCKED,
}
W02_SITE_COMPLETION_STATUS_ACTIVE = "active"
W02_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W02_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W02_SITE_COMPLETION_STATUS_SET = {
    W02_SITE_COMPLETION_STATUS_ACTIVE,
    W02_SITE_COMPLETION_STATUS_COMPLETED,
    W02_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W02_EVIDENCE_REQUIRED_ITEM_TYPES = {"sandbox_scenario"}
W02_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W03_TRACKER_STATUS_PENDING = "pending"
W03_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W03_TRACKER_STATUS_DONE = "done"
W03_TRACKER_STATUS_BLOCKED = "blocked"
W03_TRACKER_STATUS_SET = {
    W03_TRACKER_STATUS_PENDING,
    W03_TRACKER_STATUS_IN_PROGRESS,
    W03_TRACKER_STATUS_DONE,
    W03_TRACKER_STATUS_BLOCKED,
}
W03_SITE_COMPLETION_STATUS_ACTIVE = "active"
W03_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W03_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W03_SITE_COMPLETION_STATUS_SET = {
    W03_SITE_COMPLETION_STATUS_ACTIVE,
    W03_SITE_COMPLETION_STATUS_COMPLETED,
    W03_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W03_EVIDENCE_REQUIRED_ITEM_TYPES = {"role_workshop"}
W03_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W04_TRACKER_STATUS_PENDING = "pending"
W04_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W04_TRACKER_STATUS_DONE = "done"
W04_TRACKER_STATUS_BLOCKED = "blocked"
W04_TRACKER_STATUS_SET = {
    W04_TRACKER_STATUS_PENDING,
    W04_TRACKER_STATUS_IN_PROGRESS,
    W04_TRACKER_STATUS_DONE,
    W04_TRACKER_STATUS_BLOCKED,
}
W04_SITE_COMPLETION_STATUS_ACTIVE = "active"
W04_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W04_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W04_SITE_COMPLETION_STATUS_SET = {
    W04_SITE_COMPLETION_STATUS_ACTIVE,
    W04_SITE_COMPLETION_STATUS_COMPLETED,
    W04_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W04_EVIDENCE_REQUIRED_ITEM_TYPES = {"coaching_action"}
W04_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W07_TRACKER_STATUS_PENDING = "pending"
W07_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W07_TRACKER_STATUS_DONE = "done"
W07_TRACKER_STATUS_BLOCKED = "blocked"
W07_TRACKER_STATUS_SET = {
    W07_TRACKER_STATUS_PENDING,
    W07_TRACKER_STATUS_IN_PROGRESS,
    W07_TRACKER_STATUS_DONE,
    W07_TRACKER_STATUS_BLOCKED,
}
W07_SITE_COMPLETION_STATUS_ACTIVE = "active"
W07_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W07_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W07_SITE_COMPLETION_STATUS_SET = {
    W07_SITE_COMPLETION_STATUS_ACTIVE,
    W07_SITE_COMPLETION_STATUS_COMPLETED,
    W07_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W07_EVIDENCE_REQUIRED_ITEM_TYPES = {"sla_checklist", "coaching_play"}
W07_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W09_TRACKER_STATUS_PENDING = "pending"
W09_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W09_TRACKER_STATUS_DONE = "done"
W09_TRACKER_STATUS_BLOCKED = "blocked"
W09_TRACKER_STATUS_SET = {
    W09_TRACKER_STATUS_PENDING,
    W09_TRACKER_STATUS_IN_PROGRESS,
    W09_TRACKER_STATUS_DONE,
    W09_TRACKER_STATUS_BLOCKED,
}
W09_SITE_COMPLETION_STATUS_ACTIVE = "active"
W09_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W09_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W09_SITE_COMPLETION_STATUS_SET = {
    W09_SITE_COMPLETION_STATUS_ACTIVE,
    W09_SITE_COMPLETION_STATUS_COMPLETED,
    W09_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W09_EVIDENCE_REQUIRED_ITEM_TYPES = {"kpi_threshold", "kpi_escalation"}
W09_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W10_TRACKER_STATUS_PENDING = "pending"
W10_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W10_TRACKER_STATUS_DONE = "done"
W10_TRACKER_STATUS_BLOCKED = "blocked"
W10_TRACKER_STATUS_SET = {
    W10_TRACKER_STATUS_PENDING,
    W10_TRACKER_STATUS_IN_PROGRESS,
    W10_TRACKER_STATUS_DONE,
    W10_TRACKER_STATUS_BLOCKED,
}
W10_SITE_COMPLETION_STATUS_ACTIVE = "active"
W10_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W10_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W10_SITE_COMPLETION_STATUS_SET = {
    W10_SITE_COMPLETION_STATUS_ACTIVE,
    W10_SITE_COMPLETION_STATUS_COMPLETED,
    W10_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W10_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W10_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W11_TRACKER_STATUS_PENDING = "pending"
W11_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W11_TRACKER_STATUS_DONE = "done"
W11_TRACKER_STATUS_BLOCKED = "blocked"
W11_TRACKER_STATUS_SET = {
    W11_TRACKER_STATUS_PENDING,
    W11_TRACKER_STATUS_IN_PROGRESS,
    W11_TRACKER_STATUS_DONE,
    W11_TRACKER_STATUS_BLOCKED,
}
W11_SITE_COMPLETION_STATUS_ACTIVE = "active"
W11_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W11_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W11_SITE_COMPLETION_STATUS_SET = {
    W11_SITE_COMPLETION_STATUS_ACTIVE,
    W11_SITE_COMPLETION_STATUS_COMPLETED,
    W11_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W11_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W11_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W12_TRACKER_STATUS_PENDING = "pending"
W12_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W12_TRACKER_STATUS_DONE = "done"
W12_TRACKER_STATUS_BLOCKED = "blocked"
W12_TRACKER_STATUS_SET = {
    W12_TRACKER_STATUS_PENDING,
    W12_TRACKER_STATUS_IN_PROGRESS,
    W12_TRACKER_STATUS_DONE,
    W12_TRACKER_STATUS_BLOCKED,
}
W12_SITE_COMPLETION_STATUS_ACTIVE = "active"
W12_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W12_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W12_SITE_COMPLETION_STATUS_SET = {
    W12_SITE_COMPLETION_STATUS_ACTIVE,
    W12_SITE_COMPLETION_STATUS_COMPLETED,
    W12_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W12_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W12_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W13_TRACKER_STATUS_PENDING = "pending"
W13_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W13_TRACKER_STATUS_DONE = "done"
W13_TRACKER_STATUS_BLOCKED = "blocked"
W13_TRACKER_STATUS_SET = {
    W13_TRACKER_STATUS_PENDING,
    W13_TRACKER_STATUS_IN_PROGRESS,
    W13_TRACKER_STATUS_DONE,
    W13_TRACKER_STATUS_BLOCKED,
}
W13_SITE_COMPLETION_STATUS_ACTIVE = "active"
W13_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W13_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W13_SITE_COMPLETION_STATUS_SET = {
    W13_SITE_COMPLETION_STATUS_ACTIVE,
    W13_SITE_COMPLETION_STATUS_COMPLETED,
    W13_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W13_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W13_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W14_TRACKER_STATUS_PENDING = "pending"
W14_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W14_TRACKER_STATUS_DONE = "done"
W14_TRACKER_STATUS_BLOCKED = "blocked"
W14_TRACKER_STATUS_SET = {
    W14_TRACKER_STATUS_PENDING,
    W14_TRACKER_STATUS_IN_PROGRESS,
    W14_TRACKER_STATUS_DONE,
    W14_TRACKER_STATUS_BLOCKED,
}
W14_SITE_COMPLETION_STATUS_ACTIVE = "active"
W14_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W14_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W14_SITE_COMPLETION_STATUS_SET = {
    W14_SITE_COMPLETION_STATUS_ACTIVE,
    W14_SITE_COMPLETION_STATUS_COMPLETED,
    W14_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W14_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W14_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W15_TRACKER_STATUS_PENDING = "pending"
W15_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W15_TRACKER_STATUS_DONE = "done"
W15_TRACKER_STATUS_BLOCKED = "blocked"
W15_TRACKER_STATUS_SET = {
    W15_TRACKER_STATUS_PENDING,
    W15_TRACKER_STATUS_IN_PROGRESS,
    W15_TRACKER_STATUS_DONE,
    W15_TRACKER_STATUS_BLOCKED,
}
W15_SITE_COMPLETION_STATUS_ACTIVE = "active"
W15_SITE_COMPLETION_STATUS_COMPLETED = "completed"
W15_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W15_SITE_COMPLETION_STATUS_SET = {
    W15_SITE_COMPLETION_STATUS_ACTIVE,
    W15_SITE_COMPLETION_STATUS_COMPLETED,
    W15_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W15_EVIDENCE_REQUIRED_ITEM_TYPES = {"self_serve_guide", "troubleshooting_runbook"}
W15_EVIDENCE_MAX_BYTES = 5 * 1024 * 1024
W21_TRACKER_STATUS_PENDING = "pending"
W21_TRACKER_STATUS_IN_PROGRESS = "in_progress"
W21_TRACKER_STATUS_DONE = "done"
W21_TRACKER_STATUS_BLOCKED = "blocked"
W21_TRACKER_STATUS_SET = {
    W21_TRACKER_STATUS_PENDING,
    W21_TRACKER_STATUS_IN_PROGRESS,
    W21_TRACKER_STATUS_DONE,
    W21_TRACKER_STATUS_BLOCKED,
}
W21_COMPLETION_STATUS_ACTIVE = "active"
W21_COMPLETION_STATUS_COMPLETED = "completed"
W21_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS = "completed_with_exceptions"
W21_COMPLETION_STATUS_SET = {
    W21_COMPLETION_STATUS_ACTIVE,
    W21_COMPLETION_STATUS_COMPLETED,
    W21_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS,
}
W21_TRACKER_SCOPE_GLOBAL = "global"
W07_COMPLETION_PACKAGE_MAX_EVIDENCE_FILES = _env_int(
    "W07_COMPLETION_PACKAGE_MAX_EVIDENCE_FILES",
    200,
    min_value=1,
)
W07_COMPLETION_PACKAGE_MAX_EVIDENCE_BYTES = _env_int(
    "W07_COMPLETION_PACKAGE_MAX_EVIDENCE_BYTES",
    50 * 1024 * 1024,
    min_value=1024 * 1024,
)
W07_WEEKLY_JOB_NAME = "adoption_w07_sla_quality_weekly"
W07_DEGRADATION_ALERT_EVENT_TYPE = "adoption_w07_quality_degradation"
OPS_QUALITY_WEEKLY_JOB_NAME = "ops_quality_report_weekly"
OPS_QUALITY_MONTHLY_JOB_NAME = "ops_quality_report_monthly"
DR_REHEARSAL_JOB_NAME = "dr_rehearsal"
OPS_GOVERNANCE_GATE_JOB_NAME = "ops_governance_gate"
OPS_GOVERNANCE_REMEDIATION_DEFAULT_MAX_ITEMS = 30
OPS_GOVERNANCE_REMEDIATION_ESCALATION_JOB_NAME = "ops_governance_remediation_escalation"
OPS_GOVERNANCE_REMEDIATION_ESCALATION_EVENT_TYPE = "ops_governance_remediation_escalation"
GOVERNANCE_REMEDIATION_ESCALATION_ENABLED = _env_bool("GOVERNANCE_REMEDIATION_ESCALATION_ENABLED", True)
GOVERNANCE_REMEDIATION_ESCALATION_DUE_SOON_HOURS = _env_int(
    "GOVERNANCE_REMEDIATION_ESCALATION_DUE_SOON_HOURS",
    12,
    min_value=0,
)
GOVERNANCE_REMEDIATION_ESCALATION_NOTIFY_ENABLED = _env_bool(
    "GOVERNANCE_REMEDIATION_ESCALATION_NOTIFY_ENABLED",
    True,
)

ADOPTION_PLAN_START = date(2026, 3, 2)
ADOPTION_PLAN_END = date(2026, 6, 12)

ADOPTION_WEEKLY_EXECUTION: list[dict[str, Any]] = [
    {
        "week": 1,
        "start_date": "2026-03-02",
        "end_date": "2026-03-06",
        "phase": "Preparation",
        "focus": "Role workflow lock",
        "actions": [
            "Lock 5 core workflows per role (owner/manager/operator/auditor).",
            "Define first-7-day checklist and support channel.",
            "Identify pilot users and site champions.",
        ],
        "deliverables": ["Workflow map v1", "First-7-day checklist v1", "Pilot roster"],
        "owner": "PM + Ops Lead",
        "success_metric": "Workflow agreement 100%",
    },
    {
        "week": 2,
        "start_date": "2026-03-09",
        "end_date": "2026-03-13",
        "phase": "Preparation",
        "focus": "SOP and sandbox",
        "actions": [
            "Publish one-page SOP for each critical flow.",
            "Prepare sandbox scenario for inspection/work-order/report.",
            "Finalize FAQ top 20 from pilot dry-run.",
        ],
        "deliverables": ["SOP set v1", "Sandbox script", "FAQ v1"],
        "owner": "Ops PM + QA",
        "success_metric": "Pilot dry-run pass rate >= 90%",
    },
    {
        "week": 3,
        "start_date": "2026-03-16",
        "end_date": "2026-03-20",
        "phase": "Launch",
        "focus": "Go-live onboarding",
        "actions": [
            "Run kickoff session (60m) + role-based workshop (20m x 4).",
            "Enable in-app quick links to docs and handover brief.",
            "Start daily office hours (15m) for first week.",
        ],
        "deliverables": ["Kickoff recording", "Role workshop deck", "Daily office-hour notes"],
        "owner": "Product + Training Lead",
        "success_metric": "First-week login rate >= 90%",
    },
    {
        "week": 4,
        "start_date": "2026-03-23",
        "end_date": "2026-03-27",
        "phase": "Adaptation",
        "focus": "First success acceleration",
        "actions": [
            "Track first-success funnel and remove top 3 blockers.",
            "Coach site champions on escalations and alerts.",
            "Publish common mistakes and fast fixes.",
        ],
        "deliverables": ["TTV funnel report", "Champion coaching notes", "Mistake guide v1"],
        "owner": "CS + Ops Lead",
        "success_metric": "Median TTV <= 15 minutes",
    },
    {
        "week": 5,
        "start_date": "2026-03-30",
        "end_date": "2026-04-03",
        "phase": "Adaptation",
        "focus": "Usage consistency",
        "actions": [
            "Launch weekly mission for each role.",
            "Review overdue work-order behavior by site.",
            "Tune help docs using real questions.",
        ],
        "deliverables": ["Weekly mission board", "Site behavior report", "Help docs v2"],
        "owner": "Ops PM + Site Champions",
        "success_metric": "2-week retention >= 65%",
    },
    {
        "week": 6,
        "start_date": "2026-04-06",
        "end_date": "2026-04-10",
        "phase": "Habit",
        "focus": "Operational rhythm",
        "actions": [
            "Introduce Monday planning and Friday review cadence.",
            "Use handover brief in daily operation meeting.",
            "Audit token/role setup for each site.",
        ],
        "deliverables": ["Cadence template", "Handover routine checklist", "RBAC audit report"],
        "owner": "Ops Manager",
        "success_metric": "Weekly active rate >= 75%",
    },
    {
        "week": 7,
        "start_date": "2026-04-13",
        "end_date": "2026-04-17",
        "phase": "Habit",
        "focus": "SLA quality",
        "actions": [
            "Review SLA overdue and escalation trends by site.",
            "Run targeted coaching for low-performing teams.",
            "Enforce alert retry follow-up policy.",
        ],
        "deliverables": ["SLA trend report", "Coaching action list", "Alert follow-up SOP"],
        "owner": "Ops Lead + QA",
        "success_metric": "SLA response time improves >= 10%",
    },
    {
        "week": 8,
        "start_date": "2026-04-20",
        "end_date": "2026-04-24",
        "phase": "Habit",
        "focus": "Report discipline",
        "actions": [
            "Standardize monthly report generation and distribution.",
            "Review data quality (missing fields, inconsistent statuses).",
            "Close documentation gaps from previous weeks.",
        ],
        "deliverables": ["Reporting SOP v2", "Data quality dashboard", "Docs release note"],
        "owner": "Auditor + Ops PM",
        "success_metric": "Monthly report on-time rate >= 95%",
    },
    {
        "week": 9,
        "start_date": "2026-04-27",
        "end_date": "2026-05-01",
        "phase": "Autonomy",
        "focus": "Shift to KPI operation",
        "actions": [
            "Switch management rhythm from training to KPI review.",
            "Set red/yellow/green threshold per KPI.",
            "Assign KPI owners and escalation path.",
        ],
        "deliverables": ["KPI threshold matrix", "Owner assignment table", "Escalation map"],
        "owner": "Head of Ops",
        "success_metric": "KPI owner coverage 100%",
    },
    {
        "week": 10,
        "start_date": "2026-05-04",
        "end_date": "2026-05-08",
        "phase": "Autonomy",
        "focus": "Self-serve support",
        "actions": [
            "Convert repetitive support issues to self-serve guides.",
            "Publish role-based troubleshooting runbook.",
            "Reduce office-hour dependency.",
        ],
        "deliverables": ["Self-serve KB v1", "Troubleshooting runbook", "Support reduction report"],
        "owner": "CS Lead",
        "success_metric": "Support ticket repeat rate down >= 20%",
    },
    {
        "week": 11,
        "start_date": "2026-05-11",
        "end_date": "2026-05-15",
        "phase": "Autonomy",
        "focus": "Scale readiness",
        "actions": [
            "Review process with expansion sites.",
            "Validate onboarding package in a new-site simulation.",
            "Finalize risk register and fallback playbook.",
        ],
        "deliverables": ["Scale checklist", "New-site simulation report", "Fallback playbook"],
        "owner": "Program Manager",
        "success_metric": "New-site simulation success >= 90%",
    },
    {
        "week": 12,
        "start_date": "2026-05-18",
        "end_date": "2026-05-22",
        "phase": "Autonomy",
        "focus": "Closure and handoff",
        "actions": [
            "Run 8-week/12-week closure review.",
            "Confirm independent execution ratio per core workflow.",
            "Approve next-quarter operating plan.",
        ],
        "deliverables": ["Program closure report", "Independent execution scorecard", "Q3 roadmap draft"],
        "owner": "Executive Sponsor + Ops Director",
        "success_metric": "Independent execution >= 80%",
    },
    {
        "week": 13,
        "start_date": "2026-05-25",
        "end_date": "2026-05-29",
        "phase": "Sustain",
        "focus": "Continuous improvement",
        "actions": [
            "Run weekly improvement review with site champions.",
            "Convert closure findings into tracked optimization actions.",
            "Lock next-quarter governance cadence and owners.",
        ],
        "deliverables": ["Improvement backlog v1", "Owner action board", "Quarterly governance calendar"],
        "owner": "Ops Director + PMO",
        "success_metric": "Improvement action closure >= 85%",
    },
    {
        "week": 14,
        "start_date": "2026-06-01",
        "end_date": "2026-06-05",
        "phase": "Stabilize",
        "focus": "Stability sprint",
        "actions": [
            "Measure P95 latency for critical APIs and confirm alert threshold.",
            "Run post-deploy smoke and rollback checklist as standard operation.",
            "Validate evidence/audit archive integrity batch and close findings.",
        ],
        "deliverables": ["Latency baseline v1", "Smoke/rollback checklist v1", "Archive integrity report v1"],
        "owner": "SRE + Ops QA",
        "success_metric": "Stability readiness score >= 85%",
    },
    {
        "week": 15,
        "start_date": "2026-06-08",
        "end_date": "2026-06-12",
        "phase": "Optimize",
        "focus": "Operations efficiency",
        "actions": [
            "Unify execution-tracker UI blocks for W07~W14 with shared components.",
            "Standardize policy API response envelope for adoption policy endpoints.",
            "Automate weekly operations report publication with exception digest.",
        ],
        "deliverables": ["Tracker UI common component v1", "Policy response standard v1", "Weekly ops report auto-run v1"],
        "owner": "Ops PM + Platform Engineer",
        "success_metric": "Weekly ops report on-time >= 95%",
    },
]

ADOPTION_TRAINING_OUTLINE: list[dict[str, Any]] = [
    {
        "module": "M1. Platform Quickstart",
        "audience": "All roles",
        "duration_min": 60,
        "contents": ["Login and token basics", "Navigation and docs", "Daily routine overview"],
        "format": "Live demo + guided practice",
    },
    {
        "module": "M2. Inspection Execution",
        "audience": "Operator, Manager",
        "duration_min": 45,
        "contents": ["Inspection entry", "Risk flag rules", "Print/export inspection report"],
        "format": "Scenario lab",
    },
    {
        "module": "M3. Work-Order Lifecycle",
        "audience": "Operator, Manager",
        "duration_min": 60,
        "contents": ["Create/ack/complete/cancel/reopen", "Event timeline usage", "Comment standards"],
        "format": "Hands-on lab",
    },
    {
        "module": "M4. SLA and Escalation Ops",
        "audience": "Manager, Owner",
        "duration_min": 50,
        "contents": ["SLA policy reading", "Escalation batch run", "Alert retry procedure"],
        "format": "Live operation drill",
    },
    {
        "module": "M5. Handover Brief and Daily Meeting",
        "audience": "Manager, Owner",
        "duration_min": 40,
        "contents": ["Handover brief interpretation", "Top-work-order triage", "Action logging"],
        "format": "Workshop",
    },
    {
        "module": "M6. Monthly Audit Reporting",
        "audience": "Auditor, Manager",
        "duration_min": 45,
        "contents": ["Monthly JSON read", "CSV/PDF export", "Distribution checklist"],
        "format": "Report clinic",
    },
    {
        "module": "M7. RBAC and Token Governance",
        "audience": "Owner",
        "duration_min": 35,
        "contents": ["Role/site scope design", "Token issue/revoke policy", "Audit log review"],
        "format": "Control workshop",
    },
    {
        "module": "M8. Incident and Recovery Playbook",
        "audience": "Owner, Manager",
        "duration_min": 50,
        "contents": ["Failed alert response", "SLA rollback process", "Escalation command center protocol"],
        "format": "Table-top exercise",
    },
]

ADOPTION_KPI_DASHBOARD_ITEMS: list[dict[str, str]] = [
    {
        "id": "KPI-01",
        "name": "First-week login rate",
        "formula": "users logged in at least once in first 7 days / activated users",
        "target": ">= 90%",
        "data_source": "Auth logs",
        "frequency": "Daily",
    },
    {
        "id": "KPI-02",
        "name": "First success time (TTV)",
        "formula": "median minutes from first login to first completed core action",
        "target": "<= 15 min",
        "data_source": "Audit logs + API events",
        "frequency": "Daily",
    },
    {
        "id": "KPI-03",
        "name": "Weekly active rate",
        "formula": "users active at least 3 days in week / total active users",
        "target": ">= 75%",
        "data_source": "Activity aggregation",
        "frequency": "Weekly",
    },
    {
        "id": "KPI-04",
        "name": "Two-week retention",
        "formula": "users active in week N and N+1 / users active in week N",
        "target": ">= 65%",
        "data_source": "Activity aggregation",
        "frequency": "Weekly",
    },
    {
        "id": "KPI-05",
        "name": "SLA overdue response improvement",
        "formula": "baseline overdue response time - current overdue response time",
        "target": ">= 20% improvement",
        "data_source": "Work-order + job-runs",
        "frequency": "Weekly",
    },
    {
        "id": "KPI-06",
        "name": "Alert retry success rate",
        "formula": "alert retries resolved / total alert retries",
        "target": ">= 90%",
        "data_source": "Alert deliveries",
        "frequency": "Daily",
    },
    {
        "id": "KPI-07",
        "name": "Monthly report on-time rate",
        "formula": "reports exported by due date / scheduled reports",
        "target": ">= 95%",
        "data_source": "Audit logs",
        "frequency": "Monthly",
    },
    {
        "id": "KPI-08",
        "name": "Independent execution ratio",
        "formula": "users completing all 5 core tasks without support / active users",
        "target": ">= 80%",
        "data_source": "Checklist + support records",
        "frequency": "Bi-weekly",
    },
]

ADOPTION_PROMOTION_PACK: list[dict[str, Any]] = [
    {
        "campaign": "Launch Week Wallboard",
        "goal": "Create visibility and urgency for first-week adoption.",
        "channels": ["Lobby display", "Team chat", "Email digest"],
        "assets": [
            "1-page launch poster",
            "Daily KPI snapshot card",
            "Top adopter spotlight template",
        ],
        "cadence": "Daily (week 1-2)",
    },
    {
        "campaign": "Site Champion Story",
        "goal": "Spread practical success cases across teams.",
        "channels": ["Weekly townhall", "Internal newsletter"],
        "assets": [
            "Before/after process story template",
            "3-minute demo recording format",
            "Problem-solution-result summary card",
        ],
        "cadence": "Weekly",
    },
    {
        "campaign": "Referral Sprint",
        "goal": "Increase organic peer onboarding.",
        "channels": ["Team challenge board", "Ops standup"],
        "assets": [
            "Invite checklist",
            "Referral badge image set",
            "Simple recognition leaderboard",
        ],
        "cadence": "Bi-weekly",
    },
]

ADOPTION_EDUCATION_PACK: list[dict[str, Any]] = [
    {
        "track": "Starter Track",
        "target_roles": ["Operator", "Manager"],
        "components": ["Quickstart session", "Guided sandbox", "First-success checklist"],
        "completion_rule": "Complete M1-M3 and pass hands-on check",
        "duration_weeks": 2,
    },
    {
        "track": "Control Track",
        "target_roles": ["Owner", "Auditor"],
        "components": ["RBAC governance lab", "Audit/report workshop", "Incident drill"],
        "completion_rule": "Complete M6-M8 and submit governance quiz",
        "duration_weeks": 3,
    },
    {
        "track": "Champion Track",
        "target_roles": ["Site Champion"],
        "components": ["Coaching playbook", "Weekly blocker clinic", "KPI mentoring"],
        "completion_rule": "Lead 2 weekly clinics and close top blocker",
        "duration_weeks": 4,
    },
]

ADOPTION_FUN_PACK: list[dict[str, Any]] = [
    {
        "program": "Weekly Mission Bingo",
        "how_it_works": "Each role clears 5 mission tiles per week using real operations.",
        "rewards": ["Mission badge", "Team shout-out"],
        "anti_abuse_rule": "Only audited production actions count.",
    },
    {
        "program": "SLA Rescue Challenge",
        "how_it_works": "Teams compete to reduce overdue and failed-alert counts.",
        "rewards": ["Rescue cup", "Priority coaching slot"],
        "anti_abuse_rule": "Score uses net improvement and quality checks.",
    },
    {
        "program": "Report Relay",
        "how_it_works": "Cross-role relay to finish monthly report package on time.",
        "rewards": ["Relay champion badge", "Quarterly recognition"],
        "anti_abuse_rule": "Report must pass audit checklist for points.",
    },
]

ADOPTION_WORKFLOW_LOCK_MATRIX: dict[str, Any] = {
    "states": ["DRAFT", "REVIEW", "APPROVED", "LOCKED"],
    "rows": [
        {
            "role": " (Operator)",
            "permissions": {
                "DRAFT": "",
                "REVIEW": "",
                "APPROVED": "",
                "LOCKED": "",
            },
        },
        {
            "role": " (Manager)",
            "permissions": {
                "DRAFT": "",
                "REVIEW": "/",
                "APPROVED": "",
                "LOCKED": "",
            },
        },
        {
            "role": " (Owner)",
            "permissions": {
                "DRAFT": "",
                "REVIEW": "/",
                "APPROVED": "",
                "LOCKED": "",
            },
        },
        {
            "role": "(Admin)",
            "permissions": {
                "DRAFT": " ",
                "REVIEW": " ",
                "APPROVED": " ",
                "LOCKED": " (+ )",
            },
        },
    ],
}

ADOPTION_W02_SOP_RUNBOOKS: list[dict[str, Any]] = [
    {
        "id": "SOP-INS-01",
        "name": "Inspection one-page SOP",
        "target_roles": ["Operator", "Manager"],
        "owner": "Ops PM",
        "trigger": "Before daily inspection shift",
        "checkpoints": [
            "Create inspection with required fields",
            "Confirm risk flags and print view",
            "Validate audit trail and site scope",
        ],
        "definition_of_done": "3 consecutive dry-runs without validation errors",
    },
    {
        "id": "SOP-WO-01",
        "name": "Work-order lifecycle SOP",
        "target_roles": ["Operator", "Manager"],
        "owner": "Ops Lead",
        "trigger": "When work-order is created",
        "checkpoints": [
            "open -> acked -> completed transition",
            "cancel/reopen exception path verified",
            "event timeline includes actor/note",
        ],
        "definition_of_done": "All lifecycle paths verified in sandbox",
    },
    {
        "id": "SOP-SLA-01",
        "name": "SLA escalation and retry SOP",
        "target_roles": ["Manager", "Owner"],
        "owner": "QA Lead",
        "trigger": "15-minute escalation cadence",
        "checkpoints": [
            "Escalation batch run result reviewed",
            "Failed deliveries list triaged",
            "Retry batch executed with audit evidence",
        ],
        "definition_of_done": "No unresolved failed alert older than 24h",
    },
    {
        "id": "SOP-RPT-01",
        "name": "Monthly report export SOP",
        "target_roles": ["Auditor", "Owner"],
        "owner": "Audit Lead",
        "trigger": "Monthly close checklist",
        "checkpoints": [
            "Monthly summary reviewed",
            "CSV and PDF exports generated",
            "Export actions captured in audit logs",
        ],
        "definition_of_done": "Export package delivered within SLA",
    },
    {
        "id": "SOP-RBAC-01",
        "name": "RBAC token hygiene SOP",
        "target_roles": ["Owner", "Admin"],
        "owner": "Security Admin",
        "trigger": "Weekly governance review",
        "checkpoints": [
            "Role and site scope verification",
            "Unused token revoke check",
            "workflow_locks admin override review",
        ],
        "definition_of_done": "High-risk permission drift resolved <= 48h",
    },
]

ADOPTION_W02_SANDBOX_SCENARIOS: list[dict[str, Any]] = [
    {
        "id": "SX-INS-01",
        "module": "Inspection",
        "objective": "Create high-risk inspection and confirm risk detection path.",
        "api_flow": [
            "POST /api/inspections",
            "GET /api/inspections",
            "GET /inspections/{id}/print",
        ],
        "pass_criteria": [
            "risk_level is warning or danger",
            "risk_flags includes threshold breach",
            "print endpoint renders without error",
        ],
        "duration_min": 20,
    },
    {
        "id": "SX-WO-01",
        "module": "Work-order + SLA",
        "objective": "Validate work-order state transitions and SLA escalation.",
        "api_flow": [
            "POST /api/work-orders",
            "PATCH /api/work-orders/{id}/ack",
            "POST /api/work-orders/escalations/run",
            "GET /api/work-orders/{id}/events",
        ],
        "pass_criteria": [
            "acked transition succeeds",
            "escalation result includes target id",
            "timeline includes status_changed event",
        ],
        "duration_min": 30,
    },
    {
        "id": "SX-RPT-01",
        "module": "Reporting + Audit",
        "objective": "Generate monthly report package and verify audit evidence.",
        "api_flow": [
            "GET /api/reports/monthly",
            "GET /api/reports/monthly/csv",
            "GET /api/reports/monthly/pdf",
            "GET /api/admin/audit-logs",
        ],
        "pass_criteria": [
            "monthly summary returns expected totals",
            "csv/pdf downloads succeed",
            "audit logs contain export actions",
        ],
        "duration_min": 25,
    },
]

ADOPTION_W02_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W02-E01",
        "date": "2026-03-09",
        "start_time": "09:00",
        "end_time": "10:00",
        "title": "Kickoff - SOP owner assignment",
        "owner": "Ops PM + QA",
        "output": "SOP owner table v1",
    },
    {
        "id": "W02-E02",
        "date": "2026-03-10",
        "start_time": "14:00",
        "end_time": "15:00",
        "title": "Inspection sandbox drill",
        "owner": "Operator Champion",
        "output": "SX-INS-01 pass report",
    },
    {
        "id": "W02-E03",
        "date": "2026-03-11",
        "start_time": "14:00",
        "end_time": "15:30",
        "title": "Work-order/SLA sandbox drill",
        "owner": "Ops Lead",
        "output": "SX-WO-01 evidence pack",
    },
    {
        "id": "W02-E04",
        "date": "2026-03-12",
        "start_time": "16:00",
        "end_time": "17:00",
        "title": "Reporting and audit sandbox drill",
        "owner": "Audit Lead",
        "output": "SX-RPT-01 export proof",
    },
    {
        "id": "W02-E05",
        "date": "2026-03-13",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W02 sign-off review",
        "owner": "Owner + PM",
        "output": "W02 go/no-go decision",
    },
]

W02_SAMPLE_EVIDENCE_ARTIFACTS: list[dict[str, Any]] = [
    {
        "sample_id": "sx-ins-01",
        "title": "Inspection Sandbox Evidence",
        "description": "SX-INS-01     ",
        "file_name": "w02-sample-sx-ins-01-proof.txt",
        "content_type": "text/plain",
        "tracker_item_type": "sandbox_scenario",
        "tracker_item_key": "SX-INS-01",
        "content": (
            "W02 Sample Evidence\n"
            "Scenario: SX-INS-01\n"
            "Module: Inspection\n"
            "Result: PASS\n"
            "Checked Items:\n"
            "- risk_level warning/danger  \n"
            "- risk_flags   \n"
            "- print view  \n"
        ),
    },
    {
        "sample_id": "sx-wo-01",
        "title": "Work-Order/SLA Sandbox Evidence",
        "description": "SX-WO-01     ",
        "file_name": "w02-sample-sx-wo-01-proof.txt",
        "content_type": "text/plain",
        "tracker_item_type": "sandbox_scenario",
        "tracker_item_key": "SX-WO-01",
        "content": (
            "W02 Sample Evidence\n"
            "Scenario: SX-WO-01\n"
            "Module: Work-order + SLA\n"
            "Result: PASS\n"
            "Checked Items:\n"
            "- open->acked->completed   \n"
            "- escalation     \n"
            "- timeline status_changed  \n"
        ),
    },
    {
        "sample_id": "sx-rpt-01",
        "title": "Reporting/Audit Sandbox Evidence",
        "description": "SX-RPT-01     ",
        "file_name": "w02-sample-sx-rpt-01-proof.txt",
        "content_type": "text/plain",
        "tracker_item_type": "sandbox_scenario",
        "tracker_item_key": "SX-RPT-01",
        "content": (
            "W02 Sample Evidence\n"
            "Scenario: SX-RPT-01\n"
            "Module: Reporting + Audit\n"
            "Result: PASS\n"
            "Checked Items:\n"
            "- monthly summary  \n"
            "- csv/pdf  \n"
            "- export audit   \n"
        ),
    },
]

ADOPTION_W03_KICKOFF_AGENDA: list[dict[str, Any]] = [
    {
        "id": "KICKOFF-01",
        "topic": "Why now: launch goals and target KPI",
        "owner": "Product Lead",
        "duration_min": 10,
        "objective": "Align launch urgency and weekly target",
        "expected_output": "Shared KPI board confirmed",
    },
    {
        "id": "KICKOFF-02",
        "topic": "Role mission map and first action",
        "owner": "Ops PM",
        "duration_min": 10,
        "objective": "Clarify role-by-role first action",
        "expected_output": "Role mission one-pager distributed",
    },
    {
        "id": "KICKOFF-03",
        "topic": "Live demo: inspection -> work-order -> report",
        "owner": "Solution Engineer",
        "duration_min": 15,
        "objective": "Prove end-to-end happy path",
        "expected_output": "Demo recording and quick guide",
    },
    {
        "id": "KICKOFF-04",
        "topic": "Support path: docs, handover brief, office hour",
        "owner": "Training Lead",
        "duration_min": 10,
        "objective": "Reduce first-week blocker delay",
        "expected_output": "Support channel and SLA announced",
    },
    {
        "id": "KICKOFF-05",
        "topic": "Q&A and commitment check",
        "owner": "Owner + PM",
        "duration_min": 15,
        "objective": "Confirm go-live readiness by site",
        "expected_output": "Site commitment checklist signed",
    },
]

ADOPTION_W03_ROLE_WORKSHOPS: list[dict[str, Any]] = [
    {
        "id": "WS-OPR-01",
        "role": "Operator",
        "trainer": "Training Lead",
        "duration_min": 20,
        "objective": "     1 ",
        "checklist": [
            "Create inspection with required fields",
            "Review risk flags and print preview",
            "Submit first work-order escalation note",
        ],
        "success_criteria": "First inspection cycle completed under 20 minutes",
    },
    {
        "id": "WS-MGR-01",
        "role": "Manager",
        "trainer": "Ops Lead",
        "duration_min": 20,
        "objective": " ACK/ SLA   ",
        "checklist": [
            "Acknowledge one incoming work-order",
            "Complete work-order with resolution note",
            "Review overdue/escalated dashboard counts",
        ],
        "success_criteria": "Manager handles full lifecycle without support",
    },
    {
        "id": "WS-OWN-01",
        "role": "Owner",
        "trainer": "Product Manager",
        "duration_min": 20,
        "objective": "      ",
        "checklist": [
            "Open dashboard summary with site filter",
            "Review handover brief and top priority queue",
            "Confirm weekly KPI review cadence",
        ],
        "success_criteria": "Weekly review checklist approved",
    },
    {
        "id": "WS-AUD-01",
        "role": "Auditor",
        "trainer": "Audit Lead",
        "duration_min": 20,
        "objective": "      ",
        "checklist": [
            "Generate monthly summary report",
            "Download CSV and PDF package",
            "Verify export actions in audit log",
        ],
        "success_criteria": "Audit package reproducible within 15 minutes",
    },
]

ADOPTION_W03_OFFICE_HOURS: list[dict[str, Any]] = [
    {
        "id": "OH-2026-03-16",
        "date": "2026-03-16",
        "start_time": "17:00",
        "end_time": "17:15",
        "host": "Training Lead",
        "focus": "Launch day blocker triage",
        "channel": "#ka-facility-help",
    },
    {
        "id": "OH-2026-03-17",
        "date": "2026-03-17",
        "start_time": "17:00",
        "end_time": "17:15",
        "host": "Ops PM",
        "focus": "Role workshop Q&A follow-up",
        "channel": "#ka-facility-help",
    },
    {
        "id": "OH-2026-03-18",
        "date": "2026-03-18",
        "start_time": "17:00",
        "end_time": "17:15",
        "host": "Ops Lead",
        "focus": "Work-order/SLA issue triage",
        "channel": "#ka-facility-help",
    },
    {
        "id": "OH-2026-03-19",
        "date": "2026-03-19",
        "start_time": "17:00",
        "end_time": "17:15",
        "host": "Audit Lead",
        "focus": "Reporting and audit export questions",
        "channel": "#ka-facility-help",
    },
    {
        "id": "OH-2026-03-20",
        "date": "2026-03-20",
        "start_time": "17:00",
        "end_time": "17:15",
        "host": "Product + Training Lead",
        "focus": "Week-close retrospective and FAQ capture",
        "channel": "#ka-facility-help",
    },
]

ADOPTION_W03_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W03-E01",
        "date": "2026-03-16",
        "start_time": "09:00",
        "end_time": "10:00",
        "title": "Kickoff session (60m)",
        "owner": "Product + Training Lead",
        "output": "Kickoff recording + launch KPI board",
    },
    {
        "id": "W03-E02",
        "date": "2026-03-16",
        "start_time": "10:30",
        "end_time": "10:50",
        "title": "Role workshop - Operator",
        "owner": "Training Lead",
        "output": "WS-OPR-01 completion checklist",
    },
    {
        "id": "W03-E03",
        "date": "2026-03-16",
        "start_time": "11:00",
        "end_time": "11:20",
        "title": "Role workshop - Manager",
        "owner": "Ops Lead",
        "output": "WS-MGR-01 completion checklist",
    },
    {
        "id": "W03-E04",
        "date": "2026-03-16",
        "start_time": "11:30",
        "end_time": "11:50",
        "title": "Role workshop - Owner",
        "owner": "Product Manager",
        "output": "WS-OWN-01 completion checklist",
    },
    {
        "id": "W03-E05",
        "date": "2026-03-16",
        "start_time": "14:00",
        "end_time": "14:20",
        "title": "Role workshop - Auditor",
        "owner": "Audit Lead",
        "output": "WS-AUD-01 completion checklist",
    },
    {
        "id": "W03-E06",
        "date": "2026-03-16",
        "start_time": "17:00",
        "end_time": "17:15",
        "title": "Daily office hour #1",
        "owner": "Training Lead",
        "output": "Day-1 blocker resolution log",
    },
    {
        "id": "W03-E07",
        "date": "2026-03-17",
        "start_time": "17:00",
        "end_time": "17:15",
        "title": "Daily office hour #2",
        "owner": "Ops PM",
        "output": "Day-2 FAQ update",
    },
    {
        "id": "W03-E08",
        "date": "2026-03-18",
        "start_time": "17:00",
        "end_time": "17:15",
        "title": "Daily office hour #3",
        "owner": "Ops Lead",
        "output": "SLA issue follow-up list",
    },
    {
        "id": "W03-E09",
        "date": "2026-03-19",
        "start_time": "17:00",
        "end_time": "17:15",
        "title": "Daily office hour #4",
        "owner": "Audit Lead",
        "output": "Reporting Q&A digest",
    },
    {
        "id": "W03-E10",
        "date": "2026-03-20",
        "start_time": "17:00",
        "end_time": "17:15",
        "title": "Daily office hour #5",
        "owner": "Product + Training Lead",
        "output": "W03 week-close note",
    },
]

ADOPTION_W04_COACHING_ACTIONS: list[dict[str, Any]] = [
    {
        "id": "W04-CA-01",
        "champion_role": "Site Champion",
        "action": "Run first-success funnel review per site",
        "owner": "CS + Ops Lead",
        "due_hint": "Mon 10:00",
        "objective": "Identify drop-off between login, inspection, and WO completion",
        "evidence_required": True,
        "quick_fix": "Focus first on the largest drop-off stage",
    },
    {
        "id": "W04-CA-02",
        "champion_role": "Site Champion",
        "action": "Close top blocker #1 with owner and due date",
        "owner": "Ops Lead",
        "due_hint": "Tue 15:00",
        "objective": "Remove the most frequent execution blocker in one cycle",
        "evidence_required": True,
        "quick_fix": "Assign one accountable owner and verify within 24h",
    },
    {
        "id": "W04-CA-03",
        "champion_role": "Site Champion",
        "action": "Close top blocker #2 and publish fix note",
        "owner": "QA Lead",
        "due_hint": "Wed 16:00",
        "objective": "Reduce repeated failures by documenting the fix path",
        "evidence_required": True,
        "quick_fix": "Attach screenshot + API response snippet",
    },
    {
        "id": "W04-CA-04",
        "champion_role": "Site Champion",
        "action": "Close top blocker #3 and run 1 retest",
        "owner": "Ops PM",
        "due_hint": "Thu 14:00",
        "objective": "Confirm blocker removal with one real retest",
        "evidence_required": True,
        "quick_fix": "Retest with production-like data",
    },
    {
        "id": "W04-CA-05",
        "champion_role": "Manager",
        "action": "Coach low-performing users (1:1 x 3)",
        "owner": "Site Manager",
        "due_hint": "Thu 17:00",
        "objective": "Reduce median time-to-first-success to <= 15 minutes",
        "evidence_required": True,
        "quick_fix": "Use 15-minute script + checklist",
    },
    {
        "id": "W04-CA-06",
        "champion_role": "Owner",
        "action": "Approve W04 acceleration close report",
        "owner": "Owner + PM",
        "due_hint": "Fri 17:00",
        "objective": "Decide go/no-go for W05 consistency mission",
        "evidence_required": False,
        "quick_fix": "Require blocker trend and TTV delta in one page",
    },
]

ADOPTION_W04_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W04-E01",
        "date": "2026-03-23",
        "start_time": "10:00",
        "end_time": "10:30",
        "title": "W04 kickoff - first-success funnel review",
        "owner": "CS + Ops Lead",
        "output": "Site funnel baseline and top drop-off stage",
    },
    {
        "id": "W04-E02",
        "date": "2026-03-23",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Blocker triage #1",
        "owner": "Ops Lead",
        "output": "Top blocker owner assigned",
    },
    {
        "id": "W04-E03",
        "date": "2026-03-24",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Blocker triage #2",
        "owner": "QA Lead",
        "output": "Fix note published",
    },
    {
        "id": "W04-E04",
        "date": "2026-03-25",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Blocker triage #3 + retest",
        "owner": "Ops PM",
        "output": "Retest evidence attached",
    },
    {
        "id": "W04-E05",
        "date": "2026-03-26",
        "start_time": "15:00",
        "end_time": "15:45",
        "title": "Site champion coaching clinic",
        "owner": "Site Manager",
        "output": "Low performer coaching log",
    },
    {
        "id": "W04-E06",
        "date": "2026-03-27",
        "start_time": "16:30",
        "end_time": "17:00",
        "title": "W04 close review",
        "owner": "Owner + PM",
        "output": "W04 close report + W05 handoff",
    },
]

W04_COMMON_MISTAKE_FIX_CATALOG: list[dict[str, str]] = [
    {
        "mistake_key": "missing_assignee",
        "mistake": "   /",
        "symptom": "pending/in_progress    ",
        "quick_fix": "   assignee , 24   ",
        "where_to_check": "W04 Tracker Overview + assignee breakdown",
    },
    {
        "mistake_key": "missing_evidence",
        "mistake": "     ",
        "symptom": "  missing evidence blocker ",
        "quick_fix": "   txt/pdf/png  ",
        "where_to_check": "W04 Tracker item evidence list",
    },
    {
        "mistake_key": "slow_first_action",
        "mistake": "    TTV ",
        "symptom": "funnel auth->inspection  ",
        "quick_fix": "  15     ",
        "where_to_check": "W04 Funnel stage timings",
    },
    {
        "mistake_key": "wo_completion_delay",
        "mistake": "   ",
        "symptom": "inspection->work_order_complete  ",
        "quick_fix": "ACK    ",
        "where_to_check": "Work-order timeline + W04 Funnel",
    },
    {
        "mistake_key": "alert_delivery_failures",
        "mistake": "  ",
        "symptom": "failed alert delivery ,   ",
        "quick_fix": "     +   ",
        "where_to_check": "Alert deliveries / retries / guard",
    },
]

ADOPTION_W05_ROLE_MISSIONS: list[dict[str, Any]] = [
    {
        "id": "W05-M-01",
        "role": "Operator",
        "mission": "Daily first action within 15 minutes for assigned queue",
        "weekly_target": "5/5 weekdays",
        "owner": "Site Champion",
        "evidence_required": True,
        "evidence_hint": "Tracker screenshot + first action timestamp",
    },
    {
        "id": "W05-M-02",
        "role": "Manager",
        "mission": "Overdue backlog review and reassignment",
        "weekly_target": "2 review sessions",
        "owner": "Ops Manager",
        "evidence_required": True,
        "evidence_hint": "Before/after overdue list",
    },
    {
        "id": "W05-M-03",
        "role": "Auditor",
        "mission": "Data consistency spot-check (status and due_at)",
        "weekly_target": "10 sampled records",
        "owner": "Audit Lead",
        "evidence_required": True,
        "evidence_hint": "Spot-check sheet + issue notes",
    },
    {
        "id": "W05-M-04",
        "role": "Site Champion",
        "mission": "Weekly mission coaching and blocker follow-up",
        "weekly_target": "Top 3 blockers closed",
        "owner": "Ops PM",
        "evidence_required": True,
        "evidence_hint": "Coaching log + closure proof",
    },
    {
        "id": "W05-M-05",
        "role": "Owner",
        "mission": "Retention and overdue trend review sign-off",
        "weekly_target": "1 sign-off",
        "owner": "Owner + PM",
        "evidence_required": False,
        "evidence_hint": "Weekly decision memo",
    },
]

ADOPTION_W05_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W05-E01",
        "date": "2026-03-30",
        "start_time": "10:00",
        "end_time": "10:30",
        "title": "W05 kickoff - weekly mission board launch",
        "owner": "Ops PM + Site Champions",
        "output": "Mission board v1",
    },
    {
        "id": "W05-E02",
        "date": "2026-03-31",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Overdue behavior review by site",
        "owner": "Ops Manager",
        "output": "Site overdue action list",
    },
    {
        "id": "W05-E03",
        "date": "2026-04-01",
        "start_time": "15:30",
        "end_time": "16:00",
        "title": "Help docs tuning workshop",
        "owner": "QA + Training Lead",
        "output": "Help docs v2 draft",
    },
    {
        "id": "W05-E04",
        "date": "2026-04-02",
        "start_time": "16:30",
        "end_time": "17:00",
        "title": "Retention checkpoint",
        "owner": "CS + Ops Lead",
        "output": "2-week retention interim report",
    },
    {
        "id": "W05-E05",
        "date": "2026-04-03",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W05 close review",
        "owner": "Owner + PM",
        "output": "W05 consistency close memo",
    },
]

ADOPTION_W05_HELP_DOCS: list[dict[str, Any]] = [
    {
        "doc_id": "W05-HD-01",
        "title": " overdue   ",
        "audience": "Manager/Operator",
        "problem": "overdue    ",
        "quick_steps": [
            "overdue  priority + due_at  ",
            "    reassignment",
            "48      escalated ",
        ],
        "api_refs": ["/api/work-orders", "/api/work-orders/escalations/run"],
    },
    {
        "doc_id": "W05-HD-02",
        "title": "    ",
        "audience": "Operator/Site Champion",
        "problem": " /   TTV ",
        "quick_steps": [
            "  15    1 ",
            "ACK      ",
            "      ",
        ],
        "api_refs": ["/api/inspections", "/api/work-orders"],
    },
    {
        "doc_id": "W05-HD-03",
        "title": "   ",
        "audience": "Auditor/Manager",
        "problem": "status     ",
        "quick_steps": [
            "done   completion_checked ",
            "in_progress     ",
            "     ",
        ],
        "api_refs": [
            "/api/adoption/w04/tracker/items",
            "/api/adoption/w04/tracker/readiness",
        ],
    },
]

ADOPTION_W06_RHYTHM_CHECKLIST: list[dict[str, Any]] = [
    {
        "id": "W06-RC-01",
        "day": "Monday",
        "routine": "Weekly planning board setup (site priorities + owners)",
        "owner_role": "Manager",
        "definition_of_done": "   5   ",
        "evidence_hint": "Planning board snapshot + owner assignment",
    },
    {
        "id": "W06-RC-02",
        "day": "Daily",
        "routine": "Daily operation meeting with handover brief",
        "owner_role": "Manager/Operator",
        "definition_of_done": "handover  action item  3 ",
        "evidence_hint": "Handover brief export + action notes",
    },
    {
        "id": "W06-RC-03",
        "day": "Wednesday",
        "routine": "Mid-week cadence check and backlog rebalance",
        "owner_role": "Ops Lead",
        "definition_of_done": "overdue     ETA ",
        "evidence_hint": "Before/after overdue list",
    },
    {
        "id": "W06-RC-04",
        "day": "Friday",
        "routine": "Weekly review and next-week carry-over triage",
        "owner_role": "Owner/Manager",
        "definition_of_done": "  +   carry-over ",
        "evidence_hint": "Weekly review memo",
    },
]

ADOPTION_W06_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W06-E01",
        "date": "2026-04-06",
        "start_time": "09:30",
        "end_time": "10:00",
        "title": "W06 kickoff - operational rhythm launch",
        "owner": "Ops Manager",
        "output": "Cadence board v1",
    },
    {
        "id": "W06-E02",
        "date": "2026-04-07",
        "start_time": "10:00",
        "end_time": "10:20",
        "title": "Daily handover brief drill",
        "owner": "Shift Lead",
        "output": "Handover action list",
    },
    {
        "id": "W06-E03",
        "date": "2026-04-08",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Mid-week backlog rebalance",
        "owner": "Ops Lead + QA",
        "output": "Reassigned overdue items",
    },
    {
        "id": "W06-E04",
        "date": "2026-04-09",
        "start_time": "15:30",
        "end_time": "16:00",
        "title": "RBAC/token audit checkpoint",
        "owner": "Owner + Security",
        "output": "RBAC audit delta list",
    },
    {
        "id": "W06-E05",
        "date": "2026-04-10",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W06 close review",
        "owner": "Ops Manager + Owner",
        "output": "Operational rhythm close report",
    },
]

ADOPTION_W06_RBAC_AUDIT_CHECKLIST: list[dict[str, Any]] = [
    {
        "id": "W06-RBAC-01",
        "control": "Role coverage by site",
        "objective": "operator/manager  1   ",
        "api_ref": "/api/admin/users",
        "pass_criteria": "site    ",
    },
    {
        "id": "W06-RBAC-02",
        "control": "Token expiry hygiene",
        "objective": "     ",
        "api_ref": "/api/admin/tokens",
        "pass_criteria": "7      100%",
    },
    {
        "id": "W06-RBAC-03",
        "control": "Site scope correctness",
        "objective": "/ site_scope  ",
        "api_ref": "/api/auth/me",
        "pass_criteria": "scope mismatch 0",
    },
    {
        "id": "W06-RBAC-04",
        "control": "Audit traceability",
        "objective": "       ",
        "api_ref": "/api/admin/audit-logs",
        "pass_criteria": "  action   0",
    },
]

ADOPTION_W07_SLA_CHECKLIST: list[dict[str, Any]] = [
    {
        "id": "W07-SLA-01",
        "cadence": "Daily 09:00",
        "control": "Overdue/ack-delay triage by site",
        "owner_role": "Ops Lead",
        "target": " overdue open  100% owner ",
        "definition_of_done": " / ETA   ",
        "evidence_hint": "SLA triage board screenshot",
    },
    {
        "id": "W07-SLA-02",
        "cadence": "Daily 14:00",
        "control": "Escalation follow-up and unblock",
        "owner_role": "Manager/Operator",
        "target": " escalated  24  ack 100%",
        "definition_of_done": "escalated  assignee/ETA ",
        "evidence_hint": "Escalation follow-up memo",
    },
    {
        "id": "W07-SLA-03",
        "cadence": "Wednesday 16:00",
        "control": "Mid-week SLA quality review",
        "owner_role": "Ops PM + QA",
        "target": "ack median   ",
        "definition_of_done": "site   +   3 ",
        "evidence_hint": "SLA quality review note",
    },
    {
        "id": "W07-SLA-04",
        "cadence": "Friday 17:00",
        "control": "Weekly close and next-week hardening",
        "owner_role": "Owner/Manager",
        "target": "SLA response time 10% ",
        "definition_of_done": " KPI     ",
        "evidence_hint": "Weekly SLA close report",
    },
]

ADOPTION_W07_COACHING_PLAYS: list[dict[str, Any]] = [
    {
        "id": "W07-CP-01",
        "trigger": "ack median > 60 (site)",
        "play": " triage 20 +   + due_at ",
        "owner": "Site Champion",
        "expected_impact": "ack latency  ",
        "evidence_hint": "Before/after ack median snapshot",
        "api_ref": "/api/ops/adoption/w07/sla-quality",
    },
    {
        "id": "W07-CP-02",
        "trigger": "escalation rate >= 30%",
        "play": "    +  2 ",
        "owner": "Ops Lead",
        "expected_impact": "escalation rate ",
        "evidence_hint": "Escalation board export",
        "api_ref": "/api/work-orders/escalations/run",
    },
    {
        "id": "W07-CP-03",
        "trigger": "alert success rate < 95%",
        "play": "   +  URL/ ",
        "owner": "Ops Engineer",
        "expected_impact": "Alert delivery  ",
        "evidence_hint": "Retry run result + guard state",
        "api_ref": "/api/ops/alerts/retries/run",
    },
    {
        "id": "W07-CP-04",
        "trigger": "SLA run cadence <  1",
        "play": "Cron   +    ",
        "owner": "Owner/Admin",
        "expected_impact": "SLA   ",
        "evidence_hint": "Job run log export",
        "api_ref": "/api/ops/job-runs",
    },
]

ADOPTION_W07_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W07-E01",
        "date": "2026-04-13",
        "start_time": "09:00",
        "end_time": "09:30",
        "title": "W07 kickoff - SLA quality baseline",
        "owner": "Ops Lead + QA",
        "output": "Baseline snapshot and risk shortlist",
    },
    {
        "id": "W07-E02",
        "date": "2026-04-14",
        "start_time": "14:00",
        "end_time": "14:30",
        "title": "Escalation coaching clinic",
        "owner": "Site Champion",
        "output": "Coaching action checklist",
    },
    {
        "id": "W07-E03",
        "date": "2026-04-15",
        "start_time": "16:00",
        "end_time": "16:40",
        "title": "Mid-week SLA quality review",
        "owner": "Ops PM + QA",
        "output": "Top risk sites and mitigation owner",
    },
    {
        "id": "W07-E04",
        "date": "2026-04-16",
        "start_time": "15:30",
        "end_time": "16:00",
        "title": "Alert retry follow-up checkpoint",
        "owner": "Ops Engineer",
        "output": "Alert failure remediation log",
    },
    {
        "id": "W07-E05",
        "date": "2026-04-17",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W07 close review",
        "owner": "Owner + Ops Manager",
        "output": "SLA quality close report",
    },
]

ADOPTION_W08_REPORT_DISCIPLINE_CHECKLIST: list[dict[str, Any]] = [
    {
        "id": "W08-RD-01",
        "cadence": "Daily 09:30",
        "discipline": "Monthly export readiness check",
        "owner_role": "Auditor",
        "target": "  CSV/PDF    100%",
        "definition_of_done": "export  /  0",
        "evidence_hint": "Export smoke test ",
        "api_ref": "/api/reports/monthly",
    },
    {
        "id": "W08-RD-02",
        "cadence": "Daily 14:30",
        "discipline": "Work-order data quality triage",
        "owner_role": "Ops PM",
        "target": "due_at /   ",
        "definition_of_done": "  backlog  0",
        "evidence_hint": "Data quality triage ",
        "api_ref": "/api/ops/adoption/w08/report-discipline",
    },
    {
        "id": "W08-RD-03",
        "cadence": "Wednesday 16:00",
        "discipline": "Site benchmark review",
        "owner_role": "Owner",
        "target": " 3 site    100%",
        "definition_of_done": "site  owner/ETA ",
        "evidence_hint": "Benchmark  ",
        "api_ref": "/api/ops/adoption/w08/site-benchmark",
    },
    {
        "id": "W08-RD-04",
        "cadence": "Friday 17:00",
        "discipline": "Weekly reporting close",
        "owner_role": "Owner + Auditor",
        "target": "report discipline score >= 85",
        "definition_of_done": "  /  ",
        "evidence_hint": "Weekly close report",
        "api_ref": "/api/ops/adoption/w08/report-discipline",
    },
]

ADOPTION_W08_DATA_QUALITY_CONTROLS: list[dict[str, Any]] = [
    {
        "id": "W08-DQ-01",
        "control": "Missing due_at guard",
        "objective": "SLA    ",
        "api_ref": "/api/work-orders",
        "pass_criteria": "due_at missing rate <= 2%",
    },
    {
        "id": "W08-DQ-02",
        "control": "Invalid priority normalization",
        "objective": "  (low/medium/high/critical)",
        "api_ref": "/api/work-orders",
        "pass_criteria": "invalid priority 0",
    },
    {
        "id": "W08-DQ-03",
        "control": "Completion timestamp integrity",
        "objective": "completed  timestamp  ",
        "api_ref": "/api/work-orders/{id}/complete",
        "pass_criteria": "completed_without_completed_at 0",
    },
    {
        "id": "W08-DQ-04",
        "control": "Report export traceability",
        "objective": "CSV/PDF    ",
        "api_ref": "/api/admin/audit-logs",
        "pass_criteria": "report_monthly_export_*  0",
    },
]

ADOPTION_W08_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W08-E01",
        "date": "2026-04-20",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W08 kickoff - report discipline baseline",
        "owner": "Auditor + Ops PM",
        "output": "Baseline discipline snapshot",
    },
    {
        "id": "W08-E02",
        "date": "2026-04-21",
        "start_time": "14:00",
        "end_time": "14:30",
        "title": "Data quality triage clinic",
        "owner": "Ops Lead",
        "output": "Top data-quality issues and owners",
    },
    {
        "id": "W08-E03",
        "date": "2026-04-22",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Site benchmark coaching",
        "owner": "Owner",
        "output": "Bottom-site improvement actions",
    },
    {
        "id": "W08-E04",
        "date": "2026-04-23",
        "start_time": "15:30",
        "end_time": "16:00",
        "title": "Monthly export rehearsal",
        "owner": "Audit Lead",
        "output": "CSV/PDF export rehearsal evidence",
    },
    {
        "id": "W08-E05",
        "date": "2026-04-24",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W08 close review",
        "owner": "Owner + Auditor",
        "output": "W08 close and next-week hardening list",
    },
]

ADOPTION_W08_REPORTING_SOP: list[dict[str, Any]] = [
    {
        "step_id": "W08-SOP-01",
        "stage": "Prepare",
        "action": "  month/site    ",
        "output": "Export parameter sheet",
        "api_ref": "/api/reports/monthly",
    },
    {
        "step_id": "W08-SOP-02",
        "stage": "Export",
        "action": "CSV/PDF    / ",
        "output": "CSV/PDF artifact pair",
        "api_ref": "/api/reports/monthly/csv",
    },
    {
        "step_id": "W08-SOP-03",
        "stage": "Audit",
        "action": " export action    ",
        "output": "Audit trace log",
        "api_ref": "/api/admin/audit-logs",
    },
    {
        "step_id": "W08-SOP-04",
        "stage": "Close",
        "action": " discipline score    site   ",
        "output": "Discipline close report",
        "api_ref": "/api/ops/adoption/w08/report-discipline",
    },
]

ADOPTION_W09_KPI_THRESHOLD_MATRIX: list[dict[str, Any]] = [
    {
        "id": "W09-KPI-01",
        "kpi_key": "two_week_retention_percent",
        "kpi_name": "Two-week retention",
        "direction": "higher_better",
        "owner_role": "Ops Manager",
        "green_threshold": 65.0,
        "yellow_threshold": 55.0,
        "target": ">= 65%",
        "source_api": "/api/ops/adoption/w05/consistency",
    },
    {
        "id": "W09-KPI-02",
        "kpi_key": "weekly_active_rate_percent",
        "kpi_name": "Weekly active rate",
        "direction": "higher_better",
        "owner_role": "Ops Lead",
        "green_threshold": 75.0,
        "yellow_threshold": 65.0,
        "target": ">= 75%",
        "source_api": "/api/ops/adoption/w06/rhythm",
    },
    {
        "id": "W09-KPI-03",
        "kpi_key": "escalation_rate_percent",
        "kpi_name": "Escalation rate",
        "direction": "lower_better",
        "owner_role": "Site Champion",
        "green_threshold": 20.0,
        "yellow_threshold": 30.0,
        "target": "<= 20%",
        "source_api": "/api/ops/adoption/w07/sla-quality",
    },
    {
        "id": "W09-KPI-04",
        "kpi_key": "report_discipline_score",
        "kpi_name": "Report discipline score",
        "direction": "higher_better",
        "owner_role": "Audit Lead",
        "green_threshold": 85.0,
        "yellow_threshold": 75.0,
        "target": ">= 85",
        "source_api": "/api/ops/adoption/w08/report-discipline",
    },
    {
        "id": "W09-KPI-05",
        "kpi_key": "data_quality_issue_rate_percent",
        "kpi_name": "Data quality issue rate",
        "direction": "lower_better",
        "owner_role": "Ops PM",
        "green_threshold": 5.0,
        "yellow_threshold": 10.0,
        "target": "<= 5%",
        "source_api": "/api/ops/adoption/w08/report-discipline",
    },
]

ADOPTION_W09_ESCALATION_MAP: list[dict[str, Any]] = [
    {
        "id": "W09-ESC-01",
        "kpi_key": "two_week_retention_percent",
        "condition": "status == red for 1 week",
        "escalate_to": "Head of Ops",
        "sla_hours": 24,
        "action": "Run retention recovery clinic and role mission rebalance",
    },
    {
        "id": "W09-ESC-02",
        "kpi_key": "weekly_active_rate_percent",
        "condition": "status == red for 1 week",
        "escalate_to": "Owner",
        "sla_hours": 24,
        "action": "Assign daily cadence owner and close missing role coverage",
    },
    {
        "id": "W09-ESC-03",
        "kpi_key": "escalation_rate_percent",
        "condition": "status == red for 3 consecutive days",
        "escalate_to": "Ops Lead + QA",
        "sla_hours": 8,
        "action": "Force triage window and high-risk queue split",
    },
    {
        "id": "W09-ESC-04",
        "kpi_key": "report_discipline_score",
        "condition": "status == red on weekly close",
        "escalate_to": "Audit Lead",
        "sla_hours": 24,
        "action": "Issue export remediation order and verify audit traces",
    },
]

ADOPTION_W09_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W09-E01",
        "date": "2026-04-27",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W09 kickoff - KPI ownership lock",
        "owner": "Head of Ops",
        "output": "KPI owner assignment matrix",
    },
    {
        "id": "W09-E02",
        "date": "2026-04-28",
        "start_time": "14:00",
        "end_time": "14:30",
        "title": "Threshold tuning clinic",
        "owner": "Ops PM + QA",
        "output": "Green/yellow/red threshold baseline",
    },
    {
        "id": "W09-E03",
        "date": "2026-04-29",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Mid-week KPI red review",
        "owner": "Owner + Ops Lead",
        "output": "Top blockers and escalation owners",
    },
    {
        "id": "W09-E04",
        "date": "2026-04-30",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Escalation map dry-run",
        "owner": "Site Champion",
        "output": "Escalation response rehearsal note",
    },
    {
        "id": "W09-E05",
        "date": "2026-05-01",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W09 close review",
        "owner": "Head of Ops + Owner",
        "output": "KPI   ",
    },
]

ADOPTION_W10_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W10-SS-01",
        "title": "Repeated Ticket Triage Guide",
        "problem_cluster": "   ",
        "owner_role": "CS Lead",
        "target": "  20% ",
        "source_api": "/api/ops/adoption/w10/self-serve",
    },
    {
        "id": "W10-SS-02",
        "title": "First Response Self-Check",
        "problem_cluster": "  ",
        "owner_role": "Ops QA",
        "target": "  15 ",
        "source_api": "/api/work-orders",
    },
    {
        "id": "W10-SS-03",
        "title": "SLA Breach Quick Fix Card",
        "problem_cluster": "SLA  ",
        "owner_role": "Ops Lead",
        "target": "SLA  10%p ",
        "source_api": "/api/ops/adoption/w07/sla-quality",
    },
    {
        "id": "W10-SS-04",
        "title": "Data Quality Recovery Checklist",
        "problem_cluster": "/ ",
        "owner_role": "Audit Lead",
        "target": "DQ  <= 5%",
        "source_api": "/api/ops/adoption/w08/report-discipline",
    },
    {
        "id": "W10-SS-05",
        "title": "Role-based Escalation Decision Tree",
        "problem_cluster": "  ",
        "owner_role": "Site Champion",
        "target": "  0",
        "source_api": "/api/ops/adoption/w09/kpi-operation",
    },
]

ADOPTION_W10_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W10-RB-01",
        "module": "Inspection",
        "symptom": "  / ",
        "owner_role": "Operator Champion",
        "definition_of_done": ", , ,  ",
        "api_ref": "/api/inspections",
    },
    {
        "id": "W10-RB-02",
        "module": "Work-order",
        "symptom": "  / ",
        "owner_role": "Ops Lead",
        "definition_of_done": "     ",
        "api_ref": "/api/work-orders",
    },
    {
        "id": "W10-RB-03",
        "module": "Report",
        "symptom": "  /",
        "owner_role": "Auditor",
        "definition_of_done": "CSV/PDF    ",
        "api_ref": "/api/reports/monthly/csv",
    },
    {
        "id": "W10-RB-04",
        "module": "Alert",
        "symptom": " / ",
        "owner_role": "SRE",
        "definition_of_done": "    guard/recover ",
        "api_ref": "/api/ops/alerts/deliveries",
    },
]

ADOPTION_W10_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W10-E01",
        "date": "2026-05-04",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W10 kickoff - self-serve baseline",
        "owner": "CS Lead + Ops PM",
        "output": "  Top list +  ",
    },
    {
        "id": "W10-E02",
        "date": "2026-05-05",
        "start_time": "14:00",
        "end_time": "14:30",
        "title": "Guide publishing sprint",
        "owner": "Operator Champion",
        "output": "Self-serve guide 1 ",
    },
    {
        "id": "W10-E03",
        "date": "2026-05-06",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Runbook walkthrough drill",
        "owner": "Ops Lead",
        "output": "   ",
    },
    {
        "id": "W10-E04",
        "date": "2026-05-07",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Office-hour dependency review",
        "owner": "CS Lead",
        "output": "   ",
    },
    {
        "id": "W10-E05",
        "date": "2026-05-08",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W10 close review",
        "owner": "Head of Ops + CS Lead",
        "output": "Self-serve   ",
    },
]


ADOPTION_W11_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W11-SR-01",
        "title": "Scale Readiness Checklist",
        "problem_cluster": "   ",
        "owner_role": "Program Manager",
        "target": "  100%",
        "source_api": "/api/ops/adoption/w11/scale-readiness",
    },
    {
        "id": "W11-SR-02",
        "title": "New-site Token and RBAC Baseline",
        "problem_cluster": "/   ",
        "owner_role": "Security Admin",
        "target": "   0",
        "source_api": "/api/auth/me",
    },
    {
        "id": "W11-SR-03",
        "title": "Multi-site SOP Sync",
        "problem_cluster": " SOP ",
        "owner_role": "Ops Lead",
        "target": " SOP  >= 95%",
        "source_api": "/api/public/adoption-plan/w11",
    },
    {
        "id": "W11-SR-04",
        "title": "Fallback Playbook Coverage",
        "problem_cluster": "/  ",
        "owner_role": "SRE",
        "target": "fallback  >= 85%",
        "source_api": "/api/ops/security/posture",
    },
    {
        "id": "W11-SR-05",
        "title": "Expansion Go/No-go Gate",
        "problem_cluster": "   ",
        "owner_role": "Head of Ops",
        "target": "    >= 90%",
        "source_api": "/api/ops/adoption/w11/readiness-policy",
    },
]

ADOPTION_W11_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W11-RB-01",
        "module": "New-site Onboarding",
        "symptom": "     ",
        "owner_role": "Program Manager",
        "definition_of_done": "///  ",
        "api_ref": "/api/public/adoption-plan/w11",
    },
    {
        "id": "W11-RB-02",
        "module": "RBAC and Token",
        "symptom": " /  ",
        "owner_role": "Security Admin",
        "definition_of_done": " ,  ,  ",
        "api_ref": "/api/admin/users",
    },
    {
        "id": "W11-RB-03",
        "module": "Reporting and Audit",
        "symptom": "    ",
        "owner_role": "Audit Lead",
        "definition_of_done": "CSV/PDF  +   ",
        "api_ref": "/api/reports/monthly/csv",
    },
    {
        "id": "W11-RB-04",
        "module": "Alert and Escalation",
        "symptom": "    ",
        "owner_role": "Ops QA",
        "definition_of_done": " /MTTR  ",
        "api_ref": "/api/ops/alerts/kpi/channels",
    },
]

ADOPTION_W11_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W11-E01",
        "date": "2026-05-11",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W11 kickoff - scale readiness baseline",
        "owner": "Program Manager + Ops Lead",
        "output": "  / ",
    },
    {
        "id": "W11-E02",
        "date": "2026-05-12",
        "start_time": "14:00",
        "end_time": "14:40",
        "title": "New-site simulation drill",
        "owner": "Site Champion",
        "output": "   / ",
    },
    {
        "id": "W11-E03",
        "date": "2026-05-13",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Fallback playbook drill",
        "owner": "SRE",
        "output": "Fallback     ",
    },
    {
        "id": "W11-E04",
        "date": "2026-05-14",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Risk register triage",
        "owner": "PM + QA",
        "output": "  Top list   ",
    },
    {
        "id": "W11-E05",
        "date": "2026-05-15",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W11 close review",
        "owner": "Head of Ops + Program Manager",
        "output": "Scale readiness go/no-go decision",
    },
]

ADOPTION_W12_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W12-CH-01",
        "title": "Closure Review Checklist",
        "problem_cluster": "   ",
        "owner_role": "Executive Sponsor",
        "target": "   100%",
        "source_api": "/api/ops/adoption/w12/closure-handoff",
    },
    {
        "id": "W12-CH-02",
        "title": "Independent Execution Scorecard",
        "problem_cluster": "   ",
        "owner_role": "Head of Ops",
        "target": "  >= 80%",
        "source_api": "/api/ops/adoption/w12/handoff-policy",
    },
    {
        "id": "W12-CH-03",
        "title": "Quarterly Handoff Package",
        "problem_cluster": "   ",
        "owner_role": "Program Manager",
        "target": "   100% ",
        "source_api": "/api/public/adoption-plan/w12",
    },
    {
        "id": "W12-CH-04",
        "title": "Runbook Ownership Transfer",
        "problem_cluster": "  ",
        "owner_role": "Ops Lead",
        "target": "    100%",
        "source_api": "/api/ops/runbook/checks",
    },
    {
        "id": "W12-CH-05",
        "title": "Post-Program Risk Ledger",
        "problem_cluster": "   ",
        "owner_role": "Audit Lead",
        "target": "   0",
        "source_api": "/api/public/post-mvp/risks",
    },
]

ADOPTION_W12_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W12-RB-01",
        "module": "Inspection and Work-Order",
        "symptom": "    ",
        "owner_role": "Ops QA",
        "definition_of_done": "  //  ",
        "api_ref": "/api/work-orders",
    },
    {
        "id": "W12-RB-02",
        "module": "Reporting and Audit",
        "symptom": "     ",
        "owner_role": "Audit Lead",
        "definition_of_done": "CSV/PDF/   ",
        "api_ref": "/api/reports/monthly/csv",
    },
    {
        "id": "W12-RB-03",
        "module": "Security and Access",
        "symptom": "/    ",
        "owner_role": "Security Admin",
        "definition_of_done": "    ",
        "api_ref": "/api/admin/tokens",
    },
    {
        "id": "W12-RB-04",
        "module": "Alert and SLA Guard",
        "symptom": " /   ",
        "owner_role": "SRE",
        "definition_of_done": "Guard latest + recovery run  ",
        "api_ref": "/api/ops/alerts/channels/guard",
    },
]

ADOPTION_W12_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W12-E01",
        "date": "2026-05-18",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W12 kickoff - closure baseline",
        "owner": "Executive Sponsor + Ops Director",
        "output": " //  ",
    },
    {
        "id": "W12-E02",
        "date": "2026-05-19",
        "start_time": "14:00",
        "end_time": "14:40",
        "title": "Independent execution drill",
        "owner": "Site Champions",
        "output": "    ",
    },
    {
        "id": "W12-E03",
        "date": "2026-05-20",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Handoff package validation",
        "owner": "Program Manager + Audit Lead",
        "output": "//   ",
    },
    {
        "id": "W12-E04",
        "date": "2026-05-21",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Q3 operating plan review",
        "owner": "Ops Director",
        "output": "    ",
    },
    {
        "id": "W12-E05",
        "date": "2026-05-22",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W12 closure sign-off",
        "owner": "Executive Sponsor",
        "output": "   handoff ",
    },
]

ADOPTION_W13_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W13-CH-01",
        "title": "Continuous Improvement Checklist",
        "problem_cluster": "   ",
        "owner_role": "Executive Sponsor",
        "target": "   100%",
        "source_api": "/api/ops/adoption/w13/closure-handoff",
    },
    {
        "id": "W13-CH-02",
        "title": "Stability Optimization Scorecard",
        "problem_cluster": "   ",
        "owner_role": "Head of Ops",
        "target": "  >= 80%",
        "source_api": "/api/ops/adoption/w13/handoff-policy",
    },
    {
        "id": "W13-CH-03",
        "title": "Quarterly Optimization Package",
        "problem_cluster": "   ",
        "owner_role": "Program Manager",
        "target": "   100% ",
        "source_api": "/api/public/adoption-plan/w13",
    },
    {
        "id": "W13-CH-04",
        "title": "Runbook Ownership Transfer",
        "problem_cluster": "  ",
        "owner_role": "Ops Lead",
        "target": "    100%",
        "source_api": "/api/ops/runbook/checks",
    },
    {
        "id": "W13-CH-05",
        "title": "Post-Program Risk Ledger",
        "problem_cluster": "   ",
        "owner_role": "Audit Lead",
        "target": "   0",
        "source_api": "/api/public/post-mvp/risks",
    },
]

ADOPTION_W13_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W13-RB-01",
        "module": "Inspection and Work-Order",
        "symptom": "    ",
        "owner_role": "Ops QA",
        "definition_of_done": "  //  ",
        "api_ref": "/api/work-orders",
    },
    {
        "id": "W13-RB-02",
        "module": "Reporting and Audit",
        "symptom": "     ",
        "owner_role": "Audit Lead",
        "definition_of_done": "CSV/PDF/   ",
        "api_ref": "/api/reports/monthly/csv",
    },
    {
        "id": "W13-RB-03",
        "module": "Security and Access",
        "symptom": "/    ",
        "owner_role": "Security Admin",
        "definition_of_done": "    ",
        "api_ref": "/api/admin/tokens",
    },
    {
        "id": "W13-RB-04",
        "module": "Alert and SLA Guard",
        "symptom": " /   ",
        "owner_role": "SRE",
        "definition_of_done": "Guard latest + recovery run  ",
        "api_ref": "/api/ops/alerts/channels/guard",
    },
]

ADOPTION_W13_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W13-E01",
        "date": "2026-05-25",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W13 kickoff - improvement baseline",
        "owner": "Executive Sponsor + Ops Director",
        "output": " //  ",
    },
    {
        "id": "W13-E02",
        "date": "2026-05-26",
        "start_time": "14:00",
        "end_time": "14:40",
        "title": "Independent execution drill",
        "owner": "Site Champions",
        "output": "    ",
    },
    {
        "id": "W13-E03",
        "date": "2026-05-27",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Handoff package validation",
        "owner": "Program Manager + Audit Lead",
        "output": "//   ",
    },
    {
        "id": "W13-E04",
        "date": "2026-05-28",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Q3 operating plan review",
        "owner": "Ops Director",
        "output": "    ",
    },
    {
        "id": "W13-E05",
        "date": "2026-05-29",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W13 improvement sign-off",
        "owner": "Executive Sponsor",
        "output": "   ",
    },
]

ADOPTION_W14_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W14-ST-01",
        "title": "Critical API Latency Baseline",
        "problem_cluster": " API   ",
        "owner_role": "SRE",
        "target": "P95 latency threshold  100%",
        "source_api": "/api/ops/adoption/w14/stability-sprint",
    },
    {
        "id": "W14-ST-02",
        "title": "Post-deploy Smoke Standard",
        "problem_cluster": "   ",
        "owner_role": "Ops QA",
        "target": "  smoke  100%",
        "source_api": "/api/ops/adoption/w14/stability-policy",
    },
    {
        "id": "W14-ST-03",
        "title": "Rollback Decision Checklist",
        "problem_cluster": "  ",
        "owner_role": "Release Manager",
        "target": "  SLA <= 10",
        "source_api": "/api/public/adoption-plan/w14",
    },
    {
        "id": "W14-ST-04",
        "title": "Evidence and Audit Integrity Validation",
        "problem_cluster": "/   ",
        "owner_role": "Audit Lead",
        "target": "   >= 99%",
        "source_api": "/api/admin/audit-integrity",
    },
    {
        "id": "W14-ST-05",
        "title": "Weekly Stability Exception Triage",
        "problem_cluster": "  ",
        "owner_role": "Ops Director",
        "target": " backlog 7   >= 90%",
        "source_api": "/api/ops/handover/brief",
    },
]

ADOPTION_W14_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W14-RB-01",
        "module": "API Performance",
        "symptom": " API  ",
        "owner_role": "SRE",
        "definition_of_done": "  /// ",
        "api_ref": "/api/ops/dashboard/trends",
    },
    {
        "id": "W14-RB-02",
        "module": "Deployment Verification",
        "symptom": "    ",
        "owner_role": "Ops QA",
        "definition_of_done": " // ",
        "api_ref": "/api/ops/job-runs",
    },
    {
        "id": "W14-RB-03",
        "module": "Rollback Control",
        "symptom": "     ",
        "owner_role": "Release Manager",
        "definition_of_done": " , ,   ",
        "api_ref": "/api/work-orders/escalations/run",
    },
    {
        "id": "W14-RB-04",
        "module": "Archive Integrity",
        "symptom": "/   ",
        "owner_role": "Audit Lead",
        "definition_of_done": "  0 +  ",
        "api_ref": "/api/admin/audit-archive/monthly",
    },
]

ADOPTION_W14_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W14-E01",
        "date": "2026-06-01",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W14 kickoff - stability baseline",
        "owner": "SRE Lead + Ops Director",
        "output": "//   ",
    },
    {
        "id": "W14-E02",
        "date": "2026-06-02",
        "start_time": "14:00",
        "end_time": "14:40",
        "title": "Critical API latency drill",
        "owner": "SRE",
        "output": " API P95    ",
    },
    {
        "id": "W14-E03",
        "date": "2026-06-03",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Smoke and rollback simulation",
        "owner": "Release Manager + Ops QA",
        "output": " /   ",
    },
    {
        "id": "W14-E04",
        "date": "2026-06-04",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Archive integrity batch review",
        "owner": "Audit Lead",
        "output": "      ",
    },
    {
        "id": "W14-E05",
        "date": "2026-06-05",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W14 stability sign-off",
        "owner": "Ops Director + Security Admin",
        "output": "   ",
    },
]

ADOPTION_W15_SELF_SERVE_GUIDES: list[dict[str, Any]] = [
    {
        "id": "W15-OP-01",
        "title": "Execution Tracker UI Commonization Checklist",
        "problem_cluster": "W07~W14  UI  ",
        "owner_role": "Frontend Lead",
        "target": "   100%",
        "source_api": "/api/ops/adoption/w15/ops-efficiency",
    },
    {
        "id": "W15-OP-02",
        "title": "Policy API Response Standard Checklist",
        "problem_cluster": " API   ",
        "owner_role": "Platform Engineer",
        "target": "   100%",
        "source_api": "/api/ops/adoption/w15/efficiency-policy",
    },
    {
        "id": "W15-OP-03",
        "title": "Weekly Ops Report Auto-publish",
        "problem_cluster": "     ",
        "owner_role": "Ops PM",
        "target": "  on-time >= 95%",
        "source_api": "/api/public/adoption-plan/w15",
    },
    {
        "id": "W15-OP-04",
        "title": "Exception Digest and Owner Routing",
        "problem_cluster": "    ",
        "owner_role": "Audit Lead",
        "target": "   100%",
        "source_api": "/api/ops/handover/brief",
    },
    {
        "id": "W15-OP-05",
        "title": "Action Closure SLA Governance",
        "problem_cluster": "   ",
        "owner_role": "Ops Director",
        "target": "7   0",
        "source_api": "/api/ops/adoption/w15/ops-efficiency",
    },
]

ADOPTION_W15_TROUBLESHOOTING_RUNBOOK: list[dict[str, Any]] = [
    {
        "id": "W15-RB-01",
        "module": "Tracker UI",
        "symptom": "  UI  ",
        "owner_role": "Frontend Lead",
        "definition_of_done": " UI /   ",
        "api_ref": "/api/public/adoption-plan/w15",
    },
    {
        "id": "W15-RB-02",
        "module": "Policy API Standard",
        "symptom": " API    ",
        "owner_role": "Platform Engineer",
        "definition_of_done": " schema  +  ",
        "api_ref": "/api/ops/adoption/w15/efficiency-policy",
    },
    {
        "id": "W15-RB-03",
        "module": "Weekly Ops Report",
        "symptom": "  / ",
        "owner_role": "Ops PM",
        "definition_of_done": "  +   ",
        "api_ref": "/api/ops/adoption/w15/ops-efficiency",
    },
    {
        "id": "W15-RB-04",
        "module": "Exception Governance",
        "symptom": "     ",
        "owner_role": "Audit Lead",
        "definition_of_done": "  // ",
        "api_ref": "/api/admin/audit-logs",
    },
]

ADOPTION_W15_SCHEDULED_EVENTS: list[dict[str, Any]] = [
    {
        "id": "W15-E01",
        "date": "2026-06-08",
        "start_time": "09:00",
        "end_time": "09:40",
        "title": "W15 kickoff - efficiency baseline",
        "owner": "Ops PM + Platform Engineer",
        "output": "  / ",
    },
    {
        "id": "W15-E02",
        "date": "2026-06-09",
        "start_time": "14:00",
        "end_time": "14:40",
        "title": "Tracker UI common component drill",
        "owner": "Frontend Lead",
        "output": "   / ",
    },
    {
        "id": "W15-E03",
        "date": "2026-06-10",
        "start_time": "16:00",
        "end_time": "16:30",
        "title": "Policy response standardization review",
        "owner": "Platform Engineer",
        "output": " API    ",
    },
    {
        "id": "W15-E04",
        "date": "2026-06-11",
        "start_time": "15:00",
        "end_time": "15:30",
        "title": "Weekly report automation dry-run",
        "owner": "Ops PM + Audit Lead",
        "output": "     dry-run",
    },
    {
        "id": "W15-E05",
        "date": "2026-06-12",
        "start_time": "17:00",
        "end_time": "17:30",
        "title": "W15 efficiency sign-off",
        "owner": "Ops Director",
        "output": "    ",
    },
]


FACILITY_WEB_MODULES: list[dict[str, Any]] = [
    {
        "id": "inspection-ops",
        "name": "Inspection Operations",
        "name_ko": " ",
        "description": "  , ,     .",
        "kpi_hint": "High risk detection lead time",
        "links": [
            {"label": "Create Inspection", "href": "/api/inspections"},
            {"label": "List Inspections", "href": "/api/inspections"},
            {"label": "Print Inspection", "href": "/inspections/{id}/print"},
        ],
    },
    {
        "id": "work-order-ops",
        "name": "Work-Order Operations",
        "name_ko": " ",
        "description": "  ACK///  .",
        "kpi_hint": "Time-To-First-Action",
        "links": [
            {"label": "Create Work-Order", "href": "/api/work-orders"},
            {"label": "Work-Order Timeline", "href": "/api/work-orders/{id}/events"},
            {"label": "Escalation Batch Run", "href": "/api/work-orders/escalations/run"},
        ],
    },
    {
        "id": "sla-alerts",
        "name": "SLA and Alerts",
        "name_ko": "SLA/ ",
        "description": "SLA , , ,   .",
        "kpi_hint": "SLA on-time rate and alert success",
        "links": [
            {"label": "SLA Simulator", "href": "/api/ops/sla/simulate"},
            {"label": "Failed Deliveries", "href": "/api/ops/alerts/deliveries"},
            {"label": "Retry Batch Run", "href": "/api/ops/alerts/retries/run"},
        ],
    },
    {
        "id": "reporting-audit",
        "name": "Reporting and Audit",
        "name_ko": "/",
        "description": "   CSV/PDF ,    .",
        "kpi_hint": "Monthly report on-time rate",
        "links": [
            {"label": "Monthly Report", "href": "/api/reports/monthly"},
            {"label": "Monthly CSV", "href": "/api/reports/monthly/csv"},
            {"label": "Monthly PDF", "href": "/api/reports/monthly/pdf"},
        ],
    },
    {
        "id": "ops-command",
        "name": "Ops Command Center",
        "name_ko": " ",
        "description": " /      .",
        "kpi_hint": "Open risk backlog burn-down",
        "links": [
            {"label": "Dashboard Summary", "href": "/api/ops/dashboard/summary"},
            {"label": "Dashboard Trends", "href": "/api/ops/dashboard/trends"},
            {"label": "Handover Brief", "href": "/api/ops/handover/brief"},
        ],
    },
    {
        "id": "rbac-governance",
        "name": "RBAC and Governance",
        "name_ko": "/",
        "description": "//RBAC/SLA     .",
        "kpi_hint": "Policy drift unresolved > 7d",
        "links": [
            {"label": "Auth Me", "href": "/api/auth/me"},
            {"label": "Admin Users", "href": "/api/admin/users"},
            {"label": "Admin Audit Logs", "href": "/api/admin/audit-logs"},
            {"label": "Workflow Locks", "href": "/api/workflow-locks"},
        ],
    },
    {
        "id": "report-discipline",
        "name": "Report Discipline",
        "name_ko": " ",
        "description": "W08    ,  ,   .",
        "kpi_hint": "Report discipline score >= 85",
        "links": [
            {"label": "W08 Pack", "href": "/api/public/adoption-plan/w08"},
            {"label": "W08 Discipline", "href": "/api/ops/adoption/w08/report-discipline"},
            {"label": "W08 Benchmark", "href": "/api/ops/adoption/w08/site-benchmark"},
        ],
    },
    {
        "id": "kpi-operations",
        "name": "KPI Operations",
        "name_ko": "KPI ",
        "description": "W09  KPI //    .",
        "kpi_hint": "KPI owner coverage 100%",
        "links": [
            {"label": "W09 Pack", "href": "/api/public/adoption-plan/w09"},
            {"label": "W09 KPI Ops", "href": "/api/ops/adoption/w09/kpi-operation"},
            {"label": "W09 KPI Policy", "href": "/api/ops/adoption/w09/kpi-policy"},
            {"label": "W09 Tracker", "href": "/api/adoption/w09/tracker/items"},
        ],
    },
    {
        "id": "self-serve-support",
        "name": "Self-serve Support",
        "name_ko": " ",
        "description": "W10    /   .",
        "kpi_hint": "Support repeat rate down >= 20%",
        "links": [
            {"label": "W10 Pack", "href": "/api/public/adoption-plan/w10"},
            {"label": "W10 Self-serve", "href": "/api/ops/adoption/w10/self-serve"},
            {"label": "W10 Support Policy", "href": "/api/ops/adoption/w10/support-policy"},
            {"label": "W10 Tracker", "href": "/api/adoption/w10/tracker/items"},
        ],
    },
    {
        "id": "scale-readiness",
        "name": "Scale Readiness",
        "name_ko": " ",
        "description": "W11     , , fallback playbook .",
        "kpi_hint": "New-site simulation success >= 90%",
        "links": [
            {"label": "W11 Pack", "href": "/api/public/adoption-plan/w11"},
            {"label": "W11 Scale Readiness", "href": "/api/ops/adoption/w11/scale-readiness"},
            {"label": "W11 Readiness Policy", "href": "/api/ops/adoption/w11/readiness-policy"},
            {"label": "W11 Tracker", "href": "/api/adoption/w11/tracker/items"},
        ],
    },
    {
        "id": "closure-handoff",
        "name": "Closure and Handoff",
        "name_ko": "  ",
        "description": "W12   ,  ,     .",
        "kpi_hint": "Independent execution >= 80%",
        "links": [
            {"label": "W12 Pack", "href": "/api/public/adoption-plan/w12"},
            {"label": "W12 Closure Handoff", "href": "/api/ops/adoption/w12/closure-handoff"},
            {"label": "W12 Handoff Policy", "href": "/api/ops/adoption/w12/handoff-policy"},
            {"label": "W12 Tracker", "href": "/api/adoption/w12/tracker/items"},
        ],
    },
    {
        "id": "continuous-improvement",
        "name": "Continuous Improvement",
        "name_ko": " ",
        "description": "W13    ,   ,   .",
        "kpi_hint": "Improvement action closure >= 85%",
        "links": [
            {"label": "W13 Pack", "href": "/api/public/adoption-plan/w13"},
            {"label": "W13 Closure Handoff", "href": "/api/ops/adoption/w13/closure-handoff"},
            {"label": "W13 Handoff Policy", "href": "/api/ops/adoption/w13/handoff-policy"},
            {"label": "W13 Tracker", "href": "/api/adoption/w13/tracker/items"},
        ],
    },
    {
        "id": "stability-sprint",
        "name": "Stability Sprint",
        "name_ko": " ",
        "description": "W14  //     .",
        "kpi_hint": "Stability readiness score >= 85%",
        "links": [
            {"label": "W14 Pack", "href": "/api/public/adoption-plan/w14"},
            {"label": "W14 Stability Sprint", "href": "/api/ops/adoption/w14/stability-sprint"},
            {"label": "W14 Stability Policy", "href": "/api/ops/adoption/w14/stability-policy"},
            {"label": "W14 Tracker", "href": "/api/adoption/w14/tracker/items"},
        ],
    },
    {
        "id": "operations-efficiency",
        "name": "Operations Efficiency",
        "name_ko": " ",
        "description": "W15   UI ,  API ,     .",
        "kpi_hint": "Weekly ops report on-time >= 95%",
        "links": [
            {"label": "W15 Pack", "href": "/api/public/adoption-plan/w15"},
            {"label": "W15 Ops Efficiency", "href": "/api/ops/adoption/w15/ops-efficiency"},
            {"label": "W15 Efficiency Policy", "href": "/api/ops/adoption/w15/efficiency-policy"},
            {"label": "W15 Tracker", "href": "/api/adoption/w15/tracker/items"},
        ],
    },
    {
        "id": "growth-roadmap",
        "name": "Growth and Post-MVP",
        "name_ko": " ",
        "description": "Post-MVP , ,  ,   .",
        "kpi_hint": "Release gate pass ratio",
        "links": [
            {"label": "Post-MVP Plan", "href": "/api/public/post-mvp"},
            {"label": "Backlog CSV", "href": "/api/public/post-mvp/backlog.csv"},
            {"label": "Release ICS", "href": "/api/public/post-mvp/releases.ics"},
        ],
    },
]

POST_MVP_PLAN_START = date(2026, 6, 1)
POST_MVP_PLAN_END = date(2026, 11, 27)

POST_MVP_ROADMAP_PHASES: list[dict[str, Any]] = [
    {
        "phase": "Phase 1 - Stabilize",
        "start_date": "2026-05-25",
        "end_date": "2026-06-19",
        "duration_weeks": 4,
        "objective": "Production hardening and operational baseline.",
        "outcomes": [
            "P95 API latency baseline and alert thresholds configured.",
            "Failure drill playbook validated with on-call rotation.",
            "Top 20 operational support issues converted to runbooks.",
        ],
        "release_gate": "R1 Operations Stability",
    },
    {
        "phase": "Phase 2 - Automate",
        "start_date": "2026-06-22",
        "end_date": "2026-08-07",
        "duration_weeks": 7,
        "objective": "Automation depth for SLA, reporting, and alert handling.",
        "outcomes": [
            "SLA assistant suggestions shipped for priority and due time.",
            "Monthly report automation with approval checklist in one flow.",
            "Retry and escalation jobs running with incident-safe guardrails.",
        ],
        "release_gate": "R2 Automation Pack",
    },
    {
        "phase": "Phase 3 - Scale",
        "start_date": "2026-08-10",
        "end_date": "2026-10-02",
        "duration_weeks": 8,
        "objective": "Multi-site scale, integrations, and governance.",
        "outcomes": [
            "Site template onboarding flow reduced to under 30 minutes.",
            "External integrations for ERP/BI delivered with audit trail.",
            "RBAC policy governance dashboard adopted by site owners.",
        ],
        "release_gate": "R3 Scale and Integration",
    },
    {
        "phase": "Phase 4 - Optimize",
        "start_date": "2026-10-05",
        "end_date": "2026-11-27",
        "duration_weeks": 8,
        "objective": "Business optimization and expansion readiness.",
        "outcomes": [
            "Cross-site benchmarking with KPI league table.",
            "Operational cost-to-close metric tracked and improved.",
            "Next-year expansion plan and staffing model finalized.",
        ],
        "release_gate": "R4 Optimization and FY Plan",
    },
]

POST_MVP_EXECUTION_BACKLOG: list[dict[str, Any]] = [
    {
        "id": "PMVP-01",
        "epic": "Reliability",
        "item": "Implement API latency/error budget dashboard",
        "priority": "P0",
        "owner": "Backend Lead",
        "estimate_points": 8,
        "target_release": "R1",
        "status": "ready",
        "success_kpi": "P95 API latency <= 450ms",
    },
    {
        "id": "PMVP-02",
        "epic": "Reliability",
        "item": "Add incident drill scenario runner and scorecard",
        "priority": "P0",
        "owner": "SRE",
        "estimate_points": 5,
        "target_release": "R1",
        "status": "ready",
        "success_kpi": "Monthly drill pass rate >= 90%",
    },
    {
        "id": "PMVP-03",
        "epic": "Automation",
        "item": "SLA due-time recommendation API and explainability log",
        "priority": "P1",
        "owner": "Backend Lead",
        "estimate_points": 8,
        "target_release": "R2",
        "status": "planned",
        "success_kpi": "Manual due-time overrides down >= 25%",
    },
    {
        "id": "PMVP-04",
        "epic": "Automation",
        "item": "One-click monthly package (JSON+CSV+PDF+approval note)",
        "priority": "P1",
        "owner": "Ops PM",
        "estimate_points": 5,
        "target_release": "R2",
        "status": "planned",
        "success_kpi": "Report preparation time down >= 40%",
    },
    {
        "id": "PMVP-05",
        "epic": "Automation",
        "item": "Escalation job anomaly detector with safe-stop switch",
        "priority": "P1",
        "owner": "SRE",
        "estimate_points": 5,
        "target_release": "R2",
        "status": "planned",
        "success_kpi": "False escalation rate <= 1%",
    },
    {
        "id": "PMVP-06",
        "epic": "Scale",
        "item": "Site onboarding template wizard",
        "priority": "P1",
        "owner": "Product",
        "estimate_points": 8,
        "target_release": "R3",
        "status": "planned",
        "success_kpi": "New site setup <= 30 minutes",
    },
    {
        "id": "PMVP-07",
        "epic": "Scale",
        "item": "ERP/BI outbound webhook connector",
        "priority": "P2",
        "owner": "Integrations",
        "estimate_points": 8,
        "target_release": "R3",
        "status": "planned",
        "success_kpi": "Data sync success rate >= 99%",
    },
    {
        "id": "PMVP-08",
        "epic": "Scale",
        "item": "Policy governance board (site-by-site RBAC drift)",
        "priority": "P1",
        "owner": "Security",
        "estimate_points": 5,
        "target_release": "R3",
        "status": "planned",
        "success_kpi": "Policy drift unresolved >7d count = 0",
    },
    {
        "id": "PMVP-09",
        "epic": "Optimization",
        "item": "Cross-site benchmark dashboard",
        "priority": "P2",
        "owner": "Data Analyst",
        "estimate_points": 5,
        "target_release": "R4",
        "status": "planned",
        "success_kpi": "Monthly benchmark review held 100%",
    },
    {
        "id": "PMVP-10",
        "epic": "Optimization",
        "item": "Cost-to-close per work-order analytics",
        "priority": "P2",
        "owner": "Finance Ops",
        "estimate_points": 5,
        "target_release": "R4",
        "status": "planned",
        "success_kpi": "Cost-to-close reduced >= 10%",
    },
    {
        "id": "PMVP-11",
        "epic": "Optimization",
        "item": "Executive expansion readiness pack automation",
        "priority": "P2",
        "owner": "Program Manager",
        "estimate_points": 3,
        "target_release": "R4",
        "status": "planned",
        "success_kpi": "Quarter planning prep time <= 2 days",
    },
    {
        "id": "PMVP-12",
        "epic": "Platform",
        "item": "Public changelog and release-note API",
        "priority": "P3",
        "owner": "Developer Experience",
        "estimate_points": 3,
        "target_release": "R4",
        "status": "backlog",
        "success_kpi": "Release notes published within 24h",
    },
]

POST_MVP_RELEASE_MILESTONES: list[dict[str, str]] = [
    {
        "release": "R1",
        "name": "Operations Stability",
        "date": "2026-06-19",
        "owner": "Backend Lead + SRE",
        "goal": "Reliability baseline and incident drill readiness",
    },
    {
        "release": "R1.5",
        "name": "Stability Retrospective",
        "date": "2026-07-03",
        "owner": "Ops PM",
        "goal": "Assess error budget and support load delta",
    },
    {
        "release": "R2",
        "name": "Automation Pack",
        "date": "2026-08-07",
        "owner": "Ops PM + Backend Lead",
        "goal": "Automated reporting and escalation quality controls",
    },
    {
        "release": "R2.5",
        "name": "Automation Adoption Check",
        "date": "2026-08-28",
        "owner": "Training Lead",
        "goal": "Verify workflow adoption and issue burn-down",
    },
    {
        "release": "R3",
        "name": "Scale and Integration",
        "date": "2026-10-02",
        "owner": "Product + Integrations",
        "goal": "Multi-site onboarding and integration reliability",
    },
    {
        "release": "R3.5",
        "name": "Scale Risk Review",
        "date": "2026-10-23",
        "owner": "Program Manager",
        "goal": "Close top scaling risks before optimization phase",
    },
    {
        "release": "R4",
        "name": "Optimization and FY Plan",
        "date": "2026-11-27",
        "owner": "Executive Sponsor",
        "goal": "KPI optimization and next-year expansion readiness",
    },
]

POST_MVP_KPI_DASHBOARD_SPEC: list[dict[str, str]] = [
    {
        "id": "OPS-01",
        "name": "SLA On-Time Completion",
        "formula": "completed_within_due / total_completed",
        "target": ">= 95%",
        "data_source": "work_orders",
        "cadence": "weekly",
        "owner": "Ops Lead",
        "alert_rule": "< 92% for 2 consecutive weeks",
    },
    {
        "id": "OPS-02",
        "name": "Median Time-To-First-Action",
        "formula": "median(first_ack_at - created_at)",
        "target": "<= 20 min",
        "data_source": "work_orders + work_order_events",
        "cadence": "weekly",
        "owner": "Site Managers",
        "alert_rule": "> 30 min in any week",
    },
    {
        "id": "OPS-03",
        "name": "Escalation Accuracy",
        "formula": "valid_escalations / total_escalations",
        "target": ">= 99%",
        "data_source": "job_runs + work_order_events",
        "cadence": "weekly",
        "owner": "SRE",
        "alert_rule": "< 98% in a week",
    },
    {
        "id": "OPS-04",
        "name": "Alert Delivery Success",
        "formula": "delivered / attempted",
        "target": ">= 99.5%",
        "data_source": "alert_deliveries",
        "cadence": "daily",
        "owner": "SRE",
        "alert_rule": "< 99.0% in 24h",
    },
    {
        "id": "OPS-05",
        "name": "Report On-Time Rate",
        "formula": "reports_submitted_on_time / reports_expected",
        "target": ">= 98%",
        "data_source": "monthly_reports",
        "cadence": "monthly",
        "owner": "Auditor",
        "alert_rule": "< 95% in month close",
    },
    {
        "id": "OPS-06",
        "name": "New Site Setup Time",
        "formula": "median(site_ready_at - site_request_at)",
        "target": "<= 30 min",
        "data_source": "admin_audit_logs",
        "cadence": "monthly",
        "owner": "Product Ops",
        "alert_rule": "> 45 min median",
    },
    {
        "id": "OPS-07",
        "name": "Policy Drift Aging",
        "formula": "count(drift_items_age_days > 7)",
        "target": "= 0",
        "data_source": "sla_policies + admin_audit_logs",
        "cadence": "weekly",
        "owner": "Security",
        "alert_rule": "> 0 for 2 weeks",
    },
    {
        "id": "OPS-08",
        "name": "Cost-To-Close",
        "formula": "sum(work_order_cost) / closed_work_orders",
        "target": "-10% QoQ",
        "data_source": "work_orders + finance export",
        "cadence": "monthly",
        "owner": "Finance Ops",
        "alert_rule": "No improvement for 2 months",
    },
]

POST_MVP_RISK_REGISTER: list[dict[str, str]] = [
    {
        "id": "RISK-01",
        "title": "Escalation noise from incorrect due-time policies",
        "probability": "medium",
        "impact": "high",
        "signal": "Escalation volume spikes > 2x baseline",
        "mitigation": "Approve policy changes only via proposal flow + simulation",
        "owner": "Ops Lead",
        "status": "open",
        "review_cycle": "weekly",
    },
    {
        "id": "RISK-02",
        "title": "Webhook reliability degradation",
        "probability": "medium",
        "impact": "high",
        "signal": "Alert delivery success < 99%",
        "mitigation": "Multi-endpoint fallback + retry batch + timeout tuning",
        "owner": "SRE",
        "status": "open",
        "review_cycle": "weekly",
    },
    {
        "id": "RISK-03",
        "title": "RBAC scope misconfiguration during scale-out",
        "probability": "medium",
        "impact": "high",
        "signal": "Unauthorized attempts increase on new sites",
        "mitigation": "Template-based site scope + monthly RBAC audit",
        "owner": "Security",
        "status": "open",
        "review_cycle": "bi-weekly",
    },
    {
        "id": "RISK-04",
        "title": "Slow report close due to manual handoffs",
        "probability": "medium",
        "impact": "medium",
        "signal": "Monthly report on-time rate < 95%",
        "mitigation": "One-click package and checklist automation",
        "owner": "Auditor",
        "status": "open",
        "review_cycle": "monthly",
    },
    {
        "id": "RISK-05",
        "title": "Data schema drift across integrations",
        "probability": "low",
        "impact": "high",
        "signal": "Integration sync errors above threshold",
        "mitigation": "Contract versioning + replay queue for failed payloads",
        "owner": "Integrations",
        "status": "monitoring",
        "review_cycle": "weekly",
    },
    {
        "id": "RISK-06",
        "title": "Adoption regression after initial launch wave",
        "probability": "medium",
        "impact": "medium",
        "signal": "Weekly active users drop > 15%",
        "mitigation": "Champion clinics + targeted mission campaigns",
        "owner": "Training Lead",
        "status": "open",
        "review_cycle": "weekly",
    },
    {
        "id": "RISK-07",
        "title": "Single-owner bottleneck for policy approvals",
        "probability": "low",
        "impact": "medium",
        "signal": "Proposal pending age > 3 business days",
        "mitigation": "Define backup approver rotation",
        "owner": "Program Manager",
        "status": "open",
        "review_cycle": "bi-weekly",
    },
    {
        "id": "RISK-08",
        "title": "Cost metrics unavailable from source systems",
        "probability": "medium",
        "impact": "medium",
        "signal": "Cost-to-close KPI missing for month close",
        "mitigation": "Interim manual import and source contract enforcement",
        "owner": "Finance Ops",
        "status": "open",
        "review_cycle": "monthly",
    },
]


@asynccontextmanager
async def app_lifespan(_: FastAPI) -> AsyncIterator[None]:
    ensure_database()
    _ensure_evidence_storage_ready()
    ensure_legacy_admin_token_seed()
    _init_rate_limit_backend()
    preflight = _refresh_startup_preflight_snapshot()
    if bool(preflight.get("has_error")) and PREFLIGHT_FAIL_ON_ERROR:
        raise RuntimeError("Startup preflight failed with blocking errors.")
    yield


app = FastAPI(
    title="KA Facility OS",
    description="Inspection MVP for apartment facility operations",
    version="0.32.0",
    lifespan=app_lifespan,
)
ops_router = APIRouter(prefix="/api/ops", tags=["ops"])
admin_router = APIRouter(prefix="/api/admin", tags=["admin"])
adoption_router = APIRouter(prefix="/api/adoption", tags=["adoption"])
public_router = APIRouter(prefix="/api/public", tags=["public"])


def _build_browser_json_view_html(path_label: str, raw_href: str, status_code: int, payload: Any) -> str:
    payload_text = json.dumps(payload, ensure_ascii=False, indent=2) if payload is not None else "null"
    return f"""
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KA Facility OS - API Browser View</title>
  <style>
    :root {{
      --ink: #0f2139;
      --muted: #4b6282;
      --line: #d5e0ee;
      --bg: #f3f8ff;
      --card: #fff;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      margin: 0;
      color: var(--ink);
      font-family: "SUIT", "Pretendard", "IBM Plex Sans KR", "Noto Sans KR", sans-serif;
      background:
        radial-gradient(780px 300px at 8% -20%, #e1f6ff 0%, transparent 58%),
        radial-gradient(700px 300px at 95% -20%, #ffedd8 0%, transparent 58%),
        var(--bg);
    }}
    .wrap {{ max-width: 980px; margin: 0 auto; padding: 18px 14px 42px; }}
    .hero {{
      border: 1px solid var(--line);
      border-radius: 14px;
      background: linear-gradient(145deg, #fff 0%, #eef7f5 52%, #fff4e8 100%);
      padding: 14px;
      box-shadow: 0 10px 22px rgba(15, 34, 60, 0.08);
    }}
    .hero h1 {{ margin: 0; font-size: 22px; }}
    .hero p {{ margin: 8px 0 0; color: var(--muted); font-size: 13px; }}
    .meta {{
      margin-top: 10px;
      border: 1px solid #c9d9ec;
      background: #f2f8ff;
      border-radius: 10px;
      padding: 9px;
      font-size: 12px;
      color: #24496f;
    }}
    .links {{
      margin-top: 10px;
      display: flex;
      flex-wrap: wrap;
      gap: 7px;
    }}
    .links a {{
      text-decoration: none;
      border: 1px solid #b8cee8;
      border-radius: 999px;
      padding: 6px 10px;
      font-size: 12px;
      font-weight: 700;
      color: #22507f;
      background: #f3f8ff;
    }}
    pre {{
      margin: 12px 0 0;
      border: 1px solid var(--line);
      border-radius: 12px;
      background: var(--card);
      padding: 12px;
      max-height: 68vh;
      overflow: auto;
      font-family: "Consolas", "D2Coding", "IBM Plex Mono", monospace;
      font-size: 12px;
      line-height: 1.45;
      white-space: pre-wrap;
      word-break: break-word;
    }}
  </style>
</head>
<body>
  <div class="wrap">
    <section class="hero">
      <h1>API Browser View</h1>
      <p>   JSON      HTML .</p>
      <div class="meta">
        Path: {html.escape(path_label)} | HTTP: {status_code}
      </div>
      <div class="links">
        <a href="/">Public Main</a>
        <a href="/web/console">Operations Console</a>
        <a href="{html.escape(raw_href)}">Raw JSON</a>
      </div>
      <pre>{html.escape(payload_text)}</pre>
    </section>
  </div>
</body>
</html>
"""


def _init_rate_limit_backend() -> None:
    global _RATE_LIMIT_REDIS
    _RATE_LIMIT_REDIS = None
    if API_RATE_LIMIT_STORE not in {"redis", "auto"}:
        return
    if not API_RATE_LIMIT_REDIS_URL:
        return
    if Redis is None:
        return
    try:
        client = Redis.from_url(
            API_RATE_LIMIT_REDIS_URL,
            decode_responses=True,
            socket_connect_timeout=1,
            socket_timeout=1,
        )
        client.ping()
        _RATE_LIMIT_REDIS = client
    except Exception:
        _RATE_LIMIT_REDIS = None


def _rate_limit_backend_snapshot() -> dict[str, Any]:
    redis_url_configured = bool(API_RATE_LIMIT_REDIS_URL.strip())
    redis_client_ready = _RATE_LIMIT_REDIS is not None
    redis_ping_ok = False
    redis_error: str | None = None
    if redis_client_ready:
        try:
            _RATE_LIMIT_REDIS.ping()
            redis_ping_ok = True
        except Exception as exc:  # pragma: no cover - network-dependent path
            redis_error = str(exc)

    active_backend = "redis" if redis_ping_ok else "memory"
    if API_RATE_LIMIT_STORE == "redis":
        status = "ok" if redis_ping_ok else "critical"
        message = (
            "Redis rate limit backend is active."
            if redis_ping_ok
            else "Redis is required but unavailable; rate limit fallback is active."
        )
    elif API_RATE_LIMIT_STORE == "auto":
        status = "ok" if redis_ping_ok else "warning"
        if redis_ping_ok:
            message = "Auto mode currently uses Redis backend."
        elif redis_url_configured:
            message = "Auto mode is falling back to memory because Redis is unavailable."
        else:
            message = "Auto mode is using memory backend (Redis URL not configured)."
    else:
        status = "ok" if ENV_NAME != "production" else "warning"
        message = (
            "Memory rate limit backend is configured."
            if ENV_NAME != "production"
            else "Production is using memory rate limit backend."
        )

    return {
        "status": status,
        "message": message,
        "configured_store": API_RATE_LIMIT_STORE,
        "active_backend": active_backend,
        "redis_url_configured": redis_url_configured,
        "redis_client_ready": redis_client_ready,
        "redis_ping_ok": redis_ping_ok,
        "redis_error": redis_error,
    }


def _audit_signing_snapshot() -> dict[str, Any]:
    enabled = bool(AUDIT_ARCHIVE_SIGNING_KEY.strip())
    if enabled:
        return {
            "status": "ok",
            "message": "Monthly audit archive signing is enabled.",
            "enabled": True,
            "algorithm": "hmac-sha256",
        }
    status = "warning" if ENV_NAME == "production" else "ok"
    return {
        "status": status,
        "message": "Monthly audit archive signing key is not configured.",
        "enabled": False,
        "algorithm": "unsigned",
    }


def _parse_api_latency_targets(raw: str) -> list[dict[str, str]]:
    methods = {"GET", "POST", "PUT", "PATCH", "DELETE"}
    entries: list[dict[str, str]] = []
    seen: set[str] = set()
    for token in str(raw or "").split(","):
        chunk = token.strip()
        if not chunk:
            continue
        method = "GET"
        path = chunk

        if ":" in chunk:
            maybe_method, maybe_path = chunk.split(":", 1)
            maybe_method = maybe_method.strip().upper()
            if maybe_method in methods:
                method = maybe_method
                path = maybe_path.strip()
        elif " " in chunk:
            maybe_method, maybe_path = chunk.split(None, 1)
            maybe_method = maybe_method.strip().upper()
            if maybe_method in methods:
                method = maybe_method
                path = maybe_path.strip()

        if not path:
            continue
        if not path.startswith("/"):
            path = "/" + path.lstrip("/")
        key = f"{method} {path}"
        if key in seen:
            continue
        seen.add(key)
        entries.append({"key": key, "method": method, "path": path})

    if entries:
        return entries
    return [
        {"key": "GET /health", "method": "GET", "path": "/health"},
        {"key": "GET /meta", "method": "GET", "path": "/meta"},
    ]


def _percentile_value(values: list[float], percentile: float) -> float | None:
    if not values:
        return None
    sorted_values = sorted(values)
    if percentile <= 0:
        return float(sorted_values[0])
    if percentile >= 100:
        return float(sorted_values[-1])
    rank = (len(sorted_values) - 1) * (percentile / 100.0)
    lower = int(math.floor(rank))
    upper = int(math.ceil(rank))
    if lower == upper:
        return float(sorted_values[lower])
    weight = rank - lower
    return float(sorted_values[lower] + (sorted_values[upper] - sorted_values[lower]) * weight)


API_LATENCY_TARGETS: list[dict[str, str]] = _parse_api_latency_targets(API_LATENCY_TARGETS_RAW)
_API_LATENCY_TARGET_KEYS = {entry["key"] for entry in API_LATENCY_TARGETS}


def _record_api_latency_sample(
    *,
    method: str,
    path: str,
    duration_ms: float,
    status_code: int | None,
    is_error: bool,
) -> None:
    if not API_LATENCY_MONITOR_ENABLED:
        return
    key = f"{method.upper()} {path}"
    if key not in _API_LATENCY_TARGET_KEYS:
        return
    bounded_duration = max(0.0, float(duration_ms))
    max_samples = max(20, API_LATENCY_MONITOR_WINDOW)
    sampled_at = datetime.now(timezone.utc)
    now_iso = sampled_at.isoformat()
    with _API_LATENCY_LOCK:
        bucket = _API_LATENCY_SAMPLES.get(key)
        if bucket is None:
            bucket = deque(maxlen=max_samples)
            _API_LATENCY_SAMPLES[key] = bucket
        elif bucket.maxlen != max_samples:
            bucket = deque(bucket, maxlen=max_samples)
            _API_LATENCY_SAMPLES[key] = bucket
        bucket.append(bounded_duration)
        _API_LATENCY_LAST_SEEN_AT[key] = now_iso
    _persist_api_latency_sample(
        endpoint_key=key,
        method=method.upper(),
        path=path,
        duration_ms=bounded_duration,
        status_code=status_code,
        is_error=is_error,
        sampled_at=sampled_at,
    )


def _persist_api_latency_sample(
    *,
    endpoint_key: str,
    method: str,
    path: str,
    duration_ms: float,
    status_code: int | None,
    is_error: bool,
    sampled_at: datetime,
) -> None:
    if not API_LATENCY_PERSIST_ENABLED:
        return
    global _API_LATENCY_PERSIST_WRITE_COUNT
    try:
        with get_conn() as conn:
            conn.execute(
                insert(api_latency_samples).values(
                    endpoint_key=endpoint_key,
                    method=method[:10],
                    path=path[:240],
                    duration_ms=max(0.0, float(duration_ms)),
                    status_code=status_code,
                    is_error=bool(is_error),
                    sampled_at=sampled_at,
                )
            )
            _API_LATENCY_PERSIST_WRITE_COUNT += 1
            if _API_LATENCY_PERSIST_WRITE_COUNT % API_LATENCY_PERSIST_PRUNE_INTERVAL == 0:
                cutoff = sampled_at - timedelta(days=API_LATENCY_PERSIST_RETENTION_DAYS)
                conn.execute(delete(api_latency_samples).where(api_latency_samples.c.sampled_at < cutoff))
    except SQLAlchemyError:
        # Keep request path resilient even if latency persistence is temporarily unavailable.
        return


def _load_persisted_api_latency_records(
    *,
    endpoint_key: str,
    limit: int,
) -> tuple[list[dict[str, Any]], str | None]:
    if not API_LATENCY_PERSIST_ENABLED:
        return [], None
    try:
        with get_conn() as conn:
            rows = conn.execute(
                select(
                    api_latency_samples.c.duration_ms,
                    api_latency_samples.c.status_code,
                    api_latency_samples.c.is_error,
                    api_latency_samples.c.sampled_at,
                )
                .where(api_latency_samples.c.endpoint_key == endpoint_key)
                .order_by(api_latency_samples.c.sampled_at.desc(), api_latency_samples.c.id.desc())
                .limit(max(1, int(limit)))
            ).mappings().all()
    except SQLAlchemyError:
        return [], None
    if not rows:
        return [], None
    records = [
        {
            "duration_ms": max(0.0, float(row.get("duration_ms") or 0.0)),
            "status_code": int(row.get("status_code")) if row.get("status_code") is not None else None,
            "is_error": bool(row.get("is_error")),
            "sampled_at": _as_datetime(row.get("sampled_at")),
        }
        for row in rows
    ]
    sampled_at = rows[0].get("sampled_at")
    last_seen_at = _as_datetime(sampled_at).isoformat() if sampled_at is not None else None
    return records, last_seen_at


def _build_burn_rate_window_stats(
    *,
    records: list[dict[str, Any]],
    since_at: datetime,
    latency_warning_ms: float,
    error_budget_percent: float,
    latency_budget_percent: float,
    min_samples: int,
) -> dict[str, Any]:
    scoped = [row for row in records if _as_datetime(row.get("sampled_at")) >= since_at]
    total_count = len(scoped)
    error_count = sum(1 for row in scoped if bool(row.get("is_error")))
    slow_count = sum(1 for row in scoped if float(row.get("duration_ms") or 0.0) >= latency_warning_ms)
    error_rate_percent = round((error_count / total_count) * 100.0, 4) if total_count > 0 else 0.0
    slow_rate_percent = round((slow_count / total_count) * 100.0, 4) if total_count > 0 else 0.0
    error_burn = round(error_rate_percent / error_budget_percent, 4) if total_count > 0 else 0.0
    latency_burn = round(slow_rate_percent / latency_budget_percent, 4) if total_count > 0 else 0.0
    burn_rate = round(max(error_burn, latency_burn), 4) if total_count > 0 else 0.0
    return {
        "sample_count": total_count,
        "error_count": error_count,
        "slow_count": slow_count,
        "error_rate_percent": round(error_rate_percent, 2),
        "slow_rate_percent": round(slow_rate_percent, 2),
        "error_burn_rate": error_burn,
        "latency_burn_rate": latency_burn,
        "burn_rate": burn_rate,
        "ready": total_count >= min_samples,
    }


def _build_api_latency_snapshot() -> dict[str, Any]:
    generated_at = datetime.now(timezone.utc)
    warning_ms = max(1.0, float(API_LATENCY_P95_WARNING_MS))
    critical_ms = max(warning_ms, float(API_LATENCY_P95_CRITICAL_MS))
    min_samples = max(1, int(API_LATENCY_MIN_SAMPLES))
    window_size = max(20, API_LATENCY_MONITOR_WINDOW)
    burn_short_window_min = max(1, int(API_BURN_RATE_SHORT_WINDOW_MIN))
    burn_long_window_min = max(burn_short_window_min, int(API_BURN_RATE_LONG_WINDOW_MIN))
    burn_min_samples = max(1, int(API_BURN_RATE_MIN_SAMPLES))
    burn_warning = max(0.1, float(API_BURN_RATE_WARNING))
    burn_critical = max(burn_warning, float(API_BURN_RATE_CRITICAL))
    error_slo_percent = max(0.1, min(100.0, float(API_BURN_RATE_ERROR_SLO_PERCENT)))
    latency_slo_percent = max(0.1, min(100.0, float(API_BURN_RATE_LATENCY_SLO_PERCENT)))
    error_budget_percent = max(0.01, round(100.0 - error_slo_percent, 4))
    latency_budget_percent = max(0.01, round(100.0 - latency_slo_percent, 4))
    persisted_limit = max(window_size, int(API_BURN_RATE_SAMPLE_LIMIT))
    endpoints: list[dict[str, Any]] = []

    with _API_LATENCY_LOCK:
        memory_samples = {key: list(values) for key, values in _API_LATENCY_SAMPLES.items()}
        memory_last_seen = dict(_API_LATENCY_LAST_SEEN_AT)
        for target in API_LATENCY_TARGETS:
            key = target["key"]
            persisted_records, persisted_last_seen_at = _load_persisted_api_latency_records(
                endpoint_key=key,
                limit=persisted_limit,
            )
            sample_source = "database" if persisted_records else "memory"
            samples = (
                [float(row.get("duration_ms") or 0.0) for row in persisted_records]
                if persisted_records
                else list(memory_samples.get(key, []))
            )
            sample_count = len(samples)
            p95_ms = _percentile_value(samples, 95.0)
            p99_ms = _percentile_value(samples, 99.0)
            last_seen_at = persisted_last_seen_at or memory_last_seen.get(key)
            error_count = sum(1 for row in persisted_records if bool(row.get("is_error"))) if persisted_records else 0
            error_rate_percent = round((error_count / sample_count) * 100.0, 2) if sample_count > 0 else 0.0

            status = "ok"
            message = "P95 latency is within threshold."
            if sample_count < min_samples:
                status = "warning"
                message = f"Insufficient samples (need >= {min_samples})."
            elif p95_ms is None:
                status = "warning"
                message = "Latency samples are unavailable."
            elif p95_ms >= critical_ms:
                status = "critical"
                message = f"P95 latency {round(p95_ms, 2)}ms exceeds critical threshold {round(critical_ms, 2)}ms."
            elif p95_ms >= warning_ms:
                status = "warning"
                message = f"P95 latency {round(p95_ms, 2)}ms exceeds warning threshold {round(warning_ms, 2)}ms."

            burn_short = {
                "sample_count": 0,
                "error_count": 0,
                "slow_count": 0,
                "error_rate_percent": 0.0,
                "slow_rate_percent": 0.0,
                "error_burn_rate": 0.0,
                "latency_burn_rate": 0.0,
                "burn_rate": 0.0,
                "ready": False,
            }
            burn_long = dict(burn_short)
            if persisted_records:
                burn_short = _build_burn_rate_window_stats(
                    records=persisted_records,
                    since_at=generated_at - timedelta(minutes=burn_short_window_min),
                    latency_warning_ms=warning_ms,
                    error_budget_percent=error_budget_percent,
                    latency_budget_percent=latency_budget_percent,
                    min_samples=burn_min_samples,
                )
                burn_long = _build_burn_rate_window_stats(
                    records=persisted_records,
                    since_at=generated_at - timedelta(minutes=burn_long_window_min),
                    latency_warning_ms=warning_ms,
                    error_budget_percent=error_budget_percent,
                    latency_budget_percent=latency_budget_percent,
                    min_samples=burn_min_samples,
                )

            burn_status = "ok"
            burn_message = "Burn-rate is within threshold."
            burn_rate_short = float(burn_short.get("burn_rate") or 0.0)
            burn_rate_long = float(burn_long.get("burn_rate") or 0.0)
            effective_burn = max(burn_rate_short, burn_rate_long)
            if not bool(burn_short.get("ready")) or not bool(burn_long.get("ready")):
                burn_status = "warning"
                burn_message = "Burn-rate monitor warming up due to low recent sample coverage."
            elif effective_burn >= burn_critical:
                burn_status = "critical"
                burn_message = (
                    f"Burn-rate {round(effective_burn, 2)} exceeds critical threshold {round(burn_critical, 2)}."
                )
            elif effective_burn >= burn_warning:
                burn_status = "warning"
                burn_message = (
                    f"Burn-rate {round(effective_burn, 2)} exceeds warning threshold {round(burn_warning, 2)}."
                )

            endpoints.append(
                {
                    "endpoint": key,
                    "method": target["method"],
                    "path": target["path"],
                    "sample_count": sample_count,
                    "p95_ms": None if p95_ms is None else round(float(p95_ms), 2),
                    "p99_ms": None if p99_ms is None else round(float(p99_ms), 2),
                    "error_count": error_count,
                    "error_rate_percent": error_rate_percent,
                    "status": status,
                    "message": message,
                    "last_seen_at": last_seen_at,
                    "sample_source": sample_source,
                    "burn_rate_short": round(burn_rate_short, 4),
                    "burn_rate_long": round(burn_rate_long, 4),
                    "burn_status": burn_status,
                    "burn_message": burn_message,
                    "burn_windows": {
                        "short": {
                            "window_minutes": burn_short_window_min,
                            "sample_count": int(burn_short.get("sample_count") or 0),
                            "error_count": int(burn_short.get("error_count") or 0),
                            "slow_count": int(burn_short.get("slow_count") or 0),
                            "error_rate_percent": float(burn_short.get("error_rate_percent") or 0.0),
                            "slow_rate_percent": float(burn_short.get("slow_rate_percent") or 0.0),
                            "error_burn_rate": float(burn_short.get("error_burn_rate") or 0.0),
                            "latency_burn_rate": float(burn_short.get("latency_burn_rate") or 0.0),
                            "burn_rate": float(burn_short.get("burn_rate") or 0.0),
                            "ready": bool(burn_short.get("ready")),
                        },
                        "long": {
                            "window_minutes": burn_long_window_min,
                            "sample_count": int(burn_long.get("sample_count") or 0),
                            "error_count": int(burn_long.get("error_count") or 0),
                            "slow_count": int(burn_long.get("slow_count") or 0),
                            "error_rate_percent": float(burn_long.get("error_rate_percent") or 0.0),
                            "slow_rate_percent": float(burn_long.get("slow_rate_percent") or 0.0),
                            "error_burn_rate": float(burn_long.get("error_burn_rate") or 0.0),
                            "latency_burn_rate": float(burn_long.get("latency_burn_rate") or 0.0),
                            "burn_rate": float(burn_long.get("burn_rate") or 0.0),
                            "ready": bool(burn_long.get("ready")),
                        },
                    },
                }
            )

    critical_count = sum(1 for item in endpoints if item["status"] == "critical")
    warning_count = sum(1 for item in endpoints if item["status"] == "warning")
    insufficient_count = sum(
        1 for item in endpoints if int(item.get("sample_count") or 0) < min_samples
    )
    status = "ok"
    if critical_count > 0:
        status = "critical"
    elif warning_count > 0:
        status = "warning"

    message = "Critical API latency monitor is healthy."
    if status == "critical":
        message = f"{critical_count} endpoint(s) exceeded critical P95 threshold."
    elif status == "warning":
        if insufficient_count > 0 and warning_count == insufficient_count:
            message = f"Latency monitor is warming up ({insufficient_count} endpoint(s) below minimum samples)."
        else:
            message = f"{warning_count} endpoint(s) exceeded warning P95 threshold or have low sample coverage."

    burn_critical_count = sum(1 for item in endpoints if item.get("burn_status") == "critical")
    burn_warning_count = sum(1 for item in endpoints if item.get("burn_status") == "warning")
    burn_warming_up_count = sum(
        1
        for item in endpoints
        if bool((item.get("burn_windows") or {}).get("short", {}).get("ready")) is False
        or bool((item.get("burn_windows") or {}).get("long", {}).get("ready")) is False
    )
    burn_status = "ok"
    if burn_critical_count > 0:
        burn_status = "critical"
    elif burn_warning_count > 0:
        burn_status = "warning"
    burn_message = "Burn-rate monitor is healthy."
    if burn_status == "critical":
        burn_message = f"{burn_critical_count} endpoint(s) exceeded critical burn-rate threshold."
    elif burn_status == "warning":
        if burn_warning_count == burn_warming_up_count:
            burn_message = "Burn-rate monitor warming up (insufficient sample coverage)."
        else:
            burn_message = f"{burn_warning_count} endpoint(s) exceeded burn-rate warning threshold."

    return {
        "status": status,
        "message": message,
        "enabled": API_LATENCY_MONITOR_ENABLED,
        "warning_threshold_ms": round(warning_ms, 2),
        "critical_threshold_ms": round(critical_ms, 2),
        "min_samples": min_samples,
        "window_size": window_size,
        "persist_enabled": API_LATENCY_PERSIST_ENABLED,
        "persist_retention_days": API_LATENCY_PERSIST_RETENTION_DAYS,
        "target_count": len(API_LATENCY_TARGETS),
        "critical_count": critical_count,
        "warning_count": warning_count,
        "insufficient_samples_count": insufficient_count,
        "burn_rate": {
            "status": burn_status,
            "message": burn_message,
            "short_window_minutes": burn_short_window_min,
            "long_window_minutes": burn_long_window_min,
            "warning_threshold": round(burn_warning, 4),
            "critical_threshold": round(burn_critical, 4),
            "min_samples": burn_min_samples,
            "error_slo_percent": round(error_slo_percent, 4),
            "latency_slo_percent": round(latency_slo_percent, 4),
            "error_budget_percent": error_budget_percent,
            "latency_budget_percent": latency_budget_percent,
            "critical_count": burn_critical_count,
            "warning_count": burn_warning_count,
            "warming_up_count": burn_warming_up_count,
        },
        "endpoints": endpoints,
    }


def _build_evidence_archive_integrity_batch(
    *,
    sample_per_table: int | None = None,
    max_issues: int | None = None,
) -> dict[str, Any]:
    per_table_limit = max(1, min(int(sample_per_table or EVIDENCE_INTEGRITY_SAMPLE_PER_TABLE), 200))
    issue_limit = max(1, min(int(max_issues or EVIDENCE_INTEGRITY_MAX_ISSUES), 500))
    checked_count = 0
    missing_blob_count = 0
    missing_hash_count = 0
    digest_mismatch_count = 0
    read_error_count = 0
    issues: list[dict[str, Any]] = []
    table_summaries: list[dict[str, Any]] = []

    with get_conn() as conn:
        for module, table in EVIDENCE_INTEGRITY_TABLES:
            rows = conn.execute(
                select(table)
                .order_by(table.c.uploaded_at.desc(), table.c.id.desc())
                .limit(per_table_limit)
            ).mappings().all()
            table_checked = 0
            table_missing_blob = 0
            table_missing_hash = 0
            table_digest_mismatch = 0
            table_read_error = 0

            for row in rows:
                table_checked += 1
                checked_count += 1
                row_id = int(row.get("id") or 0)
                site = str(row.get("site") or "")
                stored_sha = str(row.get("sha256") or "").strip().lower()
                if not stored_sha:
                    table_missing_hash += 1
                    missing_hash_count += 1
                    if len(issues) < issue_limit:
                        issues.append(
                            {
                                "module": module,
                                "evidence_id": row_id,
                                "site": site,
                                "reason": "missing_sha256",
                            }
                        )

                try:
                    blob = _read_evidence_blob(row=dict(row))
                except Exception as exc:  # pragma: no cover - defensive path
                    blob = None
                    table_read_error += 1
                    read_error_count += 1
                    if len(issues) < issue_limit:
                        issues.append(
                            {
                                "module": module,
                                "evidence_id": row_id,
                                "site": site,
                                "reason": "read_error",
                                "error": str(exc),
                            }
                        )

                if blob is None:
                    table_missing_blob += 1
                    missing_blob_count += 1
                    if len(issues) < issue_limit:
                        issues.append(
                            {
                                "module": module,
                                "evidence_id": row_id,
                                "site": site,
                                "reason": "missing_blob",
                                "storage_backend": str(row.get("storage_backend") or "db"),
                            }
                        )
                    continue

                actual_sha = hashlib.sha256(blob).hexdigest()
                if stored_sha and stored_sha != actual_sha:
                    table_digest_mismatch += 1
                    digest_mismatch_count += 1
                    if len(issues) < issue_limit:
                        issues.append(
                            {
                                "module": module,
                                "evidence_id": row_id,
                                "site": site,
                                "reason": "sha256_mismatch",
                                "stored_sha256": stored_sha,
                                "actual_sha256": actual_sha,
                            }
                        )

            table_summaries.append(
                {
                    "module": module,
                    "checked_count": table_checked,
                    "missing_blob_count": table_missing_blob,
                    "missing_hash_count": table_missing_hash,
                    "digest_mismatch_count": table_digest_mismatch,
                    "read_error_count": table_read_error,
                }
            )

    archive = build_monthly_audit_archive(month=None, include_entries=False, max_entries=10000)
    archive_payload = {
        "month": archive["month"],
        "window_start": archive["window_start"],
        "window_end": archive["window_end"],
        "generated_at": archive["generated_at"],
        "entry_count": archive["entry_count"],
        "max_entries": archive["max_entries"],
        "chain": archive["chain"],
        "entries": archive["entries"],
    }
    archive_payload_text = json.dumps(archive_payload, ensure_ascii=False, separators=(",", ":"), sort_keys=True)
    computed_archive_sha = hashlib.sha256(archive_payload_text.encode("utf-8")).hexdigest()
    expected_signature = _sign_payload(archive_payload_text)
    stored_signature = archive.get("signature")
    stored_signature_algorithm = str(archive.get("signature_algorithm") or "unsigned")
    archive_sha_ok = str(archive.get("archive_sha256") or "") == computed_archive_sha
    if expected_signature is None:
        archive_signature_ok = stored_signature in {None, ""}
        archive_signature_algorithm_ok = stored_signature_algorithm == "unsigned"
    else:
        archive_signature_ok = stored_signature == expected_signature
        archive_signature_algorithm_ok = stored_signature_algorithm == "hmac-sha256"

    status = "ok"
    if digest_mismatch_count > 0 or (not archive_sha_ok) or (not archive_signature_ok) or (not archive_signature_algorithm_ok):
        status = "critical"
    elif missing_blob_count > 0 or missing_hash_count > 0 or read_error_count > 0 or checked_count == 0:
        status = "warning"

    if status == "critical":
        message = "Evidence/archive integrity critical issue detected."
    elif status == "warning":
        if checked_count == 0:
            message = "No evidence rows available for integrity sampling."
        else:
            message = "Evidence/archive integrity sampling found warnings."
    else:
        message = "Evidence/archive integrity sampling is healthy."

    return {
        "status": status,
        "message": message,
        "sample_per_table": per_table_limit,
        "checked_count": checked_count,
        "missing_blob_count": missing_blob_count,
        "missing_hash_count": missing_hash_count,
        "digest_mismatch_count": digest_mismatch_count,
        "read_error_count": read_error_count,
        "issue_count": len(issues),
        "issues": issues,
        "tables": table_summaries,
        "archive": {
            "month": archive.get("month"),
            "entry_count": archive.get("entry_count"),
            "chain_ok": bool((archive.get("chain") or {}).get("chain_ok", False)),
            "archive_sha_ok": archive_sha_ok,
            "signature_ok": archive_signature_ok,
            "signature_algorithm_ok": archive_signature_algorithm_ok,
            "signature_algorithm": stored_signature_algorithm,
            "signed": expected_signature is not None,
        },
    }


def _build_deploy_checklist_payload() -> dict[str, Any]:
    rollback_guide_path = Path("docs/W15_MIGRATION_ROLLBACK.md")
    rollback_guide_exists = rollback_guide_path.exists()
    rollback_guide_sha256: str | None = None
    if rollback_guide_exists:
        try:
            rollback_guide_sha256 = hashlib.sha256(rollback_guide_path.read_bytes()).hexdigest()
        except OSError:
            rollback_guide_exists = False
            rollback_guide_sha256 = None

    return {
        "version": DEPLOY_CHECKLIST_VERSION,
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "policy": {
            "deploy_smoke_recent_hours": max(1, DEPLOY_SMOKE_RECENT_HOURS),
            "require_runbook_gate": DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE,
            "rollback_on_failure_recommended": True,
            "rollback_guide_required": True,
            "rollback_guide_path": str(rollback_guide_path).replace("\\", "/"),
            "rollback_guide_exists": rollback_guide_exists,
            "rollback_guide_sha256": rollback_guide_sha256,
        },
        "steps": [
            {
                "phase": "pre_deploy",
                "id": "pre_01_backup",
                "required": True,
                "item": "Confirm DB backup/snapshot is available.",
            },
            {
                "phase": "pre_deploy",
                "id": "pre_02_release_note",
                "required": True,
                "item": "Record release scope and rollback owner.",
            },
            {
                "phase": "post_deploy",
                "id": "smoke_01_health",
                "required": True,
                "item": "Verify /health and /meta responses.",
            },
            {
                "phase": "post_deploy",
                "id": "smoke_02_auth_and_runbook",
                "required": True,
                "item": "Verify /api/auth/me and runbook checks (no critical).",
            },
            {
                "phase": "post_deploy",
                "id": "smoke_03_security",
                "required": True,
                "item": "Verify /api/ops/security/posture and expected rate-limit backend.",
            },
            {
                "phase": "rollback_ready",
                "id": "rollback_01_trigger",
                "required": True,
                "item": "Rollback command prepared (Render rollback API or dashboard).",
            },
            {
                "phase": "rollback_ready",
                "id": "rollback_02_checklist",
                "required": True,
                "item": "Use docs/W15_MIGRATION_ROLLBACK.md for verification sequence.",
                "path": str(rollback_guide_path).replace("\\", "/"),
                "exists": rollback_guide_exists,
                "sha256": rollback_guide_sha256,
            },
        ],
    }


def _week_start_utc(dt: datetime) -> datetime:
    return datetime(dt.year, dt.month, dt.day, tzinfo=timezone.utc) - timedelta(days=dt.weekday())


def _startup_path_writable(path_value: str) -> tuple[bool, str]:
    try:
        target = Path(path_value)
        target.mkdir(parents=True, exist_ok=True)
        probe = target / ".write_probe"
        probe.write_text("ok", encoding="utf-8")
        probe.unlink(missing_ok=True)
        return True, f"Path is writable: {target}"
    except Exception as exc:  # pragma: no cover - filesystem dependent
        return False, f"Path not writable: {path_value} ({exc})"


def _run_startup_preflight_snapshot() -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    checks: list[dict[str, Any]] = []

    for env_name in sorted(PREFLIGHT_REQUIRED_ENV):
        value = getenv(env_name)
        ok = value is not None and value.strip() != ""
        checks.append(
            {
                "id": f"required_env_{env_name.lower()}",
                "severity": "error",
                "status": "ok" if ok else "error",
                "message": f"{env_name} is configured." if ok else f"{env_name} is missing.",
            }
        )

    redis_required = API_RATE_LIMIT_STORE == "redis"
    redis_ok = (not redis_required) or bool(API_RATE_LIMIT_REDIS_URL)
    checks.append(
        {
            "id": "rate_limit_redis_config",
            "severity": "error" if redis_required else "warning",
            "status": "ok" if redis_ok else "error",
            "message": (
                "API rate-limit redis config is valid."
                if redis_ok
                else "API_RATE_LIMIT_STORE=redis requires API_RATE_LIMIT_REDIS_URL."
            ),
        }
    )

    signing_required = ENV_NAME in {"prod", "production", "staging"}
    signing_ok = bool(AUDIT_ARCHIVE_SIGNING_KEY)
    checks.append(
        {
            "id": "audit_archive_signing_key",
            "severity": "error" if signing_required else "warning",
            "status": "ok" if signing_ok else ("error" if signing_required else "warning"),
            "message": (
                "Audit archive signing key is configured."
                if signing_ok
                else "AUDIT_ARCHIVE_SIGNING_KEY is not configured."
            ),
        }
    )

    rollback_guide = Path("docs/W15_MIGRATION_ROLLBACK.md")
    checks.append(
        {
            "id": "rollback_guide_file",
            "severity": "error",
            "status": "ok" if rollback_guide.exists() else "error",
            "message": (
                "Rollback guide file is present."
                if rollback_guide.exists()
                else "Missing docs/W15_MIGRATION_ROLLBACK.md."
            ),
        }
    )

    alert_noise_policy_doc = Path("docs/W17_ALERT_NOISE_POLICY.md")
    checks.append(
        {
            "id": "alert_noise_policy_doc",
            "severity": "warning",
            "status": "ok" if alert_noise_policy_doc.exists() else "warning",
            "message": (
                "Alert noise policy document is present."
                if alert_noise_policy_doc.exists()
                else "Alert noise policy document is missing (docs/W17_ALERT_NOISE_POLICY.md)."
            ),
        }
    )

    if OPS_DAILY_CHECK_ARCHIVE_ENABLED:
        archive_ok, archive_message = _startup_path_writable(OPS_DAILY_CHECK_ARCHIVE_PATH)
        checks.append(
            {
                "id": "ops_daily_archive_path",
                "severity": "error",
                "status": "ok" if archive_ok else "error",
                "message": archive_message,
            }
        )

    if OPS_QUALITY_REPORT_ARCHIVE_ENABLED:
        quality_ok, quality_message = _startup_path_writable(OPS_QUALITY_REPORT_ARCHIVE_PATH)
        checks.append(
            {
                "id": "ops_quality_report_archive_path",
                "severity": "error",
                "status": "ok" if quality_ok else "error",
                "message": quality_message,
            }
        )

    if DR_REHEARSAL_ENABLED:
        dr_ok, dr_message = _startup_path_writable(DR_REHEARSAL_BACKUP_PATH)
        checks.append(
            {
                "id": "dr_rehearsal_backup_path",
                "severity": "error",
                "status": "ok" if dr_ok else "error",
                "message": dr_message,
            }
        )

    error_count = sum(1 for item in checks if item.get("status") == "error")
    warning_count = sum(1 for item in checks if item.get("status") == "warning")
    overall_status = "critical" if error_count > 0 else ("warning" if warning_count > 0 else "ok")
    return {
        "generated_at": now.isoformat(),
        "env": ENV_NAME,
        "fail_on_error": PREFLIGHT_FAIL_ON_ERROR,
        "overall_status": overall_status,
        "has_error": error_count > 0,
        "error_count": error_count,
        "warning_count": warning_count,
        "check_count": len(checks),
        "checks": checks,
    }


def _refresh_startup_preflight_snapshot() -> dict[str, Any]:
    snapshot = _run_startup_preflight_snapshot()
    with _PREFLIGHT_LOCK:
        _PREFLIGHT_SNAPSHOT.clear()
        _PREFLIGHT_SNAPSHOT.update(snapshot)
    return dict(snapshot)


def _get_startup_preflight_snapshot(*, refresh: bool = False) -> dict[str, Any]:
    if refresh:
        return _refresh_startup_preflight_snapshot()
    with _PREFLIGHT_LOCK:
        if _PREFLIGHT_SNAPSHOT:
            return dict(_PREFLIGHT_SNAPSHOT)
    return _refresh_startup_preflight_snapshot()


def _build_alert_noise_policy_snapshot() -> dict[str, Any]:
    return {
        "version": "v1",
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "review_window_days": max(1, ALERT_NOISE_REVIEW_WINDOW_DAYS),
        "false_positive_threshold_percent": round(max(0.0, ALERT_NOISE_FALSE_POSITIVE_THRESHOLD_PERCENT), 2),
        "false_negative_threshold_percent": round(max(0.0, ALERT_NOISE_FALSE_NEGATIVE_THRESHOLD_PERCENT), 2),
        "policy_doc_path": "docs/W17_ALERT_NOISE_POLICY.md",
        "evaluation": {
            "false_positive_definition": "Dispatched alert without actionable incident confirmation.",
            "false_negative_definition": "Incident confirmed without matching alert dispatch.",
        },
    }


def _build_admin_security_dashboard_snapshot(*, days: int = 30) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(1, min(int(days), 180))
    start = now - timedelta(days=window_days)
    sensitive_actions = {
        "admin_token_issue",
        "admin_token_rotate",
        "admin_token_revoke",
        "admin_user_create",
        "admin_user_update",
        "sla_policy_update",
        "sla_policy_restore",
        "admin_audit_chain_rebaseline",
    }

    with get_conn() as conn:
        audit_rows = conn.execute(
            select(
                admin_audit_logs.c.actor_username,
                admin_audit_logs.c.action,
                admin_audit_logs.c.status,
                admin_audit_logs.c.created_at,
            ).where(admin_audit_logs.c.created_at >= start)
        ).mappings().all()
        token_rows = conn.execute(
            select(
                admin_tokens.c.id,
                admin_tokens.c.user_id,
                admin_tokens.c.expires_at,
                admin_tokens.c.last_used_at,
                admin_tokens.c.created_at,
                admin_tokens.c.site_scope,
                admin_users.c.role.label("role"),
                admin_users.c.username.label("username"),
            ).where(admin_tokens.c.is_active.is_(True))
            .where(admin_users.c.id == admin_tokens.c.user_id)
        ).mappings().all()
        user_rows = conn.execute(
            select(
                admin_users.c.id,
                admin_users.c.username,
                admin_users.c.role,
                admin_users.c.is_active,
            )
        ).mappings().all()

    user_count = len(user_rows)
    active_users = [row for row in user_rows if bool(row.get("is_active"))]
    active_user_count = len(active_users)

    total_actions = len(audit_rows)
    failed_actions = 0
    sensitive_count = 0
    actor_counts: dict[str, int] = {}
    off_hours_actions = 0
    sensitive_events: list[dict[str, Any]] = []

    for row in audit_rows:
        actor = str(row.get("actor_username") or "unknown")
        actor_counts[actor] = actor_counts.get(actor, 0) + 1
        action = str(row.get("action") or "")
        status = str(row.get("status") or "success")
        if status in {"warning", "failed", "error"}:
            failed_actions += 1
        if action in sensitive_actions:
            sensitive_count += 1
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is not None and (created_at.hour < 6 or created_at.hour >= 22):
            off_hours_actions += 1
        if action in sensitive_actions:
            sensitive_events.append(
                {
                    "actor": actor,
                    "action": action,
                    "status": status,
                    "created_at": created_at.isoformat() if created_at is not None else None,
                    "off_hours": bool(created_at is not None and (created_at.hour < 6 or created_at.hour >= 22)),
                }
            )

    expiring_7d = 0
    stale_14d = 0
    rotate_overdue = 0
    wildcard_scope_tokens = 0
    non_owner_wildcard_tokens = 0
    dormant_30d = 0
    active_token_user_ids: set[int] = set()
    for row in token_rows:
        expires_at = _as_optional_datetime(row.get("expires_at"))
        last_used = _as_optional_datetime(row.get("last_used_at"))
        created_at = _as_optional_datetime(row.get("created_at"))
        user_id_raw = row.get("user_id")
        try:
            user_id = int(user_id_raw) if user_id_raw is not None else None
        except (TypeError, ValueError):
            user_id = None
        if user_id is not None:
            active_token_user_ids.add(user_id)
        if expires_at is not None and expires_at <= (now + timedelta(days=7)):
            expiring_7d += 1
        baseline = last_used or created_at
        if baseline is not None and baseline <= (now - timedelta(days=14)):
            stale_14d += 1
        if baseline is not None and baseline <= (now - timedelta(days=30)):
            dormant_30d += 1
        if created_at is not None and created_at <= (now - timedelta(days=max(1, ADMIN_TOKEN_ROTATE_AFTER_DAYS))):
            rotate_overdue += 1
        token_scope = _site_scope_text_to_list(row.get("site_scope"), default_all=True)
        role = str(row.get("role") or "operator").strip().lower() or "operator"
        if SITE_SCOPE_ALL in token_scope:
            wildcard_scope_tokens += 1
            if role not in {"owner", "admin"}:
                non_owner_wildcard_tokens += 1

    active_user_ids = {
        int(row["id"])
        for row in active_users
        if row.get("id") is not None
    }
    users_without_active_token = len(active_user_ids - active_token_user_ids)

    anomalies: list[dict[str, Any]] = []
    if failed_actions >= max(10, window_days):
        anomalies.append(
            {
                "id": "failed_actions_spike",
                "status": "warning",
                "metric": failed_actions,
                "threshold": max(10, window_days),
                "message": "Failed/warning admin actions are above threshold.",
            }
        )
    if sensitive_count >= max(15, window_days * 2):
        anomalies.append(
            {
                "id": "sensitive_action_volume",
                "status": "warning",
                "metric": sensitive_count,
                "threshold": max(15, window_days * 2),
                "message": "Sensitive admin action volume is elevated.",
            }
        )
    if off_hours_actions >= max(5, window_days // 2):
        anomalies.append(
            {
                "id": "off_hours_activity",
                "status": "warning",
                "metric": off_hours_actions,
                "threshold": max(5, window_days // 2),
                "message": "Off-hours admin action volume requires review.",
            }
        )
    if expiring_7d > 0:
        anomalies.append(
            {
                "id": "token_expiring_soon",
                "status": "warning",
                "metric": expiring_7d,
                "threshold": 0,
                "message": "Active admin tokens are expiring within 7 days.",
            }
        )
    if stale_14d > 0:
        anomalies.append(
            {
                "id": "stale_token_usage",
                "status": "warning",
                "metric": stale_14d,
                "threshold": 0,
                "message": "Some active tokens have not been used in 14+ days.",
            }
        )
    if rotate_overdue > 0:
        anomalies.append(
            {
                "id": "token_rotate_overdue",
                "status": "warning",
                "metric": rotate_overdue,
                "threshold": 0,
                "message": "Some active tokens exceeded rotate-after policy window.",
            }
        )
    if users_without_active_token > 0:
        anomalies.append(
            {
                "id": "users_without_active_token",
                "status": "warning",
                "metric": users_without_active_token,
                "threshold": 0,
                "message": "Some active admin users do not have any active token.",
            }
        )
    if dormant_30d > 0:
        anomalies.append(
            {
                "id": "dormant_tokens",
                "status": "warning",
                "metric": dormant_30d,
                "threshold": 0,
                "message": "Some active tokens have not been used in 30+ days.",
            }
        )
    if non_owner_wildcard_tokens > 0:
        anomalies.append(
            {
                "id": "token_wildcard_scope_non_owner",
                "status": "critical",
                "metric": non_owner_wildcard_tokens,
                "threshold": 0,
                "message": "Wildcard-scope tokens are issued to non-owner roles.",
            }
        )

    top_actors = [
        {"actor": actor, "action_count": count}
        for actor, count in sorted(actor_counts.items(), key=lambda item: item[1], reverse=True)[:10]
    ]

    risk_score = 0
    risk_score += min(25, failed_actions * 2)
    risk_score += min(15, off_hours_actions * 2)
    risk_score += min(20, expiring_7d * 3)
    risk_score += min(20, rotate_overdue * 3)
    risk_score += min(10, users_without_active_token * 2)
    risk_score += min(10, dormant_30d * 2)
    risk_score += min(40, non_owner_wildcard_tokens * 20)
    risk_score = min(100, risk_score)

    if risk_score >= 80:
        risk_level = "critical"
    elif risk_score >= 60:
        risk_level = "high"
    elif risk_score >= 30:
        risk_level = "medium"
    else:
        risk_level = "low"

    anomaly_statuses = {str(item.get("status") or "warning") for item in anomalies}
    if "critical" in anomaly_statuses or risk_level == "critical":
        overall_status = "critical"
    elif anomalies:
        overall_status = "warning"
    else:
        overall_status = "ok"

    recommendation_map = {
        "failed_actions_spike": " /       .",
        "sensitive_action_volume": " (//)  2   .",
        "off_hours_activity": "  Change Ticket  .",
        "token_expiring_soon": "7        .",
        "stale_token_usage": "14      .",
        "token_rotate_overdue": "     rotate .",
        "users_without_active_token": "          .",
        "dormant_tokens": "30    revoke    .",
        "token_wildcard_scope_non_owner": "-owner wildcard  site    .",
    }
    recommendations: list[str] = []
    for anomaly in anomalies:
        rec = recommendation_map.get(str(anomaly.get("id") or ""))
        if rec and rec not in recommendations:
            recommendations.append(rec)

    recent_sensitive_events = sorted(
        sensitive_events,
        key=lambda item: str(item.get("created_at") or ""),
        reverse=True,
    )[:20]

    return {
        "generated_at": now.isoformat(),
        "window_days": window_days,
        "window_start": start.isoformat(),
        "window_end": now.isoformat(),
        "overall_status": overall_status,
        "users": {
            "total_users": user_count,
            "active_users": active_user_count,
        },
        "tokens": {
            "active_tokens": len(token_rows),
            "expiring_7d": expiring_7d,
            "stale_14d": stale_14d,
            "rotate_overdue": rotate_overdue,
            "dormant_30d": dormant_30d,
            "wildcard_scope_tokens": wildcard_scope_tokens,
            "non_owner_wildcard_tokens": non_owner_wildcard_tokens,
        },
        "coverage": {
            "active_users_without_token": users_without_active_token,
        },
        "actions": {
            "total": total_actions,
            "failed_or_warning": failed_actions,
            "sensitive_total": sensitive_count,
            "off_hours_total": off_hours_actions,
            "unique_actors": len(actor_counts),
        },
        "risk": {
            "score": risk_score,
            "level": risk_level,
        },
        "anomalies": anomalies,
        "top_actors": top_actors,
        "recent_sensitive_events": recent_sensitive_events,
        "recommendations": recommendations,
    }


def _build_ops_quality_job_summary(*, start: datetime, end: datetime) -> dict[str, Any]:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs.c.job_name, job_runs.c.status, job_runs.c.detail_json, job_runs.c.finished_at)
            .where(job_runs.c.finished_at >= start)
            .where(job_runs.c.finished_at < end)
            .order_by(job_runs.c.finished_at.asc(), job_runs.c.id.asc())
        ).mappings().all()
        deliveries = conn.execute(
            select(alert_deliveries.c.status)
            .where(alert_deliveries.c.created_at >= start)
            .where(alert_deliveries.c.created_at < end)
        ).mappings().all()

    by_job: dict[str, dict[str, int]] = {}
    total_critical_findings = 0
    for row in rows:
        job_name = str(row.get("job_name") or "unknown")
        status = str(row.get("status") or "success")
        bucket = by_job.setdefault(
            job_name,
            {
                "total": 0,
                "success": 0,
                "warning": 0,
                "critical": 0,
            },
        )
        bucket["total"] += 1
        if status in {"success", "ok"}:
            bucket["success"] += 1
        elif status in {"warning"}:
            bucket["warning"] += 1
        else:
            bucket["critical"] += 1

        if job_name == "ops_daily_check":
            detail = _parse_job_detail_json(row.get("detail_json"))
            try:
                total_critical_findings += int(detail.get("critical_count") or 0)
            except (TypeError, ValueError):
                pass

    total_alert = len(deliveries)
    alert_success = 0
    for row in deliveries:
        delivery_status = str(row.get("status") or "")
        if delivery_status == "success":
            alert_success += 1
    alert_success_rate = round((alert_success / total_alert) * 100.0, 2) if total_alert > 0 else None

    job_rows = [
        {
            "job_name": job_name,
            "total": values["total"],
            "success": values["success"],
            "warning": values["warning"],
            "critical": values["critical"],
            "success_rate_percent": round((values["success"] / values["total"]) * 100.0, 2) if values["total"] > 0 else 0.0,
        }
        for job_name, values in sorted(by_job.items())
    ]
    return {
        "job_count": len(job_rows),
        "job_runs_total": len(rows),
        "critical_findings_total": total_critical_findings,
        "alert_delivery_total": total_alert,
        "alert_delivery_success_rate_percent": alert_success_rate,
        "jobs": job_rows,
    }


def _build_ops_quality_report_payload(*, window: str, start: datetime, end: datetime, label: str) -> dict[str, Any]:
    summary = _build_ops_quality_job_summary(start=start, end=end)
    preflight = _get_startup_preflight_snapshot(refresh=False)
    admin_security = _build_admin_security_dashboard_snapshot(days=max(1, int((end - start).days)))
    weekly_streak = _build_ops_quality_weekly_streak_snapshot()
    alert_policy = _build_alert_noise_policy_snapshot()
    recommendation_items: list[str] = []
    if summary.get("critical_findings_total", 0) > 0:
        recommendation_items.append("Reduce critical runbook findings before next release.")
    if (summary.get("alert_delivery_success_rate_percent") or 0) < 95:
        recommendation_items.append("Improve alert channel reliability to >=95% success rate.")
    if admin_security.get("anomalies"):
        recommendation_items.append("Review admin security anomalies and assign owners.")
    if preflight.get("has_error"):
        recommendation_items.append("Resolve startup preflight errors immediately.")
    if not recommendation_items:
        recommendation_items.append("Maintain current operational baseline and continue weekly checks.")

    return {
        "template_version": "ops-quality-v1",
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "window": window,
        "label": label,
        "period": {
            "start": start.isoformat(),
            "end": end.isoformat(),
        },
        "summary": summary,
        "preflight": {
            "overall_status": preflight.get("overall_status"),
            "error_count": preflight.get("error_count"),
            "warning_count": preflight.get("warning_count"),
        },
        "admin_security": {
            "overall_status": admin_security.get("overall_status"),
            "anomaly_count": len(admin_security.get("anomalies", [])),
            "top_actors": admin_security.get("top_actors", [])[:3],
        },
        "weekly_streak": weekly_streak,
        "alert_noise_policy": {
            "review_window_days": alert_policy.get("review_window_days"),
            "false_positive_threshold_percent": alert_policy.get("false_positive_threshold_percent"),
            "false_negative_threshold_percent": alert_policy.get("false_negative_threshold_percent"),
        },
        "recommendations": recommendation_items,
    }


def _build_ops_quality_report_csv(payload: dict[str, Any]) -> str:
    summary = payload.get("summary", {}) if isinstance(payload.get("summary"), dict) else {}
    jobs = summary.get("jobs", []) if isinstance(summary.get("jobs"), list) else []
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(["template_version", payload.get("template_version")])
    writer.writerow(["generated_at", payload.get("generated_at")])
    writer.writerow(["window", payload.get("window")])
    writer.writerow(["label", payload.get("label")])
    period = payload.get("period", {}) if isinstance(payload.get("period"), dict) else {}
    writer.writerow(["period_start", period.get("start")])
    writer.writerow(["period_end", period.get("end")])
    writer.writerow(["job_runs_total", summary.get("job_runs_total")])
    writer.writerow(["critical_findings_total", summary.get("critical_findings_total")])
    writer.writerow(["alert_delivery_total", summary.get("alert_delivery_total")])
    writer.writerow(["alert_delivery_success_rate_percent", summary.get("alert_delivery_success_rate_percent")])
    writer.writerow([])
    writer.writerow(["job_name", "total", "success", "warning", "critical", "success_rate_percent"])
    for row in jobs:
        if not isinstance(row, dict):
            continue
        writer.writerow(
            [
                row.get("job_name"),
                row.get("total"),
                row.get("success"),
                row.get("warning"),
                row.get("critical"),
                row.get("success_rate_percent"),
            ]
        )
    return buffer.getvalue()


def _prune_ops_quality_report_archive_files(*, archive_dir: Path, now: datetime) -> int:
    cutoff = now - timedelta(days=max(1, OPS_QUALITY_REPORT_ARCHIVE_RETENTION_DAYS))
    deleted_count = 0
    for pattern in ("ops-quality-report-*.json", "ops-quality-report-*.csv"):
        for file_path in archive_dir.glob(pattern):
            try:
                modified_at = datetime.fromtimestamp(file_path.stat().st_mtime, tz=timezone.utc)
            except OSError:
                continue
            if modified_at >= cutoff:
                continue
            try:
                file_path.unlink()
                deleted_count += 1
            except OSError:
                continue
    return deleted_count


def _publish_ops_quality_report_artifacts(
    *,
    payload: dict[str, Any],
    window: str,
    finished_at: datetime,
) -> dict[str, Any]:
    archive = {
        "enabled": OPS_QUALITY_REPORT_ARCHIVE_ENABLED,
        "path": OPS_QUALITY_REPORT_ARCHIVE_PATH,
        "retention_days": max(1, OPS_QUALITY_REPORT_ARCHIVE_RETENTION_DAYS),
        "json_file": None,
        "csv_file": None,
        "pruned_files": 0,
        "error": None,
    }
    if not OPS_QUALITY_REPORT_ARCHIVE_ENABLED:
        return archive
    try:
        archive_dir = Path(OPS_QUALITY_REPORT_ARCHIVE_PATH)
        archive_dir.mkdir(parents=True, exist_ok=True)
        stamp = finished_at.strftime("%Y%m%dT%H%M%SZ")
        base_name = f"ops-quality-report-{window}-{stamp}"
        json_file = archive_dir / f"{base_name}.json"
        csv_file = archive_dir / f"{base_name}.csv"
        json_file.write_text(json.dumps(payload, ensure_ascii=False, indent=2, default=str), encoding="utf-8")
        csv_file.write_text(_build_ops_quality_report_csv(payload), encoding="utf-8")
        archive["json_file"] = str(json_file)
        archive["csv_file"] = str(csv_file)
        archive["pruned_files"] = _prune_ops_quality_report_archive_files(archive_dir=archive_dir, now=finished_at)
    except Exception as exc:  # pragma: no cover - filesystem dependent
        archive["error"] = str(exc)
    return archive


def _build_ops_quality_weekly_streak_snapshot() -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_start = now - timedelta(days=70)
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.status)
            .where(job_runs.c.job_name == OPS_QUALITY_WEEKLY_JOB_NAME)
            .where(job_runs.c.finished_at >= window_start)
            .order_by(job_runs.c.finished_at.asc(), job_runs.c.id.asc())
        ).mappings().all()

    success_weeks: set[str] = set()
    for row in rows:
        if str(row.get("status") or "") not in {"success", "ok"}:
            continue
        finished_at = _as_optional_datetime(row.get("finished_at"))
        if finished_at is None:
            continue
        week_start = _week_start_utc(finished_at)
        success_weeks.add(week_start.date().isoformat())

    streak = 0
    probe = _week_start_utc(now)
    for _ in range(max(1, OPS_QUALITY_WEEKLY_STREAK_TARGET * 2)):
        key = probe.date().isoformat()
        if key in success_weeks:
            streak += 1
            probe = probe - timedelta(days=7)
            continue
        break

    return {
        "target_weeks": max(1, OPS_QUALITY_WEEKLY_STREAK_TARGET),
        "current_streak_weeks": streak,
        "target_met": streak >= max(1, OPS_QUALITY_WEEKLY_STREAK_TARGET),
        "successful_weeks_in_window": len(success_weeks),
    }


def run_ops_quality_report_job(
    *,
    window: str = "weekly",
    month: str | None = None,
    trigger: str = "manual",
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    normalized_window = window.strip().lower()
    if normalized_window not in {"weekly", "monthly"}:
        raise HTTPException(status_code=400, detail="window must be weekly or monthly")

    if normalized_window == "weekly":
        end = now
        start = end - timedelta(days=7)
        label = f"week-{start.date().isoformat()}-{end.date().isoformat()}"
        job_name = OPS_QUALITY_WEEKLY_JOB_NAME
    else:
        start, end, normalized_month = _month_window(month)
        label = normalized_month
        job_name = OPS_QUALITY_MONTHLY_JOB_NAME

    payload = _build_ops_quality_report_payload(window=normalized_window, start=start, end=end, label=label)
    summary = payload.get("summary", {}) if isinstance(payload.get("summary"), dict) else {}
    critical_findings = int(summary.get("critical_findings_total") or 0)
    status = "warning" if critical_findings > 0 else "success"
    started_at = datetime.now(timezone.utc)
    finished_at = datetime.now(timezone.utc)
    archive = _publish_ops_quality_report_artifacts(payload=payload, window=normalized_window, finished_at=finished_at)
    detail = {
        "window": normalized_window,
        "label": label,
        "summary": summary,
        "archive": archive,
        "report": payload,
    }
    run_id = _write_job_run(
        job_name=job_name,
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )

    streak = _build_ops_quality_weekly_streak_snapshot()
    return {
        "run_id": run_id,
        "job_name": job_name,
        "trigger": trigger,
        "status": status,
        "window": normalized_window,
        "label": label,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        "archive": archive,
        "streak": streak,
        "report": payload,
    }


def run_dr_rehearsal_job(
    *,
    trigger: str = "manual",
    simulate_restore: bool = True,
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    backup_path = Path(DR_REHEARSAL_BACKUP_PATH)
    counts: dict[str, int] = {}
    status = "success"
    notes: list[str] = []
    backup_file: str | None = None
    restore_valid = False
    pruned_files = 0

    if not DR_REHEARSAL_ENABLED:
        status = "warning"
        notes.append("DR rehearsal is disabled by policy.")
    else:
        with get_conn() as conn:
            table_map = {
                "inspections": inspections,
                "work_orders": work_orders,
                "work_order_events": work_order_events,
                "job_runs": job_runs,
                "admin_audit_logs": admin_audit_logs,
            }
            for table_name, table in table_map.items():
                total = conn.execute(select(func.count()).select_from(table)).scalar_one_or_none()
                counts[table_name] = int(total or 0)

        try:
            backup_path.mkdir(parents=True, exist_ok=True)
            stamp = started_at.strftime("%Y%m%dT%H%M%SZ")
            backup_file_path = backup_path / f"dr-rehearsal-{stamp}.json"
            payload = {
                "generated_at": started_at.isoformat(),
                "counts": counts,
                "trigger": trigger,
            }
            backup_file_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
            backup_file = str(backup_file_path)
            if simulate_restore:
                loaded = json.loads(backup_file_path.read_text(encoding="utf-8"))
                restore_counts = loaded.get("counts", {}) if isinstance(loaded, dict) else {}
                restore_valid = (
                    isinstance(restore_counts, dict)
                    and set(restore_counts.keys()) == set(counts.keys())
                    and all(int(restore_counts.get(key, -1)) >= 0 for key in counts.keys())
                )
                if not restore_valid:
                    status = "warning"
                    notes.append("Restore simulation validation failed.")
                else:
                    notes.append("Restore simulation validation succeeded.")
            cutoff = started_at - timedelta(days=max(1, DR_REHEARSAL_RETENTION_DAYS))
            for file_path in backup_path.glob("dr-rehearsal-*.json"):
                try:
                    modified_at = datetime.fromtimestamp(file_path.stat().st_mtime, tz=timezone.utc)
                except OSError:
                    continue
                if modified_at >= cutoff:
                    continue
                try:
                    file_path.unlink()
                    pruned_files += 1
                except OSError:
                    continue
        except Exception as exc:  # pragma: no cover - filesystem dependent
            status = "critical"
            notes.append(f"DR rehearsal backup write failed: {exc}")

    finished_at = datetime.now(timezone.utc)
    detail = {
        "enabled": DR_REHEARSAL_ENABLED,
        "backup_path": DR_REHEARSAL_BACKUP_PATH,
        "retention_days": max(1, DR_REHEARSAL_RETENTION_DAYS),
        "counts": counts,
        "backup_file": backup_file,
        "restore_valid": restore_valid,
        "simulate_restore": simulate_restore,
        "pruned_files": pruned_files,
        "notes": notes,
    }
    run_id = _write_job_run(
        job_name=DR_REHEARSAL_JOB_NAME,
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )
    return {
        "run_id": run_id,
        "job_name": DR_REHEARSAL_JOB_NAME,
        "trigger": trigger,
        "status": status,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        **detail,
    }


def _latest_dr_rehearsal_payload() -> dict[str, Any] | None:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        return None
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    return {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        **detail,
    }


def _normalize_governance_risk_level(value: Any) -> str:
    raw = str(value or "").strip().lower()
    if raw not in {"low", "medium", "high", "critical"}:
        return "high"
    return raw


def _governance_risk_rank(value: str) -> int:
    order = {"low": 1, "medium": 2, "high": 3, "critical": 4}
    return order.get(_normalize_governance_risk_level(value), 3)


def _build_ops_governance_gate_snapshot(*, now: datetime | None = None) -> dict[str, Any]:
    checked_at = now or datetime.now(timezone.utc)
    max_risk_level = _normalize_governance_risk_level(GOVERNANCE_GATE_MAX_SECURITY_RISK_LEVEL)
    preflight = _get_startup_preflight_snapshot(refresh=False)
    runbook = _build_ops_runbook_checks_snapshot(now=checked_at)
    security_dashboard = _build_admin_security_dashboard_snapshot(days=GOVERNANCE_GATE_SECURITY_DASHBOARD_DAYS)
    weekly_streak = _build_ops_quality_weekly_streak_snapshot()
    dr_latest = _latest_dr_rehearsal_payload()

    with get_conn() as conn:
        daily_latest_row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "ops_daily_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        deploy_latest_row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "deploy_smoke")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()

    daily_latest_model = _row_to_job_run_model(daily_latest_row) if daily_latest_row is not None else None
    deploy_latest_model = _row_to_job_run_model(deploy_latest_row) if deploy_latest_row is not None else None
    deploy_latest_detail = (
        deploy_latest_model.detail
        if deploy_latest_model is not None and isinstance(deploy_latest_model.detail, dict)
        else {}
    )

    required_rules = {
        "preflight_no_error": GOVERNANCE_GATE_REQUIRE_PREFLIGHT_NO_ERROR,
        "runbook_no_critical": GOVERNANCE_GATE_REQUIRE_RUNBOOK_NO_CRITICAL,
        "daily_check_recent": GOVERNANCE_GATE_REQUIRE_DAILY_CHECK_RECENT,
        "dr_restore_valid_recent": GOVERNANCE_GATE_REQUIRE_DR_RESTORE_VALID,
        "deploy_smoke_binding_recent": GOVERNANCE_GATE_REQUIRE_DEPLOY_SMOKE_BINDING,
        "weekly_streak_target_met": GOVERNANCE_GATE_REQUIRE_WEEKLY_STREAK,
        "security_risk_within_max": True,
    }

    rules: list[dict[str, Any]] = []

    def _append_rule(*, rule_id: str, required: bool, passed: bool, message: str, detail: dict[str, Any]) -> None:
        if passed:
            status = "pass"
        elif required:
            status = "fail"
        else:
            status = "warning"
        rules.append(
            {
                "id": rule_id,
                "required": required,
                "status": status,
                "passed": passed,
                "message": message,
                "detail": detail,
            }
        )

    preflight_ok = not bool(preflight.get("has_error", False))
    _append_rule(
        rule_id="preflight_no_error",
        required=required_rules["preflight_no_error"],
        passed=preflight_ok,
        message=(
            "Startup preflight has no blocking errors."
            if preflight_ok
            else "Startup preflight has blocking errors."
        ),
        detail={
            "overall_status": preflight.get("overall_status"),
            "error_count": int(preflight.get("error_count") or 0),
            "warning_count": int(preflight.get("warning_count") or 0),
        },
    )

    runbook_checks = runbook.get("checks", [])
    runbook_critical_count = sum(1 for item in runbook_checks if str(item.get("status") or "") == "critical")
    runbook_ok = runbook_critical_count == 0
    _append_rule(
        rule_id="runbook_no_critical",
        required=required_rules["runbook_no_critical"],
        passed=runbook_ok,
        message=(
            "Runbook checks have no critical items."
            if runbook_ok
            else f"Runbook checks include {runbook_critical_count} critical item(s)."
        ),
        detail={
            "overall_status": runbook.get("overall_status"),
            "critical_count": runbook_critical_count,
            "check_count": len(runbook_checks),
        },
    )

    security_risk_level = _normalize_governance_risk_level((security_dashboard.get("risk") or {}).get("level"))
    security_risk_ok = _governance_risk_rank(security_risk_level) <= _governance_risk_rank(max_risk_level)
    _append_rule(
        rule_id="security_risk_within_max",
        required=required_rules["security_risk_within_max"],
        passed=security_risk_ok,
        message=(
            "Admin security risk level is within configured ceiling."
            if security_risk_ok
            else "Admin security risk level exceeds configured ceiling."
        ),
        detail={
            "risk_level": security_risk_level,
            "risk_score": int((security_dashboard.get("risk") or {}).get("score") or 0),
            "max_risk_level": max_risk_level,
            "window_days": int(security_dashboard.get("window_days") or GOVERNANCE_GATE_SECURITY_DASHBOARD_DAYS),
        },
    )

    daily_cutoff = checked_at - timedelta(hours=max(1, GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS))
    daily_latest_finished = (
        daily_latest_model.finished_at
        if daily_latest_model is not None
        else None
    )
    daily_recent_ok = daily_latest_finished is not None and daily_latest_finished >= daily_cutoff
    _append_rule(
        rule_id="daily_check_recent",
        required=required_rules["daily_check_recent"],
        passed=daily_recent_ok,
        message=(
            "Ops daily check has a recent run."
            if daily_recent_ok
            else f"No ops daily check run in last {max(1, GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS)} hour(s)."
        ),
        detail={
            "max_age_hours": max(1, GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS),
            "latest_run_at": daily_latest_finished.isoformat() if daily_latest_finished is not None else None,
            "latest_status": daily_latest_model.status if daily_latest_model is not None else None,
        },
    )

    dr_cutoff = checked_at - timedelta(days=max(1, GOVERNANCE_GATE_DR_MAX_AGE_DAYS))
    dr_latest_finished = _as_optional_datetime(dr_latest.get("finished_at")) if isinstance(dr_latest, dict) else None
    dr_recent_ok = dr_latest_finished is not None and dr_latest_finished >= dr_cutoff
    dr_restore_valid = bool(dr_latest.get("restore_valid", False)) if isinstance(dr_latest, dict) else False
    dr_rule_ok = dr_recent_ok and dr_restore_valid
    if not DR_REHEARSAL_ENABLED:
        dr_rule_ok = not required_rules["dr_restore_valid_recent"]
    _append_rule(
        rule_id="dr_restore_valid_recent",
        required=required_rules["dr_restore_valid_recent"],
        passed=dr_rule_ok,
        message=(
            "Recent DR rehearsal restore validation is successful."
            if dr_rule_ok
            else (
                "DR rehearsal is disabled."
                if not DR_REHEARSAL_ENABLED
                else "Recent DR rehearsal with restore_valid=true is required."
            )
        ),
        detail={
            "enabled": DR_REHEARSAL_ENABLED,
            "max_age_days": max(1, GOVERNANCE_GATE_DR_MAX_AGE_DAYS),
            "latest_run_at": dr_latest_finished.isoformat() if dr_latest_finished is not None else None,
            "latest_status": dr_latest.get("status") if isinstance(dr_latest, dict) else None,
            "latest_restore_valid": dr_restore_valid,
        },
    )

    deploy_cutoff = checked_at - timedelta(hours=max(1, GOVERNANCE_GATE_DEPLOY_SMOKE_MAX_AGE_HOURS))
    deploy_latest_finished = deploy_latest_model.finished_at if deploy_latest_model is not None else None
    deploy_recent_ok = deploy_latest_finished is not None and deploy_latest_finished >= deploy_cutoff
    deploy_rollback_ready = bool(deploy_latest_detail.get("rollback_ready", False))
    deploy_runbook_gate = bool(deploy_latest_detail.get("runbook_gate_passed", False))
    deploy_reference_match = bool(deploy_latest_detail.get("rollback_reference_match", False))
    deploy_sha_match_raw = deploy_latest_detail.get("rollback_reference_sha256_match")
    deploy_sha_match = (deploy_sha_match_raw is True) if deploy_sha_match_raw is not None else False
    deploy_binding_ok = (
        deploy_recent_ok
        and deploy_rollback_ready
        and deploy_reference_match
        and deploy_sha_match
        and ((not DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE) or deploy_runbook_gate)
    )
    _append_rule(
        rule_id="deploy_smoke_binding_recent",
        required=required_rules["deploy_smoke_binding_recent"],
        passed=deploy_binding_ok,
        message=(
            "Recent deploy smoke rollback binding is valid."
            if deploy_binding_ok
            else "Recent deploy smoke rollback binding validation is required."
        ),
        detail={
            "max_age_hours": max(1, GOVERNANCE_GATE_DEPLOY_SMOKE_MAX_AGE_HOURS),
            "latest_run_at": deploy_latest_finished.isoformat() if deploy_latest_finished is not None else None,
            "latest_status": deploy_latest_model.status if deploy_latest_model is not None else None,
            "rollback_ready": deploy_rollback_ready,
            "runbook_gate_passed": deploy_runbook_gate,
            "rollback_reference_match": deploy_reference_match,
            "rollback_reference_sha256_match": deploy_sha_match_raw,
        },
    )

    streak_met = bool(weekly_streak.get("target_met", False))
    _append_rule(
        rule_id="weekly_streak_target_met",
        required=required_rules["weekly_streak_target_met"],
        passed=streak_met,
        message=(
            "Ops quality weekly streak target is met."
            if streak_met
            else "Ops quality weekly streak target is not met."
        ),
        detail={
            "current_streak_weeks": int(weekly_streak.get("current_streak_weeks") or 0),
            "target_weeks": int(weekly_streak.get("target_weeks") or 0),
        },
    )

    failure_count = sum(1 for rule in rules if rule["status"] == "fail")
    warning_count = sum(1 for rule in rules if rule["status"] == "warning")
    decision = "go"
    if failure_count > 0 or (not GOVERNANCE_GATE_ALLOW_WARNING and warning_count > 0):
        decision = "no_go"
    summary = {
        "total_rules": len(rules),
        "required_rules": sum(1 for rule in rules if bool(rule.get("required"))),
        "passed_rules": sum(1 for rule in rules if rule["status"] == "pass"),
        "failure_count": failure_count,
        "warning_count": warning_count,
    }
    return {
        "generated_at": checked_at.isoformat(),
        "decision": decision,
        "summary": summary,
        "rules": rules,
        "policy": {
            "allow_warning": GOVERNANCE_GATE_ALLOW_WARNING,
            "max_security_risk_level": max_risk_level,
            "require_preflight_no_error": required_rules["preflight_no_error"],
            "require_runbook_no_critical": required_rules["runbook_no_critical"],
            "require_daily_check_recent": required_rules["daily_check_recent"],
            "daily_check_max_age_hours": max(1, GOVERNANCE_GATE_DAILY_CHECK_MAX_AGE_HOURS),
            "require_dr_restore_valid_recent": required_rules["dr_restore_valid_recent"],
            "dr_max_age_days": max(1, GOVERNANCE_GATE_DR_MAX_AGE_DAYS),
            "require_deploy_smoke_binding_recent": required_rules["deploy_smoke_binding_recent"],
            "deploy_smoke_max_age_hours": max(1, GOVERNANCE_GATE_DEPLOY_SMOKE_MAX_AGE_HOURS),
            "require_weekly_streak_target_met": required_rules["weekly_streak_target_met"],
            "security_dashboard_days": max(7, GOVERNANCE_GATE_SECURITY_DASHBOARD_DAYS),
        },
    }


def run_ops_governance_gate_job(*, trigger: str = "manual") -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    snapshot = _build_ops_governance_gate_snapshot(now=started_at)
    summary = snapshot.get("summary", {}) if isinstance(snapshot.get("summary"), dict) else {}
    failure_count = int(summary.get("failure_count") or 0)
    warning_count = int(summary.get("warning_count") or 0)
    decision = str(snapshot.get("decision") or "no_go")
    if decision == "no_go":
        status = "critical"
    elif warning_count > 0:
        status = "warning"
    else:
        status = "success"
    finished_at = datetime.now(timezone.utc)
    detail = {
        **snapshot,
        "decision": decision,
        "failure_count": failure_count,
        "warning_count": warning_count,
    }
    run_id = _write_job_run(
        job_name=OPS_GOVERNANCE_GATE_JOB_NAME,
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )
    return {
        "run_id": run_id,
        "job_name": OPS_GOVERNANCE_GATE_JOB_NAME,
        "trigger": trigger,
        "status": status,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        **snapshot,
    }


def _latest_ops_governance_gate_payload() -> dict[str, Any] | None:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == OPS_GOVERNANCE_GATE_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        return None
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    return {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        **detail,
    }


def _governance_remediation_owner_and_sla(rule_id: str) -> tuple[str, int]:
    owner_sla_map: dict[str, tuple[str, int]] = {
        "preflight_no_error": ("Platform Owner", 4),
        "runbook_no_critical": ("Ops Lead", 4),
        "security_risk_within_max": ("Security Manager", 8),
        "daily_check_recent": ("Ops PM", 12),
        "dr_restore_valid_recent": ("DR Owner", 24),
        "deploy_smoke_binding_recent": ("Release Manager", 8),
        "weekly_streak_target_met": ("Operations Excellence Lead", 24),
    }
    return owner_sla_map.get(rule_id, ("Ops Manager", 24))


def _governance_remediation_action(rule_id: str, default_message: str) -> str:
    actions = {
        "preflight_no_error": " ENV/     preflight ",
        "runbook_no_critical": "critical       ",
        "security_risk_within_max": "    /   ",
        "daily_check_recent": "ops daily check       ",
        "dr_restore_valid_recent": "DR   restore_valid=true  ",
        "deploy_smoke_binding_recent": "     /  ",
        "weekly_streak_target_met": "   cadence  streak  ",
    }
    return actions.get(rule_id, default_message or "     ")


def _governance_rule_priority(rule_status: str, required: bool) -> int:
    if rule_status == "fail":
        return 1 if required else 2
    if rule_status == "warning":
        return 3 if required else 4
    return 9


def _build_ops_governance_remediation_plan(
    *,
    snapshot: dict[str, Any],
    include_warnings: bool = True,
    max_items: int = OPS_GOVERNANCE_REMEDIATION_DEFAULT_MAX_ITEMS,
) -> dict[str, Any]:
    generated_at_raw = snapshot.get("generated_at")
    generated_at = _as_optional_datetime(generated_at_raw) or datetime.now(timezone.utc)
    decision = str(snapshot.get("decision") or "no_go")
    rules = snapshot.get("rules") if isinstance(snapshot.get("rules"), list) else []
    normalized_max = max(1, min(int(max_items), 200))

    items: list[dict[str, Any]] = []
    for rule in rules:
        if not isinstance(rule, dict):
            continue
        status = str(rule.get("status") or "").strip().lower()
        if status == "pass":
            continue
        if status == "warning" and (not include_warnings):
            continue
        rule_id = str(rule.get("id") or "")
        required = bool(rule.get("required", False))
        owner_role, sla_hours = _governance_remediation_owner_and_sla(rule_id)
        due_at = generated_at + timedelta(hours=max(1, sla_hours))
        detail = rule.get("detail") if isinstance(rule.get("detail"), dict) else {}
        items.append(
            {
                "rule_id": rule_id,
                "rule_status": status,
                "required": required,
                "priority": _governance_rule_priority(status, required),
                "owner_role": owner_role,
                "sla_hours": max(1, sla_hours),
                "due_at": due_at.isoformat(),
                "action": _governance_remediation_action(rule_id, str(rule.get("message") or "")),
                "reason": str(rule.get("message") or ""),
                "detail": detail,
            }
        )

    items.sort(
        key=lambda item: (
            int(item.get("priority") or 9),
            int(item.get("sla_hours") or 24),
            str(item.get("rule_id") or ""),
        )
    )
    trimmed = items[:normalized_max]
    for idx, item in enumerate(trimmed, start=1):
        item["item_id"] = f"GR-{idx:03d}"

    fail_count = sum(1 for item in items if str(item.get("rule_status")) == "fail")
    warning_count = sum(1 for item in items if str(item.get("rule_status")) == "warning")
    return {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "gate_generated_at": generated_at.isoformat(),
        "decision": decision,
        "include_warnings": include_warnings,
        "max_items": normalized_max,
        "summary": {
            "total_candidates": len(items),
            "fail_count": fail_count,
            "warning_count": warning_count,
            "item_count": len(trimmed),
            "critical_path_count": sum(
                1
                for item in trimmed
                if str(item.get("rule_status")) == "fail" and bool(item.get("required"))
            ),
        },
        "items": trimmed,
    }


def _build_ops_governance_remediation_csv(plan: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "item_id",
            "rule_id",
            "rule_status",
            "required",
            "priority",
            "owner_role",
            "sla_hours",
            "due_at",
            "action",
            "reason",
        ]
    )
    for item in plan.get("items", []):
        if not isinstance(item, dict):
            continue
        writer.writerow(
            [
                item.get("item_id"),
                item.get("rule_id"),
                item.get("rule_status"),
                bool(item.get("required", False)),
                item.get("priority"),
                item.get("owner_role"),
                item.get("sla_hours"),
                item.get("due_at"),
                item.get("action"),
                item.get("reason"),
            ]
        )
    return out.getvalue()


def _normalize_w21_tracker_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W21_TRACKER_STATUS_SET:
        return value
    return W21_TRACKER_STATUS_PENDING


def _resolve_w21_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W21_COMPLETION_STATUS_SET:
        return value
    return W21_COMPLETION_STATUS_ACTIVE


def _row_to_w21_remediation_item_model(row: dict[str, Any]) -> W21RemediationTrackerItemRead:
    raw_detail = str(row.get("detail_json") or "{}")
    try:
        detail = json.loads(raw_detail)
    except json.JSONDecodeError:
        detail = {}
    if not isinstance(detail, dict):
        detail = {}
    due_at = _as_optional_datetime(row.get("due_at")) or datetime.now(timezone.utc)
    gate_generated_at = _as_optional_datetime(row.get("gate_generated_at")) or due_at
    return W21RemediationTrackerItemRead(
        id=int(row["id"]),
        item_id=str(row.get("item_id") or ""),
        rule_id=str(row.get("rule_id") or ""),
        rule_status=str(row.get("rule_status") or "warning"),
        required=bool(row.get("required", False)),
        priority=int(row.get("priority") or 9),
        owner_role=str(row.get("owner_role") or ""),
        sla_hours=max(1, int(row.get("sla_hours") or 24)),
        due_at=due_at,
        action=str(row.get("action") or ""),
        reason=str(row.get("reason") or ""),
        detail=detail,
        assignee=row.get("assignee"),
        status=_normalize_w21_tracker_status(row.get("status")),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        is_active=bool(row.get("is_active", True)),
        gate_generated_at=gate_generated_at,
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _load_w21_remediation_items(*, include_inactive: bool = False) -> list[W21RemediationTrackerItemRead]:
    stmt = select(ops_governance_remediation_tracker_items)
    if not include_inactive:
        stmt = stmt.where(ops_governance_remediation_tracker_items.c.is_active.is_(True))
    stmt = stmt.order_by(
        ops_governance_remediation_tracker_items.c.is_active.desc(),
        ops_governance_remediation_tracker_items.c.priority.asc(),
        ops_governance_remediation_tracker_items.c.due_at.asc(),
        ops_governance_remediation_tracker_items.c.id.asc(),
    )
    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w21_remediation_item_model(row) for row in rows]


def _compute_w21_remediation_overview(
    *,
    active_rows: list[W21RemediationTrackerItemRead],
    active_count: int,
    closed_count: int,
    checked_at: datetime | None = None,
) -> W21RemediationTrackerOverviewRead:
    now = checked_at or datetime.now(timezone.utc)
    pending_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_BLOCKED)
    total_items = len(active_rows)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 100
    missing_assignee_count = sum(1 for row in active_rows if not (row.assignee or "").strip())
    critical_open_count = sum(
        1
        for row in active_rows
        if row.rule_status == "fail" and bool(row.required) and row.status != W21_TRACKER_STATUS_DONE
    )
    overdue_count = sum(1 for row in active_rows if row.status != W21_TRACKER_STATUS_DONE and row.due_at < now)
    return W21RemediationTrackerOverviewRead(
        generated_at=now,
        total_items=total_items,
        active_count=active_count,
        closed_count=closed_count,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        missing_assignee_count=missing_assignee_count,
        critical_open_count=critical_open_count,
        overdue_count=overdue_count,
    )


def _compute_w21_remediation_readiness(
    *,
    active_rows: list[W21RemediationTrackerItemRead],
    checked_at: datetime | None = None,
) -> W21RemediationTrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    pending_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in active_rows if row.status == W21_TRACKER_STATUS_BLOCKED)
    total_items = len(active_rows)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 100
    missing_assignee_count = sum(1 for row in active_rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in active_rows if not bool(row.completion_checked))
    critical_open_count = sum(
        1
        for row in active_rows
        if row.rule_status == "fail" and bool(row.required) and row.status != W21_TRACKER_STATUS_DONE
    )
    overdue_count = sum(1 for row in active_rows if row.status != W21_TRACKER_STATUS_DONE and row.due_at < now)

    blockers: list[str] = []
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if critical_open_count > 0:
        blockers.append(f" fail    {critical_open_count} .")
    if overdue_count > 0:
        blockers.append(f"SLA     {overdue_count} .")

    if total_items == 0:
        readiness_score_percent = 100
        ready = True
    else:
        checks = [
            pending_count == 0,
            in_progress_count == 0,
            blocked_count == 0,
            missing_assignee_count == 0,
            missing_completion_checked_count == 0,
            critical_open_count == 0,
            overdue_count == 0,
        ]
        readiness_score_percent = int(round((sum(1 for ok in checks if ok) / len(checks)) * 100))
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
        ready = len(blockers) == 0
        if ready:
            readiness_score_percent = 100

    return W21RemediationTrackerReadinessRead(
        generated_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        critical_open_count=critical_open_count,
        overdue_count=overdue_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _row_to_w21_completion_model(
    *,
    readiness: W21RemediationTrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W21RemediationTrackerCompletionRead:
    if row is None:
        return W21RemediationTrackerCompletionRead(
            status=W21_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.generated_at,
            readiness=readiness,
        )
    return W21RemediationTrackerCompletionRead(
        status=_resolve_w21_completion_status(row.get("status")),
        completion_note=str(row.get("completion_note") or ""),
        completed_by=row.get("completed_by"),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        force_used=bool(row.get("force_used", False)),
        last_checked_at=_as_optional_datetime(row.get("last_checked_at")) or readiness.generated_at,
        readiness=readiness,
    )


def _reset_w21_completion_if_closed(
    *,
    conn: Any,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(ops_governance_remediation_tracker_runs)
        .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w21_completion_status(row.get("status"))
    if status == W21_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(ops_governance_remediation_tracker_runs)
        .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
        .values(
            status=W21_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _sync_w21_remediation_tracker(
    *,
    actor_username: str,
    include_warnings: bool,
    max_items: int,
) -> W21RemediationTrackerSyncResponse:
    snapshot = _build_ops_governance_gate_snapshot()
    plan = _build_ops_governance_remediation_plan(
        snapshot=snapshot,
        include_warnings=include_warnings,
        max_items=max_items,
    )
    plan_items = [item for item in plan.get("items", []) if isinstance(item, dict)]
    decision = str(plan.get("decision") or "no_go")
    gate_generated_at = _as_optional_datetime(plan.get("gate_generated_at")) or datetime.now(timezone.utc)
    now = datetime.now(timezone.utc)

    created_count = 0
    reopened_count = 0
    resolved_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(select(ops_governance_remediation_tracker_items)).mappings().all()
        existing_by_rule = {
            str(row.get("rule_id") or "").strip(): row
            for row in existing_rows
            if str(row.get("rule_id") or "").strip()
        }
        seen_rule_ids: set[str] = set()

        for item in plan_items:
            rule_id = str(item.get("rule_id") or "").strip()
            if not rule_id:
                continue
            seen_rule_ids.add(rule_id)
            due_at = _as_optional_datetime(item.get("due_at")) or now
            current = existing_by_rule.get(rule_id)
            if current is None:
                conn.execute(
                    insert(ops_governance_remediation_tracker_items).values(
                        item_id=str(item.get("item_id") or ""),
                        rule_id=rule_id,
                        rule_status=str(item.get("rule_status") or "warning"),
                        required=bool(item.get("required", False)),
                        priority=max(1, int(item.get("priority") or 9)),
                        owner_role=str(item.get("owner_role") or "Ops Manager"),
                        sla_hours=max(1, int(item.get("sla_hours") or 24)),
                        due_at=due_at,
                        action=str(item.get("action") or ""),
                        reason=str(item.get("reason") or ""),
                        detail_json=_to_json_text(item.get("detail") if isinstance(item.get("detail"), dict) else {}),
                        gate_generated_at=gate_generated_at,
                        source_decision=decision,
                        assignee=None,
                        status=W21_TRACKER_STATUS_PENDING,
                        completion_checked=False,
                        completion_note="",
                        completed_at=None,
                        is_active=True,
                        created_by=actor_username,
                        updated_by=actor_username,
                        created_at=now,
                        updated_at=now,
                    )
                )
                created_count += 1
                continue

            next_status = _normalize_w21_tracker_status(current.get("status"))
            next_checked = bool(current.get("completion_checked", False))
            next_note = str(current.get("completion_note") or "")
            next_completed_at = _as_optional_datetime(current.get("completed_at"))
            was_inactive = not bool(current.get("is_active", True))
            if was_inactive and next_status == W21_TRACKER_STATUS_DONE:
                next_status = W21_TRACKER_STATUS_PENDING
                next_checked = False
                next_completed_at = None
                reopen_note = f"[auto-reopened {now.isoformat()}] governance gate rule is active again."
                next_note = f"{next_note}\n{reopen_note}".strip() if next_note else reopen_note
                reopened_count += 1

            conn.execute(
                update(ops_governance_remediation_tracker_items)
                .where(ops_governance_remediation_tracker_items.c.id == int(current["id"]))
                .values(
                    item_id=str(item.get("item_id") or ""),
                    rule_status=str(item.get("rule_status") or "warning"),
                    required=bool(item.get("required", False)),
                    priority=max(1, int(item.get("priority") or 9)),
                    owner_role=str(item.get("owner_role") or "Ops Manager"),
                    sla_hours=max(1, int(item.get("sla_hours") or 24)),
                    due_at=due_at,
                    action=str(item.get("action") or ""),
                    reason=str(item.get("reason") or ""),
                    detail_json=_to_json_text(item.get("detail") if isinstance(item.get("detail"), dict) else {}),
                    gate_generated_at=gate_generated_at,
                    source_decision=decision,
                    status=next_status,
                    completion_checked=next_checked,
                    completion_note=next_note,
                    completed_at=next_completed_at,
                    is_active=True,
                    updated_by=actor_username,
                    updated_at=now,
                )
            )

        for row in existing_rows:
            rule_id = str(row.get("rule_id") or "").strip()
            if not rule_id or rule_id in seen_rule_ids:
                continue
            if not bool(row.get("is_active", True)):
                continue
            next_status = _normalize_w21_tracker_status(row.get("status"))
            next_checked = bool(row.get("completion_checked", False))
            next_note = str(row.get("completion_note") or "")
            next_completed_at = _as_optional_datetime(row.get("completed_at"))
            if next_status != W21_TRACKER_STATUS_DONE:
                next_status = W21_TRACKER_STATUS_DONE
                next_checked = True
                next_completed_at = now
                close_note = (
                    f"[auto-resolved {now.isoformat()}] current governance gate snapshot no longer requires this rule."
                )
                next_note = f"{next_note}\n{close_note}".strip() if next_note else close_note
            conn.execute(
                update(ops_governance_remediation_tracker_items)
                .where(ops_governance_remediation_tracker_items.c.id == int(row["id"]))
                .values(
                    is_active=False,
                    status=next_status,
                    completion_checked=next_checked,
                    completion_note=next_note,
                    completed_at=next_completed_at,
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
            resolved_count += 1

        if created_count > 0 or reopened_count > 0 or resolved_count > 0:
            _reset_w21_completion_if_closed(
                conn=conn,
                actor_username=actor_username,
                checked_at=now,
                reason="tracker synchronized with latest governance remediation plan",
            )

        active_rows = conn.execute(
            select(ops_governance_remediation_tracker_items)
            .where(ops_governance_remediation_tracker_items.c.is_active.is_(True))
            .order_by(
                ops_governance_remediation_tracker_items.c.priority.asc(),
                ops_governance_remediation_tracker_items.c.due_at.asc(),
                ops_governance_remediation_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    active_models = [_row_to_w21_remediation_item_model(row) for row in active_rows]
    return W21RemediationTrackerSyncResponse(
        generated_at=now,
        gate_generated_at=gate_generated_at,
        decision=decision,
        include_warnings=include_warnings,
        max_items=max(1, min(int(max_items), 200)),
        synced_count=len(active_models),
        created_count=created_count,
        reopened_count=reopened_count,
        resolved_count=resolved_count,
        active_count=len(active_models),
        items=active_models,
    )


def _build_w22_remediation_sla_snapshot(
    *,
    due_soon_hours: int = 24,
    now: datetime | None = None,
) -> dict[str, Any]:
    checked_at = now or datetime.now(timezone.utc)
    normalized_due_soon_hours = max(0, min(int(due_soon_hours), 168))
    due_soon_cutoff = checked_at + timedelta(hours=normalized_due_soon_hours)
    rows = _load_w21_remediation_items(include_inactive=False)

    pending_count = sum(1 for row in rows if row.status == W21_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W21_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W21_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W21_TRACKER_STATUS_BLOCKED)
    open_rows = [row for row in rows if row.status != W21_TRACKER_STATUS_DONE]

    overdue_rows = [row for row in open_rows if row.due_at < checked_at]
    if normalized_due_soon_hours > 0:
        due_soon_rows = [row for row in open_rows if checked_at <= row.due_at <= due_soon_cutoff]
    else:
        due_soon_rows = []
    critical_open_rows = [row for row in open_rows if row.rule_status == "fail" and bool(row.required)]
    unassigned_open_rows = [row for row in open_rows if not (row.assignee or "").strip()]

    assignee_open_counts: dict[str, int] = {}
    for row in open_rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_open_counts[assignee] = assignee_open_counts.get(assignee, 0) + 1

    top_risk_rows = sorted(
        open_rows,
        key=lambda row: (int(row.priority), row.due_at, int(row.id)),
    )[:10]
    top_risk_items = [
        {
            "id": int(row.id),
            "item_id": row.item_id,
            "rule_id": row.rule_id,
            "rule_status": row.rule_status,
            "required": bool(row.required),
            "priority": int(row.priority),
            "assignee": row.assignee,
            "status": row.status,
            "due_at": row.due_at.isoformat(),
            "minutes_until_due": int(round((row.due_at - checked_at).total_seconds() / 60.0)),
        }
        for row in top_risk_rows
    ]

    completion_rate_percent = int(round((done_count / len(rows)) * 100)) if rows else 100
    return {
        "generated_at": checked_at.isoformat(),
        "due_soon_hours": normalized_due_soon_hours,
        "metrics": {
            "total_items": len(rows),
            "open_items": len(open_rows),
            "pending_count": pending_count,
            "in_progress_count": in_progress_count,
            "done_count": done_count,
            "blocked_count": blocked_count,
            "completion_rate_percent": completion_rate_percent,
            "overdue_count": len(overdue_rows),
            "due_soon_count": len(due_soon_rows),
            "critical_open_count": len(critical_open_rows),
            "unassigned_open_count": len(unassigned_open_rows),
        },
        "assignee_open_counts": assignee_open_counts,
        "top_risk_items": top_risk_items,
    }


def run_ops_governance_remediation_escalation_job(
    *,
    trigger: str = "manual",
    dry_run: bool = False,
    include_due_soon_hours: int | None = None,
    notify_enabled: bool | None = None,
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    normalized_due_soon_hours = (
        GOVERNANCE_REMEDIATION_ESCALATION_DUE_SOON_HOURS
        if include_due_soon_hours is None
        else max(0, min(int(include_due_soon_hours), 168))
    )
    effective_notify_enabled = (
        GOVERNANCE_REMEDIATION_ESCALATION_NOTIFY_ENABLED
        if notify_enabled is None
        else bool(notify_enabled)
    )
    snapshot = _build_w22_remediation_sla_snapshot(
        due_soon_hours=normalized_due_soon_hours,
        now=started_at,
    )

    rows = _load_w21_remediation_items(include_inactive=False)
    cutoff = started_at + timedelta(hours=normalized_due_soon_hours)
    if normalized_due_soon_hours > 0:
        candidate_rows = [row for row in rows if row.status != W21_TRACKER_STATUS_DONE and row.due_at <= cutoff]
    else:
        candidate_rows = [row for row in rows if row.status != W21_TRACKER_STATUS_DONE and row.due_at < started_at]

    candidate_rows.sort(key=lambda row: (int(row.priority), row.due_at, int(row.id)))
    candidate_count = len(candidate_rows)
    critical_count = sum(
        1 for row in candidate_rows if row.rule_status == "fail" and bool(row.required)
    )

    notify_attempted = False
    notify_dispatched = False
    notify_error: str | None = None
    notify_channels: list[SlaAlertChannelResult] = []

    if (
        GOVERNANCE_REMEDIATION_ESCALATION_ENABLED
        and (not dry_run)
        and effective_notify_enabled
        and candidate_count > 0
    ):
        notify_attempted = True
        payload = {
            "event": OPS_GOVERNANCE_REMEDIATION_ESCALATION_EVENT_TYPE,
            "job_name": OPS_GOVERNANCE_REMEDIATION_ESCALATION_JOB_NAME,
            "checked_at": started_at.isoformat(),
            "dry_run": bool(dry_run),
            "due_soon_hours": normalized_due_soon_hours,
            "candidate_count": candidate_count,
            "critical_count": critical_count,
            "items": [
                {
                    "id": int(row.id),
                    "item_id": row.item_id,
                    "rule_id": row.rule_id,
                    "priority": int(row.priority),
                    "due_at": row.due_at.isoformat(),
                    "assignee": row.assignee,
                    "status": row.status,
                }
                for row in candidate_rows[:20]
            ],
        }
        notify_dispatched, notify_error, notify_channels = _dispatch_alert_event(
            event_type=OPS_GOVERNANCE_REMEDIATION_ESCALATION_EVENT_TYPE,
            payload=payload,
        )

    if not GOVERNANCE_REMEDIATION_ESCALATION_ENABLED:
        status = "warning"
    elif candidate_count == 0:
        status = "success"
    elif critical_count > 0:
        status = "critical"
    else:
        status = "warning"

    finished_at = datetime.now(timezone.utc)
    detail = {
        "enabled": GOVERNANCE_REMEDIATION_ESCALATION_ENABLED,
        "due_soon_hours": normalized_due_soon_hours,
        "notify_enabled": effective_notify_enabled,
        "dry_run": bool(dry_run),
        "snapshot": snapshot,
        "candidate_count": candidate_count,
        "critical_count": critical_count,
        "notify_attempted": notify_attempted,
        "notify_dispatched": notify_dispatched,
        "notify_error": notify_error,
        "notify_channels": [item.model_dump() for item in notify_channels],
        "items": [
            {
                "id": int(row.id),
                "item_id": row.item_id,
                "rule_id": row.rule_id,
                "rule_status": row.rule_status,
                "required": bool(row.required),
                "priority": int(row.priority),
                "assignee": row.assignee,
                "status": row.status,
                "due_at": row.due_at.isoformat(),
            }
            for row in candidate_rows[:50]
        ],
    }
    run_id = _write_job_run(
        job_name=OPS_GOVERNANCE_REMEDIATION_ESCALATION_JOB_NAME,
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )
    return {
        "run_id": run_id,
        "job_name": OPS_GOVERNANCE_REMEDIATION_ESCALATION_JOB_NAME,
        "trigger": trigger,
        "status": status,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        **detail,
    }


def _latest_ops_governance_remediation_escalation_payload() -> dict[str, Any] | None:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == OPS_GOVERNANCE_REMEDIATION_ESCALATION_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        return None
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    return {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        **detail,
    }


def _rate_limit_identity(request: Request) -> tuple[str, bool]:
    token = request.headers.get("x-admin-token", "").strip()
    if token:
        # Token hash prefix avoids storing raw secrets in keys/metrics.
        return f"auth:{_hash_token(token)[:16]}", True
    client_host = request.client.host if request.client is not None else "unknown"
    return f"ip:{client_host}", False


def _rate_limit_policy_for_request(request: Request, *, is_auth: bool) -> tuple[str, int]:
    path = request.url.path
    method = request.method.upper()
    if is_auth:
        if method == "GET" and (
            path.endswith("/completion-package")
            or path.endswith("/archive.csv")
            or path.endswith("/download")
        ):
            return "auth-heavy", API_RATE_LIMIT_MAX_AUTH_HEAVY
        if method == "POST" and (
            ("/api/adoption/w02/tracker/items/" in path and path.endswith("/evidence"))
            or ("/api/adoption/w03/tracker/items/" in path and path.endswith("/evidence"))
            or ("/api/adoption/w04/tracker/items/" in path and path.endswith("/evidence"))
            or ("/api/adoption/w07/tracker/items/" in path and path.endswith("/evidence"))
            or ("/api/adoption/w09/tracker/items/" in path and path.endswith("/evidence"))
        ):
            return "auth-upload", API_RATE_LIMIT_MAX_AUTH_UPLOAD
        if path.startswith("/api/admin/"):
            return "auth-admin", API_RATE_LIMIT_MAX_AUTH_ADMIN
        if method in {"POST", "PUT", "PATCH", "DELETE"}:
            return "auth-write", API_RATE_LIMIT_MAX_AUTH_WRITE
        return "auth-read", API_RATE_LIMIT_MAX_AUTH
    if path.endswith("/csv") or path.endswith("/pdf") or path.endswith("/ics"):
        return "public-heavy", API_RATE_LIMIT_MAX_PUBLIC_HEAVY
    return "public-read", API_RATE_LIMIT_MAX_PUBLIC


def _check_api_rate_limit_memory(*, key: str, max_requests: int, window_sec: int) -> tuple[bool, int, int]:
    now = time.monotonic()
    with _RATE_LIMIT_LOCK:
        bucket = _RATE_LIMIT_BUCKETS.get(key)
        if bucket is None:
            bucket = deque()
            _RATE_LIMIT_BUCKETS[key] = bucket

        cutoff = now - float(window_sec)
        while bucket and bucket[0] <= cutoff:
            bucket.popleft()

        if len(bucket) >= max_requests:
            wait = max(1, int(math.ceil(float(window_sec) - (now - bucket[0]))))
            return False, 0, wait

        bucket.append(now)
        remaining = max(0, max_requests - len(bucket))
        reset = max(1, int(math.ceil(float(window_sec) - (now - bucket[0]))))
        return True, remaining, reset


def _check_api_rate_limit_redis(*, key_base: str, max_requests: int, window_sec: int) -> tuple[bool, int, int] | None:
    if _RATE_LIMIT_REDIS is None:
        return None
    try:
        window_idx = int(time.time() // window_sec)
        redis_key = f"{key_base}:{window_idx}"
        count = int(_RATE_LIMIT_REDIS.incr(redis_key))
        ttl = int(_RATE_LIMIT_REDIS.ttl(redis_key))
        if ttl <= 0:
            _RATE_LIMIT_REDIS.expire(redis_key, window_sec + 1)
            ttl = window_sec
        allowed = count <= max_requests
        remaining = max(0, max_requests - count)
        reset = max(1, ttl)
        return allowed, remaining, reset
    except Exception:
        return None


def _check_api_rate_limit(*, key_base: str, max_requests: int, window_sec: int) -> tuple[bool, int, int, str]:
    backend = "memory"
    if API_RATE_LIMIT_STORE in {"redis", "auto"}:
        redis_result = _check_api_rate_limit_redis(
            key_base=key_base,
            max_requests=max_requests,
            window_sec=window_sec,
        )
        if redis_result is not None:
            allowed, remaining, reset = redis_result
            return allowed, remaining, reset, "redis"
    allowed, remaining, reset = _check_api_rate_limit_memory(
        key=key_base,
        max_requests=max_requests,
        window_sec=window_sec,
    )
    return allowed, remaining, reset, backend


@app.middleware("http")
async def browser_json_to_html_middleware(request: Request, call_next: Callable[[Request], Any]) -> Any:
    response = await call_next(request)
    if request.method != "GET":
        return response
    if request.query_params.get("raw") == "1":
        return response
    if not request.url.path.startswith("/api/"):
        return response

    accept = request.headers.get("accept", "").lower()
    if "text/html" not in accept:
        return response

    content_type = response.headers.get("content-type", "").lower()
    if not content_type.startswith("application/json"):
        return response

    body = b""
    async for chunk in response.body_iterator:
        body += chunk

    payload: Any
    if body:
        try:
            payload = json.loads(body.decode("utf-8"))
        except json.JSONDecodeError:
            payload = body.decode("utf-8", errors="replace")
    else:
        payload = None

    path_label = request.url.path
    raw_href = f"{request.url.path}?raw=1"
    if request.url.query:
        path_label = f"{request.url.path}?{request.url.query}"
        raw_href = f"{request.url.path}?{request.url.query}&raw=1"

    return HTMLResponse(_build_browser_json_view_html(path_label, raw_href, response.status_code, payload), status_code=response.status_code)


@app.middleware("http")
async def api_rate_limit_middleware(request: Request, call_next: Callable[[Request], Any]) -> Any:
    if (
        not API_RATE_LIMIT_ENABLED
        or request.method.upper() == "OPTIONS"
        or not request.url.path.startswith("/api/")
    ):
        return await call_next(request)

    identity, is_auth = _rate_limit_identity(request)
    policy_name, limit = _rate_limit_policy_for_request(request, is_auth=is_auth)
    key_base = f"{API_RATE_LIMIT_REDIS_KEY_PREFIX}:{policy_name}:{identity}"
    allowed, remaining, reset_sec, backend = _check_api_rate_limit(
        key_base=key_base,
        max_requests=limit,
        window_sec=API_RATE_LIMIT_WINDOW_SEC,
    )
    headers = {
        "X-RateLimit-Limit": str(limit),
        "X-RateLimit-Remaining": str(max(0, remaining)),
        "X-RateLimit-Reset": str(reset_sec),
        "X-RateLimit-Policy": policy_name,
        "X-RateLimit-Backend": backend,
    }
    if not allowed:
        headers["Retry-After"] = str(reset_sec)
        return JSONResponse(
            status_code=429,
            content={"detail": "Rate limit exceeded"},
            headers=headers,
        )

    response = await call_next(request)
    for key, value in headers.items():
        response.headers.setdefault(key, value)
    return response


@app.middleware("http")
async def api_latency_monitor_middleware(request: Request, call_next: Callable[[Request], Any]) -> Any:
    should_track = API_LATENCY_MONITOR_ENABLED and request.method.upper() in {"GET", "POST", "PUT", "PATCH", "DELETE"}
    if not should_track:
        return await call_next(request)

    path = request.url.path
    method = request.method.upper()
    started = time.perf_counter()
    try:
        response = await call_next(request)
    except Exception:
        duration_ms = (time.perf_counter() - started) * 1000.0
        _record_api_latency_sample(
            method=method,
            path=path,
            duration_ms=duration_ms,
            status_code=500,
            is_error=True,
        )
        raise

    duration_ms = (time.perf_counter() - started) * 1000.0
    status_code = int(getattr(response, "status_code", 0) or 0)
    _record_api_latency_sample(
        method=method,
        path=path,
        duration_ms=duration_ms,
        status_code=status_code if status_code > 0 else None,
        is_error=status_code >= 500 if status_code > 0 else False,
    )
    response.headers.setdefault("X-Request-Duration-Ms", f"{round(duration_ms, 2)}")
    return response


@app.middleware("http")
async def security_headers_middleware(request: Request, call_next: Callable[[Request], Any]) -> Any:
    response = await call_next(request)

    for key, value in SECURITY_HEADERS_BASE.items():
        response.headers.setdefault(key, value)

    if ENV_NAME == "production" or request.url.scheme.lower() == "https":
        response.headers.setdefault("Strict-Transport-Security", "max-age=63072000; includeSubDomains; preload")

    if request.headers.get("x-admin-token", "").strip():
        response.headers.setdefault("Cache-Control", "no-store")
        response.headers.setdefault("Pragma", "no-cache")

    content_type = response.headers.get("content-type", "").lower()
    path = request.url.path
    if content_type.startswith("text/html") and (path == "/" or path.startswith("/web/") or path.startswith("/api/")):
        response.headers.setdefault("Content-Security-Policy", HTML_CSP_POLICY)

    return response


def _permission_text_to_list(value: Any) -> list[str]:
    if value is None:
        return []
    if isinstance(value, str):
        return [x.strip() for x in value.split(",") if x.strip()]
    if isinstance(value, list):
        return [str(x).strip() for x in value if str(x).strip()]
    return []


def _permission_list_to_text(values: list[str]) -> str:
    normalized = sorted({v.strip() for v in values if v.strip()})
    return ",".join(normalized)


def _site_scope_text_to_list(value: Any, *, default_all: bool = True) -> list[str]:
    if value is None:
        return [SITE_SCOPE_ALL] if default_all else []
    if isinstance(value, str):
        raw_values = [x.strip() for x in value.split(",") if x.strip()]
    elif isinstance(value, list):
        raw_values = [str(x).strip() for x in value if str(x).strip()]
    else:
        raw_values = []

    if not raw_values:
        return [SITE_SCOPE_ALL] if default_all else []
    if SITE_SCOPE_ALL in raw_values:
        return [SITE_SCOPE_ALL]
    return sorted(set(raw_values))


def _site_scope_list_to_text(values: list[str]) -> str:
    normalized = _site_scope_text_to_list(values, default_all=True)
    return ",".join(normalized)


def _resolve_effective_site_scope(
    *,
    user_scope: list[str],
    token_scope: list[str] | None,
) -> list[str]:
    normalized_user_scope = _site_scope_text_to_list(user_scope, default_all=True)
    if token_scope is None:
        return normalized_user_scope

    normalized_token_scope = _site_scope_text_to_list(token_scope, default_all=True)
    if SITE_SCOPE_ALL in normalized_user_scope:
        return normalized_token_scope
    if SITE_SCOPE_ALL in normalized_token_scope:
        return normalized_user_scope

    intersection = sorted(set(normalized_user_scope).intersection(normalized_token_scope))
    return intersection


def _principal_site_scope(principal: dict[str, Any]) -> list[str]:
    raw_scope = principal.get("site_scope", [SITE_SCOPE_ALL])
    return _site_scope_text_to_list(raw_scope, default_all=True)


def _allowed_sites_for_principal(principal: dict[str, Any]) -> list[str] | None:
    scope = _principal_site_scope(principal)
    if SITE_SCOPE_ALL in scope:
        return None
    return scope


def _has_site_access(principal: dict[str, Any], site: str | None) -> bool:
    if site is None:
        return True
    scope = _principal_site_scope(principal)
    if SITE_SCOPE_ALL in scope:
        return True
    return site in scope


def _require_site_access(principal: dict[str, Any], site: str | None) -> None:
    if not _has_site_access(principal, site):
        raise HTTPException(status_code=403, detail="Site access denied")


def _require_global_site_scope(principal: dict[str, Any]) -> None:
    if SITE_SCOPE_ALL not in _principal_site_scope(principal):
        raise HTTPException(status_code=403, detail="Global site scope required")


def _effective_permissions(role: str, custom: list[str]) -> list[str]:
    perms = set(ROLE_PERMISSION_MAP.get(role, set()))
    perms.update(custom)
    if role == "owner":
        perms.add("*")
    return sorted(perms)


def _hash_token(token: str) -> str:
    return hashlib.sha256(token.encode("utf-8")).hexdigest()


def _has_active_admin_tokens() -> bool:
    try:
        with get_conn() as conn:
            row = conn.execute(
                select(admin_tokens.c.id).where(admin_tokens.c.is_active.is_(True)).limit(1)
            ).first()
        return row is not None
    except SQLAlchemyError:
        return False


def ensure_legacy_admin_token_seed() -> None:
    if not ADMIN_TOKEN:
        return

    now = datetime.now(timezone.utc)
    token_hash = _hash_token(ADMIN_TOKEN)
    with get_conn() as conn:
        existing = conn.execute(
            select(admin_tokens.c.id).where(admin_tokens.c.token_hash == token_hash)
        ).first()
        if existing is not None:
            return

        user_row = conn.execute(
            select(admin_users).where(admin_users.c.username == "legacy-admin")
        ).mappings().first()
        if user_row is None:
            result = conn.execute(
                insert(admin_users).values(
                    username="legacy-admin",
                    display_name="Legacy Bootstrap Admin",
                    role="owner",
                    permissions="*",
                    site_scope=SITE_SCOPE_ALL,
                    is_active=True,
                    created_at=now,
                    updated_at=now,
                )
            )
            user_id = int(result.inserted_primary_key[0])
        else:
            user_id = int(user_row["id"])
            conn.execute(
                update(admin_users)
                .where(admin_users.c.id == user_id)
                .values(
                    role="owner",
                    permissions="*",
                    site_scope=SITE_SCOPE_ALL,
                    is_active=True,
                    updated_at=now,
                )
            )

        conn.execute(
            insert(admin_tokens).values(
                user_id=user_id,
                label="legacy-env-admin-token",
                token_hash=token_hash,
                is_active=True,
                site_scope=None,
                expires_at=None,
                last_used_at=None,
                created_at=now,
            )
        )


def _calculate_risk(payload: InspectionCreate) -> tuple[str, list[str]]:
    flags: list[str] = []

    if payload.insulation_mohm is not None and payload.insulation_mohm <= 1:
        flags.append("insulation_low")
    if payload.winding_temp_c is not None and payload.winding_temp_c >= 90:
        flags.append("temp_high")

    volts = [payload.voltage_r, payload.voltage_s, payload.voltage_t]
    if all(v is not None for v in volts):
        values = [float(v) for v in volts]
        avg = sum(values) / 3
        if avg > 0:
            max_unbalance = max(abs(v - avg) / avg * 100 for v in values)
            if max_unbalance > 3:
                flags.append("voltage_unbalance")

    if "insulation_low" in flags or "temp_high" in flags:
        return "danger", flags
    if flags:
        return "warning", flags
    return "normal", flags


def _to_utc(dt: datetime) -> datetime:
    if dt.tzinfo is None:
        return dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(timezone.utc)


def _as_datetime(value: Any) -> datetime:
    if isinstance(value, datetime):
        if value.tzinfo is None:
            return value.replace(tzinfo=timezone.utc)
        return value
    if isinstance(value, str):
        parsed = datetime.fromisoformat(value)
        if parsed.tzinfo is None:
            return parsed.replace(tzinfo=timezone.utc)
        return parsed
    raise ValueError("Unsupported datetime value")


def _as_optional_datetime(value: Any) -> datetime | None:
    if value is None:
        return None
    return _as_datetime(value)


def _safe_download_filename(raw_value: str, *, fallback: str = "download.bin", max_length: int = 120) -> str:
    allowed = set(string.ascii_letters + string.digits + "._-")
    candidate = (raw_value or "").replace("\x00", "").strip()
    sanitized_chars: list[str] = []
    for ch in candidate:
        if ch in allowed:
            sanitized_chars.append(ch)
        elif ch in {" ", "\t"}:
            sanitized_chars.append("_")
    sanitized = "".join(sanitized_chars).strip("._")
    if not sanitized:
        sanitized = fallback
    if max_length > 0 and len(sanitized) > max_length:
        sanitized = sanitized[:max_length]
    return sanitized or fallback


def _is_allowed_evidence_content_type(content_type: str) -> bool:
    normalized = content_type.strip().lower()
    if not normalized:
        return False
    if "*" in EVIDENCE_ALLOWED_CONTENT_TYPES:
        return True
    return normalized in EVIDENCE_ALLOWED_CONTENT_TYPES


def _normalize_evidence_storage_backend(value: str) -> str:
    normalized = value.strip().lower()
    if normalized in {"fs", "filesystem", "file"}:
        return "fs"
    return "db"


def _evidence_storage_root() -> Path:
    candidate = Path(EVIDENCE_STORAGE_PATH)
    if candidate.is_absolute():
        return candidate
    project_root = Path(__file__).resolve().parent.parent
    return project_root / candidate


def _resolve_evidence_storage_abs_path(storage_key: str) -> Path | None:
    key = str(storage_key or "").strip().replace("\\", "/")
    if not key:
        return None
    if key.startswith("/") or key.startswith("\\"):
        return None
    if "\x00" in key:
        return None
    if ".." in PurePosixPath(key).parts:
        return None

    root = _evidence_storage_root().resolve()
    candidate = (root / key).resolve()
    try:
        candidate.relative_to(root)
    except ValueError:
        return None
    return candidate


def _ensure_evidence_storage_ready() -> None:
    backend = _normalize_evidence_storage_backend(EVIDENCE_STORAGE_BACKEND)
    if backend != "fs":
        return
    _evidence_storage_root().mkdir(parents=True, exist_ok=True)


def _scan_evidence_bytes(*, file_bytes: bytes, content_type: str) -> tuple[str, str, str | None]:
    if EVIDENCE_SCAN_MODE in {"off", "disabled", "none"}:
        return "skipped", "none", None

    # EICAR test string detection provides deterministic malware-scan smoke coverage.
    eicar_signature = b"X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*"
    if eicar_signature in file_bytes:
        return "infected", "basic-signature", "eicar-signature-detected"

    if content_type in {"text/html", "application/javascript", "text/javascript"}:
        lowered = file_bytes[:4096].lower()
        if b"<script" in lowered:
            return "suspicious", "basic-pattern", "active-script-pattern-detected"

    return "clean", "basic-signature", None


def _write_evidence_blob(*, file_name: str, file_bytes: bytes, sha256_digest: str) -> tuple[str, str | None, bytes]:
    backend = _normalize_evidence_storage_backend(EVIDENCE_STORAGE_BACKEND)
    if backend != "fs":
        return "db", None, file_bytes

    _ensure_evidence_storage_ready()
    extension = ""
    if "." in file_name:
        extension = "." + file_name.rsplit(".", 1)[1][:16]
    now = datetime.now(timezone.utc)
    storage_key = (
        f"{now.year:04d}/{now.month:02d}/{now.day:02d}/"
        f"{sha256_digest[:20]}-{secrets.token_hex(8)}{extension}"
    )
    abs_path = _resolve_evidence_storage_abs_path(storage_key)
    if abs_path is None:
        raise RuntimeError("Invalid evidence storage key generated")
    abs_path.parent.mkdir(parents=True, exist_ok=True)
    abs_path.write_bytes(file_bytes)
    # Keep DB rows lightweight when file-system backend is enabled.
    return "fs", storage_key, b""


def _read_evidence_blob(*, row: dict[str, Any]) -> bytes | None:
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))
    if storage_backend == "fs":
        storage_key = str(row.get("storage_key") or "").strip()
        if not storage_key:
            return None
        abs_path = _resolve_evidence_storage_abs_path(storage_key)
        if abs_path is None:
            return None
        if not abs_path.exists() or not abs_path.is_file():
            return None
        return abs_path.read_bytes()

    raw = row.get("file_bytes") or b""
    if isinstance(raw, bytes):
        return raw
    if isinstance(raw, bytearray):
        return bytes(raw)
    try:
        return bytes(raw)
    except Exception:
        return None


def _row_to_read_model(row: dict[str, Any]) -> InspectionRead:
    risk_flags_raw = row["risk_flags"] or ""
    risk_flags = [x for x in risk_flags_raw.split(",") if x]

    return InspectionRead(
        id=row["id"],
        site=row["site"],
        location=row["location"],
        cycle=row["cycle"],
        inspector=row["inspector"],
        inspected_at=_as_datetime(row["inspected_at"]),
        transformer_kva=row["transformer_kva"],
        voltage_r=row["voltage_r"],
        voltage_s=row["voltage_s"],
        voltage_t=row["voltage_t"],
        current_r=row["current_r"],
        current_s=row["current_s"],
        current_t=row["current_t"],
        winding_temp_c=row["winding_temp_c"],
        grounding_ohm=row["grounding_ohm"],
        insulation_mohm=row["insulation_mohm"],
        notes=row["notes"],
        risk_level=row["risk_level"],
        risk_flags=risk_flags,
        created_at=_as_datetime(row["created_at"]),
    )


def _is_overdue(status: str, due_at: datetime | None) -> bool:
    if due_at is None:
        return False
    if status in {"completed", "canceled"}:
        return False
    return due_at < datetime.now(timezone.utc)


def _month_window(month: str | None) -> tuple[datetime, datetime, str]:
    if month is None:
        now = datetime.now(timezone.utc)
        normalized = f"{now.year:04d}-{now.month:02d}"
    else:
        normalized = month

    try:
        year, month_num = normalized.split("-")
        start = datetime(int(year), int(month_num), 1, tzinfo=timezone.utc)
    except Exception as exc:
        raise HTTPException(status_code=400, detail="month must be YYYY-MM format") from exc

    if start.month == 12:
        end = datetime(start.year + 1, 1, 1, tzinfo=timezone.utc)
    else:
        end = datetime(start.year, start.month + 1, 1, tzinfo=timezone.utc)
    return start, end, normalized


def _token_rotate_due_at(created_at: datetime) -> datetime | None:
    if ADMIN_TOKEN_ROTATE_AFTER_DAYS <= 0:
        return None
    return created_at + timedelta(days=ADMIN_TOKEN_ROTATE_AFTER_DAYS)


def _token_idle_due_at(*, created_at: datetime, last_used_at: datetime | None) -> datetime | None:
    baseline = last_used_at or created_at
    if ADMIN_TOKEN_MAX_IDLE_DAYS <= 0:
        return None
    return baseline + timedelta(days=ADMIN_TOKEN_MAX_IDLE_DAYS)


def _load_principal_by_token(token: str) -> dict[str, Any] | None:
    now = datetime.now(timezone.utc)
    token_hash = _hash_token(token)

    stmt = (
        select(
            admin_tokens.c.id.label("token_id"),
            admin_tokens.c.user_id.label("user_id"),
            admin_tokens.c.expires_at.label("expires_at"),
            admin_tokens.c.last_used_at.label("last_used_at"),
            admin_tokens.c.created_at.label("created_at"),
            admin_tokens.c.label.label("token_label"),
            admin_tokens.c.site_scope.label("token_site_scope"),
            admin_users.c.username.label("username"),
            admin_users.c.display_name.label("display_name"),
            admin_users.c.role.label("role"),
            admin_users.c.permissions.label("permissions"),
            admin_users.c.site_scope.label("user_site_scope"),
        )
        .where(admin_tokens.c.token_hash == token_hash)
        .where(admin_tokens.c.is_active.is_(True))
        .where(admin_users.c.id == admin_tokens.c.user_id)
        .where(admin_users.c.is_active.is_(True))
        .limit(1)
    )

    try:
        with get_conn() as conn:
            row = conn.execute(stmt).mappings().first()
            if row is None:
                return None

            token_id = int(row["token_id"])
            expires_at = _as_optional_datetime(row["expires_at"])
            created_at = _as_datetime(row["created_at"])
            last_used_at = _as_optional_datetime(row["last_used_at"])
            rotate_due_at = _token_rotate_due_at(created_at)
            idle_due_at = _token_idle_due_at(created_at=created_at, last_used_at=last_used_at)

            if ADMIN_TOKEN_ROTATE_AFTER_DAYS > 0:
                rotate_cutoff = now - timedelta(days=ADMIN_TOKEN_ROTATE_AFTER_DAYS)
                if created_at <= rotate_cutoff:
                    conn.execute(
                        update(admin_tokens)
                        .where(admin_tokens.c.id == token_id)
                        .values(is_active=False, last_used_at=now)
                    )
                    return None

            if idle_due_at is not None and idle_due_at <= now:
                conn.execute(
                    update(admin_tokens)
                    .where(admin_tokens.c.id == token_id)
                    .values(is_active=False, last_used_at=now)
                )
                return None

            effective_expires_at = expires_at
            if effective_expires_at is None and ADMIN_TOKEN_REQUIRE_EXPIRY:
                effective_expires_at = created_at + timedelta(days=ADMIN_TOKEN_MAX_TTL_DAYS)

            if effective_expires_at is not None and effective_expires_at <= now:
                conn.execute(
                    update(admin_tokens)
                    .where(admin_tokens.c.id == token_id)
                    .values(is_active=False, last_used_at=now)
                )
                return None

            conn.execute(
                update(admin_tokens)
                .where(admin_tokens.c.id == token_id)
                .values(last_used_at=now)
            )
    except SQLAlchemyError:
        return None

    custom_permissions = _permission_text_to_list(row["permissions"])
    permissions = _effective_permissions(str(row["role"]), custom_permissions)
    user_scope = _site_scope_text_to_list(row["user_site_scope"], default_all=True)
    token_scope_raw = row["token_site_scope"]
    token_scope = None
    if token_scope_raw is not None:
        token_scope = _site_scope_text_to_list(token_scope_raw, default_all=True)
    effective_site_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
    rotate_due_at = _token_rotate_due_at(created_at)
    warning_due_at = None
    if rotate_due_at is not None and ADMIN_TOKEN_ROTATE_WARNING_DAYS > 0:
        warning_due_at = rotate_due_at - timedelta(days=ADMIN_TOKEN_ROTATE_WARNING_DAYS)
    must_rotate = rotate_due_at is not None and warning_due_at is not None and now >= warning_due_at
    idle_due_at = _token_idle_due_at(created_at=created_at, last_used_at=last_used_at)
    return {
        "user_id": int(row["user_id"]),
        "token_id": int(row["token_id"]),
        "token_label": str(row.get("token_label") or ""),
        "token_created_at": created_at,
        "token_expires_at": effective_expires_at,
        "token_rotate_due_at": rotate_due_at,
        "token_idle_due_at": idle_due_at,
        "token_must_rotate": must_rotate,
        "username": str(row["username"]),
        "display_name": str(row["display_name"] or row["username"]),
        "role": str(row["role"]),
        "permissions": permissions,
        "site_scope": effective_site_scope,
        "is_legacy": str(row["username"]) == "legacy-admin",
    }


def _build_local_dev_principal() -> dict[str, Any]:
    return {
        "user_id": None,
        "token_id": None,
        "token_label": "local-dev",
        "token_created_at": datetime.now(timezone.utc),
        "token_expires_at": None,
        "token_rotate_due_at": None,
        "token_idle_due_at": None,
        "token_must_rotate": False,
        "username": "local-dev",
        "display_name": "Local Dev Bypass",
        "role": "owner",
        "permissions": ["*"],
        "site_scope": [SITE_SCOPE_ALL],
        "is_legacy": True,
    }


def get_current_admin(
    x_admin_token: Annotated[str | None, Header(alias="X-Admin-Token")] = None,
) -> dict[str, Any]:
    if x_admin_token:
        principal = _load_principal_by_token(x_admin_token)
        if principal is not None:
            return principal

        if ADMIN_TOKEN and hmac.compare_digest(x_admin_token, ADMIN_TOKEN):
            return {
                "user_id": None,
                "token_id": None,
                "token_label": "legacy-env-token",
                "token_created_at": datetime.now(timezone.utc),
                "token_expires_at": None,
                "token_rotate_due_at": None,
                "token_idle_due_at": None,
                "token_must_rotate": False,
                "username": "legacy-env-token",
                "display_name": "Legacy Env Token",
                "role": "owner",
                "permissions": ["*"],
                "site_scope": [SITE_SCOPE_ALL],
                "is_legacy": True,
            }
        raise HTTPException(status_code=401, detail="Invalid admin token")

    if (
        ENV_NAME != "production"
        and ALLOW_INSECURE_LOCAL_AUTH
        and not ADMIN_TOKEN
        and not _has_active_admin_tokens()
    ):
        return _build_local_dev_principal()

    raise HTTPException(status_code=401, detail="Missing admin token")


def _has_permission(principal: dict[str, Any], permission: str) -> bool:
    permissions = set(principal.get("permissions", []))
    if "*" in permissions or permission in permissions:
        return True
    namespace = f"{permission.split(':', 1)[0]}:*"
    return namespace in permissions


def require_permission(permission: str) -> Callable[[dict[str, Any]], dict[str, Any]]:
    def dependency(principal: dict[str, Any] = Depends(get_current_admin)) -> dict[str, Any]:
        if not _has_permission(principal, permission):
            raise HTTPException(status_code=403, detail=f"Missing permission: {permission}")
        return principal

    return dependency


def _has_explicit_permission(principal: dict[str, Any], permission: str) -> bool:
    permissions = set(principal.get("permissions", []))
    return permission in permissions


def _is_workflow_admin_override(principal: dict[str, Any]) -> bool:
    if bool(principal.get("is_legacy", False)):
        return True
    return _has_explicit_permission(principal, "workflow_locks:admin")


def _require_workflow_lock_action(
    principal: dict[str, Any],
    *,
    action: str,
    status: str | None = None,
) -> None:
    role = str(principal.get("role") or "")
    is_admin = _is_workflow_admin_override(principal)
    allowed = False

    if action == "read":
        allowed = role in {"operator", "manager", "owner", "auditor"} or is_admin
    elif action in {"create", "update_draft", "submit"}:
        allowed = role == "operator" or is_admin
    elif action in {"approve", "reject"}:
        allowed = role in {"manager", "owner"} or is_admin
    elif action == "lock":
        allowed = role == "owner" or is_admin
    elif action == "unlock":
        allowed = is_admin

    if not allowed:
        raise HTTPException(status_code=403, detail=f"Workflow lock action denied: {action}")

    if status is None:
        return
    if action in {"update_draft", "submit"} and status != WORKFLOW_LOCK_STATUS_DRAFT:
        raise HTTPException(status_code=409, detail=f"{action} requires draft status")
    if action in {"approve", "reject"} and status != WORKFLOW_LOCK_STATUS_REVIEW:
        raise HTTPException(status_code=409, detail=f"{action} requires review status")
    if action == "lock" and status != WORKFLOW_LOCK_STATUS_APPROVED:
        raise HTTPException(status_code=409, detail="lock requires approved status")
    if action == "unlock" and status != WORKFLOW_LOCK_STATUS_LOCKED:
        raise HTTPException(status_code=409, detail="unlock requires locked status")


def _to_json_text(value: dict[str, Any] | None) -> str:
    data = value or {}
    return json.dumps(data, ensure_ascii=False, default=str)


def _compute_audit_entry_hash(
    *,
    prev_hash: str,
    actor_user_id: int | None,
    actor_username: str,
    action: str,
    resource_type: str,
    resource_id: str,
    status: str,
    detail_json: str,
    created_at: datetime,
) -> str:
    canonical = json.dumps(
        {
            "prev_hash": prev_hash,
            "actor_user_id": actor_user_id,
            "actor_username": actor_username,
            "action": action,
            "resource_type": resource_type,
            "resource_id": resource_id,
            "status": status,
            "detail_json": detail_json,
            "created_at": created_at.isoformat(),
        },
        ensure_ascii=False,
        separators=(",", ":"),
        sort_keys=True,
    )
    return hashlib.sha256(canonical.encode("utf-8")).hexdigest()


def _sign_payload(payload_text: str) -> str | None:
    if not AUDIT_ARCHIVE_SIGNING_KEY:
        return None
    return hmac.new(
        AUDIT_ARCHIVE_SIGNING_KEY.encode("utf-8"),
        payload_text.encode("utf-8"),
        hashlib.sha256,
    ).hexdigest()


def _write_audit_log(
    *,
    principal: dict[str, Any] | None,
    action: str,
    resource_type: str,
    resource_id: str,
    status: str = "success",
    detail: dict[str, Any] | None = None,
) -> None:
    now = datetime.now(timezone.utc)
    actor_user_id = None
    actor_username = "system"
    if principal is not None:
        actor_user_id = principal.get("user_id")
        actor_username = str(principal.get("username") or "unknown")
    detail_json = _to_json_text(detail)

    try:
        with get_conn() as conn:
            prev_row = conn.execute(
                select(admin_audit_logs.c.entry_hash)
                .order_by(admin_audit_logs.c.created_at.desc(), admin_audit_logs.c.id.desc())
                .limit(1)
            ).mappings().first()
            prev_hash = str(prev_row.get("entry_hash") or "") if prev_row is not None else ""
            entry_hash = _compute_audit_entry_hash(
                prev_hash=prev_hash,
                actor_user_id=actor_user_id,
                actor_username=actor_username,
                action=action,
                resource_type=resource_type,
                resource_id=resource_id,
                status=status,
                detail_json=detail_json,
                created_at=now,
            )
            conn.execute(
                insert(admin_audit_logs).values(
                    actor_user_id=actor_user_id,
                    actor_username=actor_username,
                    action=action,
                    resource_type=resource_type,
                    resource_id=resource_id,
                    status=status,
                    prev_hash=prev_hash or None,
                    entry_hash=entry_hash,
                    detail_json=detail_json,
                    created_at=now,
                )
            )
    except SQLAlchemyError:
        # Audit log failures must not block business requests.
        return


def _row_to_admin_audit_log_model(row: dict[str, Any]) -> AdminAuditLogRead:
    raw = str(row["detail_json"] or "{}")
    try:
        detail = json.loads(raw)
    except json.JSONDecodeError:
        detail = {"raw": raw}

    return AdminAuditLogRead(
        id=int(row["id"]),
        actor_user_id=row["actor_user_id"],
        actor_username=str(row["actor_username"]),
        action=str(row["action"]),
        resource_type=str(row["resource_type"]),
        resource_id=str(row["resource_id"]),
        status=str(row["status"]),
        detail=detail if isinstance(detail, dict) else {"value": detail},
        created_at=_as_datetime(row["created_at"]),
    )


def _verify_audit_chain(rows: list[dict[str, Any]], *, initial_prev_hash: str = "") -> dict[str, Any]:
    previous_hash = initial_prev_hash
    issues: list[dict[str, Any]] = []
    checked = 0
    for row in rows:
        checked += 1
        detail_json = str(row.get("detail_json") or "{}")
        created_at = _as_datetime(row["created_at"])
        expected = _compute_audit_entry_hash(
            prev_hash=previous_hash,
            actor_user_id=row.get("actor_user_id"),
            actor_username=str(row.get("actor_username") or ""),
            action=str(row.get("action") or ""),
            resource_type=str(row.get("resource_type") or ""),
            resource_id=str(row.get("resource_id") or ""),
            status=str(row.get("status") or ""),
            detail_json=detail_json,
            created_at=created_at,
        )
        stored_prev = str(row.get("prev_hash") or "")
        stored_hash = str(row.get("entry_hash") or "")
        if stored_prev != previous_hash:
            issues.append({"id": int(row["id"]), "reason": "prev_hash_mismatch"})
        if stored_hash != expected:
            issues.append({"id": int(row["id"]), "reason": "entry_hash_mismatch"})
        previous_hash = stored_hash or expected
    return {
        "checked_count": checked,
        "issue_count": len(issues),
        "issues": issues[:100],
        "initial_prev_hash": initial_prev_hash or None,
        "last_entry_hash": previous_hash or None,
        "chain_ok": len(issues) == 0,
    }


def build_monthly_audit_archive(
    *,
    month: str | None,
    max_entries: int = 10000,
    include_entries: bool = True,
) -> dict[str, Any]:
    start, end, normalized = _month_window(month)
    with get_conn() as conn:
        anchor_row = conn.execute(
            select(admin_audit_logs.c.entry_hash)
            .where(admin_audit_logs.c.created_at < start)
            .order_by(admin_audit_logs.c.created_at.desc(), admin_audit_logs.c.id.desc())
            .limit(1)
        ).mappings().first()
        anchor_hash = str(anchor_row.get("entry_hash") or "") if anchor_row is not None else ""
        rows = conn.execute(
            select(admin_audit_logs)
            .where(admin_audit_logs.c.created_at >= start)
            .where(admin_audit_logs.c.created_at < end)
            .order_by(admin_audit_logs.c.created_at.asc(), admin_audit_logs.c.id.asc())
            .limit(max_entries)
        ).mappings().all()
        dr_month_row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .where(job_runs.c.finished_at >= start)
            .where(job_runs.c.finished_at < end)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        dr_latest_row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .where(job_runs.c.finished_at < end)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()

    chain = _verify_audit_chain([dict(row) for row in rows], initial_prev_hash=anchor_hash)
    archive_rows: list[dict[str, Any]] = []
    if include_entries:
        for row in rows:
            detail_raw = str(row.get("detail_json") or "{}")
            try:
                detail_value = json.loads(detail_raw)
            except json.JSONDecodeError:
                detail_value = {"raw": detail_raw}
            archive_rows.append(
                {
                    "id": int(row["id"]),
                    "actor_user_id": row.get("actor_user_id"),
                    "actor_username": str(row.get("actor_username") or ""),
                    "action": str(row.get("action") or ""),
                    "resource_type": str(row.get("resource_type") or ""),
                    "resource_id": str(row.get("resource_id") or ""),
                    "status": str(row.get("status") or ""),
                    "detail": detail_value,
                    "created_at": _as_datetime(row["created_at"]).isoformat(),
                    "prev_hash": row.get("prev_hash"),
                    "entry_hash": row.get("entry_hash"),
                }
            )

    def _to_dr_attachment(row: dict[str, Any] | None) -> dict[str, Any] | None:
        if row is None:
            return None
        detail_raw = str(row.get("detail_json") or "{}")
        try:
            detail = json.loads(detail_raw)
        except json.JSONDecodeError:
            detail = {"raw": detail_raw}
        if not isinstance(detail, dict):
            detail = {"value": detail}
        started_at = _as_optional_datetime(row.get("started_at"))
        finished_at = _as_optional_datetime(row.get("finished_at"))
        counts_raw = detail.get("counts")
        counts = counts_raw if isinstance(counts_raw, dict) else {}
        return {
            "run_id": int(row["id"]),
            "status": str(row.get("status") or "unknown"),
            "trigger": str(row.get("trigger") or "unknown"),
            "started_at": started_at.isoformat() if started_at is not None else None,
            "finished_at": finished_at.isoformat() if finished_at is not None else None,
            "restore_valid": bool(detail.get("restore_valid", False)),
            "simulate_restore": bool(detail.get("simulate_restore", False)),
            "backup_file": detail.get("backup_file"),
            "pruned_files": int(detail.get("pruned_files") or 0),
            "counts": counts,
            "notes": detail.get("notes") if isinstance(detail.get("notes"), list) else [],
        }

    dr_latest_in_month = _to_dr_attachment(dr_month_row)
    dr_latest_before_window_end = _to_dr_attachment(dr_latest_row)
    dr_attachment = {
        "required": DR_REHEARSAL_ENABLED,
        "month": normalized,
        "included": dr_latest_in_month is not None,
        "status": (
            "ok"
            if dr_latest_in_month is not None
            else ("warning" if DR_REHEARSAL_ENABLED else "info")
        ),
        "message": (
            "DR rehearsal result attached for target month."
            if dr_latest_in_month is not None
            else (
                "No DR rehearsal result in target month."
                if DR_REHEARSAL_ENABLED
                else "DR rehearsal is disabled by policy."
            )
        ),
        "latest_in_month": dr_latest_in_month,
        "latest_before_window_end": dr_latest_before_window_end,
    }

    payload = {
        "month": normalized,
        "window_start": start.isoformat(),
        "window_end": end.isoformat(),
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "entry_count": len(rows),
        "max_entries": max_entries,
        "chain": chain,
        "dr_rehearsal_attachment": dr_attachment,
        "entries": archive_rows if include_entries else [],
    }
    payload_text = json.dumps(payload, ensure_ascii=False, separators=(",", ":"), sort_keys=True)
    signature = _sign_payload(payload_text)
    payload["archive_sha256"] = hashlib.sha256(payload_text.encode("utf-8")).hexdigest()
    payload["signature"] = signature
    payload["signature_algorithm"] = "hmac-sha256" if signature is not None else "unsigned"
    return payload


def rebaseline_admin_audit_chain(
    *,
    from_month: str | None = None,
    max_rows: int = 50000,
    dry_run: bool = False,
) -> dict[str, Any]:
    start_dt: datetime | None = None
    normalized_month: str | None = None
    if from_month is not None:
        start_dt, _, normalized_month = _month_window(from_month)

    with get_conn() as conn:
        anchor_hash = ""
        anchor_id: int | None = None
        if start_dt is not None:
            anchor = conn.execute(
                select(
                    admin_audit_logs.c.id,
                    admin_audit_logs.c.entry_hash,
                )
                .where(admin_audit_logs.c.created_at < start_dt)
                .order_by(admin_audit_logs.c.created_at.desc(), admin_audit_logs.c.id.desc())
                .limit(1)
            ).mappings().first()
            if anchor is not None:
                anchor_id = int(anchor["id"])
                anchor_hash = str(anchor.get("entry_hash") or "")

        stmt = select(admin_audit_logs).order_by(
            admin_audit_logs.c.created_at.asc(),
            admin_audit_logs.c.id.asc(),
        )
        if start_dt is not None:
            stmt = stmt.where(admin_audit_logs.c.created_at >= start_dt)
        rows = conn.execute(stmt.limit(max_rows)).mappings().all()

        scanned_count = len(rows)
        updated_count = 0
        first_updated_id: int | None = None
        last_updated_id: int | None = None
        previous_hash = anchor_hash

        for row in rows:
            row_id = int(row["id"])
            detail_json = str(row.get("detail_json") or "{}")
            created_at = _as_datetime(row["created_at"])
            expected_hash = _compute_audit_entry_hash(
                prev_hash=previous_hash,
                actor_user_id=row.get("actor_user_id"),
                actor_username=str(row.get("actor_username") or ""),
                action=str(row.get("action") or ""),
                resource_type=str(row.get("resource_type") or ""),
                resource_id=str(row.get("resource_id") or ""),
                status=str(row.get("status") or ""),
                detail_json=detail_json,
                created_at=created_at,
            )

            stored_prev = str(row.get("prev_hash") or "")
            stored_hash = str(row.get("entry_hash") or "")
            changed = stored_prev != previous_hash or stored_hash != expected_hash
            if changed:
                updated_count += 1
                if first_updated_id is None:
                    first_updated_id = row_id
                last_updated_id = row_id
                if not dry_run:
                    conn.execute(
                        update(admin_audit_logs)
                        .where(admin_audit_logs.c.id == row_id)
                        .values(
                            prev_hash=previous_hash or None,
                            entry_hash=expected_hash,
                        )
                    )
            previous_hash = expected_hash

    return {
        "from_month": normalized_month,
        "max_rows": max_rows,
        "dry_run": dry_run,
        "anchor_id": anchor_id,
        "scanned_count": scanned_count,
        "updated_count": updated_count,
        "first_updated_id": first_updated_id,
        "last_updated_id": last_updated_id,
        "last_entry_hash": previous_hash or None,
    }


def _write_job_run(
    *,
    job_name: str,
    trigger: str,
    status: str,
    started_at: datetime,
    finished_at: datetime,
    detail: dict[str, Any] | None = None,
) -> int | None:
    try:
        with get_conn() as conn:
            result = conn.execute(
                insert(job_runs).values(
                    job_name=job_name,
                    trigger=trigger,
                    status=status,
                    started_at=started_at,
                    finished_at=finished_at,
                    detail_json=_to_json_text(detail),
                )
            )
            return int(result.inserted_primary_key[0])
    except SQLAlchemyError:
        return None


def _row_to_job_run_model(row: dict[str, Any]) -> JobRunRead:
    raw = str(row["detail_json"] or "{}")
    try:
        detail = json.loads(raw)
    except json.JSONDecodeError:
        detail = {"raw": raw}
    if not isinstance(detail, dict):
        detail = {"value": detail}

    return JobRunRead(
        id=int(row["id"]),
        job_name=str(row["job_name"]),
        trigger=str(row["trigger"]),
        status=str(row["status"]),
        started_at=_as_datetime(row["started_at"]),
        finished_at=_as_datetime(row["finished_at"]),
        detail=detail,
    )


def _write_alert_delivery(
    *,
    event_type: str,
    target: str,
    status: str,
    error: str | None,
    payload: dict[str, Any],
) -> int | None:
    now = datetime.now(timezone.utc)
    try:
        with get_conn() as conn:
            result = conn.execute(
                insert(alert_deliveries).values(
                    event_type=event_type,
                    target=target,
                    status=status,
                    error=error,
                    payload_json=_to_json_text(payload),
                    attempt_count=1,
                    last_attempt_at=now,
                    created_at=now,
                    updated_at=now,
                )
            )
            return int(result.inserted_primary_key[0])
    except SQLAlchemyError:
        return None


def _row_to_alert_delivery_model(row: dict[str, Any]) -> AlertDeliveryRead:
    raw = str(row["payload_json"] or "{}")
    try:
        payload = json.loads(raw)
    except json.JSONDecodeError:
        payload = {"raw": raw}
    if not isinstance(payload, dict):
        payload = {"value": payload}

    return AlertDeliveryRead(
        id=int(row["id"]),
        event_type=str(row["event_type"]),
        target=str(row["target"]),
        status=str(row["status"]),
        error=row["error"],
        payload=payload,
        attempt_count=int(row["attempt_count"]),
        last_attempt_at=_as_datetime(row["last_attempt_at"]),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_sla_policy_proposal_model(row: dict[str, Any]) -> SlaPolicyProposalRead:
    policy_raw = str(row["policy_json"] or "{}")
    simulation_raw = str(row["simulation_json"] or "{}")
    try:
        policy = json.loads(policy_raw)
    except json.JSONDecodeError:
        policy = {"raw": policy_raw}
    if not isinstance(policy, dict):
        policy = {"value": policy}

    try:
        simulation = json.loads(simulation_raw)
    except json.JSONDecodeError:
        simulation = {"raw": simulation_raw}
    if not isinstance(simulation, dict):
        simulation = {"value": simulation}

    return SlaPolicyProposalRead(
        id=int(row["id"]),
        site=row["site"],
        status=str(row["status"]),
        policy=policy,
        simulation=simulation,
        note=str(row["note"] or ""),
        requested_by=str(row["requested_by"]),
        decided_by=row["decided_by"],
        decision_note=row["decision_note"],
        created_at=_as_datetime(row["created_at"]),
        decided_at=_as_optional_datetime(row["decided_at"]),
        applied_at=_as_optional_datetime(row["applied_at"]),
    )


def _write_sla_policy_revision(
    *,
    site: str | None,
    policy: dict[str, Any],
    source_action: str,
    actor_username: str,
    note: str = "",
) -> None:
    now = datetime.now(timezone.utc)
    try:
        with get_conn() as conn:
            conn.execute(
                insert(sla_policy_revisions).values(
                    site=site,
                    policy_json=_to_json_text(policy),
                    source_action=source_action,
                    actor_username=actor_username,
                    note=note,
                    created_at=now,
                )
            )
    except SQLAlchemyError:
        return


def _row_to_sla_policy_revision_model(row: dict[str, Any]) -> SlaPolicyRevisionRead:
    raw = str(row["policy_json"] or "{}")
    try:
        policy = json.loads(raw)
    except json.JSONDecodeError:
        policy = {"raw": raw}
    if not isinstance(policy, dict):
        policy = {"value": policy}

    return SlaPolicyRevisionRead(
        id=int(row["id"]),
        site=row["site"],
        policy=policy,
        source_action=str(row["source_action"]),
        actor_username=str(row["actor_username"]),
        note=str(row["note"] or ""),
        created_at=_as_datetime(row["created_at"]),
    )


def _normalize_sla_due_hours(value: Any) -> dict[str, int]:
    source = value if isinstance(value, dict) else {}
    normalized: dict[str, int] = {}
    for priority, default_hours in SLA_DEFAULT_DUE_HOURS.items():
        raw_hours = source.get(priority, default_hours)
        try:
            hours = int(raw_hours)
        except (TypeError, ValueError):
            hours = default_hours
        if hours < 1 or hours > 24 * 30:
            hours = default_hours
        normalized[priority] = hours
    return normalized


def _normalize_sla_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    due_hours = _normalize_sla_due_hours(source.get("default_due_hours"))

    raw_grace = source.get("escalation_grace_minutes", 0)
    try:
        grace_minutes = int(raw_grace)
    except (TypeError, ValueError):
        grace_minutes = 0
    grace_minutes = max(0, min(1440, grace_minutes))

    return {
        "default_due_hours": due_hours,
        "escalation_grace_minutes": grace_minutes,
    }


def _parse_sla_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_sla_policy(loaded)


def _normalize_site_name(site: str | None) -> str | None:
    if site is None:
        return None
    value = site.strip()
    return value or None


def _policy_key_for_site(site: str | None) -> str | None:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return None
    return f"{SLA_SITE_POLICY_PREFIX}{normalized_site}"


def _get_sla_policy_row(policy_key: str) -> dict[str, Any] | None:
    with get_conn() as conn:
        return conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()


def _ensure_default_sla_policy() -> tuple[dict[str, Any], datetime]:
    now = datetime.now(timezone.utc)
    row = _get_sla_policy_row(SLA_DEFAULT_POLICY_KEY)
    if row is None:
        policy = _normalize_sla_policy({})
        with get_conn() as conn:
            conn.execute(
                insert(sla_policies).values(
                    policy_key=SLA_DEFAULT_POLICY_KEY,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
        return policy, now

    policy = _parse_sla_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at


def _sla_policy_to_model(
    *,
    policy_key: str,
    site: str | None,
    source: str,
    updated_at: datetime,
    policy: dict[str, Any],
) -> SlaPolicyRead:
    return SlaPolicyRead(
        policy_key=policy_key,
        site=site,
        source=source,
        default_due_hours=policy["default_due_hours"],
        escalation_grace_minutes=policy["escalation_grace_minutes"],
        updated_at=updated_at,
    )


def _load_sla_policy(
    site: str | None = None,
) -> tuple[dict[str, Any], datetime, str, str | None, str]:
    normalized_site = _normalize_site_name(site)
    default_policy, default_updated_at = _ensure_default_sla_policy()
    site_policy_key = _policy_key_for_site(normalized_site)
    if site_policy_key is None:
        return default_policy, default_updated_at, "default", None, SLA_DEFAULT_POLICY_KEY

    row = _get_sla_policy_row(site_policy_key)
    if row is None:
        # Site requested but override does not exist: use default policy.
        return default_policy, default_updated_at, "default", normalized_site, SLA_DEFAULT_POLICY_KEY

    now = datetime.now(timezone.utc)
    policy = _parse_sla_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, "site", normalized_site, site_policy_key


def _upsert_sla_policy(
    payload: SlaPolicyUpdate,
    site: str | None = None,
    *,
    source_action: str = "manual_update",
    actor_username: str = "system",
    note: str = "",
) -> SlaPolicyRead:
    now = datetime.now(timezone.utc)
    policy = _normalize_sla_policy(payload.model_dump())
    normalized_site = _normalize_site_name(site)
    policy_key = _policy_key_for_site(normalized_site) or SLA_DEFAULT_POLICY_KEY
    source = "site" if normalized_site is not None else "default"

    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies.c.id)
            .where(sla_policies.c.policy_key == policy_key)
            .limit(1)
        ).first()
        if row is None:
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(sla_policies)
                .where(sla_policies.c.policy_key == policy_key)
                .values(policy_json=_to_json_text(policy), updated_at=now)
            )

    _write_sla_policy_revision(
        site=normalized_site,
        policy=policy,
        source_action=source_action,
        actor_username=actor_username,
        note=note,
    )

    return _sla_policy_to_model(
        policy_key=policy_key,
        site=normalized_site,
        source=source,
        updated_at=now,
        policy=policy,
    )


def _normalize_mttr_slo_recover_state(value: str | None) -> str:
    normalized = (value or "").strip().lower()
    if normalized in ALERT_MTTR_SLO_RECOVER_STATE_SET:
        return normalized
    return "quarantined"


def _default_mttr_slo_policy() -> dict[str, Any]:
    return {
        "enabled": ALERT_MTTR_SLO_ENABLED,
        "window_days": max(1, ALERT_MTTR_SLO_WINDOW_DAYS),
        "threshold_minutes": max(1, ALERT_MTTR_SLO_THRESHOLD_MINUTES),
        "min_incidents": max(1, ALERT_MTTR_SLO_MIN_INCIDENTS),
        "auto_recover_enabled": ALERT_MTTR_SLO_AUTO_RECOVER_ENABLED,
        "recover_state": _normalize_mttr_slo_recover_state(ALERT_MTTR_SLO_RECOVER_STATE),
        "recover_max_targets": max(1, min(ALERT_MTTR_SLO_RECOVER_MAX_TARGETS, 500)),
        "notify_enabled": ALERT_MTTR_SLO_NOTIFY_ENABLED,
        "notify_event_type": ALERT_MTTR_SLO_NOTIFY_EVENT_TYPE[:80],
        "notify_cooldown_minutes": max(0, min(ALERT_MTTR_SLO_NOTIFY_COOLDOWN_MINUTES, 10080)),
        "top_channels": max(1, min(ALERT_MTTR_SLO_TOP_CHANNELS, 50)),
    }


def _legacy_mttr_slo_policy() -> dict[str, Any]:
    # Legacy baseline before operational tuning (kept for safe one-time upgrade).
    return {
        "enabled": True,
        "window_days": 30,
        "threshold_minutes": 60,
        "min_incidents": 3,
        "auto_recover_enabled": True,
        "recover_state": "quarantined",
        "recover_max_targets": 30,
        "notify_enabled": True,
        "notify_event_type": "mttr_slo_breach",
        "notify_cooldown_minutes": 180,
        "top_channels": 10,
    }


def _normalize_mttr_slo_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_mttr_slo_policy()

    def _to_int(raw: Any, fallback: int, *, min_value: int, max_value: int) -> int:
        try:
            parsed = int(raw)
        except (TypeError, ValueError):
            parsed = fallback
        return max(min_value, min(parsed, max_value))

    notify_event_type = str(source.get("notify_event_type", defaults["notify_event_type"]) or "").strip()
    if not notify_event_type:
        notify_event_type = str(defaults["notify_event_type"])

    return {
        "enabled": bool(source.get("enabled", defaults["enabled"])),
        "window_days": _to_int(source.get("window_days"), int(defaults["window_days"]), min_value=1, max_value=90),
        "threshold_minutes": _to_int(
            source.get("threshold_minutes"),
            int(defaults["threshold_minutes"]),
            min_value=1,
            max_value=10080,
        ),
        "min_incidents": _to_int(source.get("min_incidents"), int(defaults["min_incidents"]), min_value=1, max_value=100000),
        "auto_recover_enabled": bool(source.get("auto_recover_enabled", defaults["auto_recover_enabled"])),
        "recover_state": _normalize_mttr_slo_recover_state(str(source.get("recover_state", defaults["recover_state"]))),
        "recover_max_targets": _to_int(
            source.get("recover_max_targets"),
            int(defaults["recover_max_targets"]),
            min_value=1,
            max_value=500,
        ),
        "notify_enabled": bool(source.get("notify_enabled", defaults["notify_enabled"])),
        "notify_event_type": notify_event_type[:80],
        "notify_cooldown_minutes": _to_int(
            source.get("notify_cooldown_minutes"),
            int(defaults["notify_cooldown_minutes"]),
            min_value=0,
            max_value=10080,
        ),
        "top_channels": _to_int(source.get("top_channels"), int(defaults["top_channels"]), min_value=1, max_value=50),
    }


def _parse_mttr_slo_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_mttr_slo_policy(loaded)


def _ensure_mttr_slo_policy() -> tuple[dict[str, Any], datetime, str]:
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == ALERT_MTTR_SLO_POLICY_KEY).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_mttr_slo_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=ALERT_MTTR_SLO_POLICY_KEY,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, ALERT_MTTR_SLO_POLICY_KEY

    policy = _parse_mttr_slo_policy_json(row["policy_json"])
    default_policy = _default_mttr_slo_policy()
    if policy == _legacy_mttr_slo_policy() and policy != default_policy:
        with get_conn() as conn:
            conn.execute(
                update(sla_policies)
                .where(sla_policies.c.policy_key == ALERT_MTTR_SLO_POLICY_KEY)
                .values(
                    policy_json=_to_json_text(default_policy),
                    updated_at=now,
                )
            )
        return default_policy, now, ALERT_MTTR_SLO_POLICY_KEY

    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, ALERT_MTTR_SLO_POLICY_KEY


def _upsert_mttr_slo_policy(payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str]:
    current_policy, _, policy_key = _ensure_mttr_slo_policy()
    merged = {**current_policy, **(payload if isinstance(payload, dict) else {})}
    normalized = _normalize_mttr_slo_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key


def _w09_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W09_KPI_POLICY_KEY_DEFAULT, None
    return f"{W09_KPI_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w09_kpi_policy() -> dict[str, Any]:
    kpis: list[dict[str, Any]] = []
    for item in ADOPTION_W09_KPI_THRESHOLD_MATRIX:
        kpis.append(
            {
                "kpi_key": str(item.get("kpi_key") or ""),
                "kpi_name": str(item.get("kpi_name") or ""),
                "direction": str(item.get("direction") or "higher_better"),
                "owner_role": str(item.get("owner_role") or ""),
                "green_threshold": float(item.get("green_threshold") or 0.0),
                "yellow_threshold": float(item.get("yellow_threshold") or 0.0),
                "target": str(item.get("target") or ""),
                "source_api": str(item.get("source_api") or ""),
            }
        )
    escalation_map: list[dict[str, Any]] = []
    for item in ADOPTION_W09_ESCALATION_MAP:
        escalation_map.append(
            {
                "id": str(item.get("id") or ""),
                "kpi_key": str(item.get("kpi_key") or ""),
                "condition": str(item.get("condition") or ""),
                "escalate_to": str(item.get("escalate_to") or ""),
                "sla_hours": int(item.get("sla_hours") or 24),
                "action": str(item.get("action") or ""),
            }
        )
    return {
        "enabled": True,
        "kpis": kpis,
        "escalation_map": escalation_map,
    }


def _normalize_w09_kpi_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w09_kpi_policy()
    default_kpis = defaults.get("kpis", [])
    default_map = {
        str(item.get("kpi_key") or ""): item
        for item in default_kpis
        if str(item.get("kpi_key") or "")
    }
    merged_map: dict[str, dict[str, Any]] = {}

    source_kpis = source.get("kpis", [])
    if isinstance(source_kpis, list):
        for item in source_kpis:
            if not isinstance(item, dict):
                continue
            kpi_key = str(item.get("kpi_key") or "").strip()
            if not kpi_key:
                continue
            merged_map[kpi_key] = item

    normalized_kpis: list[dict[str, Any]] = []
    for key, default_item in default_map.items():
        incoming = merged_map.get(key, {})
        if not isinstance(incoming, dict):
            incoming = {}
        direction = str(incoming.get("direction") or default_item.get("direction") or "higher_better").strip().lower()
        if direction not in {"higher_better", "lower_better"}:
            direction = str(default_item.get("direction") or "higher_better")
        try:
            green = float(incoming.get("green_threshold", default_item.get("green_threshold", 0.0)))
        except (TypeError, ValueError):
            green = float(default_item.get("green_threshold", 0.0))
        try:
            yellow = float(incoming.get("yellow_threshold", default_item.get("yellow_threshold", 0.0)))
        except (TypeError, ValueError):
            yellow = float(default_item.get("yellow_threshold", 0.0))

        normalized_kpis.append(
            {
                "kpi_key": key,
                "kpi_name": str(incoming.get("kpi_name") or default_item.get("kpi_name") or ""),
                "direction": direction,
                "owner_role": str(incoming.get("owner_role") or default_item.get("owner_role") or ""),
                "green_threshold": round(green, 2),
                "yellow_threshold": round(yellow, 2),
                "target": str(incoming.get("target") or default_item.get("target") or ""),
                "source_api": str(incoming.get("source_api") or default_item.get("source_api") or ""),
            }
        )

    escalation_source = source.get("escalation_map", defaults.get("escalation_map", []))
    normalized_escalations: list[dict[str, Any]] = []
    if isinstance(escalation_source, list):
        for item in escalation_source:
            if not isinstance(item, dict):
                continue
            kpi_key = str(item.get("kpi_key") or "").strip()
            if kpi_key and kpi_key not in default_map:
                continue
            try:
                sla_hours = int(item.get("sla_hours") or 24)
            except (TypeError, ValueError):
                sla_hours = 24
            normalized_escalations.append(
                {
                    "id": str(item.get("id") or ""),
                    "kpi_key": kpi_key,
                    "condition": str(item.get("condition") or ""),
                    "escalate_to": str(item.get("escalate_to") or ""),
                    "sla_hours": max(1, min(sla_hours, 168)),
                    "action": str(item.get("action") or ""),
                }
            )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "kpis": normalized_kpis,
        "escalation_map": normalized_escalations,
    }


def _parse_w09_kpi_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w09_kpi_policy(loaded)


def _ensure_w09_kpi_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w09_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w09_kpi_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w09_kpi_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w09_kpi_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w09_kpi_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in ["enabled", "kpis", "escalation_map"]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w09_kpi_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _evaluate_w09_kpi_status(
    *,
    actual: float | None,
    direction: str,
    green_threshold: float,
    yellow_threshold: float,
) -> str:
    if actual is None:
        return W09_KPI_STATUS_RED
    if direction == "lower_better":
        if actual <= green_threshold:
            return W09_KPI_STATUS_GREEN
        if actual <= yellow_threshold:
            return W09_KPI_STATUS_YELLOW
        return W09_KPI_STATUS_RED
    if actual >= green_threshold:
        return W09_KPI_STATUS_GREEN
    if actual >= yellow_threshold:
        return W09_KPI_STATUS_YELLOW
    return W09_KPI_STATUS_RED


def _w10_support_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W10_SUPPORT_POLICY_KEY_DEFAULT, None
    return f"{W10_SUPPORT_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w10_support_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "repeat_rate_green_threshold": 20.0,
        "repeat_rate_yellow_threshold": 30.0,
        "guide_publish_green_threshold": 80.0,
        "guide_publish_yellow_threshold": 60.0,
        "runbook_completion_green_threshold": 80.0,
        "runbook_completion_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w10_support_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w10_support_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "repeat_rate_green_threshold",
        float(defaults["repeat_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "repeat_rate_yellow_threshold",
        float(defaults["repeat_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "guide_publish_green_threshold",
        float(defaults["guide_publish_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "guide_publish_yellow_threshold",
        float(defaults["guide_publish_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "runbook_completion_green_threshold",
        float(defaults["runbook_completion_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "runbook_completion_yellow_threshold",
        float(defaults["runbook_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "repeat_rate_green_threshold": repeat_green,
        "repeat_rate_yellow_threshold": repeat_yellow,
        "guide_publish_green_threshold": guide_green,
        "guide_publish_yellow_threshold": guide_yellow,
        "runbook_completion_green_threshold": runbook_green,
        "runbook_completion_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w10_support_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w10_support_policy(loaded)


def _ensure_w10_support_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w10_support_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w10_support_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w10_support_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w10_support_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w10_support_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "repeat_rate_green_threshold",
        "repeat_rate_yellow_threshold",
        "guide_publish_green_threshold",
        "guide_publish_yellow_threshold",
        "runbook_completion_green_threshold",
        "runbook_completion_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w10_support_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w10_self_serve_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w10_support_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "work_orders_count": 0,
                    "unique_titles": 0,
                    "repeated_work_orders_count": 0,
                    "repeat_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W10_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "guide_publish_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W10_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "runbook_completion_rate_percent": 0.0,
                    "self_serve_readiness_score": 0.0,
                    "overall_status": W10_SUPPORT_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_titles": [],
                "guide_coverage": ADOPTION_W10_SELF_SERVE_GUIDES,
                "runbook_modules": ADOPTION_W10_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    repeat_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_titles = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w10_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w10_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w10_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W10_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W10_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W10_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W10_TRACKER_STATUS_DONE
    )
    guide_publish_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    runbook_completion_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=repeat_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("repeat_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("repeat_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=guide_publish_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("guide_publish_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("guide_publish_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=runbook_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("runbook_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("runbook_completion_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    self_serve_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W10_SUPPORT_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W10_SUPPORT_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W10_SUPPORT_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = self_serve_readiness_score >= readiness_target and overall_status != W10_SUPPORT_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": repeat_rate_percent,
            "green_threshold": float(policy.get("repeat_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("repeat_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('repeat_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "guide_publish_rate_percent",
            "kpi_name": "Self-serve guide publish rate",
            "direction": "higher_better",
            "actual_value": guide_publish_rate_percent,
            "green_threshold": float(policy.get("guide_publish_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("guide_publish_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('guide_publish_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "runbook_completion_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": runbook_completion_rate_percent,
            "green_threshold": float(policy.get("runbook_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("runbook_completion_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('runbook_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "self_serve_readiness_score",
            "kpi_name": "Self-serve readiness score",
            "direction": "higher_better",
            "actual_value": self_serve_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=self_serve_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Self-serve guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W10 Self-serve    .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "work_orders_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_work_orders_count": repeated_orders_count,
            "repeat_rate_percent": repeat_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "guide_publish_rate_percent": guide_publish_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "runbook_completion_rate_percent": runbook_completion_rate_percent,
            "self_serve_readiness_score": self_serve_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_titles": top_repeat_titles,
        "guide_coverage": ADOPTION_W10_SELF_SERVE_GUIDES,
        "runbook_modules": ADOPTION_W10_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }



def _w11_readiness_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W11_READINESS_POLICY_KEY_DEFAULT, None
    return f"{W11_READINESS_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w11_readiness_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "risk_rate_green_threshold": 20.0,
        "risk_rate_yellow_threshold": 30.0,
        "checklist_completion_green_threshold": 80.0,
        "checklist_completion_yellow_threshold": 60.0,
        "simulation_success_green_threshold": 80.0,
        "simulation_success_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w11_readiness_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w11_readiness_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "risk_rate_green_threshold",
        float(defaults["risk_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "risk_rate_yellow_threshold",
        float(defaults["risk_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "checklist_completion_green_threshold",
        float(defaults["checklist_completion_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "checklist_completion_yellow_threshold",
        float(defaults["checklist_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "simulation_success_green_threshold",
        float(defaults["simulation_success_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "simulation_success_yellow_threshold",
        float(defaults["simulation_success_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "risk_rate_green_threshold": repeat_green,
        "risk_rate_yellow_threshold": repeat_yellow,
        "checklist_completion_green_threshold": guide_green,
        "checklist_completion_yellow_threshold": guide_yellow,
        "simulation_success_green_threshold": runbook_green,
        "simulation_success_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w11_readiness_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w11_readiness_policy(loaded)


def _ensure_w11_readiness_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w11_readiness_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w11_readiness_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w11_readiness_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w11_readiness_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w11_readiness_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "risk_rate_green_threshold",
        "risk_rate_yellow_threshold",
        "checklist_completion_green_threshold",
        "checklist_completion_yellow_threshold",
        "simulation_success_green_threshold",
        "simulation_success_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w11_readiness_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w11_scale_readiness_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w11_readiness_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "work_orders_count": 0,
                    "unique_titles": 0,
                    "repeated_work_orders_count": 0,
                    "risk_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W11_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "checklist_completion_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W11_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "simulation_success_rate_percent": 0.0,
                    "scale_readiness_readiness_score": 0.0,
                    "overall_status": W11_READINESS_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_titles": [],
                "scale_checklist": ADOPTION_W11_SELF_SERVE_GUIDES,
                "simulation_runbook": ADOPTION_W11_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    risk_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_titles = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w11_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w11_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w11_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W11_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W11_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W11_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W11_TRACKER_STATUS_DONE
    )
    checklist_completion_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    simulation_success_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=risk_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("risk_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("risk_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=checklist_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("checklist_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("checklist_completion_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=simulation_success_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("simulation_success_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("simulation_success_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    scale_readiness_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W11_READINESS_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W11_READINESS_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W11_READINESS_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = scale_readiness_readiness_score >= readiness_target and overall_status != W11_READINESS_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": risk_rate_percent,
            "green_threshold": float(policy.get("risk_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("risk_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('risk_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "checklist_completion_rate_percent",
            "kpi_name": "Self-serve guide publication rate",
            "direction": "higher_better",
            "actual_value": checklist_completion_rate_percent,
            "green_threshold": float(policy.get("checklist_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("checklist_completion_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('checklist_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "simulation_success_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": simulation_success_rate_percent,
            "green_threshold": float(policy.get("simulation_success_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("simulation_success_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('simulation_success_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "scale_readiness_readiness_score",
            "kpi_name": "Scale readiness readiness score",
            "direction": "higher_better",
            "actual_value": scale_readiness_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=scale_readiness_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Scale readiness guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W11 Scale readiness    .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "work_orders_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_work_orders_count": repeated_orders_count,
            "risk_rate_percent": risk_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "checklist_completion_rate_percent": checklist_completion_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "simulation_success_rate_percent": simulation_success_rate_percent,
            "scale_readiness_readiness_score": scale_readiness_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_titles": top_repeat_titles,
        "scale_checklist": ADOPTION_W11_SELF_SERVE_GUIDES,
        "simulation_runbook": ADOPTION_W11_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }



def _w12_handoff_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W12_HANDOFF_POLICY_KEY_DEFAULT, None
    return f"{W12_HANDOFF_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w12_handoff_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "risk_rate_green_threshold": 20.0,
        "risk_rate_yellow_threshold": 30.0,
        "checklist_completion_green_threshold": 80.0,
        "checklist_completion_yellow_threshold": 60.0,
        "simulation_success_green_threshold": 80.0,
        "simulation_success_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w12_handoff_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w12_handoff_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "risk_rate_green_threshold",
        float(defaults["risk_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "risk_rate_yellow_threshold",
        float(defaults["risk_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "checklist_completion_green_threshold",
        float(defaults["checklist_completion_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "checklist_completion_yellow_threshold",
        float(defaults["checklist_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "simulation_success_green_threshold",
        float(defaults["simulation_success_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "simulation_success_yellow_threshold",
        float(defaults["simulation_success_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "risk_rate_green_threshold": repeat_green,
        "risk_rate_yellow_threshold": repeat_yellow,
        "checklist_completion_green_threshold": guide_green,
        "checklist_completion_yellow_threshold": guide_yellow,
        "simulation_success_green_threshold": runbook_green,
        "simulation_success_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w12_handoff_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w12_handoff_policy(loaded)


def _ensure_w12_handoff_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w12_handoff_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w12_handoff_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w12_handoff_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w12_handoff_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w12_handoff_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "risk_rate_green_threshold",
        "risk_rate_yellow_threshold",
        "checklist_completion_green_threshold",
        "checklist_completion_yellow_threshold",
        "simulation_success_green_threshold",
        "simulation_success_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w12_handoff_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w12_closure_handoff_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w12_handoff_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "work_orders_count": 0,
                    "unique_titles": 0,
                    "repeated_work_orders_count": 0,
                    "risk_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W12_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "checklist_completion_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W12_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "simulation_success_rate_percent": 0.0,
                    "closure_handoff_readiness_score": 0.0,
                    "overall_status": W12_HANDOFF_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_titles": [],
                "scale_checklist": ADOPTION_W12_SELF_SERVE_GUIDES,
                "simulation_runbook": ADOPTION_W12_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    risk_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_titles = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w12_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w12_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w12_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W12_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W12_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W12_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W12_TRACKER_STATUS_DONE
    )
    checklist_completion_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    simulation_success_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=risk_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("risk_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("risk_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=checklist_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("checklist_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("checklist_completion_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=simulation_success_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("simulation_success_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("simulation_success_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    closure_handoff_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W12_HANDOFF_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W12_HANDOFF_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W12_HANDOFF_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = closure_handoff_readiness_score >= readiness_target and overall_status != W12_HANDOFF_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": risk_rate_percent,
            "green_threshold": float(policy.get("risk_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("risk_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('risk_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "checklist_completion_rate_percent",
            "kpi_name": "Scale readiness guide publish rate",
            "direction": "higher_better",
            "actual_value": checklist_completion_rate_percent,
            "green_threshold": float(policy.get("checklist_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("checklist_completion_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('checklist_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "simulation_success_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": simulation_success_rate_percent,
            "green_threshold": float(policy.get("simulation_success_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("simulation_success_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('simulation_success_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "closure_handoff_readiness_score",
            "kpi_name": "Scale readiness readiness score",
            "direction": "higher_better",
            "actual_value": closure_handoff_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=closure_handoff_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Scale readiness guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W12 Scale readiness    .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "work_orders_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_work_orders_count": repeated_orders_count,
            "risk_rate_percent": risk_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "checklist_completion_rate_percent": checklist_completion_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "simulation_success_rate_percent": simulation_success_rate_percent,
            "closure_handoff_readiness_score": closure_handoff_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_titles": top_repeat_titles,
        "scale_checklist": ADOPTION_W12_SELF_SERVE_GUIDES,
        "simulation_runbook": ADOPTION_W12_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }
def _latest_mttr_slo_breach_finished_at(max_rows: int = 50) -> datetime | None:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.detail_json)
            .where(job_runs.c.job_name == "alert_mttr_slo_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(max(1, min(max_rows, 500)))
        ).mappings().all()
    for row in rows:
        raw = str(row.get("detail_json") or "{}")
        try:
            detail = json.loads(raw)
        except json.JSONDecodeError:
            detail = {}
        if not isinstance(detail, dict):
            continue
        if bool(detail.get("breach")):
            finished_at = _as_optional_datetime(row.get("finished_at"))
            if finished_at is not None:
                return finished_at
    return None


def _configured_alert_targets() -> list[str]:
    targets: list[str] = []
    merged_raw = ALERT_WEBHOOK_URLS.replace(";", ",").replace("\n", ",")
    for part in merged_raw.split(","):
        value = part.strip()
        if value:
            targets.append(value)
    if ALERT_WEBHOOK_URL:
        targets.append(ALERT_WEBHOOK_URL)

    deduped: list[str] = []
    seen: set[str] = set()
    for target in targets:
        if target in seen:
            continue
        seen.add(target)
        deduped.append(target)
    return deduped


def _normalize_ops_daily_check_alert_level(value: str | None) -> str:
    normalized = (value or "").strip().lower()
    if normalized in {"off", "none", "disabled"}:
        return "off"
    if normalized in {"warning", "warn"}:
        return "warning"
    if normalized in {"critical", "crit"}:
        return "critical"
    if normalized in {"always", "all", "ok"}:
        return "always"
    return "critical"


def _is_alert_failure_status(status: str) -> bool:
    return status.strip().lower() in {"failed", "warning"}


def _compute_alert_channel_guard_state(
    target: str,
    *,
    now: datetime | None = None,
    event_type: str | None = None,
    lookback_days: int = 30,
) -> dict[str, Any]:
    current_time = now or datetime.now(timezone.utc)
    normalized_lookback_days = max(1, lookback_days)
    history_start = current_time - timedelta(days=normalized_lookback_days)
    stmt = (
        select(
            alert_deliveries.c.status,
            alert_deliveries.c.error,
            alert_deliveries.c.last_attempt_at,
        )
        .where(alert_deliveries.c.target == target)
        .where(alert_deliveries.c.last_attempt_at >= history_start)
        .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
        .limit(200)
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    last_attempt_at: datetime | None = None
    last_status: str | None = None
    last_error: str | None = None
    last_success_at: datetime | None = None
    last_failure_at: datetime | None = None
    consecutive_failures = 0

    for idx, row in enumerate(rows):
        attempted_at = _as_optional_datetime(row.get("last_attempt_at"))
        if attempted_at is None:
            continue
        status = str(row.get("status") or "failed").strip().lower()
        error_text = str(row.get("error") or "")
        if idx == 0:
            last_attempt_at = attempted_at
            last_status = status
            last_error = error_text or None

        if status == "success":
            last_success_at = attempted_at
            # Consecutive failure run is determined from most recent attempt backward
            break
        if _is_alert_failure_status(status):
            if last_failure_at is None:
                last_failure_at = attempted_at
            consecutive_failures += 1
            continue
        break

    threshold = max(1, ALERT_CHANNEL_GUARD_FAIL_THRESHOLD)
    cooldown_minutes = max(1, ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES)
    quarantined_until: datetime | None = None
    state = "healthy"
    if consecutive_failures >= threshold and last_failure_at is not None:
        quarantined_until = last_failure_at + timedelta(minutes=cooldown_minutes)
        if current_time < quarantined_until:
            state = "quarantined"
        else:
            state = "warning"
    elif consecutive_failures > 0:
        state = "warning"

    remaining_quarantine_minutes = 0
    if quarantined_until is not None and current_time < quarantined_until:
        remaining_quarantine_minutes = max(
            1,
            int(math.ceil((quarantined_until - current_time).total_seconds() / 60.0)),
        )

    return {
        "target": target,
        "state": state if ALERT_CHANNEL_GUARD_ENABLED else "disabled",
        "state_computed": state,
        "consecutive_failures": consecutive_failures,
        "threshold": threshold,
        "cooldown_minutes": cooldown_minutes,
        "remaining_quarantine_minutes": remaining_quarantine_minutes,
        "quarantined_until": quarantined_until.isoformat() if quarantined_until is not None else None,
        "last_attempt_at": last_attempt_at.isoformat() if last_attempt_at is not None else None,
        "last_status": last_status,
        "last_error": last_error,
        "last_success_at": last_success_at.isoformat() if last_success_at is not None else None,
        "last_failure_at": last_failure_at.isoformat() if last_failure_at is not None else None,
        "delivery_count_lookback": len(rows),
    }


def _build_alert_channel_guard_snapshot(
    *,
    event_type: str | None = None,
    lookback_days: int = 30,
    max_targets: int = 100,
    now: datetime | None = None,
) -> dict[str, Any]:
    current_time = now or datetime.now(timezone.utc)
    normalized_lookback_days = max(1, lookback_days)
    normalized_max_targets = max(1, min(max_targets, 500))
    history_start = current_time - timedelta(days=normalized_lookback_days)
    target_set: set[str] = set(_configured_alert_targets())

    stmt = (
        select(alert_deliveries.c.target)
        .where(alert_deliveries.c.last_attempt_at >= history_start)
        .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
        .limit(2000)
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)
    with get_conn() as conn:
        recent_targets = conn.execute(stmt).all()
    for row in recent_targets:
        value = str(row[0] or "").strip()
        if value:
            target_set.add(value)

    channels = [
        _compute_alert_channel_guard_state(
            target,
            now=current_time,
            event_type=event_type,
            lookback_days=normalized_lookback_days,
        )
        for target in sorted(target_set)
    ]

    def _state_rank(item: dict[str, Any]) -> int:
        state = str(item.get("state_computed") or "healthy")
        if state == "quarantined":
            return 0
        if state == "warning":
            return 1
        return 2

    channels.sort(key=lambda item: (_state_rank(item), str(item.get("target") or "")))
    limited_channels = channels[:normalized_max_targets]
    quarantined_count = sum(1 for item in channels if str(item.get("state_computed")) == "quarantined")
    warning_count = sum(1 for item in channels if str(item.get("state_computed")) == "warning")
    healthy_count = sum(1 for item in channels if str(item.get("state_computed")) == "healthy")
    status = "ok"
    if quarantined_count > 0:
        status = "critical"
    elif warning_count > 0:
        status = "warning"
    if not ALERT_CHANNEL_GUARD_ENABLED:
        status = "warning" if warning_count > 0 else "ok"

    return {
        "generated_at": current_time.isoformat(),
        "event_type": event_type,
        "lookback_days": normalized_lookback_days,
        "policy": {
            "enabled": ALERT_CHANNEL_GUARD_ENABLED,
            "failure_threshold": max(1, ALERT_CHANNEL_GUARD_FAIL_THRESHOLD),
            "cooldown_minutes": max(1, ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES),
            "recovery_steps": [
                "1)  (//) ",
                "2) /api/ops/alerts/channels/guard/recover probe ",
                "3)     healthy  ",
            ],
        },
        "summary": {
            "status": status,
            "target_count": len(channels),
            "healthy_count": healthy_count,
            "warning_count": warning_count,
            "quarantined_count": quarantined_count,
            "returned_count": len(limited_channels),
        },
        "channels": limited_channels,
    }


def _build_alert_delivery_archive_csv(rows: list[dict[str, Any]]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "id",
            "event_type",
            "target",
            "status",
            "error",
            "attempt_count",
            "last_attempt_at",
            "created_at",
            "updated_at",
            "payload_json",
        ]
    )
    for row in rows:
        writer.writerow(
            [
                int(row.get("id") or 0),
                str(row.get("event_type") or ""),
                str(row.get("target") or ""),
                str(row.get("status") or ""),
                str(row.get("error") or ""),
                int(row.get("attempt_count") or 0),
                _as_optional_datetime(row.get("last_attempt_at")).isoformat()
                if _as_optional_datetime(row.get("last_attempt_at")) is not None
                else "",
                _as_optional_datetime(row.get("created_at")).isoformat()
                if _as_optional_datetime(row.get("created_at")) is not None
                else "",
                _as_optional_datetime(row.get("updated_at")).isoformat()
                if _as_optional_datetime(row.get("updated_at")) is not None
                else "",
                str(row.get("payload_json") or "{}"),
            ]
        )
    return buffer.getvalue()


def run_alert_retention_job(
    *,
    retention_days: int | None = None,
    max_delete: int | None = None,
    dry_run: bool = False,
    write_archive: bool | None = None,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    resolved_retention_days = max(1, int(retention_days if retention_days is not None else ALERT_RETENTION_DAYS))
    resolved_max_delete = max(1, min(int(max_delete if max_delete is not None else ALERT_RETENTION_MAX_DELETE), 50000))
    resolved_write_archive = ALERT_RETENTION_ARCHIVE_ENABLED if write_archive is None else bool(write_archive)
    cutoff = started_at - timedelta(days=resolved_retention_days)

    archive_file: str | None = None
    archive_error: str | None = None
    deleted_count = 0
    candidate_count = 0
    candidate_ids: list[int] = []

    with get_conn() as conn:
        rows = conn.execute(
            select(alert_deliveries)
            .where(alert_deliveries.c.last_attempt_at < cutoff)
            .order_by(alert_deliveries.c.last_attempt_at.asc(), alert_deliveries.c.id.asc())
            .limit(resolved_max_delete)
        ).mappings().all()
        candidate_count = len(rows)
        candidate_ids = [int(row["id"]) for row in rows]

        can_delete = not dry_run
        if rows and not dry_run and resolved_write_archive:
            try:
                archive_dir = Path(ALERT_RETENTION_ARCHIVE_PATH)
                archive_dir.mkdir(parents=True, exist_ok=True)
                stamp = started_at.strftime("%Y%m%dT%H%M%SZ")
                first_id = candidate_ids[0]
                last_id = candidate_ids[-1]
                file_path = archive_dir / f"alert-deliveries-{stamp}-{first_id}-{last_id}.csv"
                file_path.write_text(_build_alert_delivery_archive_csv([dict(row) for row in rows]), encoding="utf-8")
                archive_file = str(file_path)
            except Exception as exc:  # pragma: no cover - defensive path
                archive_error = str(exc)
                can_delete = False

        if rows and can_delete:
            delete_result = conn.execute(
                delete(alert_deliveries).where(alert_deliveries.c.id.in_(candidate_ids))
            )
            deleted_count = int(delete_result.rowcount or 0)

    finished_at = datetime.now(timezone.utc)
    status = "success" if archive_error is None else "warning"
    run_id = _write_job_run(
        job_name="alert_retention",
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "retention_days": resolved_retention_days,
            "max_delete": resolved_max_delete,
            "dry_run": dry_run,
            "write_archive": resolved_write_archive,
            "cutoff": cutoff.isoformat(),
            "candidate_count": candidate_count,
            "deleted_count": deleted_count,
            "archive_file": archive_file,
            "archive_error": archive_error,
            "candidate_ids": candidate_ids[:200],
        },
    )
    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": status,
        "retention_days": resolved_retention_days,
        "max_delete": resolved_max_delete,
        "dry_run": dry_run,
        "write_archive": resolved_write_archive,
        "cutoff": cutoff.isoformat(),
        "candidate_count": candidate_count,
        "deleted_count": deleted_count,
        "archive_file": archive_file,
        "archive_error": archive_error,
    }


def run_alert_guard_recover_job(
    *,
    event_type: str | None = None,
    state_filter: str = "quarantined",
    max_targets: int | None = None,
    dry_run: bool = False,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    normalized_state_filter = (state_filter or "quarantined").strip().lower()
    if normalized_state_filter not in {"quarantined", "warning", "all"}:
        normalized_state_filter = "quarantined"
    resolved_max_targets = max(1, min(int(max_targets if max_targets is not None else ALERT_GUARD_RECOVER_MAX_TARGETS), 500))

    snapshot = _build_alert_channel_guard_snapshot(
        event_type=event_type,
        lookback_days=30,
        max_targets=max(200, resolved_max_targets * 5),
        now=started_at,
    )
    channels = snapshot.get("channels", [])
    if not isinstance(channels, list):
        channels = []

    def _matches(item: dict[str, Any]) -> bool:
        state = str(item.get("state_computed") or "")
        if normalized_state_filter == "all":
            return state in {"quarantined", "warning"}
        return state == normalized_state_filter

    selected = [item for item in channels if isinstance(item, dict) and _matches(item)][:resolved_max_targets]

    processed_count = 0
    success_count = 0
    warning_count = 0
    failed_count = 0
    skipped_count = 0
    results: list[dict[str, Any]] = []

    for item in selected:
        target = str(item.get("target") or "").strip()
        if not target:
            continue
        processed_count += 1
        before_state = _compute_alert_channel_guard_state(
            target,
            event_type=event_type,
            now=datetime.now(timezone.utc),
        )
        if dry_run:
            skipped_count += 1
            results.append(
                {
                    "target": target,
                    "status": "skipped",
                    "reason": "dry_run",
                    "before_state": before_state.get("state"),
                    "after_state": before_state.get("state"),
                }
            )
            continue

        probe_payload = {
            "event": "alert_guard_recovery_batch_probe",
            "target": target,
            "event_type_scope": event_type,
            "state_filter": normalized_state_filter,
            "checked_at": datetime.now(timezone.utc).isoformat(),
        }
        ok, err = _post_json_with_retries(
            url=target,
            payload=probe_payload,
            retries=ALERT_WEBHOOK_RETRIES,
            timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
        )
        probe_status = "success" if ok and err is None else ("warning" if ok else "failed")
        if probe_status == "success":
            success_count += 1
        elif probe_status == "warning":
            warning_count += 1
        else:
            failed_count += 1

        delivery_id = _write_alert_delivery(
            event_type=event_type or "alert_guard_recover",
            target=target,
            status=probe_status,
            error=err,
            payload={**probe_payload, "probe": True},
        )
        after_state = _compute_alert_channel_guard_state(
            target,
            event_type=event_type,
            now=datetime.now(timezone.utc),
        )
        results.append(
            {
                "target": target,
                "status": probe_status,
                "error": err,
                "delivery_id": delivery_id,
                "before_state": before_state.get("state"),
                "after_state": after_state.get("state"),
                "before_consecutive_failures": before_state.get("consecutive_failures"),
                "after_consecutive_failures": after_state.get("consecutive_failures"),
            }
        )

    finished_at = datetime.now(timezone.utc)
    job_status = "success"
    if failed_count > 0:
        job_status = "warning"
    run_id = _write_job_run(
        job_name="alert_guard_recover",
        trigger=trigger,
        status=job_status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "event_type": event_type,
            "state_filter": normalized_state_filter,
            "max_targets": resolved_max_targets,
            "dry_run": dry_run,
            "selected_target_count": len(selected),
            "processed_count": processed_count,
            "success_count": success_count,
            "warning_count": warning_count,
            "failed_count": failed_count,
            "skipped_count": skipped_count,
            "results": results[:200],
        },
    )

    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": job_status,
        "event_type": event_type,
        "state_filter": normalized_state_filter,
        "max_targets": resolved_max_targets,
        "dry_run": dry_run,
        "selected_target_count": len(selected),
        "processed_count": processed_count,
        "success_count": success_count,
        "warning_count": warning_count,
        "failed_count": failed_count,
        "skipped_count": skipped_count,
        "results": results,
    }


def run_alert_mttr_slo_check_job(
    *,
    event_type: str | None = None,
    force_notify: bool = False,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    policy, policy_updated_at, policy_key = _ensure_mttr_slo_policy()
    window_days = int(policy.get("window_days") or 30)
    threshold_minutes = float(policy.get("threshold_minutes") or 60)
    min_incidents = int(policy.get("min_incidents") or 1)

    snapshot = _build_alert_channel_mttr_snapshot(
        event_type=event_type,
        windows=[window_days],
        now=started_at,
    )
    windows = snapshot.get("windows", [])
    window: dict[str, Any] = windows[0] if isinstance(windows, list) and windows else {}
    incident_count = int(window.get("incident_count") or 0)
    recovered_incidents = int(window.get("recovered_incidents") or 0)
    unresolved_incidents = int(window.get("unresolved_incidents") or 0)
    mttr_minutes = window.get("mttr_minutes")
    mttr_value = float(mttr_minutes) if mttr_minutes is not None else None
    breach = (
        bool(policy.get("enabled", True))
        and incident_count >= max(1, min_incidents)
        and mttr_value is not None
        and mttr_value > threshold_minutes
    )

    channels = window.get("channels", [])
    if not isinstance(channels, list):
        channels = []
    top_channels_limit = max(1, min(int(policy.get("top_channels") or 10), 50))
    top_channels = [
        {
            "target": str(item.get("target") or ""),
            "incident_count": int(item.get("incident_count") or 0),
            "recovered_incidents": int(item.get("recovered_incidents") or 0),
            "unresolved_incidents": int(item.get("unresolved_incidents") or 0),
            "mttr_minutes": item.get("mttr_minutes"),
            "last_incident_start": item.get("last_incident_start"),
            "last_recovery_at": item.get("last_recovery_at"),
        }
        for item in channels
        if isinstance(item, dict)
    ][:top_channels_limit]

    auto_recover_attempted = False
    auto_recover_result: dict[str, Any] | None = None
    if breach and bool(policy.get("auto_recover_enabled", True)):
        auto_recover_attempted = True
        recovered = run_alert_guard_recover_job(
            event_type=event_type,
            state_filter=str(policy.get("recover_state") or "quarantined"),
            max_targets=int(policy.get("recover_max_targets") or ALERT_GUARD_RECOVER_MAX_TARGETS),
            dry_run=False,
            trigger="mttr_slo_auto",
        )
        auto_recover_result = {
            "run_id": recovered.get("run_id"),
            "status": recovered.get("status"),
            "state_filter": recovered.get("state_filter"),
            "max_targets": recovered.get("max_targets"),
            "processed_count": recovered.get("processed_count"),
            "success_count": recovered.get("success_count"),
            "failed_count": recovered.get("failed_count"),
            "skipped_count": recovered.get("skipped_count"),
        }

    notify_attempted = False
    notify_dispatched = False
    notify_error: str | None = None
    notify_channels: list[dict[str, Any]] = []
    cooldown_active = False
    cooldown_remaining_minutes = 0
    last_breach_at = _latest_mttr_slo_breach_finished_at()
    cooldown_minutes = int(policy.get("notify_cooldown_minutes") or 0)
    if breach and bool(policy.get("notify_enabled", True)):
        if not force_notify and cooldown_minutes > 0 and last_breach_at is not None:
            next_allowed_at = last_breach_at + timedelta(minutes=cooldown_minutes)
            if started_at < next_allowed_at:
                cooldown_active = True
                cooldown_remaining_minutes = max(
                    1,
                    int(math.ceil((next_allowed_at - started_at).total_seconds() / 60.0)),
                )
        if force_notify or not cooldown_active:
            notify_attempted = True
            notify_dispatched, notify_error, channel_results = _dispatch_alert_event(
                event_type=str(policy.get("notify_event_type") or "mttr_slo_breach"),
                payload={
                    "event": "mttr_slo_breach",
                    "checked_at": started_at.isoformat(),
                    "event_type_scope": event_type,
                    "policy": {
                        "policy_key": policy_key,
                        "enabled": bool(policy.get("enabled", True)),
                        "window_days": window_days,
                        "threshold_minutes": threshold_minutes,
                        "min_incidents": min_incidents,
                        "auto_recover_enabled": bool(policy.get("auto_recover_enabled", True)),
                        "recover_state": str(policy.get("recover_state") or "quarantined"),
                        "recover_max_targets": int(policy.get("recover_max_targets") or ALERT_GUARD_RECOVER_MAX_TARGETS),
                    },
                    "window": {
                        "days": window_days,
                        "incident_count": incident_count,
                        "recovered_incidents": recovered_incidents,
                        "unresolved_incidents": unresolved_incidents,
                        "mttr_minutes": mttr_value,
                    },
                    "top_channels": top_channels,
                    "auto_recover_result": auto_recover_result,
                },
            )
            notify_channels = [item.model_dump() for item in channel_results]

    finished_at = datetime.now(timezone.utc)
    status = "success"
    if breach:
        status = "warning"
    if notify_attempted and notify_error is not None and notify_dispatched is False:
        status = "warning"

    run_id = _write_job_run(
        job_name="alert_mttr_slo_check",
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "event_type": event_type,
            "policy_key": policy_key,
            "policy_updated_at": policy_updated_at.isoformat(),
            "policy": policy,
            "window": {
                "days": window_days,
                "incident_count": incident_count,
                "recovered_incidents": recovered_incidents,
                "unresolved_incidents": unresolved_incidents,
                "mttr_minutes": mttr_value,
            },
            "breach": breach,
            "top_channels": top_channels,
            "actions": {
                "auto_recover_attempted": auto_recover_attempted,
                "auto_recover_result": auto_recover_result,
                "notify_attempted": notify_attempted,
                "notify_dispatched": notify_dispatched,
                "notify_error": notify_error,
                "notify_channels": notify_channels,
                "force_notify": force_notify,
                "cooldown_minutes": cooldown_minutes,
                "cooldown_active": cooldown_active,
                "cooldown_remaining_minutes": cooldown_remaining_minutes,
                "last_breach_at": last_breach_at.isoformat() if last_breach_at is not None else None,
            },
        },
    )

    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": status,
        "event_type": event_type,
        "policy_key": policy_key,
        "policy_updated_at": policy_updated_at.isoformat(),
        "policy": policy,
        "window": {
            "days": window_days,
            "incident_count": incident_count,
            "recovered_incidents": recovered_incidents,
            "unresolved_incidents": unresolved_incidents,
            "mttr_minutes": mttr_value,
        },
        "breach": breach,
        "top_channels": top_channels,
        "actions": {
            "auto_recover_attempted": auto_recover_attempted,
            "auto_recover_result": auto_recover_result,
            "notify_attempted": notify_attempted,
            "notify_dispatched": notify_dispatched,
            "notify_error": notify_error,
            "notify_channels": notify_channels,
            "force_notify": force_notify,
            "cooldown_minutes": cooldown_minutes,
            "cooldown_active": cooldown_active,
            "cooldown_remaining_minutes": cooldown_remaining_minutes,
            "last_breach_at": last_breach_at.isoformat() if last_breach_at is not None else None,
        },
    }


def _post_json_with_retries(
    *,
    url: str,
    payload: dict[str, Any],
    retries: int,
    timeout_sec: float,
) -> tuple[bool, str | None]:
    body = json.dumps(payload, ensure_ascii=False, default=str).encode("utf-8")
    attempts = max(1, retries)
    for attempt in range(1, attempts + 1):
        req = url_request.Request(
            url=url,
            data=body,
            method="POST",
            headers={"Content-Type": "application/json"},
        )
        try:
            with url_request.urlopen(req, timeout=timeout_sec) as resp:
                status_code = int(getattr(resp, "status", 0))
                if 200 <= status_code < 300:
                    return True, None
                err = f"webhook returned status {status_code}"
        except url_error.HTTPError as exc:
            err = f"webhook http error {exc.code}"
        except url_error.URLError as exc:
            err = f"webhook url error: {exc.reason}"
        except Exception as exc:  # pragma: no cover - defensive path
            err = f"webhook unexpected error: {exc}"

        if attempt < attempts:
            time.sleep(0.5 * (2 ** (attempt - 1)))
    return False, err


def _dispatch_alert_event(
    *,
    event_type: str,
    payload: dict[str, Any],
) -> tuple[bool, str | None, list[SlaAlertChannelResult]]:
    targets = _configured_alert_targets()
    if not targets:
        return False, None, []

    results: list[SlaAlertChannelResult] = []
    success_count = 0
    failed_count = 0

    for target in targets:
        guard_state = _compute_alert_channel_guard_state(target, event_type=event_type)
        if ALERT_CHANNEL_GUARD_ENABLED and str(guard_state.get("state_computed")) == "quarantined":
            guard_error = (
                "channel quarantined until "
                + str(guard_state.get("quarantined_until") or "unknown")
                + " (consecutive_failures="
                + str(guard_state.get("consecutive_failures") or 0)
                + ")"
            )
            _write_alert_delivery(
                event_type=event_type,
                target=target,
                status="warning",
                error=guard_error,
                payload={
                    **payload,
                    "guard": {
                        "state": guard_state.get("state_computed"),
                        "consecutive_failures": guard_state.get("consecutive_failures"),
                        "quarantined_until": guard_state.get("quarantined_until"),
                    },
                },
            )
            failed_count += 1
            results.append(SlaAlertChannelResult(target=target, success=False, error=guard_error))
            continue

        ok, err = _post_json_with_retries(
            url=target,
            payload=payload,
            retries=ALERT_WEBHOOK_RETRIES,
            timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
        )
        delivery_status = "success" if ok and err is None else ("warning" if ok else "failed")
        _write_alert_delivery(
            event_type=event_type,
            target=target,
            status=delivery_status,
            error=err,
            payload=payload,
        )
        if ok:
            success_count += 1
        else:
            failed_count += 1
        results.append(SlaAlertChannelResult(target=target, success=ok, error=err))

    if failed_count == 0:
        return True, None, results
    if success_count > 0:
        return True, f"{failed_count}/{len(results)} alert channels failed", results
    return False, "all alert channels failed", results


def _dispatch_sla_alert(
    *,
    site: str | None,
    checked_at: datetime,
    escalated_count: int,
    work_order_ids: list[int],
) -> tuple[bool, str | None, list[SlaAlertChannelResult]]:
    if escalated_count <= 0:
        return False, None, []

    payload = {
        "event": "sla_escalation",
        "site": site or "ALL",
        "checked_at": checked_at.isoformat(),
        "escalated_count": escalated_count,
        "work_order_ids": work_order_ids,
    }
    return _dispatch_alert_event(event_type="sla_escalation", payload=payload)


def _row_to_admin_user_model(row: dict[str, Any]) -> AdminUserRead:
    role = str(row["role"])
    custom_permissions = _permission_text_to_list(row["permissions"])
    user_site_scope = _site_scope_text_to_list(row["site_scope"], default_all=True)
    return AdminUserRead(
        id=int(row["id"]),
        username=str(row["username"]),
        display_name=str(row["display_name"] or row["username"]),
        role=role,
        permissions=_effective_permissions(role, custom_permissions),
        site_scope=user_site_scope,
        is_active=bool(row["is_active"]),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_admin_token_model(row: dict[str, Any]) -> AdminTokenRead:
    user_scope = _site_scope_text_to_list(row.get("user_site_scope"), default_all=True)
    token_scope_raw = row.get("token_site_scope")
    token_scope = None
    if token_scope_raw is not None:
        token_scope = _site_scope_text_to_list(token_scope_raw, default_all=True)
    effective_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
    created_at = _as_datetime(row["created_at"])
    expires_at = _as_optional_datetime(row["expires_at"])
    last_used_at = _as_optional_datetime(row["last_used_at"])
    rotate_due_at = _token_rotate_due_at(created_at)
    idle_due_at = _token_idle_due_at(created_at=created_at, last_used_at=last_used_at)
    warning_due_at = None
    if rotate_due_at is not None and ADMIN_TOKEN_ROTATE_WARNING_DAYS > 0:
        warning_due_at = rotate_due_at - timedelta(days=ADMIN_TOKEN_ROTATE_WARNING_DAYS)
    must_rotate = rotate_due_at is not None and warning_due_at is not None and datetime.now(timezone.utc) >= warning_due_at
    return AdminTokenRead(
        token_id=int(row["token_id"]),
        user_id=int(row["user_id"]),
        username=str(row["username"]),
        label=str(row["label"] or ""),
        is_active=bool(row["is_active"]),
        site_scope=effective_scope,
        expires_at=expires_at,
        last_used_at=last_used_at,
        created_at=created_at,
        rotate_due_at=rotate_due_at,
        idle_due_at=idle_due_at,
        must_rotate=must_rotate,
    )


def _row_to_work_order_model(row: dict[str, Any]) -> WorkOrderRead:
    due_at = _as_optional_datetime(row["due_at"])
    status = row["status"]
    return WorkOrderRead(
        id=row["id"],
        title=row["title"],
        description=row["description"] or "",
        site=row["site"],
        location=row["location"],
        priority=row["priority"],
        status=status,
        assignee=row["assignee"],
        reporter=row["reporter"],
        inspection_id=row["inspection_id"],
        due_at=due_at,
        acknowledged_at=_as_optional_datetime(row["acknowledged_at"]),
        completed_at=_as_optional_datetime(row["completed_at"]),
        resolution_notes=row["resolution_notes"] or "",
        is_escalated=bool(row["is_escalated"]),
        is_overdue=_is_overdue(status, due_at),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _validate_work_order_transition(current_status: str, next_status: str) -> None:
    allowed = WORK_ORDER_TRANSITIONS.get(current_status, set())
    if next_status not in allowed:
        raise HTTPException(status_code=409, detail=f"Invalid status transition: {current_status} -> {next_status}")


def _append_work_order_event(
    conn: Any,
    *,
    work_order_id: int,
    event_type: str,
    actor_username: str,
    from_status: str | None = None,
    to_status: str | None = None,
    note: str = "",
    detail: dict[str, Any] | None = None,
) -> None:
    conn.execute(
        insert(work_order_events).values(
            work_order_id=work_order_id,
            event_type=event_type,
            actor_username=actor_username,
            from_status=from_status,
            to_status=to_status,
            note=note,
            detail_json=_to_json_text(detail),
            created_at=datetime.now(timezone.utc),
        )
    )


def _row_to_work_order_event_model(row: dict[str, Any]) -> WorkOrderEventRead:
    raw = str(row["detail_json"] or "{}")
    try:
        detail = json.loads(raw)
    except json.JSONDecodeError:
        detail = {"raw": raw}
    if not isinstance(detail, dict):
        detail = {"value": detail}

    return WorkOrderEventRead(
        id=int(row["id"]),
        work_order_id=int(row["work_order_id"]),
        event_type=str(row["event_type"]),
        actor_username=str(row["actor_username"]),
        from_status=row["from_status"],
        to_status=row["to_status"],
        note=str(row["note"] or ""),
        detail=detail,
        created_at=_as_datetime(row["created_at"]),
    )


def _row_to_workflow_lock_model(row: dict[str, Any]) -> WorkflowLockRead:
    raw = str(row["content_json"] or "{}")
    try:
        content = json.loads(raw)
    except json.JSONDecodeError:
        content = {"raw": raw}
    if not isinstance(content, dict):
        content = {"value": content}

    return WorkflowLockRead(
        id=int(row["id"]),
        site=str(row["site"]),
        workflow_key=str(row["workflow_key"]),
        status=str(row["status"]),
        content=content,
        requested_ticket=row.get("requested_ticket"),
        last_comment=str(row.get("last_comment") or ""),
        lock_reason=row.get("lock_reason"),
        unlock_reason=row.get("unlock_reason"),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        reviewed_by=row.get("reviewed_by"),
        approved_by=row.get("approved_by"),
        locked_by=row.get("locked_by"),
        unlocked_by=row.get("unlocked_by"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
        reviewed_at=_as_optional_datetime(row.get("reviewed_at")),
        approved_at=_as_optional_datetime(row.get("approved_at")),
        locked_at=_as_optional_datetime(row.get("locked_at")),
        unlocked_at=_as_optional_datetime(row.get("unlocked_at")),
    )


def _row_to_w02_tracker_item_model(row: dict[str, Any]) -> W02TrackerItemRead:
    return W02TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w02_evidence_model(row: dict[str, Any]) -> W02EvidenceRead:
    return W02EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w02_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w02_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W02_SOP_RUNBOOKS:
        entries.append(
            {
                "site": site,
                "item_type": "sop_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("name", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W02_SANDBOX_SCENARIOS:
        entries.append(
            {
                "site": site,
                "item_type": "sandbox_scenario",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("objective", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W02_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w02_tracker_overview(site: str, rows: list[W02TrackerItemRead]) -> W02TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W02TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w02_tracker_readiness(
    *,
    site: str,
    rows: list[W02TrackerItemRead],
    checked_at: datetime | None = None,
) -> W02TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W02_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (sandbox_scenario)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W02TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w02_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W02_SITE_COMPLETION_STATUS_SET:
        return value
    return W02_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w02_completion_model(
    *,
    site: str,
    readiness: W02TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W02TrackerCompletionRead:
    if row is None:
        return W02TrackerCompletionRead(
            site=site,
            status=W02_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w02_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W02TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w02_tracker_items_for_site(site: str) -> list[W02TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w02_tracker_items)
            .where(adoption_w02_tracker_items.c.site == site)
            .order_by(
                adoption_w02_tracker_items.c.item_type.asc(),
                adoption_w02_tracker_items.c.item_key.asc(),
                adoption_w02_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w02_tracker_item_model(row) for row in rows]


def _reset_w02_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w02_site_runs.c.status)
        .where(adoption_w02_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w02_site_completion_status(row.get("status"))
    if status == W02_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w02_site_runs)
        .where(adoption_w02_site_runs.c.site == site)
        .values(
            status=W02_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w03_tracker_item_model(row: dict[str, Any]) -> W03TrackerItemRead:
    return W03TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w03_evidence_model(row: dict[str, Any]) -> W03EvidenceRead:
    return W03EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w03_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w03_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W03_KICKOFF_AGENDA:
        entries.append(
            {
                "site": site,
                "item_type": "kickoff_agenda",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("topic", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_ROLE_WORKSHOPS:
        entries.append(
            {
                "site": site,
                "item_type": "role_workshop",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("objective", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_OFFICE_HOURS:
        entries.append(
            {
                "site": site,
                "item_type": "office_hour",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("focus", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w03_tracker_overview(site: str, rows: list[W03TrackerItemRead]) -> W03TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W03TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w03_tracker_readiness(
    *,
    site: str,
    rows: list[W03TrackerItemRead],
    checked_at: datetime | None = None,
) -> W03TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W03_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (role_workshop)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W03TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w03_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W03_SITE_COMPLETION_STATUS_SET:
        return value
    return W03_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w03_completion_model(
    *,
    site: str,
    readiness: W03TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W03TrackerCompletionRead:
    if row is None:
        return W03TrackerCompletionRead(
            site=site,
            status=W03_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w03_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W03TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w03_tracker_items_for_site(site: str) -> list[W03TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w03_tracker_items)
            .where(adoption_w03_tracker_items.c.site == site)
            .order_by(
                adoption_w03_tracker_items.c.item_type.asc(),
                adoption_w03_tracker_items.c.item_key.asc(),
                adoption_w03_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w03_tracker_item_model(row) for row in rows]


def _reset_w03_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w03_site_runs.c.status)
        .where(adoption_w03_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w03_site_completion_status(row.get("status"))
    if status == W03_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w03_site_runs)
        .where(adoption_w03_site_runs.c.site == site)
        .values(
            status=W03_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w04_tracker_item_model(row: dict[str, Any]) -> W04TrackerItemRead:
    return W04TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w04_evidence_model(row: dict[str, Any]) -> W04EvidenceRead:
    return W04EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w04_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w04_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W04_COACHING_ACTIONS:
        entries.append(
            {
                "site": site,
                "item_type": "coaching_action",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("action", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W04_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w04_tracker_overview(site: str, rows: list[W04TrackerItemRead]) -> W04TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W04TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w04_tracker_readiness(
    *,
    site: str,
    rows: list[W04TrackerItemRead],
    checked_at: datetime | None = None,
) -> W04TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W04_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (coaching_action)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W04TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w04_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W04_SITE_COMPLETION_STATUS_SET:
        return value
    return W04_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w04_completion_model(
    *,
    site: str,
    readiness: W04TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W04TrackerCompletionRead:
    if row is None:
        return W04TrackerCompletionRead(
            site=site,
            status=W04_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w04_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W04TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w04_tracker_items_for_site(site: str) -> list[W04TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w04_tracker_items)
            .where(adoption_w04_tracker_items.c.site == site)
            .order_by(
                adoption_w04_tracker_items.c.item_type.asc(),
                adoption_w04_tracker_items.c.item_key.asc(),
                adoption_w04_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w04_tracker_item_model(row) for row in rows]


def _reset_w04_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w04_site_runs.c.status)
        .where(adoption_w04_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w04_site_completion_status(row.get("status"))
    if status == W04_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w04_site_runs)
        .where(adoption_w04_site_runs.c.site == site)
        .values(
            status=W04_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w07_tracker_item_model(row: dict[str, Any]) -> W07TrackerItemRead:
    return W07TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w07_evidence_model(row: dict[str, Any]) -> W07EvidenceRead:
    return W07EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w07_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w07_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W07_SLA_CHECKLIST:
        entries.append(
            {
                "site": site,
                "item_type": "sla_checklist",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("control", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W07_COACHING_PLAYS:
        entries.append(
            {
                "site": site,
                "item_type": "coaching_play",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("play", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W07_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w07_tracker_overview(site: str, rows: list[W07TrackerItemRead]) -> W07TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W07TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w07_tracker_readiness(
    *,
    site: str,
    rows: list[W07TrackerItemRead],
    checked_at: datetime | None = None,
) -> W07TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W07_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (sla_checklist/coaching_play)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W07TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w07_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W07_SITE_COMPLETION_STATUS_SET:
        return value
    return W07_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w07_completion_model(
    *,
    site: str,
    readiness: W07TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W07TrackerCompletionRead:
    if row is None:
        return W07TrackerCompletionRead(
            site=site,
            status=W07_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w07_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W07TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w07_tracker_items_for_site(site: str) -> list[W07TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w07_tracker_items)
            .where(adoption_w07_tracker_items.c.site == site)
            .order_by(
                adoption_w07_tracker_items.c.item_type.asc(),
                adoption_w07_tracker_items.c.item_key.asc(),
                adoption_w07_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w07_tracker_item_model(row) for row in rows]


def _reset_w07_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w07_site_runs.c.status)
        .where(adoption_w07_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w07_site_completion_status(row.get("status"))
    if status == W07_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w07_site_runs)
        .where(adoption_w07_site_runs.c.site == site)
        .values(
            status=W07_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w09_tracker_item_model(row: dict[str, Any]) -> W09TrackerItemRead:
    return W09TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w09_evidence_model(row: dict[str, Any]) -> W09EvidenceRead:
    return W09EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w09_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w09_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W09_KPI_THRESHOLD_MATRIX:
        entries.append(
            {
                "site": site,
                "item_type": "kpi_threshold",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("kpi_name", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W09_ESCALATION_MAP:
        entries.append(
            {
                "site": site,
                "item_type": "kpi_escalation",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("action", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W09_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w09_tracker_overview(site: str, rows: list[W09TrackerItemRead]) -> W09TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W09TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w09_tracker_readiness(
    *,
    site: str,
    rows: list[W09TrackerItemRead],
    checked_at: datetime | None = None,
) -> W09TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W09_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (kpi_threshold/kpi_escalation)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W09TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w09_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W09_SITE_COMPLETION_STATUS_SET:
        return value
    return W09_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w09_completion_model(
    *,
    site: str,
    readiness: W09TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W09TrackerCompletionRead:
    if row is None:
        return W09TrackerCompletionRead(
            site=site,
            status=W09_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w09_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W09TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w09_tracker_items_for_site(site: str) -> list[W09TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w09_tracker_items)
            .where(adoption_w09_tracker_items.c.site == site)
            .order_by(
                adoption_w09_tracker_items.c.item_type.asc(),
                adoption_w09_tracker_items.c.item_key.asc(),
                adoption_w09_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w09_tracker_item_model(row) for row in rows]


def _reset_w09_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w09_site_runs.c.status)
        .where(adoption_w09_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w09_site_completion_status(row.get("status"))
    if status == W09_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w09_site_runs)
        .where(adoption_w09_site_runs.c.site == site)
        .values(
            status=W09_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w10_tracker_item_model(row: dict[str, Any]) -> W10TrackerItemRead:
    return W10TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W10_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w10_evidence_model(row: dict[str, Any]) -> W10EvidenceRead:
    return W10EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w10_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w10_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W10_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W10_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W10_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w10_tracker_overview(site: str, rows: list[W10TrackerItemRead]) -> W10TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W10TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w10_tracker_readiness(
    *,
    site: str,
    rows: list[W10TrackerItemRead],
    checked_at: datetime | None = None,
) -> W10TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W10_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W10TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w10_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W10_SITE_COMPLETION_STATUS_SET:
        return value
    return W10_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w10_completion_model(
    *,
    site: str,
    readiness: W10TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W10TrackerCompletionRead:
    if row is None:
        return W10TrackerCompletionRead(
            site=site,
            status=W10_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w10_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W10TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w10_tracker_items_for_site(site: str) -> list[W10TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w10_tracker_items)
            .where(adoption_w10_tracker_items.c.site == site)
            .order_by(
                adoption_w10_tracker_items.c.item_type.asc(),
                adoption_w10_tracker_items.c.item_key.asc(),
                adoption_w10_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w10_tracker_item_model(row) for row in rows]


def _reset_w10_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w10_site_runs.c.status)
        .where(adoption_w10_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w10_site_completion_status(row.get("status"))
    if status == W10_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w10_site_runs)
        .where(adoption_w10_site_runs.c.site == site)
        .values(
            status=W10_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )



def _row_to_w11_tracker_item_model(row: dict[str, Any]) -> W11TrackerItemRead:
    return W11TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W11_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w11_evidence_model(row: dict[str, Any]) -> W11EvidenceRead:
    return W11EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w11_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w11_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W11_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W11_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W11_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w11_tracker_overview(site: str, rows: list[W11TrackerItemRead]) -> W11TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W11TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w11_tracker_readiness(
    *,
    site: str,
    rows: list[W11TrackerItemRead],
    checked_at: datetime | None = None,
) -> W11TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W11_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W11TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w11_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W11_SITE_COMPLETION_STATUS_SET:
        return value
    return W11_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w11_completion_model(
    *,
    site: str,
    readiness: W11TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W11TrackerCompletionRead:
    if row is None:
        return W11TrackerCompletionRead(
            site=site,
            status=W11_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w11_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W11TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w11_tracker_items_for_site(site: str) -> list[W11TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w11_tracker_items)
            .where(adoption_w11_tracker_items.c.site == site)
            .order_by(
                adoption_w11_tracker_items.c.item_type.asc(),
                adoption_w11_tracker_items.c.item_key.asc(),
                adoption_w11_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w11_tracker_item_model(row) for row in rows]


def _reset_w11_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w11_site_runs.c.status)
        .where(adoption_w11_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w11_site_completion_status(row.get("status"))
    if status == W11_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w11_site_runs)
        .where(adoption_w11_site_runs.c.site == site)
        .values(
            status=W11_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )




def _w13_handoff_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W13_HANDOFF_POLICY_KEY_DEFAULT, None
    return f"{W13_HANDOFF_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w13_handoff_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "risk_rate_green_threshold": 20.0,
        "risk_rate_yellow_threshold": 30.0,
        "checklist_completion_green_threshold": 80.0,
        "checklist_completion_yellow_threshold": 60.0,
        "simulation_success_green_threshold": 80.0,
        "simulation_success_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w13_handoff_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w13_handoff_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "risk_rate_green_threshold",
        float(defaults["risk_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "risk_rate_yellow_threshold",
        float(defaults["risk_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "checklist_completion_green_threshold",
        float(defaults["checklist_completion_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "checklist_completion_yellow_threshold",
        float(defaults["checklist_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "simulation_success_green_threshold",
        float(defaults["simulation_success_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "simulation_success_yellow_threshold",
        float(defaults["simulation_success_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "risk_rate_green_threshold": repeat_green,
        "risk_rate_yellow_threshold": repeat_yellow,
        "checklist_completion_green_threshold": guide_green,
        "checklist_completion_yellow_threshold": guide_yellow,
        "simulation_success_green_threshold": runbook_green,
        "simulation_success_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w13_handoff_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w13_handoff_policy(loaded)


def _ensure_w13_handoff_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w13_handoff_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w13_handoff_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w13_handoff_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w13_handoff_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w13_handoff_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "risk_rate_green_threshold",
        "risk_rate_yellow_threshold",
        "checklist_completion_green_threshold",
        "checklist_completion_yellow_threshold",
        "simulation_success_green_threshold",
        "simulation_success_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w13_handoff_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w13_closure_handoff_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w13_handoff_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "work_orders_count": 0,
                    "unique_titles": 0,
                    "repeated_work_orders_count": 0,
                    "risk_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W13_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "checklist_completion_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W13_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "simulation_success_rate_percent": 0.0,
                    "closure_handoff_readiness_score": 0.0,
                    "overall_status": W13_HANDOFF_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_titles": [],
                "scale_checklist": ADOPTION_W13_SELF_SERVE_GUIDES,
                "simulation_runbook": ADOPTION_W13_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    risk_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_titles = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w13_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w13_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w13_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W13_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W13_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W13_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W13_TRACKER_STATUS_DONE
    )
    checklist_completion_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    simulation_success_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=risk_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("risk_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("risk_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=checklist_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("checklist_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("checklist_completion_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=simulation_success_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("simulation_success_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("simulation_success_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    closure_handoff_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W13_HANDOFF_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W13_HANDOFF_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W13_HANDOFF_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = closure_handoff_readiness_score >= readiness_target and overall_status != W13_HANDOFF_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": risk_rate_percent,
            "green_threshold": float(policy.get("risk_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("risk_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('risk_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "checklist_completion_rate_percent",
            "kpi_name": "Scale readiness guide publish rate",
            "direction": "higher_better",
            "actual_value": checklist_completion_rate_percent,
            "green_threshold": float(policy.get("checklist_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("checklist_completion_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('checklist_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "simulation_success_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": simulation_success_rate_percent,
            "green_threshold": float(policy.get("simulation_success_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("simulation_success_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('simulation_success_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "closure_handoff_readiness_score",
            "kpi_name": "Scale readiness readiness score",
            "direction": "higher_better",
            "actual_value": closure_handoff_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=closure_handoff_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Scale readiness guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W13    .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "work_orders_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_work_orders_count": repeated_orders_count,
            "risk_rate_percent": risk_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "checklist_completion_rate_percent": checklist_completion_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "simulation_success_rate_percent": simulation_success_rate_percent,
            "closure_handoff_readiness_score": closure_handoff_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_titles": top_repeat_titles,
        "scale_checklist": ADOPTION_W13_SELF_SERVE_GUIDES,
        "simulation_runbook": ADOPTION_W13_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }
def _w14_stability_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W14_STABILITY_POLICY_KEY_DEFAULT, None
    return f"{W14_STABILITY_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w14_stability_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "risk_rate_green_threshold": 20.0,
        "risk_rate_yellow_threshold": 30.0,
        "checklist_completion_green_threshold": 80.0,
        "checklist_completion_yellow_threshold": 60.0,
        "simulation_success_green_threshold": 80.0,
        "simulation_success_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w14_stability_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w14_stability_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "risk_rate_green_threshold",
        float(defaults["risk_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "risk_rate_yellow_threshold",
        float(defaults["risk_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "checklist_completion_green_threshold",
        float(defaults["checklist_completion_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "checklist_completion_yellow_threshold",
        float(defaults["checklist_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "simulation_success_green_threshold",
        float(defaults["simulation_success_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "simulation_success_yellow_threshold",
        float(defaults["simulation_success_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "risk_rate_green_threshold": repeat_green,
        "risk_rate_yellow_threshold": repeat_yellow,
        "checklist_completion_green_threshold": guide_green,
        "checklist_completion_yellow_threshold": guide_yellow,
        "simulation_success_green_threshold": runbook_green,
        "simulation_success_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w14_stability_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w14_stability_policy(loaded)


def _ensure_w14_stability_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w14_stability_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w14_stability_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w14_stability_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w14_stability_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w14_stability_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "risk_rate_green_threshold",
        "risk_rate_yellow_threshold",
        "checklist_completion_green_threshold",
        "checklist_completion_yellow_threshold",
        "simulation_success_green_threshold",
        "simulation_success_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w14_stability_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w14_stability_sprint_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w14_stability_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "incidents_count": 0,
                    "unique_titles": 0,
                    "repeated_incidents_count": 0,
                    "incident_repeat_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W14_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "checklist_completion_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W14_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "simulation_success_rate_percent": 0.0,
                    "stability_sprint_readiness_score": 0.0,
                    "overall_status": W14_STABILITY_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_incidents": [],
                "scale_checklist": ADOPTION_W14_SELF_SERVE_GUIDES,
                "simulation_runbook": ADOPTION_W14_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    incident_repeat_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_incidents = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w14_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w14_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w14_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W14_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W14_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W14_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W14_TRACKER_STATUS_DONE
    )
    checklist_completion_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    simulation_success_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=incident_repeat_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("risk_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("risk_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=checklist_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("checklist_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("checklist_completion_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=simulation_success_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("simulation_success_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("simulation_success_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    stability_sprint_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W14_STABILITY_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W14_STABILITY_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W14_STABILITY_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = stability_sprint_readiness_score >= readiness_target and overall_status != W14_STABILITY_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": incident_repeat_rate_percent,
            "green_threshold": float(policy.get("risk_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("risk_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('risk_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "checklist_completion_rate_percent",
            "kpi_name": "Scale readiness guide publish rate",
            "direction": "higher_better",
            "actual_value": checklist_completion_rate_percent,
            "green_threshold": float(policy.get("checklist_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("checklist_completion_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('checklist_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "simulation_success_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": simulation_success_rate_percent,
            "green_threshold": float(policy.get("simulation_success_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("simulation_success_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('simulation_success_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "stability_sprint_readiness_score",
            "kpi_name": "Scale readiness readiness score",
            "direction": "higher_better",
            "actual_value": stability_sprint_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=stability_sprint_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Scale readiness guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W14    .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "incidents_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_incidents_count": repeated_orders_count,
            "incident_repeat_rate_percent": incident_repeat_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "checklist_completion_rate_percent": checklist_completion_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "simulation_success_rate_percent": simulation_success_rate_percent,
            "stability_sprint_readiness_score": stability_sprint_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_incidents": top_repeat_incidents,
        "scale_checklist": ADOPTION_W14_SELF_SERVE_GUIDES,
        "simulation_runbook": ADOPTION_W14_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }


def _w15_efficiency_policy_key(site: str | None) -> tuple[str, str | None]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is None:
        return W15_EFFICIENCY_POLICY_KEY_DEFAULT, None
    return f"{W15_EFFICIENCY_POLICY_KEY_SITE_PREFIX}{normalized_site}", normalized_site


def _default_w15_efficiency_policy() -> dict[str, Any]:
    return {
        "enabled": True,
        "risk_rate_green_threshold": 20.0,
        "risk_rate_yellow_threshold": 30.0,
        "checklist_completion_green_threshold": 80.0,
        "checklist_completion_yellow_threshold": 60.0,
        "simulation_success_green_threshold": 80.0,
        "simulation_success_yellow_threshold": 60.0,
        "readiness_target": 75.0,
    }


def _normalize_w15_efficiency_policy(value: Any) -> dict[str, Any]:
    source = value if isinstance(value, dict) else {}
    defaults = _default_w15_efficiency_policy()

    def _float_value(key: str, fallback: float, min_value: float, max_value: float) -> float:
        try:
            raw = float(source.get(key, fallback))
        except (TypeError, ValueError):
            raw = fallback
        return round(max(min_value, min(raw, max_value)), 2)

    repeat_green = _float_value(
        "risk_rate_green_threshold",
        float(defaults["risk_rate_green_threshold"]),
        0.0,
        100.0,
    )
    repeat_yellow = _float_value(
        "risk_rate_yellow_threshold",
        float(defaults["risk_rate_yellow_threshold"]),
        0.0,
        100.0,
    )
    if repeat_yellow < repeat_green:
        repeat_yellow = repeat_green

    guide_green = _float_value(
        "checklist_completion_green_threshold",
        float(defaults["checklist_completion_green_threshold"]),
        0.0,
        100.0,
    )
    guide_yellow = _float_value(
        "checklist_completion_yellow_threshold",
        float(defaults["checklist_completion_yellow_threshold"]),
        0.0,
        100.0,
    )
    if guide_yellow > guide_green:
        guide_yellow = guide_green

    runbook_green = _float_value(
        "simulation_success_green_threshold",
        float(defaults["simulation_success_green_threshold"]),
        0.0,
        100.0,
    )
    runbook_yellow = _float_value(
        "simulation_success_yellow_threshold",
        float(defaults["simulation_success_yellow_threshold"]),
        0.0,
        100.0,
    )
    if runbook_yellow > runbook_green:
        runbook_yellow = runbook_green

    readiness_target = _float_value(
        "readiness_target",
        float(defaults["readiness_target"]),
        0.0,
        100.0,
    )

    return {
        "enabled": bool(source.get("enabled", defaults.get("enabled", True))),
        "risk_rate_green_threshold": repeat_green,
        "risk_rate_yellow_threshold": repeat_yellow,
        "checklist_completion_green_threshold": guide_green,
        "checklist_completion_yellow_threshold": guide_yellow,
        "simulation_success_green_threshold": runbook_green,
        "simulation_success_yellow_threshold": runbook_yellow,
        "readiness_target": readiness_target,
    }


def _parse_w15_efficiency_policy_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    return _normalize_w15_efficiency_policy(loaded)


def _ensure_w15_efficiency_policy(site: str | None) -> tuple[dict[str, Any], datetime, str, str | None]:
    policy_key, normalized_site = _w15_efficiency_policy_key(site)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policies).where(sla_policies.c.policy_key == policy_key).limit(1)
        ).mappings().first()
        if row is None:
            policy = _default_w15_efficiency_policy()
            conn.execute(
                insert(sla_policies).values(
                    policy_key=policy_key,
                    policy_json=_to_json_text(policy),
                    updated_at=now,
                )
            )
            return policy, now, policy_key, normalized_site
    policy = _parse_w15_efficiency_policy_json(row["policy_json"])
    updated_at = _as_datetime(row["updated_at"]) if row["updated_at"] is not None else now
    return policy, updated_at, policy_key, normalized_site


def _upsert_w15_efficiency_policy(site: str | None, payload: dict[str, Any]) -> tuple[dict[str, Any], datetime, str, str | None]:
    current_policy, _, policy_key, normalized_site = _ensure_w15_efficiency_policy(site)
    incoming = payload if isinstance(payload, dict) else {}
    merged: dict[str, Any] = {**current_policy}
    for key in [
        "enabled",
        "risk_rate_green_threshold",
        "risk_rate_yellow_threshold",
        "checklist_completion_green_threshold",
        "checklist_completion_yellow_threshold",
        "simulation_success_green_threshold",
        "simulation_success_yellow_threshold",
        "readiness_target",
    ]:
        if key in incoming:
            merged[key] = incoming[key]
    normalized = _normalize_w15_efficiency_policy(merged)
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        conn.execute(
            update(sla_policies)
            .where(sla_policies.c.policy_key == policy_key)
            .values(
                policy_json=_to_json_text(normalized),
                updated_at=now,
            )
        )
    return normalized, now, policy_key, normalized_site


def _build_w15_ops_efficiency_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    window_start = now - timedelta(days=window_days)
    policy, policy_updated_at, policy_key, policy_site = _ensure_w15_efficiency_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    stmt = select(work_orders).where(work_orders.c.created_at >= window_start)
    if effective_site is not None:
        stmt = stmt.where(work_orders.c.site == effective_site)
    elif effective_allowed_sites is not None:
        if not effective_allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": None,
                "window_days": window_days,
                "policy": {
                    "policy_key": policy_key,
                    "updated_at": policy_updated_at.isoformat(),
                    "enabled": bool(policy.get("enabled", True)),
                },
                "metrics": {
                    "incidents_count": 0,
                    "unique_titles": 0,
                    "repeated_incidents_count": 0,
                    "incident_repeat_rate_percent": 0.0,
                    "guide_total_count": len(ADOPTION_W15_SELF_SERVE_GUIDES),
                    "guide_done_count": 0,
                    "checklist_completion_rate_percent": 0.0,
                    "runbook_total_count": len(ADOPTION_W15_TROUBLESHOOTING_RUNBOOK),
                    "runbook_done_count": 0,
                    "simulation_success_rate_percent": 0.0,
                    "ops_efficiency_readiness_score": 0.0,
                    "overall_status": W15_EFFICIENCY_STATUS_RED,
                    "target_met": False,
                },
                "kpis": [],
                "top_repeat_incidents": [],
                "scale_checklist": ADOPTION_W15_SELF_SERVE_GUIDES,
                "simulation_runbook": ADOPTION_W15_TROUBLESHOOTING_RUNBOOK,
                "recommendations": ["  site   . site_scope ."],
            }
        stmt = stmt.where(work_orders.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        wo_rows = conn.execute(stmt).mappings().all()

    title_counts: dict[str, int] = {}
    title_label: dict[str, str] = {}
    for row in wo_rows:
        title_raw = str(row.get("title") or "").strip()
        normalized = title_raw.lower() if title_raw else "(untitled)"
        title_counts[normalized] = title_counts.get(normalized, 0) + 1
        if normalized not in title_label:
            title_label[normalized] = title_raw or "(untitled)"

    total_work_orders = len(wo_rows)
    repeated_orders_count = sum(count for count in title_counts.values() if count >= 2)
    unique_titles = len(title_counts)
    incident_repeat_rate_percent = round((repeated_orders_count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0
    top_repeat_incidents = sorted(
        [
            {
                "title": title_label.get(key, key),
                "count": count,
                "share_percent": round((count / total_work_orders) * 100.0, 2) if total_work_orders > 0 else 0.0,
            }
            for key, count in title_counts.items()
            if count >= 2
        ],
        key=lambda item: int(item.get("count") or 0),
        reverse=True,
    )[:10]

    tracker_stmt = select(adoption_w15_tracker_items)
    if effective_site is not None:
        tracker_stmt = tracker_stmt.where(adoption_w15_tracker_items.c.site == effective_site)
    elif effective_allowed_sites is not None:
        tracker_stmt = tracker_stmt.where(adoption_w15_tracker_items.c.site.in_(effective_allowed_sites))
    with get_conn() as conn:
        tracker_rows = conn.execute(tracker_stmt).mappings().all()

    guide_total_count = max(
        len(ADOPTION_W15_SELF_SERVE_GUIDES),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "self_serve_guide"),
    )
    runbook_total_count = max(
        len(ADOPTION_W15_TROUBLESHOOTING_RUNBOOK),
        sum(1 for row in tracker_rows if str(row.get("item_type") or "") == "troubleshooting_runbook"),
    )
    guide_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "self_serve_guide" and str(row.get("status") or "") == W15_TRACKER_STATUS_DONE
    )
    runbook_done_count = sum(
        1
        for row in tracker_rows
        if str(row.get("item_type") or "") == "troubleshooting_runbook" and str(row.get("status") or "") == W15_TRACKER_STATUS_DONE
    )
    checklist_completion_rate_percent = round((guide_done_count / guide_total_count) * 100.0, 2) if guide_total_count > 0 else 0.0
    simulation_success_rate_percent = (
        round((runbook_done_count / runbook_total_count) * 100.0, 2) if runbook_total_count > 0 else 0.0
    )

    repeat_status = _evaluate_w09_kpi_status(
        actual=incident_repeat_rate_percent,
        direction="lower_better",
        green_threshold=float(policy.get("risk_rate_green_threshold") or 20.0),
        yellow_threshold=float(policy.get("risk_rate_yellow_threshold") or 30.0),
    )
    guide_status = _evaluate_w09_kpi_status(
        actual=checklist_completion_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("checklist_completion_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("checklist_completion_yellow_threshold") or 60.0),
    )
    runbook_status = _evaluate_w09_kpi_status(
        actual=simulation_success_rate_percent,
        direction="higher_better",
        green_threshold=float(policy.get("simulation_success_green_threshold") or 80.0),
        yellow_threshold=float(policy.get("simulation_success_yellow_threshold") or 60.0),
    )

    status_points = {
        W09_KPI_STATUS_RED: 0.0,
        W09_KPI_STATUS_YELLOW: 50.0,
        W09_KPI_STATUS_GREEN: 100.0,
    }
    ops_efficiency_readiness_score = round(
        (status_points.get(repeat_status, 0.0) + status_points.get(guide_status, 0.0) + status_points.get(runbook_status, 0.0))
        / 3.0,
        2,
    )

    status_set = {repeat_status, guide_status, runbook_status}
    overall_status = W15_EFFICIENCY_STATUS_GREEN
    if W09_KPI_STATUS_RED in status_set:
        overall_status = W15_EFFICIENCY_STATUS_RED
    elif W09_KPI_STATUS_YELLOW in status_set:
        overall_status = W15_EFFICIENCY_STATUS_YELLOW

    readiness_target = float(policy.get("readiness_target") or 75.0)
    target_met = ops_efficiency_readiness_score >= readiness_target and overall_status != W15_EFFICIENCY_STATUS_RED

    kpis = [
        {
            "kpi_key": "repeat_ticket_rate_percent",
            "kpi_name": "Repeat ticket rate",
            "direction": "lower_better",
            "actual_value": incident_repeat_rate_percent,
            "green_threshold": float(policy.get("risk_rate_green_threshold") or 20.0),
            "yellow_threshold": float(policy.get("risk_rate_yellow_threshold") or 30.0),
            "status": repeat_status,
            "target": f"<= {policy.get('risk_rate_green_threshold', 20.0)}%",
        },
        {
            "kpi_key": "checklist_completion_rate_percent",
            "kpi_name": "Scale readiness guide publish rate",
            "direction": "higher_better",
            "actual_value": checklist_completion_rate_percent,
            "green_threshold": float(policy.get("checklist_completion_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("checklist_completion_yellow_threshold") or 60.0),
            "status": guide_status,
            "target": f">= {policy.get('checklist_completion_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "simulation_success_rate_percent",
            "kpi_name": "Runbook completion rate",
            "direction": "higher_better",
            "actual_value": simulation_success_rate_percent,
            "green_threshold": float(policy.get("simulation_success_green_threshold") or 80.0),
            "yellow_threshold": float(policy.get("simulation_success_yellow_threshold") or 60.0),
            "status": runbook_status,
            "target": f">= {policy.get('simulation_success_green_threshold', 80.0)}%",
        },
        {
            "kpi_key": "ops_efficiency_readiness_score",
            "kpi_name": "Operations efficiency readiness score",
            "direction": "higher_better",
            "actual_value": ops_efficiency_readiness_score,
            "green_threshold": readiness_target,
            "yellow_threshold": max(0.0, readiness_target - 15.0),
            "status": _evaluate_w09_kpi_status(
                actual=ops_efficiency_readiness_score,
                direction="higher_better",
                green_threshold=readiness_target,
                yellow_threshold=max(0.0, readiness_target - 15.0),
            ),
            "target": f">= {readiness_target}",
        },
    ]

    recommendations: list[str] = []
    if repeat_status == W09_KPI_STATUS_RED:
        recommendations.append("   . Top   3 FAQ/  .")
    if guide_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Self-serve guide  .     .")
    if runbook_status != W09_KPI_STATUS_GREEN:
        recommendations.append("Runbook  .      .")
    if not recommendations:
        recommendations.append("W15    .    .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "readiness_target": readiness_target,
        },
        "metrics": {
            "incidents_count": total_work_orders,
            "unique_titles": unique_titles,
            "repeated_incidents_count": repeated_orders_count,
            "incident_repeat_rate_percent": incident_repeat_rate_percent,
            "guide_total_count": guide_total_count,
            "guide_done_count": guide_done_count,
            "checklist_completion_rate_percent": checklist_completion_rate_percent,
            "runbook_total_count": runbook_total_count,
            "runbook_done_count": runbook_done_count,
            "simulation_success_rate_percent": simulation_success_rate_percent,
            "ops_efficiency_readiness_score": ops_efficiency_readiness_score,
            "overall_status": overall_status,
            "target_met": target_met,
        },
        "kpis": kpis,
        "top_repeat_incidents": top_repeat_incidents,
        "scale_checklist": ADOPTION_W15_SELF_SERVE_GUIDES,
        "simulation_runbook": ADOPTION_W15_TROUBLESHOOTING_RUNBOOK,
        "recommendations": recommendations,
    }




def _latest_mttr_slo_breach_finished_at(max_rows: int = 50) -> datetime | None:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.detail_json)
            .where(job_runs.c.job_name == "alert_mttr_slo_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(max(1, min(max_rows, 500)))
        ).mappings().all()
    for row in rows:
        raw = str(row.get("detail_json") or "{}")
        try:
            detail = json.loads(raw)
        except json.JSONDecodeError:
            detail = {}
        if not isinstance(detail, dict):
            continue
        if bool(detail.get("breach")):
            finished_at = _as_optional_datetime(row.get("finished_at"))
            if finished_at is not None:
                return finished_at
    return None


def _configured_alert_targets() -> list[str]:
    targets: list[str] = []
    merged_raw = ALERT_WEBHOOK_URLS.replace(";", ",").replace("\n", ",")
    for part in merged_raw.split(","):
        value = part.strip()
        if value:
            targets.append(value)
    if ALERT_WEBHOOK_URL:
        targets.append(ALERT_WEBHOOK_URL)

    deduped: list[str] = []
    seen: set[str] = set()
    for target in targets:
        if target in seen:
            continue
        seen.add(target)
        deduped.append(target)
    return deduped


def _normalize_ops_daily_check_alert_level(value: str | None) -> str:
    normalized = (value or "").strip().lower()
    if normalized in {"off", "none", "disabled"}:
        return "off"
    if normalized in {"warning", "warn"}:
        return "warning"
    if normalized in {"critical", "crit"}:
        return "critical"
    if normalized in {"always", "all", "ok"}:
        return "always"
    return "critical"


def _is_alert_failure_status(status: str) -> bool:
    return status.strip().lower() in {"failed", "warning"}


def _compute_alert_channel_guard_state(
    target: str,
    *,
    now: datetime | None = None,
    event_type: str | None = None,
    lookback_days: int = 30,
) -> dict[str, Any]:
    current_time = now or datetime.now(timezone.utc)
    normalized_lookback_days = max(1, lookback_days)
    history_start = current_time - timedelta(days=normalized_lookback_days)
    stmt = (
        select(
            alert_deliveries.c.status,
            alert_deliveries.c.error,
            alert_deliveries.c.last_attempt_at,
        )
        .where(alert_deliveries.c.target == target)
        .where(alert_deliveries.c.last_attempt_at >= history_start)
        .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
        .limit(200)
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    last_attempt_at: datetime | None = None
    last_status: str | None = None
    last_error: str | None = None
    last_success_at: datetime | None = None
    last_failure_at: datetime | None = None
    consecutive_failures = 0

    for idx, row in enumerate(rows):
        attempted_at = _as_optional_datetime(row.get("last_attempt_at"))
        if attempted_at is None:
            continue
        status = str(row.get("status") or "failed").strip().lower()
        error_text = str(row.get("error") or "")
        if idx == 0:
            last_attempt_at = attempted_at
            last_status = status
            last_error = error_text or None

        if status == "success":
            last_success_at = attempted_at
            # Consecutive failure run is determined from most recent attempt backward
            break
        if _is_alert_failure_status(status):
            if last_failure_at is None:
                last_failure_at = attempted_at
            consecutive_failures += 1
            continue
        break

    threshold = max(1, ALERT_CHANNEL_GUARD_FAIL_THRESHOLD)
    cooldown_minutes = max(1, ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES)
    quarantined_until: datetime | None = None
    state = "healthy"
    if consecutive_failures >= threshold and last_failure_at is not None:
        quarantined_until = last_failure_at + timedelta(minutes=cooldown_minutes)
        if current_time < quarantined_until:
            state = "quarantined"
        else:
            state = "warning"
    elif consecutive_failures > 0:
        state = "warning"

    remaining_quarantine_minutes = 0
    if quarantined_until is not None and current_time < quarantined_until:
        remaining_quarantine_minutes = max(
            1,
            int(math.ceil((quarantined_until - current_time).total_seconds() / 60.0)),
        )

    return {
        "target": target,
        "state": state if ALERT_CHANNEL_GUARD_ENABLED else "disabled",
        "state_computed": state,
        "consecutive_failures": consecutive_failures,
        "threshold": threshold,
        "cooldown_minutes": cooldown_minutes,
        "remaining_quarantine_minutes": remaining_quarantine_minutes,
        "quarantined_until": quarantined_until.isoformat() if quarantined_until is not None else None,
        "last_attempt_at": last_attempt_at.isoformat() if last_attempt_at is not None else None,
        "last_status": last_status,
        "last_error": last_error,
        "last_success_at": last_success_at.isoformat() if last_success_at is not None else None,
        "last_failure_at": last_failure_at.isoformat() if last_failure_at is not None else None,
        "delivery_count_lookback": len(rows),
    }


def _build_alert_channel_guard_snapshot(
    *,
    event_type: str | None = None,
    lookback_days: int = 30,
    max_targets: int = 100,
    now: datetime | None = None,
) -> dict[str, Any]:
    current_time = now or datetime.now(timezone.utc)
    normalized_lookback_days = max(1, lookback_days)
    normalized_max_targets = max(1, min(max_targets, 500))
    history_start = current_time - timedelta(days=normalized_lookback_days)
    target_set: set[str] = set(_configured_alert_targets())

    stmt = (
        select(alert_deliveries.c.target)
        .where(alert_deliveries.c.last_attempt_at >= history_start)
        .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
        .limit(2000)
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)
    with get_conn() as conn:
        recent_targets = conn.execute(stmt).all()
    for row in recent_targets:
        value = str(row[0] or "").strip()
        if value:
            target_set.add(value)

    channels = [
        _compute_alert_channel_guard_state(
            target,
            now=current_time,
            event_type=event_type,
            lookback_days=normalized_lookback_days,
        )
        for target in sorted(target_set)
    ]

    def _state_rank(item: dict[str, Any]) -> int:
        state = str(item.get("state_computed") or "healthy")
        if state == "quarantined":
            return 0
        if state == "warning":
            return 1
        return 2

    channels.sort(key=lambda item: (_state_rank(item), str(item.get("target") or "")))
    limited_channels = channels[:normalized_max_targets]
    quarantined_count = sum(1 for item in channels if str(item.get("state_computed")) == "quarantined")
    warning_count = sum(1 for item in channels if str(item.get("state_computed")) == "warning")
    healthy_count = sum(1 for item in channels if str(item.get("state_computed")) == "healthy")
    status = "ok"
    if quarantined_count > 0:
        status = "critical"
    elif warning_count > 0:
        status = "warning"
    if not ALERT_CHANNEL_GUARD_ENABLED:
        status = "warning" if warning_count > 0 else "ok"

    return {
        "generated_at": current_time.isoformat(),
        "event_type": event_type,
        "lookback_days": normalized_lookback_days,
        "policy": {
            "enabled": ALERT_CHANNEL_GUARD_ENABLED,
            "failure_threshold": max(1, ALERT_CHANNEL_GUARD_FAIL_THRESHOLD),
            "cooldown_minutes": max(1, ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES),
            "recovery_steps": [
                "1)  (//) ",
                "2) /api/ops/alerts/channels/guard/recover probe ",
                "3)     healthy  ",
            ],
        },
        "summary": {
            "status": status,
            "target_count": len(channels),
            "healthy_count": healthy_count,
            "warning_count": warning_count,
            "quarantined_count": quarantined_count,
            "returned_count": len(limited_channels),
        },
        "channels": limited_channels,
    }


def _build_alert_delivery_archive_csv(rows: list[dict[str, Any]]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "id",
            "event_type",
            "target",
            "status",
            "error",
            "attempt_count",
            "last_attempt_at",
            "created_at",
            "updated_at",
            "payload_json",
        ]
    )
    for row in rows:
        writer.writerow(
            [
                int(row.get("id") or 0),
                str(row.get("event_type") or ""),
                str(row.get("target") or ""),
                str(row.get("status") or ""),
                str(row.get("error") or ""),
                int(row.get("attempt_count") or 0),
                _as_optional_datetime(row.get("last_attempt_at")).isoformat()
                if _as_optional_datetime(row.get("last_attempt_at")) is not None
                else "",
                _as_optional_datetime(row.get("created_at")).isoformat()
                if _as_optional_datetime(row.get("created_at")) is not None
                else "",
                _as_optional_datetime(row.get("updated_at")).isoformat()
                if _as_optional_datetime(row.get("updated_at")) is not None
                else "",
                str(row.get("payload_json") or "{}"),
            ]
        )
    return buffer.getvalue()


def run_alert_retention_job(
    *,
    retention_days: int | None = None,
    max_delete: int | None = None,
    dry_run: bool = False,
    write_archive: bool | None = None,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    resolved_retention_days = max(1, int(retention_days if retention_days is not None else ALERT_RETENTION_DAYS))
    resolved_max_delete = max(1, min(int(max_delete if max_delete is not None else ALERT_RETENTION_MAX_DELETE), 50000))
    resolved_write_archive = ALERT_RETENTION_ARCHIVE_ENABLED if write_archive is None else bool(write_archive)
    cutoff = started_at - timedelta(days=resolved_retention_days)

    archive_file: str | None = None
    archive_error: str | None = None
    deleted_count = 0
    candidate_count = 0
    candidate_ids: list[int] = []

    with get_conn() as conn:
        rows = conn.execute(
            select(alert_deliveries)
            .where(alert_deliveries.c.last_attempt_at < cutoff)
            .order_by(alert_deliveries.c.last_attempt_at.asc(), alert_deliveries.c.id.asc())
            .limit(resolved_max_delete)
        ).mappings().all()
        candidate_count = len(rows)
        candidate_ids = [int(row["id"]) for row in rows]

        can_delete = not dry_run
        if rows and not dry_run and resolved_write_archive:
            try:
                archive_dir = Path(ALERT_RETENTION_ARCHIVE_PATH)
                archive_dir.mkdir(parents=True, exist_ok=True)
                stamp = started_at.strftime("%Y%m%dT%H%M%SZ")
                first_id = candidate_ids[0]
                last_id = candidate_ids[-1]
                file_path = archive_dir / f"alert-deliveries-{stamp}-{first_id}-{last_id}.csv"
                file_path.write_text(_build_alert_delivery_archive_csv([dict(row) for row in rows]), encoding="utf-8")
                archive_file = str(file_path)
            except Exception as exc:  # pragma: no cover - defensive path
                archive_error = str(exc)
                can_delete = False

        if rows and can_delete:
            delete_result = conn.execute(
                delete(alert_deliveries).where(alert_deliveries.c.id.in_(candidate_ids))
            )
            deleted_count = int(delete_result.rowcount or 0)

    finished_at = datetime.now(timezone.utc)
    status = "success" if archive_error is None else "warning"
    run_id = _write_job_run(
        job_name="alert_retention",
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "retention_days": resolved_retention_days,
            "max_delete": resolved_max_delete,
            "dry_run": dry_run,
            "write_archive": resolved_write_archive,
            "cutoff": cutoff.isoformat(),
            "candidate_count": candidate_count,
            "deleted_count": deleted_count,
            "archive_file": archive_file,
            "archive_error": archive_error,
            "candidate_ids": candidate_ids[:200],
        },
    )
    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": status,
        "retention_days": resolved_retention_days,
        "max_delete": resolved_max_delete,
        "dry_run": dry_run,
        "write_archive": resolved_write_archive,
        "cutoff": cutoff.isoformat(),
        "candidate_count": candidate_count,
        "deleted_count": deleted_count,
        "archive_file": archive_file,
        "archive_error": archive_error,
    }


def run_alert_guard_recover_job(
    *,
    event_type: str | None = None,
    state_filter: str = "quarantined",
    max_targets: int | None = None,
    dry_run: bool = False,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    normalized_state_filter = (state_filter or "quarantined").strip().lower()
    if normalized_state_filter not in {"quarantined", "warning", "all"}:
        normalized_state_filter = "quarantined"
    resolved_max_targets = max(1, min(int(max_targets if max_targets is not None else ALERT_GUARD_RECOVER_MAX_TARGETS), 500))

    snapshot = _build_alert_channel_guard_snapshot(
        event_type=event_type,
        lookback_days=30,
        max_targets=max(200, resolved_max_targets * 5),
        now=started_at,
    )
    channels = snapshot.get("channels", [])
    if not isinstance(channels, list):
        channels = []

    def _matches(item: dict[str, Any]) -> bool:
        state = str(item.get("state_computed") or "")
        if normalized_state_filter == "all":
            return state in {"quarantined", "warning"}
        return state == normalized_state_filter

    selected = [item for item in channels if isinstance(item, dict) and _matches(item)][:resolved_max_targets]

    processed_count = 0
    success_count = 0
    warning_count = 0
    failed_count = 0
    skipped_count = 0
    results: list[dict[str, Any]] = []

    for item in selected:
        target = str(item.get("target") or "").strip()
        if not target:
            continue
        processed_count += 1
        before_state = _compute_alert_channel_guard_state(
            target,
            event_type=event_type,
            now=datetime.now(timezone.utc),
        )
        if dry_run:
            skipped_count += 1
            results.append(
                {
                    "target": target,
                    "status": "skipped",
                    "reason": "dry_run",
                    "before_state": before_state.get("state"),
                    "after_state": before_state.get("state"),
                }
            )
            continue

        probe_payload = {
            "event": "alert_guard_recovery_batch_probe",
            "target": target,
            "event_type_scope": event_type,
            "state_filter": normalized_state_filter,
            "checked_at": datetime.now(timezone.utc).isoformat(),
        }
        ok, err = _post_json_with_retries(
            url=target,
            payload=probe_payload,
            retries=ALERT_WEBHOOK_RETRIES,
            timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
        )
        probe_status = "success" if ok and err is None else ("warning" if ok else "failed")
        if probe_status == "success":
            success_count += 1
        elif probe_status == "warning":
            warning_count += 1
        else:
            failed_count += 1

        delivery_id = _write_alert_delivery(
            event_type=event_type or "alert_guard_recover",
            target=target,
            status=probe_status,
            error=err,
            payload={**probe_payload, "probe": True},
        )
        after_state = _compute_alert_channel_guard_state(
            target,
            event_type=event_type,
            now=datetime.now(timezone.utc),
        )
        results.append(
            {
                "target": target,
                "status": probe_status,
                "error": err,
                "delivery_id": delivery_id,
                "before_state": before_state.get("state"),
                "after_state": after_state.get("state"),
                "before_consecutive_failures": before_state.get("consecutive_failures"),
                "after_consecutive_failures": after_state.get("consecutive_failures"),
            }
        )

    finished_at = datetime.now(timezone.utc)
    job_status = "success"
    if failed_count > 0:
        job_status = "warning"
    run_id = _write_job_run(
        job_name="alert_guard_recover",
        trigger=trigger,
        status=job_status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "event_type": event_type,
            "state_filter": normalized_state_filter,
            "max_targets": resolved_max_targets,
            "dry_run": dry_run,
            "selected_target_count": len(selected),
            "processed_count": processed_count,
            "success_count": success_count,
            "warning_count": warning_count,
            "failed_count": failed_count,
            "skipped_count": skipped_count,
            "results": results[:200],
        },
    )

    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": job_status,
        "event_type": event_type,
        "state_filter": normalized_state_filter,
        "max_targets": resolved_max_targets,
        "dry_run": dry_run,
        "selected_target_count": len(selected),
        "processed_count": processed_count,
        "success_count": success_count,
        "warning_count": warning_count,
        "failed_count": failed_count,
        "skipped_count": skipped_count,
        "results": results,
    }


def run_alert_mttr_slo_check_job(
    *,
    event_type: str | None = None,
    force_notify: bool = False,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    policy, policy_updated_at, policy_key = _ensure_mttr_slo_policy()
    window_days = int(policy.get("window_days") or 30)
    threshold_minutes = float(policy.get("threshold_minutes") or 60)
    min_incidents = int(policy.get("min_incidents") or 1)

    snapshot = _build_alert_channel_mttr_snapshot(
        event_type=event_type,
        windows=[window_days],
        now=started_at,
    )
    windows = snapshot.get("windows", [])
    window: dict[str, Any] = windows[0] if isinstance(windows, list) and windows else {}
    incident_count = int(window.get("incident_count") or 0)
    recovered_incidents = int(window.get("recovered_incidents") or 0)
    unresolved_incidents = int(window.get("unresolved_incidents") or 0)
    mttr_minutes = window.get("mttr_minutes")
    mttr_value = float(mttr_minutes) if mttr_minutes is not None else None
    breach = (
        bool(policy.get("enabled", True))
        and incident_count >= max(1, min_incidents)
        and mttr_value is not None
        and mttr_value > threshold_minutes
    )

    channels = window.get("channels", [])
    if not isinstance(channels, list):
        channels = []
    top_channels_limit = max(1, min(int(policy.get("top_channels") or 10), 50))
    top_channels = [
        {
            "target": str(item.get("target") or ""),
            "incident_count": int(item.get("incident_count") or 0),
            "recovered_incidents": int(item.get("recovered_incidents") or 0),
            "unresolved_incidents": int(item.get("unresolved_incidents") or 0),
            "mttr_minutes": item.get("mttr_minutes"),
            "last_incident_start": item.get("last_incident_start"),
            "last_recovery_at": item.get("last_recovery_at"),
        }
        for item in channels
        if isinstance(item, dict)
    ][:top_channels_limit]

    auto_recover_attempted = False
    auto_recover_result: dict[str, Any] | None = None
    if breach and bool(policy.get("auto_recover_enabled", True)):
        auto_recover_attempted = True
        recovered = run_alert_guard_recover_job(
            event_type=event_type,
            state_filter=str(policy.get("recover_state") or "quarantined"),
            max_targets=int(policy.get("recover_max_targets") or ALERT_GUARD_RECOVER_MAX_TARGETS),
            dry_run=False,
            trigger="mttr_slo_auto",
        )
        auto_recover_result = {
            "run_id": recovered.get("run_id"),
            "status": recovered.get("status"),
            "state_filter": recovered.get("state_filter"),
            "max_targets": recovered.get("max_targets"),
            "processed_count": recovered.get("processed_count"),
            "success_count": recovered.get("success_count"),
            "failed_count": recovered.get("failed_count"),
            "skipped_count": recovered.get("skipped_count"),
        }

    notify_attempted = False
    notify_dispatched = False
    notify_error: str | None = None
    notify_channels: list[dict[str, Any]] = []
    cooldown_active = False
    cooldown_remaining_minutes = 0
    last_breach_at = _latest_mttr_slo_breach_finished_at()
    cooldown_minutes = int(policy.get("notify_cooldown_minutes") or 0)
    if breach and bool(policy.get("notify_enabled", True)):
        if not force_notify and cooldown_minutes > 0 and last_breach_at is not None:
            next_allowed_at = last_breach_at + timedelta(minutes=cooldown_minutes)
            if started_at < next_allowed_at:
                cooldown_active = True
                cooldown_remaining_minutes = max(
                    1,
                    int(math.ceil((next_allowed_at - started_at).total_seconds() / 60.0)),
                )
        if force_notify or not cooldown_active:
            notify_attempted = True
            notify_dispatched, notify_error, channel_results = _dispatch_alert_event(
                event_type=str(policy.get("notify_event_type") or "mttr_slo_breach"),
                payload={
                    "event": "mttr_slo_breach",
                    "checked_at": started_at.isoformat(),
                    "event_type_scope": event_type,
                    "policy": {
                        "policy_key": policy_key,
                        "enabled": bool(policy.get("enabled", True)),
                        "window_days": window_days,
                        "threshold_minutes": threshold_minutes,
                        "min_incidents": min_incidents,
                        "auto_recover_enabled": bool(policy.get("auto_recover_enabled", True)),
                        "recover_state": str(policy.get("recover_state") or "quarantined"),
                        "recover_max_targets": int(policy.get("recover_max_targets") or ALERT_GUARD_RECOVER_MAX_TARGETS),
                    },
                    "window": {
                        "days": window_days,
                        "incident_count": incident_count,
                        "recovered_incidents": recovered_incidents,
                        "unresolved_incidents": unresolved_incidents,
                        "mttr_minutes": mttr_value,
                    },
                    "top_channels": top_channels,
                    "auto_recover_result": auto_recover_result,
                },
            )
            notify_channels = [item.model_dump() for item in channel_results]

    finished_at = datetime.now(timezone.utc)
    status = "success"
    if breach:
        status = "warning"
    if notify_attempted and notify_error is not None and notify_dispatched is False:
        status = "warning"

    run_id = _write_job_run(
        job_name="alert_mttr_slo_check",
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "event_type": event_type,
            "policy_key": policy_key,
            "policy_updated_at": policy_updated_at.isoformat(),
            "policy": policy,
            "window": {
                "days": window_days,
                "incident_count": incident_count,
                "recovered_incidents": recovered_incidents,
                "unresolved_incidents": unresolved_incidents,
                "mttr_minutes": mttr_value,
            },
            "breach": breach,
            "top_channels": top_channels,
            "actions": {
                "auto_recover_attempted": auto_recover_attempted,
                "auto_recover_result": auto_recover_result,
                "notify_attempted": notify_attempted,
                "notify_dispatched": notify_dispatched,
                "notify_error": notify_error,
                "notify_channels": notify_channels,
                "force_notify": force_notify,
                "cooldown_minutes": cooldown_minutes,
                "cooldown_active": cooldown_active,
                "cooldown_remaining_minutes": cooldown_remaining_minutes,
                "last_breach_at": last_breach_at.isoformat() if last_breach_at is not None else None,
            },
        },
    )

    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "status": status,
        "event_type": event_type,
        "policy_key": policy_key,
        "policy_updated_at": policy_updated_at.isoformat(),
        "policy": policy,
        "window": {
            "days": window_days,
            "incident_count": incident_count,
            "recovered_incidents": recovered_incidents,
            "unresolved_incidents": unresolved_incidents,
            "mttr_minutes": mttr_value,
        },
        "breach": breach,
        "top_channels": top_channels,
        "actions": {
            "auto_recover_attempted": auto_recover_attempted,
            "auto_recover_result": auto_recover_result,
            "notify_attempted": notify_attempted,
            "notify_dispatched": notify_dispatched,
            "notify_error": notify_error,
            "notify_channels": notify_channels,
            "force_notify": force_notify,
            "cooldown_minutes": cooldown_minutes,
            "cooldown_active": cooldown_active,
            "cooldown_remaining_minutes": cooldown_remaining_minutes,
            "last_breach_at": last_breach_at.isoformat() if last_breach_at is not None else None,
        },
    }


def _post_json_with_retries(
    *,
    url: str,
    payload: dict[str, Any],
    retries: int,
    timeout_sec: float,
) -> tuple[bool, str | None]:
    body = json.dumps(payload, ensure_ascii=False, default=str).encode("utf-8")
    attempts = max(1, retries)
    for attempt in range(1, attempts + 1):
        req = url_request.Request(
            url=url,
            data=body,
            method="POST",
            headers={"Content-Type": "application/json"},
        )
        try:
            with url_request.urlopen(req, timeout=timeout_sec) as resp:
                status_code = int(getattr(resp, "status", 0))
                if 200 <= status_code < 300:
                    return True, None
                err = f"webhook returned status {status_code}"
        except url_error.HTTPError as exc:
            err = f"webhook http error {exc.code}"
        except url_error.URLError as exc:
            err = f"webhook url error: {exc.reason}"
        except Exception as exc:  # pragma: no cover - defensive path
            err = f"webhook unexpected error: {exc}"

        if attempt < attempts:
            time.sleep(0.5 * (2 ** (attempt - 1)))
    return False, err


def _dispatch_alert_event(
    *,
    event_type: str,
    payload: dict[str, Any],
) -> tuple[bool, str | None, list[SlaAlertChannelResult]]:
    targets = _configured_alert_targets()
    if not targets:
        return False, None, []

    results: list[SlaAlertChannelResult] = []
    success_count = 0
    failed_count = 0

    for target in targets:
        guard_state = _compute_alert_channel_guard_state(target, event_type=event_type)
        if ALERT_CHANNEL_GUARD_ENABLED and str(guard_state.get("state_computed")) == "quarantined":
            guard_error = (
                "channel quarantined until "
                + str(guard_state.get("quarantined_until") or "unknown")
                + " (consecutive_failures="
                + str(guard_state.get("consecutive_failures") or 0)
                + ")"
            )
            _write_alert_delivery(
                event_type=event_type,
                target=target,
                status="warning",
                error=guard_error,
                payload={
                    **payload,
                    "guard": {
                        "state": guard_state.get("state_computed"),
                        "consecutive_failures": guard_state.get("consecutive_failures"),
                        "quarantined_until": guard_state.get("quarantined_until"),
                    },
                },
            )
            failed_count += 1
            results.append(SlaAlertChannelResult(target=target, success=False, error=guard_error))
            continue

        ok, err = _post_json_with_retries(
            url=target,
            payload=payload,
            retries=ALERT_WEBHOOK_RETRIES,
            timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
        )
        delivery_status = "success" if ok and err is None else ("warning" if ok else "failed")
        _write_alert_delivery(
            event_type=event_type,
            target=target,
            status=delivery_status,
            error=err,
            payload=payload,
        )
        if ok:
            success_count += 1
        else:
            failed_count += 1
        results.append(SlaAlertChannelResult(target=target, success=ok, error=err))

    if failed_count == 0:
        return True, None, results
    if success_count > 0:
        return True, f"{failed_count}/{len(results)} alert channels failed", results
    return False, "all alert channels failed", results


def _dispatch_sla_alert(
    *,
    site: str | None,
    checked_at: datetime,
    escalated_count: int,
    work_order_ids: list[int],
) -> tuple[bool, str | None, list[SlaAlertChannelResult]]:
    if escalated_count <= 0:
        return False, None, []

    payload = {
        "event": "sla_escalation",
        "site": site or "ALL",
        "checked_at": checked_at.isoformat(),
        "escalated_count": escalated_count,
        "work_order_ids": work_order_ids,
    }
    return _dispatch_alert_event(event_type="sla_escalation", payload=payload)


def _row_to_admin_user_model(row: dict[str, Any]) -> AdminUserRead:
    role = str(row["role"])
    custom_permissions = _permission_text_to_list(row["permissions"])
    user_site_scope = _site_scope_text_to_list(row["site_scope"], default_all=True)
    return AdminUserRead(
        id=int(row["id"]),
        username=str(row["username"]),
        display_name=str(row["display_name"] or row["username"]),
        role=role,
        permissions=_effective_permissions(role, custom_permissions),
        site_scope=user_site_scope,
        is_active=bool(row["is_active"]),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_admin_token_model(row: dict[str, Any]) -> AdminTokenRead:
    user_scope = _site_scope_text_to_list(row.get("user_site_scope"), default_all=True)
    token_scope_raw = row.get("token_site_scope")
    token_scope = None
    if token_scope_raw is not None:
        token_scope = _site_scope_text_to_list(token_scope_raw, default_all=True)
    effective_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
    created_at = _as_datetime(row["created_at"])
    expires_at = _as_optional_datetime(row["expires_at"])
    last_used_at = _as_optional_datetime(row["last_used_at"])
    rotate_due_at = _token_rotate_due_at(created_at)
    idle_due_at = _token_idle_due_at(created_at=created_at, last_used_at=last_used_at)
    warning_due_at = None
    if rotate_due_at is not None and ADMIN_TOKEN_ROTATE_WARNING_DAYS > 0:
        warning_due_at = rotate_due_at - timedelta(days=ADMIN_TOKEN_ROTATE_WARNING_DAYS)
    must_rotate = rotate_due_at is not None and warning_due_at is not None and datetime.now(timezone.utc) >= warning_due_at
    return AdminTokenRead(
        token_id=int(row["token_id"]),
        user_id=int(row["user_id"]),
        username=str(row["username"]),
        label=str(row["label"] or ""),
        is_active=bool(row["is_active"]),
        site_scope=effective_scope,
        expires_at=expires_at,
        last_used_at=last_used_at,
        created_at=created_at,
        rotate_due_at=rotate_due_at,
        idle_due_at=idle_due_at,
        must_rotate=must_rotate,
    )


def _row_to_work_order_model(row: dict[str, Any]) -> WorkOrderRead:
    due_at = _as_optional_datetime(row["due_at"])
    status = row["status"]
    return WorkOrderRead(
        id=row["id"],
        title=row["title"],
        description=row["description"] or "",
        site=row["site"],
        location=row["location"],
        priority=row["priority"],
        status=status,
        assignee=row["assignee"],
        reporter=row["reporter"],
        inspection_id=row["inspection_id"],
        due_at=due_at,
        acknowledged_at=_as_optional_datetime(row["acknowledged_at"]),
        completed_at=_as_optional_datetime(row["completed_at"]),
        resolution_notes=row["resolution_notes"] or "",
        is_escalated=bool(row["is_escalated"]),
        is_overdue=_is_overdue(status, due_at),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _validate_work_order_transition(current_status: str, next_status: str) -> None:
    allowed = WORK_ORDER_TRANSITIONS.get(current_status, set())
    if next_status not in allowed:
        raise HTTPException(status_code=409, detail=f"Invalid status transition: {current_status} -> {next_status}")


def _append_work_order_event(
    conn: Any,
    *,
    work_order_id: int,
    event_type: str,
    actor_username: str,
    from_status: str | None = None,
    to_status: str | None = None,
    note: str = "",
    detail: dict[str, Any] | None = None,
) -> None:
    conn.execute(
        insert(work_order_events).values(
            work_order_id=work_order_id,
            event_type=event_type,
            actor_username=actor_username,
            from_status=from_status,
            to_status=to_status,
            note=note,
            detail_json=_to_json_text(detail),
            created_at=datetime.now(timezone.utc),
        )
    )


def _row_to_work_order_event_model(row: dict[str, Any]) -> WorkOrderEventRead:
    raw = str(row["detail_json"] or "{}")
    try:
        detail = json.loads(raw)
    except json.JSONDecodeError:
        detail = {"raw": raw}
    if not isinstance(detail, dict):
        detail = {"value": detail}

    return WorkOrderEventRead(
        id=int(row["id"]),
        work_order_id=int(row["work_order_id"]),
        event_type=str(row["event_type"]),
        actor_username=str(row["actor_username"]),
        from_status=row["from_status"],
        to_status=row["to_status"],
        note=str(row["note"] or ""),
        detail=detail,
        created_at=_as_datetime(row["created_at"]),
    )


def _row_to_workflow_lock_model(row: dict[str, Any]) -> WorkflowLockRead:
    raw = str(row["content_json"] or "{}")
    try:
        content = json.loads(raw)
    except json.JSONDecodeError:
        content = {"raw": raw}
    if not isinstance(content, dict):
        content = {"value": content}

    return WorkflowLockRead(
        id=int(row["id"]),
        site=str(row["site"]),
        workflow_key=str(row["workflow_key"]),
        status=str(row["status"]),
        content=content,
        requested_ticket=row.get("requested_ticket"),
        last_comment=str(row.get("last_comment") or ""),
        lock_reason=row.get("lock_reason"),
        unlock_reason=row.get("unlock_reason"),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        reviewed_by=row.get("reviewed_by"),
        approved_by=row.get("approved_by"),
        locked_by=row.get("locked_by"),
        unlocked_by=row.get("unlocked_by"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
        reviewed_at=_as_optional_datetime(row.get("reviewed_at")),
        approved_at=_as_optional_datetime(row.get("approved_at")),
        locked_at=_as_optional_datetime(row.get("locked_at")),
        unlocked_at=_as_optional_datetime(row.get("unlocked_at")),
    )


def _row_to_w02_tracker_item_model(row: dict[str, Any]) -> W02TrackerItemRead:
    return W02TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w02_evidence_model(row: dict[str, Any]) -> W02EvidenceRead:
    return W02EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w02_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w02_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W02_SOP_RUNBOOKS:
        entries.append(
            {
                "site": site,
                "item_type": "sop_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("name", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W02_SANDBOX_SCENARIOS:
        entries.append(
            {
                "site": site,
                "item_type": "sandbox_scenario",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("objective", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W02_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w02_tracker_overview(site: str, rows: list[W02TrackerItemRead]) -> W02TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W02TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w02_tracker_readiness(
    *,
    site: str,
    rows: list[W02TrackerItemRead],
    checked_at: datetime | None = None,
) -> W02TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W02_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W02_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (sandbox_scenario)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W02TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w02_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W02_SITE_COMPLETION_STATUS_SET:
        return value
    return W02_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w02_completion_model(
    *,
    site: str,
    readiness: W02TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W02TrackerCompletionRead:
    if row is None:
        return W02TrackerCompletionRead(
            site=site,
            status=W02_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w02_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W02TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w02_tracker_items_for_site(site: str) -> list[W02TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w02_tracker_items)
            .where(adoption_w02_tracker_items.c.site == site)
            .order_by(
                adoption_w02_tracker_items.c.item_type.asc(),
                adoption_w02_tracker_items.c.item_key.asc(),
                adoption_w02_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w02_tracker_item_model(row) for row in rows]


def _reset_w02_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w02_site_runs.c.status)
        .where(adoption_w02_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w02_site_completion_status(row.get("status"))
    if status == W02_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w02_site_runs)
        .where(adoption_w02_site_runs.c.site == site)
        .values(
            status=W02_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w03_tracker_item_model(row: dict[str, Any]) -> W03TrackerItemRead:
    return W03TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w03_evidence_model(row: dict[str, Any]) -> W03EvidenceRead:
    return W03EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w03_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w03_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W03_KICKOFF_AGENDA:
        entries.append(
            {
                "site": site,
                "item_type": "kickoff_agenda",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("topic", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_ROLE_WORKSHOPS:
        entries.append(
            {
                "site": site,
                "item_type": "role_workshop",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("objective", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_OFFICE_HOURS:
        entries.append(
            {
                "site": site,
                "item_type": "office_hour",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("focus", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W03_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w03_tracker_overview(site: str, rows: list[W03TrackerItemRead]) -> W03TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W03TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w03_tracker_readiness(
    *,
    site: str,
    rows: list[W03TrackerItemRead],
    checked_at: datetime | None = None,
) -> W03TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W03_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W03_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (role_workshop)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W03TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w03_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W03_SITE_COMPLETION_STATUS_SET:
        return value
    return W03_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w03_completion_model(
    *,
    site: str,
    readiness: W03TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W03TrackerCompletionRead:
    if row is None:
        return W03TrackerCompletionRead(
            site=site,
            status=W03_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w03_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W03TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w03_tracker_items_for_site(site: str) -> list[W03TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w03_tracker_items)
            .where(adoption_w03_tracker_items.c.site == site)
            .order_by(
                adoption_w03_tracker_items.c.item_type.asc(),
                adoption_w03_tracker_items.c.item_key.asc(),
                adoption_w03_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w03_tracker_item_model(row) for row in rows]


def _reset_w03_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w03_site_runs.c.status)
        .where(adoption_w03_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w03_site_completion_status(row.get("status"))
    if status == W03_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w03_site_runs)
        .where(adoption_w03_site_runs.c.site == site)
        .values(
            status=W03_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w04_tracker_item_model(row: dict[str, Any]) -> W04TrackerItemRead:
    return W04TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w04_evidence_model(row: dict[str, Any]) -> W04EvidenceRead:
    return W04EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w04_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w04_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W04_COACHING_ACTIONS:
        entries.append(
            {
                "site": site,
                "item_type": "coaching_action",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("action", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W04_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w04_tracker_overview(site: str, rows: list[W04TrackerItemRead]) -> W04TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W04TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w04_tracker_readiness(
    *,
    site: str,
    rows: list[W04TrackerItemRead],
    checked_at: datetime | None = None,
) -> W04TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W04_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1
        for row in rows
        if row.item_type in W04_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (coaching_action)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W04TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w04_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W04_SITE_COMPLETION_STATUS_SET:
        return value
    return W04_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w04_completion_model(
    *,
    site: str,
    readiness: W04TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W04TrackerCompletionRead:
    if row is None:
        return W04TrackerCompletionRead(
            site=site,
            status=W04_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w04_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W04TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w04_tracker_items_for_site(site: str) -> list[W04TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w04_tracker_items)
            .where(adoption_w04_tracker_items.c.site == site)
            .order_by(
                adoption_w04_tracker_items.c.item_type.asc(),
                adoption_w04_tracker_items.c.item_key.asc(),
                adoption_w04_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w04_tracker_item_model(row) for row in rows]


def _reset_w04_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w04_site_runs.c.status)
        .where(adoption_w04_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w04_site_completion_status(row.get("status"))
    if status == W04_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w04_site_runs)
        .where(adoption_w04_site_runs.c.site == site)
        .values(
            status=W04_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w07_tracker_item_model(row: dict[str, Any]) -> W07TrackerItemRead:
    return W07TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w07_evidence_model(row: dict[str, Any]) -> W07EvidenceRead:
    return W07EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w07_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w07_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W07_SLA_CHECKLIST:
        entries.append(
            {
                "site": site,
                "item_type": "sla_checklist",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("control", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W07_COACHING_PLAYS:
        entries.append(
            {
                "site": site,
                "item_type": "coaching_play",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("play", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W07_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w07_tracker_overview(site: str, rows: list[W07TrackerItemRead]) -> W07TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W07TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w07_tracker_readiness(
    *,
    site: str,
    rows: list[W07TrackerItemRead],
    checked_at: datetime | None = None,
) -> W07TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W07_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W07_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(f"  (sla_checklist/coaching_play)  {missing_required_evidence_count} .")

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W07TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w07_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W07_SITE_COMPLETION_STATUS_SET:
        return value
    return W07_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w07_completion_model(
    *,
    site: str,
    readiness: W07TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W07TrackerCompletionRead:
    if row is None:
        return W07TrackerCompletionRead(
            site=site,
            status=W07_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w07_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W07TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w07_tracker_items_for_site(site: str) -> list[W07TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w07_tracker_items)
            .where(adoption_w07_tracker_items.c.site == site)
            .order_by(
                adoption_w07_tracker_items.c.item_type.asc(),
                adoption_w07_tracker_items.c.item_key.asc(),
                adoption_w07_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w07_tracker_item_model(row) for row in rows]


def _reset_w07_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w07_site_runs.c.status)
        .where(adoption_w07_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w07_site_completion_status(row.get("status"))
    if status == W07_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w07_site_runs)
        .where(adoption_w07_site_runs.c.site == site)
        .values(
            status=W07_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w09_tracker_item_model(row: dict[str, Any]) -> W09TrackerItemRead:
    return W09TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row["status"]),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w09_evidence_model(row: dict[str, Any]) -> W09EvidenceRead:
    return W09EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w09_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w09_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W09_KPI_THRESHOLD_MATRIX:
        entries.append(
            {
                "site": site,
                "item_type": "kpi_threshold",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("kpi_name", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W09_ESCALATION_MAP:
        entries.append(
            {
                "site": site,
                "item_type": "kpi_escalation",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("action", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W09_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w09_tracker_overview(site: str, rows: list[W09TrackerItemRead]) -> W09TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W09TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w09_tracker_readiness(
    *,
    site: str,
    rows: list[W09TrackerItemRead],
    checked_at: datetime | None = None,
) -> W09TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W09_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W09_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (kpi_threshold/kpi_escalation)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W09TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w09_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W09_SITE_COMPLETION_STATUS_SET:
        return value
    return W09_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w09_completion_model(
    *,
    site: str,
    readiness: W09TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W09TrackerCompletionRead:
    if row is None:
        return W09TrackerCompletionRead(
            site=site,
            status=W09_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w09_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W09TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w09_tracker_items_for_site(site: str) -> list[W09TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w09_tracker_items)
            .where(adoption_w09_tracker_items.c.site == site)
            .order_by(
                adoption_w09_tracker_items.c.item_type.asc(),
                adoption_w09_tracker_items.c.item_key.asc(),
                adoption_w09_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w09_tracker_item_model(row) for row in rows]


def _reset_w09_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w09_site_runs.c.status)
        .where(adoption_w09_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w09_site_completion_status(row.get("status"))
    if status == W09_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w09_site_runs)
        .where(adoption_w09_site_runs.c.site == site)
        .values(
            status=W09_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w10_tracker_item_model(row: dict[str, Any]) -> W10TrackerItemRead:
    return W10TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W10_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w10_evidence_model(row: dict[str, Any]) -> W10EvidenceRead:
    return W10EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w10_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w10_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W10_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W10_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W10_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w10_tracker_overview(site: str, rows: list[W10TrackerItemRead]) -> W10TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W10TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w10_tracker_readiness(
    *,
    site: str,
    rows: list[W10TrackerItemRead],
    checked_at: datetime | None = None,
) -> W10TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W10_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W10_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W10TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w10_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W10_SITE_COMPLETION_STATUS_SET:
        return value
    return W10_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w10_completion_model(
    *,
    site: str,
    readiness: W10TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W10TrackerCompletionRead:
    if row is None:
        return W10TrackerCompletionRead(
            site=site,
            status=W10_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w10_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W10TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w10_tracker_items_for_site(site: str) -> list[W10TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w10_tracker_items)
            .where(adoption_w10_tracker_items.c.site == site)
            .order_by(
                adoption_w10_tracker_items.c.item_type.asc(),
                adoption_w10_tracker_items.c.item_key.asc(),
                adoption_w10_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w10_tracker_item_model(row) for row in rows]


def _reset_w10_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w10_site_runs.c.status)
        .where(adoption_w10_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w10_site_completion_status(row.get("status"))
    if status == W10_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w10_site_runs)
        .where(adoption_w10_site_runs.c.site == site)
        .values(
            status=W10_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )



def _row_to_w11_tracker_item_model(row: dict[str, Any]) -> W11TrackerItemRead:
    return W11TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W11_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w11_evidence_model(row: dict[str, Any]) -> W11EvidenceRead:
    return W11EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w11_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w11_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W11_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W11_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W11_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w11_tracker_overview(site: str, rows: list[W11TrackerItemRead]) -> W11TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W11TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w11_tracker_readiness(
    *,
    site: str,
    rows: list[W11TrackerItemRead],
    checked_at: datetime | None = None,
) -> W11TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W11_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W11_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W11TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w11_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W11_SITE_COMPLETION_STATUS_SET:
        return value
    return W11_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w11_completion_model(
    *,
    site: str,
    readiness: W11TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W11TrackerCompletionRead:
    if row is None:
        return W11TrackerCompletionRead(
            site=site,
            status=W11_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w11_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W11TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w11_tracker_items_for_site(site: str) -> list[W11TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w11_tracker_items)
            .where(adoption_w11_tracker_items.c.site == site)
            .order_by(
                adoption_w11_tracker_items.c.item_type.asc(),
                adoption_w11_tracker_items.c.item_key.asc(),
                adoption_w11_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w11_tracker_item_model(row) for row in rows]


def _reset_w11_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w11_site_runs.c.status)
        .where(adoption_w11_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w11_site_completion_status(row.get("status"))
    if status == W11_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w11_site_runs)
        .where(adoption_w11_site_runs.c.site == site)
        .values(
            status=W11_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )



def _row_to_w12_tracker_item_model(row: dict[str, Any]) -> W12TrackerItemRead:
    return W12TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W12_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w12_evidence_model(row: dict[str, Any]) -> W12EvidenceRead:
    return W12EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w12_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w12_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W12_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W12_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W12_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w12_tracker_overview(site: str, rows: list[W12TrackerItemRead]) -> W12TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W12TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w12_tracker_readiness(
    *,
    site: str,
    rows: list[W12TrackerItemRead],
    checked_at: datetime | None = None,
) -> W12TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W12_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W12_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W12TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w12_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W12_SITE_COMPLETION_STATUS_SET:
        return value
    return W12_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w12_completion_model(
    *,
    site: str,
    readiness: W12TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W12TrackerCompletionRead:
    if row is None:
        return W12TrackerCompletionRead(
            site=site,
            status=W12_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w12_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W12TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w12_tracker_items_for_site(site: str) -> list[W12TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w12_tracker_items)
            .where(adoption_w12_tracker_items.c.site == site)
            .order_by(
                adoption_w12_tracker_items.c.item_type.asc(),
                adoption_w12_tracker_items.c.item_key.asc(),
                adoption_w12_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w12_tracker_item_model(row) for row in rows]


def _reset_w12_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w12_site_runs.c.status)
        .where(adoption_w12_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w12_site_completion_status(row.get("status"))
    if status == W12_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w12_site_runs)
        .where(adoption_w12_site_runs.c.site == site)
        .values(
            status=W12_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w13_tracker_item_model(row: dict[str, Any]) -> W13TrackerItemRead:
    return W13TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W13_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w13_evidence_model(row: dict[str, Any]) -> W13EvidenceRead:
    return W13EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w13_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w13_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W13_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W13_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W13_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w13_tracker_overview(site: str, rows: list[W13TrackerItemRead]) -> W13TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W13TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w13_tracker_readiness(
    *,
    site: str,
    rows: list[W13TrackerItemRead],
    checked_at: datetime | None = None,
) -> W13TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W13_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W13_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W13TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w13_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W13_SITE_COMPLETION_STATUS_SET:
        return value
    return W13_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w13_completion_model(
    *,
    site: str,
    readiness: W13TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W13TrackerCompletionRead:
    if row is None:
        return W13TrackerCompletionRead(
            site=site,
            status=W13_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w13_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W13TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w13_tracker_items_for_site(site: str) -> list[W13TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w13_tracker_items)
            .where(adoption_w13_tracker_items.c.site == site)
            .order_by(
                adoption_w13_tracker_items.c.item_type.asc(),
                adoption_w13_tracker_items.c.item_key.asc(),
                adoption_w13_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w13_tracker_item_model(row) for row in rows]


def _reset_w13_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w13_site_runs.c.status)
        .where(adoption_w13_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w13_site_completion_status(row.get("status"))
    if status == W13_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w13_site_runs)
        .where(adoption_w13_site_runs.c.site == site)
        .values(
            status=W13_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )
def _row_to_w14_tracker_item_model(row: dict[str, Any]) -> W14TrackerItemRead:
    return W14TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W14_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w14_evidence_model(row: dict[str, Any]) -> W14EvidenceRead:
    return W14EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w14_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w14_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W14_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W14_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W14_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w14_tracker_overview(site: str, rows: list[W14TrackerItemRead]) -> W14TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W14TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w14_tracker_readiness(
    *,
    site: str,
    rows: list[W14TrackerItemRead],
    checked_at: datetime | None = None,
) -> W14TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W14_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W14_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W14TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w14_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W14_SITE_COMPLETION_STATUS_SET:
        return value
    return W14_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w14_completion_model(
    *,
    site: str,
    readiness: W14TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W14TrackerCompletionRead:
    if row is None:
        return W14TrackerCompletionRead(
            site=site,
            status=W14_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w14_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W14TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w14_tracker_items_for_site(site: str) -> list[W14TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w14_tracker_items)
            .where(adoption_w14_tracker_items.c.site == site)
            .order_by(
                adoption_w14_tracker_items.c.item_type.asc(),
                adoption_w14_tracker_items.c.item_key.asc(),
                adoption_w14_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w14_tracker_item_model(row) for row in rows]


def _reset_w14_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w14_site_runs.c.status)
        .where(adoption_w14_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w14_site_completion_status(row.get("status"))
    if status == W14_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w14_site_runs)
        .where(adoption_w14_site_runs.c.site == site)
        .values(
            status=W14_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )


def _row_to_w15_tracker_item_model(row: dict[str, Any]) -> W15TrackerItemRead:
    return W15TrackerItemRead(
        id=int(row["id"]),
        site=str(row["site"]),
        item_type=str(row["item_type"]),
        item_key=str(row["item_key"]),
        item_name=str(row["item_name"]),
        assignee=row.get("assignee"),
        status=str(row.get("status") or W15_TRACKER_STATUS_PENDING),
        completion_checked=bool(row.get("completion_checked", False)),
        completion_note=str(row.get("completion_note") or ""),
        due_at=_as_optional_datetime(row.get("due_at")),
        completed_at=_as_optional_datetime(row.get("completed_at")),
        evidence_count=int(row.get("evidence_count") or 0),
        created_by=str(row.get("created_by") or "system"),
        updated_by=str(row.get("updated_by") or "system"),
        created_at=_as_datetime(row["created_at"]),
        updated_at=_as_datetime(row["updated_at"]),
    )


def _row_to_w15_evidence_model(row: dict[str, Any]) -> W15EvidenceRead:
    return W15EvidenceRead(
        id=int(row["id"]),
        tracker_item_id=int(row["tracker_item_id"]),
        site=str(row["site"]),
        file_name=str(row["file_name"]),
        content_type=str(row.get("content_type") or "application/octet-stream"),
        file_size=int(row.get("file_size") or 0),
        storage_backend=_normalize_evidence_storage_backend(str(row.get("storage_backend") or "db")),
        sha256=str(row.get("sha256") or ""),
        malware_scan_status=str(row.get("malware_scan_status") or "unknown"),
        malware_scan_engine=row.get("malware_scan_engine"),
        malware_scanned_at=_as_optional_datetime(row.get("malware_scanned_at")),
        note=str(row.get("note") or ""),
        uploaded_by=str(row.get("uploaded_by") or "system"),
        uploaded_at=_as_datetime(row["uploaded_at"]),
    )


def _adoption_w15_catalog_items(site: str) -> list[dict[str, Any]]:
    payload = _adoption_w15_payload()
    timeline = payload.get("timeline", {})
    default_due_at: datetime | None = None
    end_date_raw = str(timeline.get("end_date") or "")
    if end_date_raw:
        try:
            parsed = datetime.strptime(f"{end_date_raw} 23:59", "%Y-%m-%d %H:%M")
            default_due_at = parsed.replace(tzinfo=timezone.utc)
        except ValueError:
            default_due_at = None

    entries: list[dict[str, Any]] = []
    for item in ADOPTION_W15_SELF_SERVE_GUIDES:
        entries.append(
            {
                "site": site,
                "item_type": "self_serve_guide",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W15_TROUBLESHOOTING_RUNBOOK:
        entries.append(
            {
                "site": site,
                "item_type": "troubleshooting_runbook",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("symptom", "")),
                "due_at": default_due_at,
            }
        )
    for item in ADOPTION_W15_SCHEDULED_EVENTS:
        event_due_at = default_due_at
        try:
            event_due = datetime.strptime(
                f"{str(item.get('date', ''))} {str(item.get('end_time', '23:59'))}",
                "%Y-%m-%d %H:%M",
            )
            event_due_at = event_due.replace(tzinfo=timezone.utc)
        except ValueError:
            pass
        entries.append(
            {
                "site": site,
                "item_type": "scheduled_event",
                "item_key": str(item.get("id", "")),
                "item_name": str(item.get("title", "")),
                "due_at": event_due_at,
            }
        )
    return entries


def _compute_w15_tracker_overview(site: str, rows: list[W15TrackerItemRead]) -> W15TrackerOverviewRead:
    pending_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_BLOCKED)
    total = len(rows)
    completion_rate = int(round((done_count / total) * 100)) if total > 0 else 0
    evidence_total = sum(int(row.evidence_count) for row in rows)
    assignee_breakdown: dict[str, int] = {}
    for row in rows:
        assignee = (row.assignee or "unassigned").strip() or "unassigned"
        assignee_breakdown[assignee] = assignee_breakdown.get(assignee, 0) + 1

    return W15TrackerOverviewRead(
        site=site,
        total_items=total,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate,
        evidence_total_count=evidence_total,
        assignee_breakdown=assignee_breakdown,
    )


def _compute_w15_tracker_readiness(
    *,
    site: str,
    rows: list[W15TrackerItemRead],
    checked_at: datetime | None = None,
) -> W15TrackerReadinessRead:
    now = checked_at or datetime.now(timezone.utc)
    total_items = len(rows)
    pending_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_PENDING)
    in_progress_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_IN_PROGRESS)
    done_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_DONE)
    blocked_count = sum(1 for row in rows if row.status == W15_TRACKER_STATUS_BLOCKED)
    completion_rate_percent = int(round((done_count / total_items) * 100)) if total_items > 0 else 0
    evidence_total_count = sum(int(row.evidence_count) for row in rows)

    missing_assignee_count = sum(1 for row in rows if not (row.assignee or "").strip())
    missing_completion_checked_count = sum(1 for row in rows if not bool(row.completion_checked))
    missing_required_evidence_count = sum(
        1 for row in rows if row.item_type in W15_EVIDENCE_REQUIRED_ITEM_TYPES and int(row.evidence_count) <= 0
    )

    blockers: list[str] = []
    if total_items == 0:
        blockers.append("  . bootstrap  .")
    if pending_count > 0:
        blockers.append(f"pending  {pending_count}  .")
    if in_progress_count > 0:
        blockers.append(f"in_progress  {in_progress_count}  .")
    if blocked_count > 0:
        blockers.append(f"blocked  {blocked_count}  .")
    if missing_assignee_count > 0:
        blockers.append(f"   {missing_assignee_count} .")
    if missing_completion_checked_count > 0:
        blockers.append(f"    {missing_completion_checked_count} .")
    if missing_required_evidence_count > 0:
        blockers.append(
            f"  (self_serve_guide/troubleshooting_runbook)  {missing_required_evidence_count} ."
        )

    rule_checks = [
        total_items > 0,
        pending_count == 0,
        in_progress_count == 0,
        blocked_count == 0,
        missing_assignee_count == 0,
        missing_completion_checked_count == 0,
        missing_required_evidence_count == 0,
    ]
    readiness_score_percent = int(round((sum(1 for ok in rule_checks if ok) / len(rule_checks)) * 100))
    if total_items > 0:
        readiness_score_percent = max(readiness_score_percent, completion_rate_percent)
    ready = len(blockers) == 0
    if ready:
        readiness_score_percent = 100

    return W15TrackerReadinessRead(
        site=site,
        checked_at=now,
        total_items=total_items,
        pending_count=pending_count,
        in_progress_count=in_progress_count,
        done_count=done_count,
        blocked_count=blocked_count,
        completion_rate_percent=completion_rate_percent,
        evidence_total_count=evidence_total_count,
        missing_assignee_count=missing_assignee_count,
        missing_completion_checked_count=missing_completion_checked_count,
        missing_required_evidence_count=missing_required_evidence_count,
        readiness_score_percent=readiness_score_percent,
        ready=ready,
        blockers=blockers,
    )


def _resolve_w15_site_completion_status(raw: Any) -> str:
    value = str(raw or "").strip().lower()
    if value in W15_SITE_COMPLETION_STATUS_SET:
        return value
    return W15_SITE_COMPLETION_STATUS_ACTIVE


def _row_to_w15_completion_model(
    *,
    site: str,
    readiness: W15TrackerReadinessRead,
    row: dict[str, Any] | None,
) -> W15TrackerCompletionRead:
    if row is None:
        return W15TrackerCompletionRead(
            site=site,
            status=W15_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            completed_by=None,
            completed_at=None,
            force_used=False,
            last_checked_at=readiness.checked_at,
            readiness=readiness,
        )

    status = _resolve_w15_site_completion_status(row.get("status"))
    completion_note = str(row.get("completion_note") or "")
    completed_by = row.get("completed_by")
    completed_at = _as_optional_datetime(row.get("completed_at"))
    force_used = bool(row.get("force_used", False))
    last_checked_at = _as_optional_datetime(row.get("last_checked_at")) or readiness.checked_at
    return W15TrackerCompletionRead(
        site=site,
        status=status,
        completion_note=completion_note,
        completed_by=completed_by,
        completed_at=completed_at,
        force_used=force_used,
        last_checked_at=last_checked_at,
        readiness=readiness,
    )


def _load_w15_tracker_items_for_site(site: str) -> list[W15TrackerItemRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w15_tracker_items)
            .where(adoption_w15_tracker_items.c.site == site)
            .order_by(
                adoption_w15_tracker_items.c.item_type.asc(),
                adoption_w15_tracker_items.c.item_key.asc(),
                adoption_w15_tracker_items.c.id.asc(),
            )
        ).mappings().all()
    return [_row_to_w15_tracker_item_model(row) for row in rows]


def _reset_w15_completion_if_closed(
    *,
    conn: Any,
    site: str,
    actor_username: str,
    checked_at: datetime,
    reason: str,
) -> None:
    row = conn.execute(
        select(adoption_w15_site_runs.c.status)
        .where(adoption_w15_site_runs.c.site == site)
        .limit(1)
    ).mappings().first()
    if row is None:
        return
    status = _resolve_w15_site_completion_status(row.get("status"))
    if status == W15_SITE_COMPLETION_STATUS_ACTIVE:
        return
    conn.execute(
        update(adoption_w15_site_runs)
        .where(adoption_w15_site_runs.c.site == site)
        .values(
            status=W15_SITE_COMPLETION_STATUS_ACTIVE,
            completion_note="",
            force_used=False,
            completed_by=None,
            completed_at=None,
            last_checked_at=checked_at,
            readiness_json=_to_json_text(
                {
                    "auto_reopened": True,
                    "reason": reason,
                    "checked_at": checked_at.isoformat(),
                }
            ),
            updated_by=actor_username,
            updated_at=checked_at,
        )
    )




def _median_minutes(values: list[float]) -> float | None:
    if not values:
        return None
    try:
        return round(float(statistics.median(values)), 2)
    except statistics.StatisticsError:
        return None


def _percentile_minutes(values: list[float], percentile: float) -> float | None:
    if not values:
        return None
    if percentile <= 0:
        return round(float(min(values)), 2)
    if percentile >= 100:
        return round(float(max(values)), 2)
    sorted_values = sorted(values)
    if len(sorted_values) == 1:
        return round(float(sorted_values[0]), 2)
    rank = (len(sorted_values) - 1) * (percentile / 100.0)
    lower = int(math.floor(rank))
    upper = int(math.ceil(rank))
    if lower == upper:
        return round(float(sorted_values[lower]), 2)
    weight = rank - lower
    interpolated = sorted_values[lower] + (sorted_values[upper] - sorted_values[lower]) * weight
    return round(float(interpolated), 2)


def _build_w04_funnel_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(1, min(int(days), 90))
    start = now - timedelta(days=window_days)

    inspection_stmt = (
        select(inspections.c.inspector, inspections.c.site, inspections.c.created_at)
        .where(inspections.c.created_at >= start)
    )
    completion_stmt = (
        select(work_order_events.c.actor_username, work_orders.c.site, work_order_events.c.created_at)
        .select_from(work_order_events.join(work_orders, work_order_events.c.work_order_id == work_orders.c.id))
        .where(work_order_events.c.event_type == "status_changed")
        .where(work_order_events.c.to_status == "completed")
        .where(work_order_events.c.created_at >= start)
    )

    if site is not None:
        inspection_stmt = inspection_stmt.where(inspections.c.site == site)
        completion_stmt = completion_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": site,
                "window_days": window_days,
                "target_ttv_minutes": 15.0,
                "metrics": {
                    "total_users": 0,
                    "inspection_converted_users": 0,
                    "work_order_completed_users": 0,
                    "inspection_conversion_rate_percent": 0.0,
                    "work_order_completion_rate_percent": 0.0,
                    "median_ttv_minutes": None,
                    "target_met": False,
                },
                "stage_timings_minutes": {
                    "auth_to_first_inspection": None,
                    "inspection_to_first_work_order_complete": None,
                    "auth_to_first_work_order_complete": None,
                },
                "stages": [],
                "actors": [],
            }
        inspection_stmt = inspection_stmt.where(inspections.c.site.in_(allowed_sites))
        completion_stmt = completion_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        auth_rows = conn.execute(
            select(admin_audit_logs.c.actor_username, admin_audit_logs.c.created_at)
            .where(admin_audit_logs.c.created_at >= start)
            .where(admin_audit_logs.c.actor_username.is_not(None))
            .where(admin_audit_logs.c.actor_username != "system")
        ).mappings().all()
        inspection_rows = conn.execute(inspection_stmt).mappings().all()
        completion_rows = conn.execute(completion_stmt).mappings().all()

    actor_auth_first: dict[str, datetime] = {}
    for row in auth_rows:
        actor = str(row.get("actor_username") or "").strip()
        if not actor:
            continue
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is None:
            continue
        prev = actor_auth_first.get(actor)
        if prev is None or created_at < prev:
            actor_auth_first[actor] = created_at

    considered_actors: set[str] = set()
    actor_first_inspection: dict[str, datetime] = {}
    for row in inspection_rows:
        actor = str(row.get("inspector") or "").strip()
        if not actor:
            continue
        considered_actors.add(actor)
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is None:
            continue
        prev = actor_first_inspection.get(actor)
        if prev is None or created_at < prev:
            actor_first_inspection[actor] = created_at

    actor_first_complete: dict[str, datetime] = {}
    for row in completion_rows:
        actor = str(row.get("actor_username") or "").strip()
        if not actor or actor == "system":
            continue
        considered_actors.add(actor)
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is None:
            continue
        prev = actor_first_complete.get(actor)
        if prev is None or created_at < prev:
            actor_first_complete[actor] = created_at

    if site is None and allowed_sites is None:
        considered_actors.update(actor_auth_first.keys())

    inspection_converted = 0
    completion_converted = 0
    auth_to_inspection_minutes: list[float] = []
    inspection_to_complete_minutes: list[float] = []
    auth_to_complete_minutes: list[float] = []
    actor_rows: list[dict[str, Any]] = []

    for actor in sorted(considered_actors):
        auth_at = actor_auth_first.get(actor)
        inspection_at = actor_first_inspection.get(actor)
        complete_at = actor_first_complete.get(actor)
        anchors = [x for x in [auth_at, inspection_at, complete_at] if x is not None]
        if not anchors:
            continue
        first_auth = auth_at or min(anchors)

        has_inspection = inspection_at is not None and inspection_at >= first_auth
        has_complete = complete_at is not None and complete_at >= first_auth
        if has_inspection:
            inspection_converted += 1
            auth_to_inspection_minutes.append((inspection_at - first_auth).total_seconds() / 60.0)
        if has_complete:
            completion_converted += 1
            auth_to_complete_minutes.append((complete_at - first_auth).total_seconds() / 60.0)
        if has_inspection and has_complete and complete_at is not None and inspection_at is not None and complete_at >= inspection_at:
            inspection_to_complete_minutes.append((complete_at - inspection_at).total_seconds() / 60.0)

        actor_rows.append(
            {
                "actor": actor,
                "first_auth_at": first_auth.isoformat() if first_auth is not None else None,
                "first_inspection_at": inspection_at.isoformat() if inspection_at is not None else None,
                "first_work_order_complete_at": complete_at.isoformat() if complete_at is not None else None,
            }
        )

    total_users = len(actor_rows)
    inspection_conversion_rate = round((inspection_converted / total_users) * 100, 2) if total_users > 0 else 0.0
    completion_conversion_rate = round((completion_converted / total_users) * 100, 2) if total_users > 0 else 0.0
    median_ttv_minutes = _median_minutes(auth_to_complete_minutes)
    target_ttv_minutes = 15.0
    target_met = median_ttv_minutes is not None and median_ttv_minutes <= target_ttv_minutes

    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "target_ttv_minutes": target_ttv_minutes,
        "metrics": {
            "total_users": total_users,
            "inspection_converted_users": inspection_converted,
            "work_order_completed_users": completion_converted,
            "inspection_conversion_rate_percent": inspection_conversion_rate,
            "work_order_completion_rate_percent": completion_conversion_rate,
            "median_ttv_minutes": median_ttv_minutes,
            "target_met": target_met,
        },
        "stage_timings_minutes": {
            "auth_to_first_inspection": _median_minutes(auth_to_inspection_minutes),
            "inspection_to_first_work_order_complete": _median_minutes(inspection_to_complete_minutes),
            "auth_to_first_work_order_complete": median_ttv_minutes,
        },
        "stages": [
            {
                "stage_id": "authenticated",
                "label": "Authenticated Users",
                "user_count": total_users,
                "conversion_rate_percent": 100.0 if total_users > 0 else 0.0,
            },
            {
                "stage_id": "first_inspection",
                "label": "First Inspection Created",
                "user_count": inspection_converted,
                "conversion_rate_percent": inspection_conversion_rate,
            },
            {
                "stage_id": "first_work_order_complete",
                "label": "First Work-Order Completed",
                "user_count": completion_converted,
                "conversion_rate_percent": completion_conversion_rate,
            },
        ],
        "actors": actor_rows[:100],
    }


def _build_w04_blocker_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
    max_items: int = 3,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(1, min(int(days), 90))
    start = now - timedelta(days=window_days)
    limit_items = max(1, min(int(max_items), 10))

    overdue_stmt = (
        select(work_orders.c.id)
        .where(work_orders.c.status.in_(["open", "acked"]))
        .where(work_orders.c.due_at.is_not(None))
        .where(work_orders.c.due_at < now)
    )
    alert_stmt = (
        select(alert_deliveries.c.id)
        .where(alert_deliveries.c.last_attempt_at >= start)
        .where(alert_deliveries.c.status.in_(["failed", "warning"]))
    )
    audit_fail_stmt = (
        select(admin_audit_logs.c.id)
        .where(admin_audit_logs.c.created_at >= start)
        .where(admin_audit_logs.c.status != "success")
    )
    tracker_stmt = select(adoption_w04_tracker_items.c.id).where(
        adoption_w04_tracker_items.c.status.in_(
            [
                W04_TRACKER_STATUS_PENDING,
                W04_TRACKER_STATUS_IN_PROGRESS,
                W04_TRACKER_STATUS_BLOCKED,
            ]
        )
    )

    if site is not None:
        overdue_stmt = overdue_stmt.where(work_orders.c.site == site)
        tracker_stmt = tracker_stmt.where(adoption_w04_tracker_items.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": site,
                "window_days": window_days,
                "top": [],
                "counts": {},
            }
        overdue_stmt = overdue_stmt.where(work_orders.c.site.in_(allowed_sites))
        tracker_stmt = tracker_stmt.where(adoption_w04_tracker_items.c.site.in_(allowed_sites))

    with get_conn() as conn:
        overdue_count = len(conn.execute(overdue_stmt).all())
        failed_alert_count = len(conn.execute(alert_stmt).all())
        audit_fail_count = len(conn.execute(audit_fail_stmt).all())
        tracker_open_count = len(conn.execute(tracker_stmt).all())

    funnel = _build_w04_funnel_snapshot(site=site, days=window_days, allowed_sites=allowed_sites)
    ttv = funnel.get("metrics", {}).get("median_ttv_minutes")
    inspection_conv = float(funnel.get("metrics", {}).get("inspection_conversion_rate_percent") or 0.0)
    completion_conv = float(funnel.get("metrics", {}).get("work_order_completion_rate_percent") or 0.0)

    candidates: list[dict[str, Any]] = []
    if overdue_count > 0:
        candidates.append(
            {
                "blocker_key": "overdue_open_work_orders",
                "title": "Overdue open work orders",
                "count": overdue_count,
                "source": "work_orders",
                "recommendation": "  overdue     ETA ",
            }
        )
    if failed_alert_count > 0:
        candidates.append(
            {
                "blocker_key": "failed_alert_deliveries",
                "title": "Failed alert deliveries",
                "count": failed_alert_count,
                "source": "alert_deliveries",
                "recommendation": "      channel guard  ",
            }
        )
    if audit_fail_count > 0:
        candidates.append(
            {
                "blocker_key": "audit_operation_failures",
                "title": "Audit-recorded failed operations",
                "count": audit_fail_count,
                "source": "admin_audit_logs",
                "recommendation": " action      ",
            }
        )
    if tracker_open_count > 0:
        candidates.append(
            {
                "blocker_key": "w04_tracker_open_items",
                "title": "Open W04 coaching items",
                "count": tracker_open_count,
                "source": "adoption_w04_tracker",
                "recommendation": "pending/in_progress     24   ",
            }
        )
    if isinstance(ttv, (int, float)) and float(ttv) > 15.0:
        candidates.append(
            {
                "blocker_key": "median_ttv_over_target",
                "title": "Median TTV over target",
                "count": int(round(float(ttv))),
                "source": "w04_funnel",
                "recommendation": "  15        ",
            }
        )
    if inspection_conv < 70.0:
        candidates.append(
            {
                "blocker_key": "low_inspection_conversion",
                "title": "Low inspection conversion",
                "count": int(round(70.0 - inspection_conv)),
                "source": "w04_funnel",
                "recommendation": "    /  ",
            }
        )
    if completion_conv < 50.0:
        candidates.append(
            {
                "blocker_key": "low_completion_conversion",
                "title": "Low work-order completion conversion",
                "count": int(round(50.0 - completion_conv)),
                "source": "w04_funnel",
                "recommendation": "ACK/     1:1  ",
            }
        )

    top = sorted(candidates, key=lambda x: (int(x.get("count", 0)), str(x.get("blocker_key", ""))), reverse=True)[:limit_items]
    counts = {str(item["blocker_key"]): int(item["count"]) for item in candidates}
    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "top": top,
        "counts": counts,
    }


def _build_w04_common_mistakes_payload(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    blockers = _build_w04_blocker_snapshot(site=site, days=days, allowed_sites=allowed_sites, max_items=10)
    blocker_counts = blockers.get("counts", {})
    mistake_items: list[dict[str, Any]] = []
    mapping = {
        "missing_assignee": {"w04_tracker_open_items"},
        "missing_evidence": {"w04_tracker_open_items"},
        "slow_first_action": {"median_ttv_over_target", "low_inspection_conversion"},
        "wo_completion_delay": {"overdue_open_work_orders", "low_completion_conversion"},
        "alert_delivery_failures": {"failed_alert_deliveries"},
    }

    for item in W04_COMMON_MISTAKE_FIX_CATALOG:
        key = str(item.get("mistake_key") or "")
        related_blockers = mapping.get(key, set())
        observed_count = sum(int(blocker_counts.get(name, 0)) for name in related_blockers)
        mistake_items.append(
            {
                "mistake_key": key,
                "mistake": item.get("mistake", ""),
                "symptom": item.get("symptom", ""),
                "quick_fix": item.get("quick_fix", ""),
                "where_to_check": item.get("where_to_check", ""),
                "observed_count": observed_count,
            }
        )
    sorted_items = sorted(mistake_items, key=lambda x: int(x.get("observed_count", 0)), reverse=True)
    now = datetime.now(timezone.utc)
    return {
        "title": "W04 Common Mistakes and Quick Fix Guide",
        "public": True,
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": max(1, min(int(days), 90)),
        "items": sorted_items,
        "top_blockers": blockers.get("top", []),
    }


def _build_w04_common_mistakes_html(payload: dict[str, Any]) -> str:
    rows: list[str] = []
    for item in payload.get("items", []):
        rows.append(
            "<tr>"
            f"<td>{html.escape(str(item.get('mistake', '')))}</td>"
            f"<td>{html.escape(str(item.get('symptom', '')))}</td>"
            f"<td>{html.escape(str(item.get('quick_fix', '')))}</td>"
            f"<td>{html.escape(str(item.get('where_to_check', '')))}</td>"
            f"<td>{html.escape(str(item.get('observed_count', 0)))}</td>"
            "</tr>"
        )
    if not rows:
        rows.append("<tr><td colspan='5'>No data</td></tr>")

    return f"""
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>W04 Common Mistakes</title>
  <style>
    body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 0; background: #f2f6fb; color: #112; }}
    .wrap {{ max-width: 980px; margin: 0 auto; padding: 18px; }}
    .box {{ background: #fff; border: 1px solid #d8e2ef; border-radius: 12px; padding: 14px; }}
    h1 {{ margin: 0 0 8px; font-size: 24px; }}
    p {{ margin: 0 0 10px; color: #355; }}
    table {{ width: 100%; border-collapse: collapse; }}
    th, td {{ border: 1px solid #d8e2ef; padding: 8px; font-size: 13px; text-align: left; vertical-align: top; }}
    th {{ background: #eef4fb; }}
    .links a {{ margin-right: 8px; }}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="box">
      <h1>{html.escape(str(payload.get("title", "W04 Common Mistakes")))}</h1>
      <p>Generated: {html.escape(str(payload.get("generated_at", "")))}</p>
      <p>Site: {html.escape(str(payload.get("site", "ALL")))} | Window: {html.escape(str(payload.get("window_days", "")))} days</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w04/common-mistakes">JSON</a>
        <a href="/api/public/adoption-plan/w04">W04 Pack</a>
        <a href="/">Main</a>
      </div>
      <table>
        <thead>
          <tr><th>Mistake</th><th>Symptom</th><th>Quick Fix</th><th>Where To Check</th><th>Observed</th></tr>
        </thead>
        <tbody>
          {"".join(rows)}
        </tbody>
      </table>
    </div>
  </div>
</body>
</html>
"""


def _build_w05_usage_consistency_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 90))
    start = now - timedelta(days=window_days)
    midpoint = start + timedelta(days=max(1, window_days // 2))

    event_stmt = (
        select(work_order_events.c.actor_username, work_orders.c.site, work_order_events.c.created_at)
        .select_from(work_order_events.join(work_orders, work_order_events.c.work_order_id == work_orders.c.id))
        .where(work_order_events.c.created_at >= start)
    )
    inspection_stmt = (
        select(inspections.c.inspector, inspections.c.site, inspections.c.created_at)
        .where(inspections.c.created_at >= start)
    )
    open_work_orders_stmt = select(work_orders.c.site, work_orders.c.status, work_orders.c.due_at).where(
        work_orders.c.status.in_(["open", "acked"])
    )

    if site is not None:
        event_stmt = event_stmt.where(work_orders.c.site == site)
        inspection_stmt = inspection_stmt.where(inspections.c.site == site)
        open_work_orders_stmt = open_work_orders_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": site,
                "window_days": window_days,
                "target_retention_percent": 65.0,
                "metrics": {
                    "active_users": 0,
                    "early_period_users": 0,
                    "retained_users": 0,
                    "two_week_retention_percent": 0.0,
                    "target_met": False,
                    "inspection_activity_users": 0,
                    "open_work_orders": 0,
                    "overdue_open_work_orders": 0,
                    "overdue_ratio_percent": 0.0,
                },
                "top_sites_by_overdue": [],
                "mission_recommendations": [],
            }
        event_stmt = event_stmt.where(work_orders.c.site.in_(allowed_sites))
        inspection_stmt = inspection_stmt.where(inspections.c.site.in_(allowed_sites))
        open_work_orders_stmt = open_work_orders_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        event_rows = conn.execute(event_stmt).mappings().all()
        inspection_rows = conn.execute(inspection_stmt).mappings().all()
        open_work_order_rows = conn.execute(open_work_orders_stmt).mappings().all()

    early_users: set[str] = set()
    late_users: set[str] = set()
    active_users: set[str] = set()
    for row in event_rows:
        actor = str(row.get("actor_username") or "").strip()
        if not actor or actor == "system":
            continue
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is None:
            continue
        active_users.add(actor)
        if created_at < midpoint:
            early_users.add(actor)
        else:
            late_users.add(actor)

    inspection_users: set[str] = set()
    for row in inspection_rows:
        actor = str(row.get("inspector") or "").strip()
        if actor:
            inspection_users.add(actor)

    retained_users = early_users.intersection(late_users)
    early_count = len(early_users)
    retained_count = len(retained_users)
    retention_percent = round((retained_count / early_count) * 100, 2) if early_count > 0 else 0.0
    target_retention_percent = 65.0

    open_total = 0
    overdue_total = 0
    site_open: dict[str, int] = {}
    site_overdue: dict[str, int] = {}
    for row in open_work_order_rows:
        row_site = str(row.get("site") or "").strip()
        if not row_site:
            continue
        open_total += 1
        site_open[row_site] = int(site_open.get(row_site, 0)) + 1
        due_at = _as_optional_datetime(row.get("due_at"))
        if due_at is not None and due_at < now:
            overdue_total += 1
            site_overdue[row_site] = int(site_overdue.get(row_site, 0)) + 1

    overdue_ratio_percent = round((overdue_total / open_total) * 100, 2) if open_total > 0 else 0.0

    top_sites_by_overdue: list[dict[str, Any]] = []
    if site is None:
        for site_name, total in site_open.items():
            overdue = int(site_overdue.get(site_name, 0))
            ratio = round((overdue / total) * 100, 2) if total > 0 else 0.0
            top_sites_by_overdue.append(
                {
                    "site": site_name,
                    "open_work_orders": total,
                    "overdue_open_work_orders": overdue,
                    "overdue_ratio_percent": ratio,
                }
            )
        top_sites_by_overdue = sorted(
            top_sites_by_overdue,
            key=lambda item: (float(item.get("overdue_ratio_percent") or 0.0), int(item.get("overdue_open_work_orders") or 0)),
            reverse=True,
        )[:5]
    else:
        top_sites_by_overdue = [
            {
                "site": site,
                "open_work_orders": open_total,
                "overdue_open_work_orders": overdue_total,
                "overdue_ratio_percent": overdue_ratio_percent,
            }
        ]

    mission_recommendations: list[str] = []
    if retention_percent < target_retention_percent:
        mission_recommendations.append("    Site Champion 1:1  .")
    if overdue_ratio_percent >= 25.0:
        mission_recommendations.append("overdue  .   ETA   .")
    if len(inspection_users) < max(3, len(active_users) // 2):
        mission_recommendations.append("   .      .")
    if not mission_recommendations:
        mission_recommendations.append("    .     .")

    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "target_retention_percent": target_retention_percent,
        "metrics": {
            "active_users": len(active_users),
            "early_period_users": early_count,
            "retained_users": retained_count,
            "two_week_retention_percent": retention_percent,
            "target_met": retention_percent >= target_retention_percent,
            "inspection_activity_users": len(inspection_users),
            "open_work_orders": open_total,
            "overdue_open_work_orders": overdue_total,
            "overdue_ratio_percent": overdue_ratio_percent,
        },
        "top_sites_by_overdue": top_sites_by_overdue,
        "mission_recommendations": mission_recommendations,
    }


def _build_w06_operational_rhythm_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(7, min(int(days), 90))
    start = now - timedelta(days=window_days)

    def _scope_matches(scope_values: list[str], *, site_name: str | None, allowed: list[str] | None) -> bool:
        normalized = _site_scope_text_to_list(scope_values, default_all=True)
        if SITE_SCOPE_ALL in normalized:
            if site_name is not None:
                return True
            return not (allowed is not None and len(allowed) == 0)
        if site_name is not None:
            return site_name in normalized
        if allowed is not None:
            return any(item in allowed for item in normalized)
        return True

    event_stmt = (
        select(work_order_events.c.actor_username, work_orders.c.site, work_order_events.c.created_at)
        .select_from(work_order_events.join(work_orders, work_order_events.c.work_order_id == work_orders.c.id))
        .where(work_order_events.c.created_at >= start)
    )
    inspection_stmt = select(inspections.c.inspector, inspections.c.site, inspections.c.created_at).where(
        inspections.c.created_at >= start
    )
    handover_stmt = (
        select(admin_audit_logs.c.actor_username, admin_audit_logs.c.resource_id, admin_audit_logs.c.created_at)
        .where(admin_audit_logs.c.action == "ops_handover_brief_view")
        .where(admin_audit_logs.c.created_at >= start)
    )
    overdue_stmt = select(work_orders.c.id).where(work_orders.c.status.in_(["open", "acked"])).where(
        work_orders.c.due_at.is_not(None)
    ).where(work_orders.c.due_at < now)

    if site is not None:
        event_stmt = event_stmt.where(work_orders.c.site == site)
        inspection_stmt = inspection_stmt.where(inspections.c.site == site)
        overdue_stmt = overdue_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": site,
                "window_days": window_days,
                "target_weekly_active_rate_percent": 75.0,
                "metrics": {
                    "eligible_users": 0,
                    "active_users": 0,
                    "weekly_active_rate_percent": 0.0,
                    "target_met": False,
                    "handover_brief_views": 0,
                    "handover_days_covered": 0,
                    "cadence_adherence_percent": 0.0,
                    "overdue_open_work_orders": 0,
                    "active_tokens": 0,
                    "tokens_expiring_7d": 0,
                    "tokens_stale_14d": 0,
                    "users_without_active_token": 0,
                },
                "role_coverage": [],
                "site_activity": [],
                "recommendations": [],
            }
        event_stmt = event_stmt.where(work_orders.c.site.in_(allowed_sites))
        inspection_stmt = inspection_stmt.where(inspections.c.site.in_(allowed_sites))
        overdue_stmt = overdue_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        event_rows = conn.execute(event_stmt).mappings().all()
        inspection_rows = conn.execute(inspection_stmt).mappings().all()
        handover_rows = conn.execute(handover_stmt).mappings().all()
        overdue_rows = conn.execute(overdue_stmt).all()
        user_rows = conn.execute(
            select(
                admin_users.c.id,
                admin_users.c.username,
                admin_users.c.role,
                admin_users.c.site_scope,
            ).where(admin_users.c.is_active.is_(True))
        ).mappings().all()
        token_rows = conn.execute(
            select(
                admin_tokens.c.user_id,
                admin_tokens.c.expires_at,
                admin_tokens.c.last_used_at,
                admin_tokens.c.site_scope,
            ).where(admin_tokens.c.is_active.is_(True))
        ).mappings().all()

    eligible_roles = {"owner", "manager", "operator"}
    eligible_by_id: dict[int, dict[str, Any]] = {}
    for row in user_rows:
        role = str(row.get("role") or "").strip().lower()
        if role not in eligible_roles:
            continue
        scope_values = _site_scope_text_to_list(row.get("site_scope"), default_all=True)
        if not _scope_matches(scope_values, site_name=site, allowed=allowed_sites):
            continue
        user_id = int(row.get("id") or 0)
        if user_id <= 0:
            continue
        eligible_by_id[user_id] = {
            "username": str(row.get("username") or "").strip(),
            "role": role,
            "scope": scope_values,
        }

    eligible_users = {
        str(info.get("username") or "").strip()
        for info in eligible_by_id.values()
        if str(info.get("username") or "").strip()
    }

    active_users: set[str] = set()
    site_activity_counter: dict[str, int] = {}
    for row in event_rows:
        actor = str(row.get("actor_username") or "").strip()
        row_site = str(row.get("site") or "").strip()
        if not actor or actor == "system":
            continue
        active_users.add(actor)
        if row_site:
            site_activity_counter[row_site] = int(site_activity_counter.get(row_site, 0)) + 1
    for row in inspection_rows:
        actor = str(row.get("inspector") or "").strip()
        row_site = str(row.get("site") or "").strip()
        if not actor:
            continue
        active_users.add(actor)
        if row_site:
            site_activity_counter[row_site] = int(site_activity_counter.get(row_site, 0)) + 1

    active_eligible_users = active_users.intersection(eligible_users)
    eligible_count = len(eligible_users)
    active_count = len(active_eligible_users)
    weekly_active_rate_percent = round((active_count / eligible_count) * 100, 2) if eligible_count > 0 else 0.0
    target_weekly_active_rate_percent = 75.0

    handover_view_count = 0
    handover_days: set[str] = set()
    for row in handover_rows:
        resource_id = str(row.get("resource_id") or "").strip()
        if site is not None:
            if resource_id not in {site, "all"}:
                continue
        elif allowed_sites is not None:
            if resource_id != "all" and resource_id not in allowed_sites:
                continue
        created_at = _as_optional_datetime(row.get("created_at"))
        if created_at is None:
            continue
        handover_view_count += 1
        handover_days.add(created_at.date().isoformat())

    expected_handover_days = max(1, min(window_days, 5))
    cadence_adherence_percent = round((len(handover_days) / expected_handover_days) * 100, 2)
    if cadence_adherence_percent > 100.0:
        cadence_adherence_percent = 100.0

    now_plus_7d = now + timedelta(days=7)
    stale_cutoff = now - timedelta(days=14)
    active_token_count = 0
    tokens_expiring_7d = 0
    tokens_stale_14d = 0
    users_with_active_token: set[int] = set()
    for row in token_rows:
        user_id = int(row.get("user_id") or 0)
        if user_id not in eligible_by_id:
            continue
        user_scope = eligible_by_id[user_id]["scope"]
        token_scope_raw = row.get("site_scope")
        token_scope = _site_scope_text_to_list(token_scope_raw, default_all=True) if token_scope_raw is not None else None
        effective_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
        if not _scope_matches(effective_scope, site_name=site, allowed=allowed_sites):
            continue
        active_token_count += 1
        users_with_active_token.add(user_id)
        expires_at = _as_optional_datetime(row.get("expires_at"))
        if expires_at is not None and expires_at <= now_plus_7d:
            tokens_expiring_7d += 1
        last_used_at = _as_optional_datetime(row.get("last_used_at"))
        if last_used_at is None or last_used_at < stale_cutoff:
            tokens_stale_14d += 1

    users_without_active_token = max(0, len(eligible_by_id) - len(users_with_active_token))
    overdue_open_work_orders = len(overdue_rows)

    role_to_users: dict[str, set[str]] = {"owner": set(), "manager": set(), "operator": set()}
    for info in eligible_by_id.values():
        role = str(info.get("role") or "").strip().lower()
        username = str(info.get("username") or "").strip()
        if role in role_to_users and username:
            role_to_users[role].add(username)

    role_coverage = [
        {
            "role": role,
            "user_count": len(users),
            "active_user_count": len(users.intersection(active_eligible_users)),
        }
        for role, users in role_to_users.items()
    ]

    site_activity: list[dict[str, Any]] = []
    if site is None:
        for site_name, count in site_activity_counter.items():
            site_activity.append({"site": site_name, "activity_events": int(count)})
        site_activity = sorted(site_activity, key=lambda item: int(item.get("activity_events", 0)), reverse=True)[:8]
    else:
        site_activity = [{"site": site, "activity_events": int(site_activity_counter.get(site, 0))}]

    recommendations: list[str] = []
    if weekly_active_rate_percent < target_weekly_active_rate_percent:
        recommendations.append("  .      .")
    if cadence_adherence_percent < 80.0:
        recommendations.append("handover   .    action  .")
    if users_without_active_token > 0:
        recommendations.append("     . RBAC/   .")
    if tokens_expiring_7d > 0 or tokens_stale_14d > 0:
        recommendations.append(" /     /  .")
    if overdue_open_work_orders > 0:
        recommendations.append("overdue   .  /ETA   .")
    if not recommendations:
        recommendations.append("    .  cadence .")

    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "target_weekly_active_rate_percent": target_weekly_active_rate_percent,
        "metrics": {
            "eligible_users": eligible_count,
            "active_users": active_count,
            "weekly_active_rate_percent": weekly_active_rate_percent,
            "target_met": weekly_active_rate_percent >= target_weekly_active_rate_percent,
            "handover_brief_views": handover_view_count,
            "handover_days_covered": len(handover_days),
            "cadence_adherence_percent": cadence_adherence_percent,
            "overdue_open_work_orders": overdue_open_work_orders,
            "active_tokens": active_token_count,
            "tokens_expiring_7d": tokens_expiring_7d,
            "tokens_stale_14d": tokens_stale_14d,
            "users_without_active_token": users_without_active_token,
        },
        "role_coverage": role_coverage,
        "site_activity": site_activity,
        "recommendations": recommendations,
    }


def _build_w07_sla_quality_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(7, min(int(days), 90))
    baseline_days = window_days
    start = now - timedelta(days=window_days)
    baseline_start = start - timedelta(days=baseline_days)

    def _empty_snapshot() -> dict[str, Any]:
        return {
            "generated_at": now.isoformat(),
            "site": site,
            "window_days": window_days,
            "baseline_days": baseline_days,
            "target_response_improvement_percent": 10.0,
            "thresholds": {
                "escalation_rate_percent": round(max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD), 2),
                "alert_success_rate_percent": round(max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD)), 2),
                "data_quality_issue_rate_percent": 5.0,
            },
            "metrics": {
                "created_work_orders": 0,
                "acked_work_orders": 0,
                "completed_work_orders": 0,
                "median_ack_minutes": None,
                "p90_ack_minutes": None,
                "baseline_median_ack_minutes": None,
                "response_time_improvement_percent": None,
                "target_met": False,
                "median_mttr_minutes": None,
                "priority_mttr_minutes": {},
                "sla_violation_count": 0,
                "sla_violation_rate_percent": 0.0,
                "open_work_orders": 0,
                "overdue_open_work_orders": 0,
                "escalated_open_work_orders": 0,
                "escalated_work_orders": 0,
                "escalation_rate_percent": 0.0,
                "alert_total": 0,
                "alert_success_count": 0,
                "alert_success_rate_percent": 0.0,
                "sla_run_count": 0,
                "data_quality_gate_pass": True,
                "data_quality_issue_count": 0,
                "data_quality_critical_issue_count": 0,
                "data_quality_issue_rate_percent": 0.0,
            },
            "data_quality": {
                "gate_pass": True,
                "issue_count": 0,
                "critical_issue_count": 0,
                "issue_rate_percent": 0.0,
                "checks": {
                    "missing_due_at_count": 0,
                    "missing_priority_count": 0,
                    "invalid_status_count": 0,
                    "completed_without_completed_at_count": 0,
                    "ack_before_created_count": 0,
                    "completion_before_created_count": 0,
                    "due_before_created_count": 0,
                },
            },
            "top_risk_sites": [],
            "recommendations": [],
        }

    current_stmt = select(
        work_orders.c.site,
        work_orders.c.status,
        work_orders.c.priority,
        work_orders.c.created_at,
        work_orders.c.acknowledged_at,
        work_orders.c.completed_at,
        work_orders.c.due_at,
        work_orders.c.is_escalated,
    ).where(work_orders.c.created_at >= start)
    baseline_stmt = (
        select(
            work_orders.c.site,
            work_orders.c.created_at,
            work_orders.c.acknowledged_at,
        )
        .where(work_orders.c.created_at >= baseline_start)
        .where(work_orders.c.created_at < start)
    )
    open_stmt = select(
        work_orders.c.site,
        work_orders.c.status,
        work_orders.c.priority,
        work_orders.c.due_at,
        work_orders.c.is_escalated,
    ).where(work_orders.c.status.in_(["open", "acked"]))
    alert_stmt = select(
        alert_deliveries.c.status,
        alert_deliveries.c.payload_json,
        alert_deliveries.c.created_at,
    ).where(alert_deliveries.c.created_at >= start)
    sla_run_stmt = (
        select(job_runs.c.detail_json)
        .where(job_runs.c.job_name == "sla_escalation")
        .where(job_runs.c.finished_at >= start)
    )

    if site is not None:
        current_stmt = current_stmt.where(work_orders.c.site == site)
        baseline_stmt = baseline_stmt.where(work_orders.c.site == site)
        open_stmt = open_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return _empty_snapshot()
        current_stmt = current_stmt.where(work_orders.c.site.in_(allowed_sites))
        baseline_stmt = baseline_stmt.where(work_orders.c.site.in_(allowed_sites))
        open_stmt = open_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        current_rows = conn.execute(current_stmt).mappings().all()
        baseline_rows = conn.execute(baseline_stmt).mappings().all()
        open_rows = conn.execute(open_stmt).mappings().all()
        alert_rows = conn.execute(alert_stmt).mappings().all()
        sla_run_rows = conn.execute(sla_run_stmt).mappings().all()

    def _ack_minutes(rows: list[dict[str, Any]]) -> list[float]:
        values: list[float] = []
        for row in rows:
            created_at = _as_optional_datetime(row.get("created_at"))
            acknowledged_at = _as_optional_datetime(row.get("acknowledged_at"))
            if created_at is None or acknowledged_at is None or acknowledged_at < created_at:
                continue
            values.append((acknowledged_at - created_at).total_seconds() / 60.0)
        return values

    def _normalize_priority(raw: Any) -> str:
        value = str(raw or "").strip().lower()
        if value in {"low", "medium", "high", "critical"}:
            return value
        return "unknown"

    def _safe_rate(numerator: int, denominator: int) -> float:
        if denominator <= 0:
            return 0.0
        return round((float(numerator) / float(denominator)) * 100.0, 2)

    current_ack_minutes = _ack_minutes(current_rows)
    baseline_ack_minutes = _ack_minutes(baseline_rows)
    median_ack_minutes = _median_minutes(current_ack_minutes)
    p90_ack_minutes = _percentile_minutes(current_ack_minutes, 90.0)
    baseline_median_ack_minutes = _median_minutes(baseline_ack_minutes)
    response_time_improvement_percent: float | None = None
    if baseline_median_ack_minutes is not None and median_ack_minutes is not None:
        if baseline_median_ack_minutes > 0:
            response_time_improvement_percent = round(
                ((baseline_median_ack_minutes - median_ack_minutes) / baseline_median_ack_minutes) * 100.0,
                2,
            )
        else:
            response_time_improvement_percent = 0.0

    created_work_orders = len(current_rows)
    acked_work_orders = sum(1 for row in current_rows if _as_optional_datetime(row.get("acknowledged_at")) is not None)
    completed_work_orders = sum(1 for row in current_rows if _as_optional_datetime(row.get("completed_at")) is not None)
    escalated_work_orders = sum(1 for row in current_rows if bool(row.get("is_escalated", False)))
    escalation_rate_percent = _safe_rate(escalated_work_orders, created_work_orders)

    priority_mttr_values: dict[str, list[float]] = {}
    overall_mttr_values: list[float] = []
    site_created: dict[str, int] = {}
    site_escalated_work_orders: dict[str, int] = {}
    site_violation_count: dict[str, int] = {}
    site_ack_values: dict[str, list[float]] = {}

    missing_due_at_count = 0
    missing_priority_count = 0
    invalid_status_count = 0
    completed_without_completed_at_count = 0
    ack_before_created_count = 0
    completion_before_created_count = 0
    due_before_created_count = 0
    sla_violation_count = 0

    valid_statuses = {"open", "acked", "completed", "canceled"}
    for row in current_rows:
        row_site = str(row.get("site") or "").strip()
        if row_site:
            site_created[row_site] = int(site_created.get(row_site, 0)) + 1
            if bool(row.get("is_escalated", False)):
                site_escalated_work_orders[row_site] = int(site_escalated_work_orders.get(row_site, 0)) + 1

        status_value = str(row.get("status") or "").strip().lower()
        if status_value not in valid_statuses:
            invalid_status_count += 1

        priority_value = _normalize_priority(row.get("priority"))
        if priority_value == "unknown":
            missing_priority_count += 1

        created_at = _as_optional_datetime(row.get("created_at"))
        acknowledged_at = _as_optional_datetime(row.get("acknowledged_at"))
        completed_at = _as_optional_datetime(row.get("completed_at"))
        due_at = _as_optional_datetime(row.get("due_at"))

        if due_at is None:
            missing_due_at_count += 1
        elif created_at is not None and due_at < created_at:
            due_before_created_count += 1

        if status_value == "completed" and completed_at is None:
            completed_without_completed_at_count += 1

        if created_at is not None and acknowledged_at is not None:
            if acknowledged_at < created_at:
                ack_before_created_count += 1
            elif row_site:
                site_ack_values.setdefault(row_site, []).append(
                    (acknowledged_at - created_at).total_seconds() / 60.0
                )

        if created_at is not None and completed_at is not None:
            if completed_at < created_at:
                completion_before_created_count += 1
            else:
                mttr_minutes = (completed_at - created_at).total_seconds() / 60.0
                overall_mttr_values.append(mttr_minutes)
                priority_mttr_values.setdefault(priority_value, []).append(mttr_minutes)

        violated = False
        if due_at is not None:
            if completed_at is not None:
                violated = completed_at > due_at
            else:
                violated = now > due_at
        if violated:
            sla_violation_count += 1
            if row_site:
                site_violation_count[row_site] = int(site_violation_count.get(row_site, 0)) + 1

    priority_mttr_minutes = {
        priority: _median_minutes(values)
        for priority, values in sorted(priority_mttr_values.items(), key=lambda item: item[0])
        if values
    }
    median_mttr_minutes = _median_minutes(overall_mttr_values)
    sla_violation_rate_percent = _safe_rate(sla_violation_count, created_work_orders)

    open_work_orders = 0
    overdue_open_work_orders = 0
    escalated_open_work_orders = 0
    site_open: dict[str, int] = {}
    site_overdue: dict[str, int] = {}
    site_escalated_open: dict[str, int] = {}
    for row in open_rows:
        row_site = str(row.get("site") or "").strip()
        if not row_site:
            continue
        open_work_orders += 1
        site_open[row_site] = int(site_open.get(row_site, 0)) + 1
        due_at = _as_optional_datetime(row.get("due_at"))
        if due_at is not None and due_at < now:
            overdue_open_work_orders += 1
            site_overdue[row_site] = int(site_overdue.get(row_site, 0)) + 1
        if bool(row.get("is_escalated", False)):
            escalated_open_work_orders += 1
            site_escalated_open[row_site] = int(site_escalated_open.get(row_site, 0)) + 1

    alert_total = 0
    alert_success_count = 0
    for row in alert_rows:
        payload_raw = str(row.get("payload_json") or "{}")
        payload: dict[str, Any] = {}
        try:
            loaded = json.loads(payload_raw)
            if isinstance(loaded, dict):
                payload = loaded
        except json.JSONDecodeError:
            payload = {}

        payload_site_raw = payload.get("site")
        payload_site = _normalize_site_name(str(payload_site_raw)) if payload_site_raw is not None else None
        if site is not None:
            if payload_site != site:
                continue
        elif allowed_sites is not None:
            if payload_site is None or payload_site == "ALL" or payload_site not in allowed_sites:
                continue

        alert_total += 1
        if str(row.get("status") or "").strip().lower() == "success":
            alert_success_count += 1
    alert_success_rate_percent = _safe_rate(alert_success_count, alert_total)

    sla_run_count = 0
    for row in sla_run_rows:
        run_site: str | None = None
        detail_raw = str(row.get("detail_json") or "{}")
        try:
            loaded = json.loads(detail_raw)
            if isinstance(loaded, dict):
                site_raw = loaded.get("site")
                if site_raw is not None:
                    run_site = _normalize_site_name(str(site_raw))
        except json.JSONDecodeError:
            run_site = None

        if site is not None:
            if run_site not in {None, site}:
                continue
        elif allowed_sites is not None:
            if run_site is not None and run_site not in allowed_sites:
                continue
        sla_run_count += 1

    top_risk_sites: list[dict[str, Any]] = []
    if site is None:
        all_sites = set(site_open) | set(site_created)
        for site_name in sorted(all_sites):
            created_count = int(site_created.get(site_name, 0))
            violation_count = int(site_violation_count.get(site_name, 0))
            ack_values = site_ack_values.get(site_name, [])
            top_risk_sites.append(
                {
                    "site": site_name,
                    "open_work_orders": int(site_open.get(site_name, 0)),
                    "overdue_open_work_orders": int(site_overdue.get(site_name, 0)),
                    "escalated_open_work_orders": int(site_escalated_open.get(site_name, 0)),
                    "escalation_rate_percent": _safe_rate(
                        int(site_escalated_work_orders.get(site_name, 0)),
                        created_count,
                    ),
                    "sla_violation_rate_percent": _safe_rate(violation_count, created_count),
                    "median_ack_minutes": _median_minutes(ack_values),
                    "p90_ack_minutes": _percentile_minutes(ack_values, 90.0),
                }
            )
        top_risk_sites = sorted(
            top_risk_sites,
            key=lambda item: (
                float(item.get("sla_violation_rate_percent") or 0.0),
                float(item.get("escalation_rate_percent") or 0.0),
                int(item.get("overdue_open_work_orders") or 0),
                int(item.get("open_work_orders") or 0),
            ),
            reverse=True,
        )[:5]
    elif site is not None:
        ack_values = site_ack_values.get(site, [])
        created_count = int(site_created.get(site, 0))
        top_risk_sites = [
            {
                "site": site,
                "open_work_orders": open_work_orders,
                "overdue_open_work_orders": overdue_open_work_orders,
                "escalated_open_work_orders": escalated_open_work_orders,
                "escalation_rate_percent": _safe_rate(int(site_escalated_work_orders.get(site, 0)), created_count),
                "sla_violation_rate_percent": _safe_rate(int(site_violation_count.get(site, 0)), created_count),
                "median_ack_minutes": _median_minutes(ack_values),
                "p90_ack_minutes": _percentile_minutes(ack_values, 90.0),
            }
        ]

    target_response_improvement_percent = 10.0
    data_quality_issue_count = (
        missing_due_at_count
        + missing_priority_count
        + invalid_status_count
        + completed_without_completed_at_count
        + ack_before_created_count
        + completion_before_created_count
        + due_before_created_count
    )
    data_quality_critical_issue_count = (
        completed_without_completed_at_count
        + ack_before_created_count
        + completion_before_created_count
        + due_before_created_count
    )
    data_quality_issue_rate_percent = _safe_rate(data_quality_issue_count, created_work_orders)
    data_quality_gate_pass = data_quality_critical_issue_count == 0 and data_quality_issue_rate_percent <= 5.0

    recommendations: list[str] = []
    if response_time_improvement_percent is None:
        recommendations.append("ACK    . ack    .")
    elif response_time_improvement_percent < target_response_improvement_percent:
        recommendations.append("SLA response   .  site  .")
    if p90_ack_minutes is not None and p90_ack_minutes > 120.0:
        recommendations.append("ACK p90 120 .    / ACK  .")
    if sla_violation_rate_percent > 20.0:
        recommendations.append("SLA violation rate . due_at/  triage  .")
    if overdue_open_work_orders > 0:
        recommendations.append("overdue open   .   ETA  .")
    if escalation_rate_percent >= max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD):
        recommendations.append("escalation rate .     .")
    if alert_total > 0 and alert_success_rate_percent < max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD)):
        recommendations.append("alert  .      .")
    expected_runs = max(1, window_days // 7)
    if sla_run_count < expected_runs:
        recommendations.append("SLA    . Cron/   .")
    if not data_quality_gate_pass:
        recommendations.append("   . due_at//   .")
    if not recommendations:
        recommendations.append("SLA    .    .")

    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "baseline_days": baseline_days,
        "target_response_improvement_percent": target_response_improvement_percent,
        "thresholds": {
            "escalation_rate_percent": round(max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD), 2),
            "alert_success_rate_percent": round(max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD)), 2),
            "data_quality_issue_rate_percent": 5.0,
        },
        "metrics": {
            "created_work_orders": created_work_orders,
            "acked_work_orders": acked_work_orders,
            "completed_work_orders": completed_work_orders,
            "median_ack_minutes": median_ack_minutes,
            "p90_ack_minutes": p90_ack_minutes,
            "baseline_median_ack_minutes": baseline_median_ack_minutes,
            "response_time_improvement_percent": response_time_improvement_percent,
            "target_met": (
                response_time_improvement_percent is not None
                and response_time_improvement_percent >= target_response_improvement_percent
            ),
            "median_mttr_minutes": median_mttr_minutes,
            "priority_mttr_minutes": priority_mttr_minutes,
            "sla_violation_count": sla_violation_count,
            "sla_violation_rate_percent": sla_violation_rate_percent,
            "open_work_orders": open_work_orders,
            "overdue_open_work_orders": overdue_open_work_orders,
            "escalated_open_work_orders": escalated_open_work_orders,
            "escalated_work_orders": escalated_work_orders,
            "escalation_rate_percent": escalation_rate_percent,
            "alert_total": alert_total,
            "alert_success_count": alert_success_count,
            "alert_success_rate_percent": alert_success_rate_percent,
            "sla_run_count": sla_run_count,
            "data_quality_gate_pass": data_quality_gate_pass,
            "data_quality_issue_count": data_quality_issue_count,
            "data_quality_critical_issue_count": data_quality_critical_issue_count,
            "data_quality_issue_rate_percent": data_quality_issue_rate_percent,
        },
        "data_quality": {
            "gate_pass": data_quality_gate_pass,
            "issue_count": data_quality_issue_count,
            "critical_issue_count": data_quality_critical_issue_count,
            "issue_rate_percent": data_quality_issue_rate_percent,
            "checks": {
                "missing_due_at_count": missing_due_at_count,
                "missing_priority_count": missing_priority_count,
                "invalid_status_count": invalid_status_count,
                "completed_without_completed_at_count": completed_without_completed_at_count,
                "ack_before_created_count": ack_before_created_count,
                "completion_before_created_count": completion_before_created_count,
                "due_before_created_count": due_before_created_count,
            },
        },
        "top_risk_sites": top_risk_sites,
        "recommendations": recommendations,
    }


def _build_w08_report_discipline_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    start = now - timedelta(days=window_days)

    def _safe_rate(numerator: int, denominator: int) -> float:
        if denominator <= 0:
            return 0.0
        return round((float(numerator) / float(denominator)) * 100.0, 2)

    def _priority_valid(value: Any) -> bool:
        return str(value or "").strip().lower() in {"low", "medium", "high", "critical"}

    wo_stmt = select(
        work_orders.c.site,
        work_orders.c.status,
        work_orders.c.priority,
        work_orders.c.due_at,
        work_orders.c.completed_at,
        work_orders.c.created_at,
    ).where(work_orders.c.created_at >= start)
    insp_stmt = select(
        inspections.c.site,
        inspections.c.risk_level,
        inspections.c.created_at,
    ).where(inspections.c.created_at >= start)
    export_stmt = (
        select(
            admin_audit_logs.c.action,
            admin_audit_logs.c.detail_json,
            admin_audit_logs.c.created_at,
        )
        .where(admin_audit_logs.c.created_at >= start)
        .where(admin_audit_logs.c.action.in_(["report_monthly_export_csv", "report_monthly_export_pdf"]))
    )

    if site is not None:
        wo_stmt = wo_stmt.where(work_orders.c.site == site)
        insp_stmt = insp_stmt.where(inspections.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return {
                "generated_at": now.isoformat(),
                "site": site,
                "window_days": window_days,
                "target_discipline_score": 85.0,
                "thresholds": {
                    "missing_due_rate_percent": 2.0,
                    "data_quality_issue_rate_percent": 5.0,
                    "report_export_coverage_percent": 95.0,
                },
                "metrics": {
                    "site_count": 0,
                    "work_orders_created": 0,
                    "work_orders_completed": 0,
                    "work_orders_missing_due_at": 0,
                    "missing_due_rate_percent": 0.0,
                    "invalid_priority_count": 0,
                    "completed_without_completed_at_count": 0,
                    "open_overdue_count": 0,
                    "overdue_rate_percent": 0.0,
                    "sla_violation_count": 0,
                    "sla_violation_rate_percent": 0.0,
                    "data_quality_issue_count": 0,
                    "data_quality_issue_rate_percent": 0.0,
                    "inspections_created": 0,
                    "inspections_high_risk": 0,
                    "report_export_count": 0,
                    "report_export_csv_count": 0,
                    "report_export_pdf_count": 0,
                    "report_export_coverage_percent": 0.0,
                    "report_export_last_at": None,
                    "discipline_score": 0.0,
                    "target_met": False,
                },
                "top_risk_sites": [],
                "site_benchmark": [],
                "recommendations": ["  site scope  ."],
            }
        wo_stmt = wo_stmt.where(work_orders.c.site.in_(allowed_sites))
        insp_stmt = insp_stmt.where(inspections.c.site.in_(allowed_sites))

    with get_conn() as conn:
        wo_rows = conn.execute(wo_stmt).mappings().all()
        insp_rows = conn.execute(insp_stmt).mappings().all()
        export_rows = conn.execute(export_stmt).mappings().all()

    site_stats: dict[str, dict[str, Any]] = {}

    def _site_bucket(site_name: str) -> dict[str, Any]:
        if site_name not in site_stats:
            site_stats[site_name] = {
                "site": site_name,
                "work_orders_created": 0,
                "work_orders_completed": 0,
                "work_orders_missing_due_at": 0,
                "invalid_priority_count": 0,
                "completed_without_completed_at_count": 0,
                "open_overdue_count": 0,
                "sla_violation_count": 0,
                "data_quality_issue_count": 0,
                "inspections_created": 0,
                "inspections_high_risk": 0,
                "report_export_count": 0,
                "report_export_csv_count": 0,
                "report_export_pdf_count": 0,
                "report_export_last_at": None,
            }
        return site_stats[site_name]

    for row in wo_rows:
        site_name = _normalize_site_name(str(row.get("site") or ""))
        if site_name is None:
            continue
        bucket = _site_bucket(site_name)
        bucket["work_orders_created"] = int(bucket["work_orders_created"]) + 1

        status = str(row.get("status") or "").strip().lower()
        due_at = _as_optional_datetime(row.get("due_at"))
        completed_at = _as_optional_datetime(row.get("completed_at"))

        if status == "completed":
            bucket["work_orders_completed"] = int(bucket["work_orders_completed"]) + 1
            if completed_at is None:
                bucket["completed_without_completed_at_count"] = int(bucket["completed_without_completed_at_count"]) + 1

        if due_at is None:
            bucket["work_orders_missing_due_at"] = int(bucket["work_orders_missing_due_at"]) + 1

        if not _priority_valid(row.get("priority")):
            bucket["invalid_priority_count"] = int(bucket["invalid_priority_count"]) + 1

        is_open = status in {"open", "acked"}
        if is_open and due_at is not None and due_at < now:
            bucket["open_overdue_count"] = int(bucket["open_overdue_count"]) + 1

        violated = False
        if due_at is not None:
            if completed_at is not None:
                violated = completed_at > due_at
            elif is_open:
                violated = now > due_at
        if violated:
            bucket["sla_violation_count"] = int(bucket["sla_violation_count"]) + 1

    for row in insp_rows:
        site_name = _normalize_site_name(str(row.get("site") or ""))
        if site_name is None:
            continue
        bucket = _site_bucket(site_name)
        bucket["inspections_created"] = int(bucket["inspections_created"]) + 1
        risk = str(row.get("risk_level") or "").strip().lower()
        if risk in {"high", "critical"}:
            bucket["inspections_high_risk"] = int(bucket["inspections_high_risk"]) + 1

    for row in export_rows:
        action = str(row.get("action") or "").strip().lower()
        detail = _parse_job_detail_json(row.get("detail_json"))
        detail_site_raw = detail.get("site")
        detail_site = _normalize_site_name(str(detail_site_raw)) if detail_site_raw is not None else None

        if site is not None:
            if detail_site not in {None, "ALL", site}:
                continue
            target_site = site
        elif allowed_sites is not None:
            if detail_site is None or detail_site == "ALL" or detail_site not in allowed_sites:
                continue
            target_site = detail_site
        else:
            if detail_site in {None, "ALL"}:
                continue
            target_site = detail_site

        if target_site is None:
            continue
        bucket = _site_bucket(target_site)
        bucket["report_export_count"] = int(bucket["report_export_count"]) + 1
        if action == "report_monthly_export_csv":
            bucket["report_export_csv_count"] = int(bucket["report_export_csv_count"]) + 1
        if action == "report_monthly_export_pdf":
            bucket["report_export_pdf_count"] = int(bucket["report_export_pdf_count"]) + 1
        created_at = _as_optional_datetime(row.get("created_at"))
        current_last = _as_optional_datetime(bucket.get("report_export_last_at"))
        if created_at is not None and (current_last is None or created_at > current_last):
            bucket["report_export_last_at"] = created_at

    benchmark_rows: list[dict[str, Any]] = []
    for site_name in sorted(site_stats.keys()):
        bucket = site_stats[site_name]
        created_count = int(bucket["work_orders_created"])
        missing_due = int(bucket["work_orders_missing_due_at"])
        invalid_priority = int(bucket["invalid_priority_count"])
        completed_missing = int(bucket["completed_without_completed_at_count"])
        overdue_open = int(bucket["open_overdue_count"])
        violations = int(bucket["sla_violation_count"])
        data_quality_issue_count = missing_due + invalid_priority + completed_missing
        bucket["data_quality_issue_count"] = data_quality_issue_count

        missing_due_rate = _safe_rate(missing_due, created_count)
        overdue_rate = _safe_rate(overdue_open, created_count)
        violation_rate = _safe_rate(violations, created_count)
        data_quality_issue_rate = _safe_rate(data_quality_issue_count, created_count)

        expected_exports = max(1, int(math.ceil(float(window_days) / 30.0)) * 2)
        export_coverage = _safe_rate(int(bucket["report_export_count"]), expected_exports)
        risk_score = round((data_quality_issue_rate * 0.4) + (overdue_rate * 0.3) + (violation_rate * 0.3), 2)
        discipline_score = round(
            max(0.0, min(100.0, 100.0 - risk_score + min(15.0, export_coverage * 0.15))),
            2,
        )

        benchmark_rows.append(
            {
                "site": site_name,
                "work_orders_created": created_count,
                "work_orders_completed": int(bucket["work_orders_completed"]),
                "missing_due_rate_percent": missing_due_rate,
                "overdue_rate_percent": overdue_rate,
                "sla_violation_rate_percent": violation_rate,
                "data_quality_issue_rate_percent": data_quality_issue_rate,
                "report_export_count": int(bucket["report_export_count"]),
                "report_export_coverage_percent": export_coverage,
                "inspections_high_risk": int(bucket["inspections_high_risk"]),
                "risk_score": risk_score,
                "discipline_score": discipline_score,
                "report_export_last_at": (
                    _as_optional_datetime(bucket.get("report_export_last_at")).isoformat()
                    if _as_optional_datetime(bucket.get("report_export_last_at")) is not None
                    else None
                ),
            }
        )

    total_created = sum(int(row.get("work_orders_created") or 0) for row in benchmark_rows)
    total_completed = sum(int(row.get("work_orders_completed") or 0) for row in benchmark_rows)
    total_missing_due = sum(int(site_stats[row["site"]]["work_orders_missing_due_at"]) for row in benchmark_rows)
    total_invalid_priority = sum(int(site_stats[row["site"]]["invalid_priority_count"]) for row in benchmark_rows)
    total_completed_missing = sum(int(site_stats[row["site"]]["completed_without_completed_at_count"]) for row in benchmark_rows)
    total_overdue_open = sum(int(site_stats[row["site"]]["open_overdue_count"]) for row in benchmark_rows)
    total_violations = sum(int(site_stats[row["site"]]["sla_violation_count"]) for row in benchmark_rows)
    total_issue_count = sum(int(site_stats[row["site"]]["data_quality_issue_count"]) for row in benchmark_rows)
    total_inspections = sum(int(site_stats[row["site"]]["inspections_created"]) for row in benchmark_rows)
    total_high_risk = sum(int(site_stats[row["site"]]["inspections_high_risk"]) for row in benchmark_rows)
    total_exports = sum(int(site_stats[row["site"]]["report_export_count"]) for row in benchmark_rows)
    total_exports_csv = sum(int(site_stats[row["site"]]["report_export_csv_count"]) for row in benchmark_rows)
    total_exports_pdf = sum(int(site_stats[row["site"]]["report_export_pdf_count"]) for row in benchmark_rows)

    expected_total_exports = max(1, int(math.ceil(float(window_days) / 30.0)) * 2 * max(1, len(benchmark_rows)))
    export_coverage_percent = _safe_rate(total_exports, expected_total_exports)
    missing_due_rate_percent = _safe_rate(total_missing_due, total_created)
    overdue_rate_percent = _safe_rate(total_overdue_open, total_created)
    violation_rate_percent = _safe_rate(total_violations, total_created)
    issue_rate_percent = _safe_rate(total_issue_count, total_created)
    global_risk_score = round((issue_rate_percent * 0.4) + (overdue_rate_percent * 0.3) + (violation_rate_percent * 0.3), 2)
    discipline_score = round(
        max(0.0, min(100.0, 100.0 - global_risk_score + min(15.0, export_coverage_percent * 0.15))),
        2,
    )

    top_risk_sites = sorted(
        benchmark_rows,
        key=lambda row: (
            float(row.get("risk_score") or 0.0),
            float(row.get("overdue_rate_percent") or 0.0),
            int(row.get("work_orders_created") or 0),
        ),
        reverse=True,
    )[:5]
    site_benchmark = sorted(
        benchmark_rows,
        key=lambda row: (
            float(row.get("discipline_score") or 0.0),
            float(row.get("report_export_coverage_percent") or 0.0),
            -float(row.get("risk_score") or 0.0),
        ),
        reverse=True,
    )

    report_export_last_at: str | None = None
    for row in benchmark_rows:
        candidate = _as_optional_datetime(row.get("report_export_last_at"))
        if candidate is None:
            continue
        current = _as_optional_datetime(report_export_last_at)
        if current is None or candidate > current:
            report_export_last_at = candidate.isoformat()

    recommendations: list[str] = []
    if missing_due_rate_percent > 2.0:
        recommendations.append("due_at   .     .")
    if issue_rate_percent > 5.0:
        recommendations.append("    .  triage .")
    if overdue_rate_percent > 10.0:
        recommendations.append("overdue open  .   ETA  .")
    if violation_rate_percent > 10.0:
        recommendations.append("SLA  .     .")
    if export_coverage_percent < 95.0:
        recommendations.append("  export  . CSV/PDF    .")
    if total_high_risk > 0 and total_inspections > 0:
        recommendations.append("   . W07    .")
    if not recommendations:
        recommendations.append("W08    .    .")

    return {
        "generated_at": now.isoformat(),
        "site": site,
        "window_days": window_days,
        "target_discipline_score": 85.0,
        "thresholds": {
            "missing_due_rate_percent": 2.0,
            "data_quality_issue_rate_percent": 5.0,
            "report_export_coverage_percent": 95.0,
        },
        "metrics": {
            "site_count": len(benchmark_rows),
            "work_orders_created": total_created,
            "work_orders_completed": total_completed,
            "work_orders_missing_due_at": total_missing_due,
            "missing_due_rate_percent": missing_due_rate_percent,
            "invalid_priority_count": total_invalid_priority,
            "completed_without_completed_at_count": total_completed_missing,
            "open_overdue_count": total_overdue_open,
            "overdue_rate_percent": overdue_rate_percent,
            "sla_violation_count": total_violations,
            "sla_violation_rate_percent": violation_rate_percent,
            "data_quality_issue_count": total_issue_count,
            "data_quality_issue_rate_percent": issue_rate_percent,
            "inspections_created": total_inspections,
            "inspections_high_risk": total_high_risk,
            "report_export_count": total_exports,
            "report_export_csv_count": total_exports_csv,
            "report_export_pdf_count": total_exports_pdf,
            "report_export_coverage_percent": export_coverage_percent,
            "report_export_last_at": report_export_last_at,
            "discipline_score": discipline_score,
            "target_met": discipline_score >= 85.0,
        },
        "top_risk_sites": top_risk_sites,
        "site_benchmark": site_benchmark,
        "recommendations": recommendations,
    }


def _build_w09_kpi_operation_snapshot(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    window_days = max(14, min(int(days), 120))
    policy, policy_updated_at, policy_key, policy_site = _ensure_w09_kpi_policy(site)

    effective_site = policy_site if policy_site is not None else _normalize_site_name(site)
    effective_allowed_sites = allowed_sites if effective_site is None else None

    w05 = _build_w05_usage_consistency_snapshot(
        site=effective_site,
        days=window_days,
        allowed_sites=effective_allowed_sites,
    )
    w06 = _build_w06_operational_rhythm_snapshot(
        site=effective_site,
        days=window_days,
        allowed_sites=effective_allowed_sites,
    )
    w07 = _build_w07_sla_quality_snapshot(
        site=effective_site,
        days=max(7, min(window_days, 90)),
        allowed_sites=effective_allowed_sites,
    )
    w08 = _build_w08_report_discipline_snapshot(
        site=effective_site,
        days=window_days,
        allowed_sites=effective_allowed_sites,
    )

    w05_metrics = w05.get("metrics", {}) if isinstance(w05.get("metrics"), dict) else {}
    w06_metrics = w06.get("metrics", {}) if isinstance(w06.get("metrics"), dict) else {}
    w07_metrics = w07.get("metrics", {}) if isinstance(w07.get("metrics"), dict) else {}
    w08_metrics = w08.get("metrics", {}) if isinstance(w08.get("metrics"), dict) else {}

    metric_values: dict[str, float | None] = {
        "two_week_retention_percent": (
            float(w05_metrics.get("two_week_retention_percent"))
            if w05_metrics.get("two_week_retention_percent") is not None
            else None
        ),
        "weekly_active_rate_percent": (
            float(w06_metrics.get("weekly_active_rate_percent"))
            if w06_metrics.get("weekly_active_rate_percent") is not None
            else None
        ),
        "escalation_rate_percent": (
            float(w07_metrics.get("escalation_rate_percent"))
            if w07_metrics.get("escalation_rate_percent") is not None
            else None
        ),
        "report_discipline_score": (
            float(w08_metrics.get("discipline_score"))
            if w08_metrics.get("discipline_score") is not None
            else None
        ),
        "data_quality_issue_rate_percent": (
            float(w08_metrics.get("data_quality_issue_rate_percent"))
            if w08_metrics.get("data_quality_issue_rate_percent") is not None
            else None
        ),
    }

    kpis = policy.get("kpis", []) if isinstance(policy.get("kpis"), list) else []
    rows: list[dict[str, Any]] = []
    status_counts = {W09_KPI_STATUS_GREEN: 0, W09_KPI_STATUS_YELLOW: 0, W09_KPI_STATUS_RED: 0}
    owner_assigned_count = 0

    escalation_map = policy.get("escalation_map", []) if isinstance(policy.get("escalation_map"), list) else []
    escalation_by_kpi: dict[str, list[dict[str, Any]]] = {}
    for item in escalation_map:
        if not isinstance(item, dict):
            continue
        kpi_key = str(item.get("kpi_key") or "")
        escalation_by_kpi.setdefault(kpi_key, []).append(item)

    for item in kpis:
        if not isinstance(item, dict):
            continue
        kpi_key = str(item.get("kpi_key") or "").strip()
        if not kpi_key:
            continue
        kpi_name = str(item.get("kpi_name") or kpi_key)
        direction = str(item.get("direction") or "higher_better").strip().lower()
        owner_role = str(item.get("owner_role") or "").strip()
        if owner_role:
            owner_assigned_count += 1
        try:
            green_threshold = float(item.get("green_threshold") or 0.0)
        except (TypeError, ValueError):
            green_threshold = 0.0
        try:
            yellow_threshold = float(item.get("yellow_threshold") or 0.0)
        except (TypeError, ValueError):
            yellow_threshold = 0.0

        actual_value = metric_values.get(kpi_key)
        status = _evaluate_w09_kpi_status(
            actual=actual_value,
            direction=direction,
            green_threshold=green_threshold,
            yellow_threshold=yellow_threshold,
        )
        status_counts[status] = int(status_counts.get(status, 0)) + 1
        rows.append(
            {
                "kpi_key": kpi_key,
                "kpi_name": kpi_name,
                "owner_role": owner_role,
                "direction": direction,
                "target": str(item.get("target") or ""),
                "actual_value": actual_value,
                "green_threshold": round(green_threshold, 2),
                "yellow_threshold": round(yellow_threshold, 2),
                "status": status,
                "source_api": str(item.get("source_api") or ""),
                "escalation_rules": escalation_by_kpi.get(kpi_key, []),
            }
        )

    total_kpis = len(rows)
    owner_coverage_percent = round((owner_assigned_count / total_kpis) * 100.0, 2) if total_kpis > 0 else 0.0
    red_count = int(status_counts.get(W09_KPI_STATUS_RED, 0))
    yellow_count = int(status_counts.get(W09_KPI_STATUS_YELLOW, 0))
    green_count = int(status_counts.get(W09_KPI_STATUS_GREEN, 0))

    overall_status = W09_KPI_STATUS_GREEN
    if red_count > 0:
        overall_status = W09_KPI_STATUS_RED
    elif yellow_count > 0:
        overall_status = W09_KPI_STATUS_YELLOW
    if owner_coverage_percent < 100.0 and overall_status == W09_KPI_STATUS_GREEN:
        overall_status = W09_KPI_STATUS_YELLOW

    escalation_candidates: list[dict[str, Any]] = []
    for row in rows:
        if str(row.get("status")) != W09_KPI_STATUS_RED:
            continue
        for rule in row.get("escalation_rules", []):
            if not isinstance(rule, dict):
                continue
            escalation_candidates.append(
                {
                    "kpi_key": row.get("kpi_key"),
                    "kpi_name": row.get("kpi_name"),
                    "actual_value": row.get("actual_value"),
                    "condition": str(rule.get("condition") or ""),
                    "escalate_to": str(rule.get("escalate_to") or ""),
                    "sla_hours": int(rule.get("sla_hours") or 24),
                    "action": str(rule.get("action") or ""),
                }
            )

    top_red_kpis = [
        {
            "kpi_key": row.get("kpi_key"),
            "kpi_name": row.get("kpi_name"),
            "actual_value": row.get("actual_value"),
            "target": row.get("target"),
            "owner_role": row.get("owner_role"),
        }
        for row in rows
        if str(row.get("status")) == W09_KPI_STATUS_RED
    ][:3]

    recommendations: list[str] = []
    if owner_coverage_percent < 100.0:
        recommendations.append("KPI owner   . Owner assignment 100% .")
    if red_count > 0:
        recommendations.append("Red KPI .     / .")
    if red_count == 0 and yellow_count > 0:
        recommendations.append("Yellow KPI  .   KPI  .")
    if red_count == 0 and yellow_count == 0 and owner_coverage_percent >= 100.0:
        recommendations.append("W09 KPI   .   .")

    return {
        "generated_at": now.isoformat(),
        "site": effective_site,
        "window_days": window_days,
        "policy": {
            "policy_key": policy_key,
            "updated_at": policy_updated_at.isoformat(),
            "enabled": bool(policy.get("enabled", True)),
            "kpi_count": total_kpis,
            "escalation_rule_count": len(escalation_map),
        },
        "metrics": {
            "kpi_count": total_kpis,
            "owner_assigned_count": owner_assigned_count,
            "owner_coverage_percent": owner_coverage_percent,
            "green_count": green_count,
            "yellow_count": yellow_count,
            "red_count": red_count,
            "overall_status": overall_status,
        },
        "kpis": rows,
        "top_red_kpis": top_red_kpis,
        "escalation_candidates": escalation_candidates[:10],
        "source_metrics": {
            "w05_two_week_retention_percent": metric_values.get("two_week_retention_percent"),
            "w06_weekly_active_rate_percent": metric_values.get("weekly_active_rate_percent"),
            "w07_escalation_rate_percent": metric_values.get("escalation_rate_percent"),
            "w08_report_discipline_score": metric_values.get("report_discipline_score"),
            "w08_data_quality_issue_rate_percent": metric_values.get("data_quality_issue_rate_percent"),
        },
        "recommendations": recommendations,
    }


def _parse_job_detail_json(raw: Any) -> dict[str, Any]:
    try:
        loaded = json.loads(str(raw or "{}"))
    except json.JSONDecodeError:
        loaded = {}
    if isinstance(loaded, dict):
        return loaded
    return {}


def _build_w07_degradation_signals(snapshot: dict[str, Any]) -> dict[str, Any]:
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    escalation_rate = float(metrics.get("escalation_rate_percent") or 0.0)
    alert_success_rate = float(metrics.get("alert_success_rate_percent") or 0.0)
    violation_rate = float(metrics.get("sla_violation_rate_percent") or 0.0)
    data_quality_gate_pass = bool(metrics.get("data_quality_gate_pass", True))
    response_improvement = metrics.get("response_time_improvement_percent")

    escalation_threshold = max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD)
    success_threshold = max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD))
    violation_threshold = max(10.0, escalation_threshold)

    reasons: list[str] = []
    if escalation_rate >= escalation_threshold:
        reasons.append(f"escalation_rate={escalation_rate}% >= {round(escalation_threshold, 2)}%")
    if alert_success_rate < success_threshold:
        reasons.append(f"alert_success_rate={alert_success_rate}% < {round(success_threshold, 2)}%")
    if violation_rate >= violation_threshold:
        reasons.append(f"sla_violation_rate={violation_rate}% >= {round(violation_threshold, 2)}%")
    if not data_quality_gate_pass:
        reasons.append("data_quality_gate=FAIL")
    if isinstance(response_improvement, (int, float)) and float(response_improvement) < 0:
        reasons.append(f"ack_improvement={round(float(response_improvement), 2)}% < 0%")

    return {
        "degraded": len(reasons) > 0,
        "reasons": reasons,
        "signals": {
            "escalation_rate_percent": round(escalation_rate, 2),
            "alert_success_rate_percent": round(alert_success_rate, 2),
            "sla_violation_rate_percent": round(violation_rate, 2),
            "data_quality_gate_pass": data_quality_gate_pass,
            "response_time_improvement_percent": response_improvement,
        },
        "thresholds": {
            "escalation_rate_percent": round(escalation_threshold, 2),
            "alert_success_rate_percent": round(success_threshold, 2),
            "sla_violation_rate_percent": round(violation_threshold, 2),
        },
    }


def _w07_alert_cooldown_state(*, now: datetime, site: str | None, max_rows: int = 200) -> tuple[bool, int, str | None]:
    cooldown_minutes = max(0, W07_QUALITY_ALERT_COOLDOWN_MINUTES)
    if cooldown_minutes <= 0:
        return False, 0, None

    with get_conn() as conn:
        rows = conn.execute(
            select(
                alert_deliveries.c.payload_json,
                alert_deliveries.c.last_attempt_at,
                alert_deliveries.c.created_at,
            )
            .where(alert_deliveries.c.event_type == W07_DEGRADATION_ALERT_EVENT_TYPE)
            .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
            .limit(max(1, min(max_rows, 500)))
        ).mappings().all()

    target_site = _normalize_site_name(site)
    for row in rows:
        payload = _parse_job_detail_json(row.get("payload_json"))
        payload_site = _normalize_site_name(str(payload.get("site") or "")) if payload.get("site") is not None else None
        if target_site is None:
            if payload_site not in {None, "ALL"}:
                continue
        elif payload_site != target_site:
            continue

        attempted_at = _as_optional_datetime(row.get("last_attempt_at")) or _as_optional_datetime(row.get("created_at"))
        if attempted_at is None:
            continue
        next_allowed_at = attempted_at + timedelta(minutes=cooldown_minutes)
        if now < next_allowed_at:
            remaining = max(1, int(math.ceil((next_allowed_at - now).total_seconds() / 60.0)))
            return True, remaining, attempted_at.isoformat()
        return False, 0, attempted_at.isoformat()
    return False, 0, None


def run_w07_sla_quality_weekly_job(
    *,
    site: str | None = None,
    days: int = 14,
    trigger: str = "api",
    force_notify: bool = False,
    allowed_sites: list[str] | None = None,
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    run_site = _normalize_site_name(site)
    window_days = max(max(7, W07_QUALITY_ALERT_MIN_WINDOW_DAYS), min(int(days), 90))
    snapshot = _build_w07_sla_quality_snapshot(
        site=run_site,
        days=window_days,
        allowed_sites=allowed_sites if run_site is None else None,
    )
    degradation = _build_w07_degradation_signals(snapshot)
    now = datetime.now(timezone.utc)

    alert_attempted = False
    alert_dispatched = False
    alert_error: str | None = None
    alert_channels: list[SlaAlertChannelResult] = []
    cooldown_active = False
    cooldown_remaining_minutes = 0
    last_alert_at: str | None = None

    if bool(degradation.get("degraded")) and W07_QUALITY_ALERT_ENABLED:
        cooldown_active, cooldown_remaining_minutes, last_alert_at = _w07_alert_cooldown_state(
            now=now,
            site=run_site,
        )
        if force_notify or not cooldown_active:
            alert_attempted = True
            payload = {
                "event": W07_DEGRADATION_ALERT_EVENT_TYPE,
                "site": run_site or "ALL",
                "checked_at": now.isoformat(),
                "window_days": int(snapshot.get("window_days") or window_days),
                "signals": degradation.get("signals", {}),
                "thresholds": degradation.get("thresholds", {}),
                "reasons": degradation.get("reasons", []),
                "metrics": snapshot.get("metrics", {}),
            }
            alert_dispatched, alert_error, alert_channels = _dispatch_alert_event(
                event_type=W07_DEGRADATION_ALERT_EVENT_TYPE,
                payload=payload,
            )

    status = "success"
    if bool(degradation.get("degraded")):
        status = "warning"
        if alert_attempted and not alert_dispatched:
            status = "critical"

    finished_at = datetime.now(timezone.utc)
    detail = {
        "site": run_site,
        "window_days": window_days,
        "degradation": degradation,
        "alert_enabled": W07_QUALITY_ALERT_ENABLED,
        "force_notify": force_notify,
        "cooldown_active": cooldown_active,
        "cooldown_remaining_minutes": cooldown_remaining_minutes,
        "last_alert_at": last_alert_at,
        "alert_attempted": alert_attempted,
        "alert_dispatched": alert_dispatched,
        "alert_error": alert_error,
        "alert_channels": [item.model_dump(mode="json") for item in alert_channels],
        "snapshot": snapshot,
    }
    run_id = _write_job_run(
        job_name=W07_WEEKLY_JOB_NAME,
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )
    return {
        "run_id": run_id,
        "job_name": W07_WEEKLY_JOB_NAME,
        "trigger": trigger,
        "status": status,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        "site": run_site,
        "window_days": window_days,
        "degradation": degradation,
        "cooldown_active": cooldown_active,
        "cooldown_remaining_minutes": cooldown_remaining_minutes,
        "last_alert_at": last_alert_at,
        "alert_enabled": W07_QUALITY_ALERT_ENABLED,
        "alert_attempted": alert_attempted,
        "alert_dispatched": alert_dispatched,
        "alert_error": alert_error,
        "alert_channels": [item.model_dump(mode="json") for item in alert_channels],
        "snapshot": snapshot,
    }


def _is_w07_run_visible(
    *,
    detail_site: str | None,
    requested_site: str | None,
    allowed_sites: list[str] | None,
) -> bool:
    if requested_site is not None:
        return detail_site == requested_site
    if allowed_sites is None:
        return True
    if not allowed_sites:
        return False
    if detail_site is None:
        return False
    return detail_site in allowed_sites


def _read_w07_weekly_job_runs(
    *,
    site: str | None,
    allowed_sites: list[str] | None,
    limit: int,
) -> list[tuple[JobRunRead, dict[str, Any]]]:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == W07_WEEKLY_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(max(1, min(limit * 10, 1000)))
        ).mappings().all()

    collected: list[tuple[JobRunRead, dict[str, Any]]] = []
    for row in rows:
        model = _row_to_job_run_model(row)
        detail = model.detail if isinstance(model.detail, dict) else {}
        detail_site = _normalize_site_name(detail.get("site"))
        if not _is_w07_run_visible(detail_site=detail_site, requested_site=site, allowed_sites=allowed_sites):
            continue
        collected.append((model, detail))
        if len(collected) >= limit:
            break
    return collected


def _build_w07_weekly_trends_payload(
    *,
    site: str | None,
    allowed_sites: list[str] | None,
    limit: int = 26,
) -> dict[str, Any]:
    runs = _read_w07_weekly_job_runs(site=site, allowed_sites=allowed_sites, limit=max(1, min(limit, 104)))
    points: list[dict[str, Any]] = []
    for model, detail in reversed(runs):
        snapshot = detail.get("snapshot", {}) if isinstance(detail.get("snapshot"), dict) else {}
        metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
        degradation = detail.get("degradation", {}) if isinstance(detail.get("degradation"), dict) else {}
        signals = degradation.get("signals", {}) if isinstance(degradation.get("signals"), dict) else {}
        points.append(
            {
                "run_id": model.id,
                "finished_at": model.finished_at.isoformat(),
                "site": detail.get("site"),
                "status": model.status,
                "window_days": detail.get("window_days"),
                "degraded": bool(degradation.get("degraded", False)),
                "escalation_rate_percent": signals.get("escalation_rate_percent", metrics.get("escalation_rate_percent")),
                "alert_success_rate_percent": signals.get("alert_success_rate_percent", metrics.get("alert_success_rate_percent")),
                "sla_violation_rate_percent": signals.get("sla_violation_rate_percent", metrics.get("sla_violation_rate_percent")),
                "median_ack_minutes": metrics.get("median_ack_minutes"),
                "p90_ack_minutes": metrics.get("p90_ack_minutes"),
                "median_mttr_minutes": metrics.get("median_mttr_minutes"),
                "data_quality_gate_pass": bool(signals.get("data_quality_gate_pass", metrics.get("data_quality_gate_pass", True))),
            }
        )
    return {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "job_name": W07_WEEKLY_JOB_NAME,
        "site": site,
        "point_count": len(points),
        "points": points,
    }


def _build_w07_weekly_archive_csv(points: list[dict[str, Any]]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "run_id",
            "finished_at",
            "site",
            "status",
            "window_days",
            "degraded",
            "escalation_rate_percent",
            "alert_success_rate_percent",
            "sla_violation_rate_percent",
            "median_ack_minutes",
            "p90_ack_minutes",
            "median_mttr_minutes",
            "data_quality_gate_pass",
        ]
    )
    for row in points:
        writer.writerow(
            [
                row.get("run_id"),
                row.get("finished_at"),
                row.get("site"),
                row.get("status"),
                row.get("window_days"),
                bool(row.get("degraded", False)),
                row.get("escalation_rate_percent"),
                row.get("alert_success_rate_percent"),
                row.get("sla_violation_rate_percent"),
                row.get("median_ack_minutes"),
                row.get("p90_ack_minutes"),
                row.get("median_mttr_minutes"),
                bool(row.get("data_quality_gate_pass", True)),
            ]
        )
    return buffer.getvalue()


def _build_w07_tracker_items_csv(rows: list[W07TrackerItemRead]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "id",
            "site",
            "item_type",
            "item_key",
            "item_name",
            "assignee",
            "status",
            "completion_checked",
            "completion_note",
            "due_at",
            "completed_at",
            "evidence_count",
            "updated_at",
        ]
    )
    for row in rows:
        writer.writerow(
            [
                row.id,
                row.site,
                row.item_type,
                row.item_key,
                row.item_name,
                row.assignee or "",
                row.status,
                bool(row.completion_checked),
                row.completion_note or "",
                row.due_at.isoformat() if row.due_at is not None else "",
                row.completed_at.isoformat() if row.completed_at is not None else "",
                int(row.evidence_count),
                row.updated_at.isoformat(),
            ]
        )
    return buffer.getvalue()


def _build_w07_evidence_index_csv(rows: list[dict[str, Any]]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "evidence_id",
            "tracker_item_id",
            "item_key",
            "item_type",
            "file_name",
            "content_type",
            "file_size",
            "sha256",
            "uploaded_by",
            "uploaded_at",
            "archive_path",
            "blob_included",
            "include_reason",
        ]
    )
    for row in rows:
        writer.writerow(
            [
                row.get("evidence_id"),
                row.get("tracker_item_id"),
                row.get("item_key"),
                row.get("item_type"),
                row.get("file_name"),
                row.get("content_type"),
                row.get("file_size"),
                row.get("sha256"),
                row.get("uploaded_by"),
                row.get("uploaded_at"),
                row.get("archive_path"),
                bool(row.get("blob_included", False)),
                row.get("include_reason"),
            ]
        )
    return buffer.getvalue()


def _build_w07_completion_package_zip(
    *,
    site: str,
    completion: W07TrackerCompletionRead,
    rows: list[W07TrackerItemRead],
    include_evidence: bool,
    include_weekly: bool,
    weekly_limit: int,
    principal: dict[str, Any] | None,
) -> tuple[bytes, dict[str, Any]]:
    generated_at = datetime.now(timezone.utc)
    actor = str((principal or {}).get("username") or "system")
    tracker_csv = _build_w07_tracker_items_csv(rows)
    tracker_json = [row.model_dump(mode="json") for row in rows]

    item_by_id: dict[int, W07TrackerItemRead] = {int(row.id): row for row in rows}
    evidence_index_rows: list[dict[str, Any]] = []
    evidence_file_count = 0
    evidence_bytes_included = 0
    evidence_missing_blob_count = 0
    evidence_truncated = False
    weekly_payload: dict[str, Any] | None = None
    weekly_latest_payload: dict[str, Any] | None = None
    weekly_csv: str | None = None

    if include_weekly:
        weekly_payload = _build_w07_weekly_trends_payload(
            site=site,
            allowed_sites=None,
            limit=max(1, min(int(weekly_limit), 104)),
        )
        weekly_csv = _build_w07_weekly_archive_csv(weekly_payload.get("points", []))
        latest_runs = _read_w07_weekly_job_runs(site=site, allowed_sites=None, limit=1)
        if latest_runs:
            latest_model, latest_detail = latest_runs[0]
            weekly_latest_payload = {
                "run_id": latest_model.id,
                "job_name": latest_model.job_name,
                "status": latest_model.status,
                "trigger": latest_model.trigger,
                "started_at": latest_model.started_at.isoformat(),
                "finished_at": latest_model.finished_at.isoformat(),
                "detail": latest_detail,
            }
        else:
            weekly_latest_payload = {
                "run_id": None,
                "job_name": W07_WEEKLY_JOB_NAME,
                "status": "not_found",
                "detail": {},
            }

    with get_conn() as conn:
        evidence_rows = conn.execute(
            select(adoption_w07_evidence_files)
            .where(adoption_w07_evidence_files.c.site == site)
            .order_by(adoption_w07_evidence_files.c.uploaded_at.asc(), adoption_w07_evidence_files.c.id.asc())
        ).mappings().all()

    package_buffer = io.BytesIO()
    with zipfile.ZipFile(package_buffer, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(
            "README.txt",
            "\n".join(
                [
                    "KA Facility OS - W07 Completion Package",
                    f"site={site}",
                    f"generated_at={generated_at.isoformat()}",
                    f"generated_by={actor}",
                    "",
                    "Contents:",
                    "- manifest.json",
                    "- completion/completion.json",
                    "- completion/readiness.json",
                    "- tracker/items.json",
                    "- tracker/items.csv",
                    "- evidence/index.csv (optional)",
                    "- evidence/files/* (optional)",
                    "- weekly/latest.json (optional)",
                    "- weekly/trends.json (optional)",
                    "- weekly/trends.csv (optional)",
                ]
            ),
        )
        zf.writestr(
            "completion/completion.json",
            json.dumps(completion.model_dump(mode="json"), ensure_ascii=False, indent=2, default=str),
        )
        zf.writestr(
            "completion/readiness.json",
            json.dumps(completion.readiness.model_dump(mode="json"), ensure_ascii=False, indent=2, default=str),
        )
        zf.writestr("tracker/items.csv", tracker_csv)
        zf.writestr("tracker/items.json", json.dumps(tracker_json, ensure_ascii=False, indent=2, default=str))
        blockers = completion.readiness.blockers if isinstance(completion.readiness.blockers, list) else []
        zf.writestr("completion/blockers.txt", "\n".join([str(x) for x in blockers]) + ("\n" if blockers else ""))

        if include_weekly and weekly_payload is not None and weekly_csv is not None:
            zf.writestr("weekly/trends.csv", weekly_csv)
            zf.writestr(
                "weekly/trends.json",
                json.dumps(weekly_payload, ensure_ascii=False, indent=2, default=str),
            )
            if weekly_latest_payload is not None:
                zf.writestr(
                    "weekly/latest.json",
                    json.dumps(weekly_latest_payload, ensure_ascii=False, indent=2, default=str),
                )

        if include_evidence:
            for evidence in evidence_rows:
                evidence_id = int(evidence.get("id") or 0)
                tracker_item_id = int(evidence.get("tracker_item_id") or 0)
                model = item_by_id.get(tracker_item_id)
                safe_item_key = _safe_download_filename(
                    str(model.item_key) if model is not None else f"item-{tracker_item_id}",
                    fallback=f"item-{tracker_item_id}",
                    max_length=80,
                )
                safe_file_name = _safe_download_filename(
                    str(evidence.get("file_name") or ""),
                    fallback=f"evidence-{evidence_id}.bin",
                    max_length=120,
                )
                archive_path = f"evidence/files/{safe_item_key}/{evidence_id}-{safe_file_name}"
                blob = _read_evidence_blob(row=evidence)
                blob_included = False
                include_reason = "missing_blob"
                blob_size = len(blob) if blob is not None else 0
                if blob is None:
                    evidence_missing_blob_count += 1
                elif evidence_file_count >= W07_COMPLETION_PACKAGE_MAX_EVIDENCE_FILES:
                    include_reason = "skipped_max_files"
                    evidence_truncated = True
                elif (evidence_bytes_included + blob_size) > W07_COMPLETION_PACKAGE_MAX_EVIDENCE_BYTES:
                    include_reason = "skipped_max_bytes"
                    evidence_truncated = True
                else:
                    zf.writestr(archive_path, blob)
                    evidence_file_count += 1
                    evidence_bytes_included += blob_size
                    blob_included = True
                    include_reason = "included"

                evidence_index_rows.append(
                    {
                        "evidence_id": evidence_id,
                        "tracker_item_id": tracker_item_id,
                        "item_key": model.item_key if model is not None else "",
                        "item_type": model.item_type if model is not None else "",
                        "file_name": str(evidence.get("file_name") or ""),
                        "content_type": str(evidence.get("content_type") or ""),
                        "file_size": int(evidence.get("file_size") or 0),
                        "sha256": str(evidence.get("sha256") or ""),
                        "uploaded_by": str(evidence.get("uploaded_by") or ""),
                        "uploaded_at": (
                            _as_optional_datetime(evidence.get("uploaded_at")).isoformat()
                            if _as_optional_datetime(evidence.get("uploaded_at")) is not None
                            else ""
                        ),
                        "archive_path": archive_path,
                        "blob_included": blob_included,
                        "include_reason": include_reason,
                    }
                )
            zf.writestr("evidence/index.csv", _build_w07_evidence_index_csv(evidence_index_rows))
            zf.writestr(
                "evidence/index.json",
                json.dumps(evidence_index_rows, ensure_ascii=False, indent=2, default=str),
            )

        manifest = {
            "title": "W07 Completion Package",
            "generated_at": generated_at.isoformat(),
            "generated_by": actor,
            "site": site,
            "completion_status": completion.status,
            "readiness_ready": bool(completion.readiness.ready),
            "completion_rate_percent": int(completion.readiness.completion_rate_percent),
            "summary": {
                "tracker_items": len(rows),
                "blockers": len(blockers),
                "include_evidence": bool(include_evidence),
                "include_weekly": bool(include_weekly),
                "evidence_rows": len(evidence_index_rows),
                "evidence_files_included": evidence_file_count,
                "evidence_bytes_included": evidence_bytes_included,
                "evidence_missing_blob": evidence_missing_blob_count,
                "evidence_truncated": evidence_truncated,
                "evidence_limit_files": W07_COMPLETION_PACKAGE_MAX_EVIDENCE_FILES,
                "evidence_limit_bytes": W07_COMPLETION_PACKAGE_MAX_EVIDENCE_BYTES,
                "weekly_points": int((weekly_payload or {}).get("point_count") or 0),
            },
            "files": {
                "tracker_csv": "tracker/items.csv",
                "completion_json": "completion/completion.json",
                "readiness_json": "completion/readiness.json",
                "blockers_txt": "completion/blockers.txt",
                "evidence_index_csv": "evidence/index.csv" if include_evidence else None,
                "weekly_trends_csv": "weekly/trends.csv" if include_weekly else None,
            },
        }
        zf.writestr(
            "manifest.json",
            json.dumps(manifest, ensure_ascii=False, indent=2, default=str),
        )

    package_bytes = package_buffer.getvalue()
    package_sha256 = hashlib.sha256(package_bytes).hexdigest()
    manifest_with_hash = {
        **manifest,
        "sha256": package_sha256,
        "bytes": len(package_bytes),
    }
    return package_bytes, manifest_with_hash


def _build_w07_automation_readiness_snapshot(
    *,
    site: str | None,
    allowed_sites: list[str] | None,
    now: datetime | None = None,
) -> dict[str, Any]:
    generated_at = now or datetime.now(timezone.utc)
    runs = _read_w07_weekly_job_runs(site=site, allowed_sites=allowed_sites, limit=1)
    latest_run_model: JobRunRead | None = None
    latest_run_detail: dict[str, Any] = {}
    if runs:
        latest_run_model, latest_run_detail = runs[0]

    latest_run_at = latest_run_model.finished_at if latest_run_model is not None else None
    latest_run_recent = (
        latest_run_at is not None
        and latest_run_at >= (generated_at - timedelta(days=8))
    )
    latest_degraded = bool((latest_run_detail.get("degradation") or {}).get("degraded", False))
    alert_targets = _configured_alert_targets()
    webhook_configured = len(alert_targets) > 0
    alert_enabled = W07_QUALITY_ALERT_ENABLED
    weekly_window_days = int(latest_run_detail.get("window_days") or max(7, W07_QUALITY_ALERT_MIN_WINDOW_DAYS))

    checks: list[dict[str, Any]] = [
        {
            "id": "w07_weekly_cron_recent",
            "status": "ok" if latest_run_recent else "warning",
            "message": (
                "W07 weekly job observed within 8 days."
                if latest_run_recent
                else "No W07 weekly job run observed within 8 days."
            ),
        },
        {
            "id": "w07_alert_channel_config",
            "status": (
                "ok"
                if webhook_configured or not alert_enabled
                else "warning"
            ),
            "message": (
                "Alert channel targets configured."
                if webhook_configured
                else (
                    "W07 quality alert is enabled but no ALERT_WEBHOOK_URL/ALERT_WEBHOOK_URLS configured."
                    if alert_enabled
                    else "W07 quality alert is disabled."
                )
            ),
            "webhook_target_count": len(alert_targets),
            "alert_enabled": alert_enabled,
        },
        {
            "id": "w07_latest_quality_state",
            "status": "warning" if latest_degraded else "ok",
            "message": (
                "Latest W07 weekly run indicates degradation."
                if latest_degraded
                else "Latest W07 weekly run is within threshold."
            ),
            "degraded": latest_degraded,
        },
        {
            "id": "w07_archive_write_mode",
            "status": "ok" if W07_WEEKLY_ARCHIVE_ENABLED else "warning",
            "message": (
                "Weekly archive file writing is enabled."
                if W07_WEEKLY_ARCHIVE_ENABLED
                else "Weekly archive file writing is disabled."
            ),
            "archive_enabled": W07_WEEKLY_ARCHIVE_ENABLED,
            "archive_path": W07_WEEKLY_ARCHIVE_PATH,
        },
    ]

    overall = "ok"
    if any(item.get("status") == "critical" for item in checks):
        overall = "critical"
    elif any(item.get("status") == "warning" for item in checks):
        overall = "warning"

    return {
        "generated_at": generated_at.isoformat(),
        "site": site,
        "overall_status": overall,
        "checks": checks,
        "runtime": {
            "latest_run_id": latest_run_model.id if latest_run_model is not None else None,
            "latest_run_status": latest_run_model.status if latest_run_model is not None else None,
            "latest_run_at": latest_run_at.isoformat() if latest_run_at is not None else None,
            "latest_run_recent": latest_run_recent,
            "latest_run_degraded": latest_degraded,
            "latest_run_window_days": weekly_window_days,
        },
        "policy": {
            "alert_enabled": alert_enabled,
            "cooldown_minutes": max(0, W07_QUALITY_ALERT_COOLDOWN_MINUTES),
            "min_window_days": max(7, W07_QUALITY_ALERT_MIN_WINDOW_DAYS),
            "escalation_rate_threshold_percent": round(max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD), 2),
            "alert_success_rate_threshold_percent": round(max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD)), 2),
            "archive_enabled": W07_WEEKLY_ARCHIVE_ENABLED,
            "archive_path": W07_WEEKLY_ARCHIVE_PATH,
        },
        "integration": {
            "webhook_target_count": len(alert_targets),
            "webhook_configured": webhook_configured,
            "webhook_targets": alert_targets,
            "recommended_cron_schedule_utc": "30 23 * * 5",
            "cron_job_name": W07_WEEKLY_JOB_NAME,
            "cron_command": "python -m app.jobs.adoption_w07_weekly --days 14",
        },
    }


def run_sla_escalation_job(
    *,
    site: str | None = None,
    dry_run: bool = False,
    limit: int = 200,
    allowed_sites: list[str] | None = None,
    trigger: str = "manual",
) -> SlaEscalationRunResponse:
    started_at = datetime.now(timezone.utc)
    now = started_at
    stmt = (
        select(work_orders)
        .where(work_orders.c.due_at.is_not(None))
        .where(work_orders.c.due_at < now)
        .where(work_orders.c.status.in_(["open", "acked"]))
        .where(work_orders.c.is_escalated.is_(False))
        .order_by(work_orders.c.due_at.asc())
        .limit(limit * 5)
    )
    if site is not None:
        stmt = stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            finished_at = datetime.now(timezone.utc)
            _write_job_run(
                job_name="sla_escalation",
                trigger=trigger,
                status="success",
                started_at=started_at,
                finished_at=finished_at,
                detail={
                    "site": site,
                    "dry_run": dry_run,
                    "limit": limit,
                    "allowed_sites": allowed_sites,
                    "candidate_count": 0,
                    "escalated_count": 0,
                    "grace_minutes_by_site": {},
                    "alert_dispatched": False,
                    "alert_error": None,
                    "alert_channels": [],
                },
            )
            return SlaEscalationRunResponse(
                checked_at=finished_at,
                dry_run=dry_run,
                site=site,
                candidate_count=0,
                escalated_count=0,
                work_order_ids=[],
                alert_dispatched=False,
                alert_error=None,
                alert_channels=[],
            )
        stmt = stmt.where(work_orders.c.site.in_(allowed_sites))

    grace_minutes_by_site: dict[str, int] = {}

    def _resolve_grace(site_name: str) -> int:
        key = site_name.strip()
        if key in grace_minutes_by_site:
            return grace_minutes_by_site[key]
        policy, _, _, _, _ = _load_sla_policy(site=key if key else None)
        grace_value = int(policy["escalation_grace_minutes"])
        grace_minutes_by_site[key] = grace_value
        return grace_value

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
        ids: list[int] = []
        for row in rows:
            due_at = _as_optional_datetime(row["due_at"])
            if due_at is None:
                continue
            row_site = str(row["site"] or "")
            row_grace = _resolve_grace(row_site)
            due_cutoff = now - timedelta(minutes=row_grace)
            if due_at < due_cutoff:
                ids.append(int(row["id"]))
            if len(ids) >= limit:
                break

        escalated_count = 0
        escalated_ids: list[int] = []
        if ids and not dry_run:
            for work_order_id in ids:
                update_result = conn.execute(
                    update(work_orders)
                    .where(work_orders.c.id == work_order_id)
                    .where(work_orders.c.status.in_(["open", "acked"]))
                    .where(work_orders.c.is_escalated.is_(False))
                    .values(is_escalated=True, updated_at=now)
                )
                if update_result.rowcount and update_result.rowcount > 0:
                    escalated_ids.append(work_order_id)
            escalated_count = len(escalated_ids)

    work_order_ids = ids if dry_run else escalated_ids

    alert_dispatched = False
    alert_error: str | None = None
    alert_channels: list[SlaAlertChannelResult] = []
    if not dry_run and escalated_count > 0:
        alert_dispatched, alert_error, alert_channels = _dispatch_sla_alert(
            site=site,
            checked_at=now,
            escalated_count=escalated_count,
            work_order_ids=work_order_ids,
        )
        _write_audit_log(
            principal=None,
            action="sla_escalation_batch",
            resource_type="work_order",
            resource_id="batch",
            status="success" if alert_error is None else "warning",
            detail={
                "site": site,
                "dry_run": dry_run,
                "allowed_sites": allowed_sites,
                "candidate_count": len(ids),
                "escalated_count": escalated_count,
                "grace_minutes_by_site": grace_minutes_by_site,
                "alert_dispatched": alert_dispatched,
                "alert_error": alert_error,
                "alert_channels": [channel.model_dump() for channel in alert_channels],
                "work_order_ids": work_order_ids,
            },
        )

    finished_at = datetime.now(timezone.utc)
    _write_job_run(
        job_name="sla_escalation",
        trigger=trigger,
        status="success" if alert_error is None else "warning",
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "site": site,
            "dry_run": dry_run,
            "limit": limit,
            "allowed_sites": allowed_sites,
            "candidate_count": len(ids),
            "escalated_count": escalated_count,
            "grace_minutes_by_site": grace_minutes_by_site,
            "alert_dispatched": alert_dispatched,
            "alert_error": alert_error,
            "alert_channels": [channel.model_dump() for channel in alert_channels],
        },
    )

    return SlaEscalationRunResponse(
        checked_at=finished_at,
        dry_run=dry_run,
        site=site,
        candidate_count=len(ids),
        escalated_count=escalated_count,
        work_order_ids=work_order_ids,
        alert_dispatched=alert_dispatched,
        alert_error=alert_error,
        alert_channels=alert_channels,
    )


def run_alert_retry_job(
    *,
    event_type: str | None = None,
    only_status: list[str] | None = None,
    limit: int = 200,
    max_attempt_count: int = 10,
    min_last_attempt_age_sec: int = 30,
    trigger: str = "manual",
) -> AlertRetryRunResponse:
    started_at = datetime.now(timezone.utc)
    now = started_at
    statuses = [s.strip().lower() for s in (only_status or ["failed", "warning"]) if s.strip()]
    if not statuses:
        statuses = ["failed", "warning"]
    statuses = sorted(set(statuses))
    normalized_limit = max(1, min(limit, 5000))
    normalized_max_attempt_count = max(1, min(max_attempt_count, 1000))
    cooldown_cutoff = now - timedelta(seconds=max(0, min(min_last_attempt_age_sec, 86400)))

    stmt = (
        select(alert_deliveries)
        .where(alert_deliveries.c.status.in_(statuses))
        .where(alert_deliveries.c.attempt_count < normalized_max_attempt_count)
        .where(alert_deliveries.c.last_attempt_at <= cooldown_cutoff)
        .order_by(alert_deliveries.c.last_attempt_at.asc(), alert_deliveries.c.id.asc())
        .limit(normalized_limit)
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    processed_count = 0
    success_count = 0
    warning_count = 0
    failed_count = 0
    delivery_ids: list[int] = []

    with get_conn() as conn:
        for row in rows:
            delivery_id = int(row["id"])
            current_status = str(row["status"] or "failed")
            current_attempt_count = int(row["attempt_count"])
            claim_result = conn.execute(
                update(alert_deliveries)
                .where(alert_deliveries.c.id == delivery_id)
                .where(alert_deliveries.c.status == current_status)
                .where(alert_deliveries.c.attempt_count == current_attempt_count)
                .values(
                    attempt_count=current_attempt_count + 1,
                    last_attempt_at=now,
                    updated_at=now,
                )
            )
            if not claim_result.rowcount or claim_result.rowcount <= 0:
                continue

            payload_raw = str(row["payload_json"] or "{}")
            try:
                payload = json.loads(payload_raw)
            except json.JSONDecodeError:
                payload = {}
            if not isinstance(payload, dict):
                payload = {}

            ok, err = _post_json_with_retries(
                url=str(row["target"]),
                payload=payload,
                retries=1,
                timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
            )
            next_status = "success" if ok and err is None else ("warning" if ok else "failed")
            conn.execute(
                update(alert_deliveries)
                .where(alert_deliveries.c.id == delivery_id)
                .where(alert_deliveries.c.attempt_count == (current_attempt_count + 1))
                .values(
                    status=next_status,
                    error=err,
                    updated_at=now,
                )
            )

            processed_count += 1
            delivery_ids.append(delivery_id)
            if next_status == "success":
                success_count += 1
            elif next_status == "warning":
                warning_count += 1
            else:
                failed_count += 1

    finished_at = datetime.now(timezone.utc)
    _write_job_run(
        job_name="alert_retry",
        trigger=trigger,
        status="warning" if failed_count > 0 else "success",
        started_at=started_at,
        finished_at=finished_at,
        detail={
            "event_type": event_type,
            "statuses": statuses,
            "limit": normalized_limit,
            "max_attempt_count": normalized_max_attempt_count,
            "min_last_attempt_age_sec": min_last_attempt_age_sec,
            "processed_count": processed_count,
            "success_count": success_count,
            "warning_count": warning_count,
            "failed_count": failed_count,
            "delivery_ids": delivery_ids,
        },
    )
    return AlertRetryRunResponse(
        checked_at=finished_at,
        event_type=event_type,
        limit=normalized_limit,
        processed_count=processed_count,
        success_count=success_count,
        warning_count=warning_count,
        failed_count=failed_count,
        delivery_ids=delivery_ids,
    )


def _normalized_ops_daily_check_rows(checks: list[dict[str, Any]]) -> list[dict[str, str]]:
    rows: list[dict[str, str]] = []
    for item in checks:
        if not isinstance(item, dict):
            continue
        rows.append(
            {
                "id": str(item.get("id") or ""),
                "status": str(item.get("status") or "unknown"),
                "message": str(item.get("message") or ""),
            }
        )
    return rows


def _build_ops_daily_check_summary(
    *,
    run_id: int | None,
    checked_at: datetime,
    trigger: str,
    status: str,
    overall_status: str,
    check_count: int,
    warning_count: int,
    critical_count: int,
    checks: list[dict[str, Any]],
    alert_level: str,
    alert_attempted: bool,
    alert_dispatched: bool,
    alert_error: str | None,
    mttr_slo_check: dict[str, Any],
) -> dict[str, Any]:
    return {
        "version": "v1",
        "job_name": "ops_daily_check",
        "run_id": run_id,
        "checked_at": checked_at.isoformat(),
        "trigger": trigger,
        "status": status,
        "overall_status": overall_status,
        "check_count": check_count,
        "warning_count": warning_count,
        "critical_count": critical_count,
        "alert": {
            "level": alert_level,
            "attempted": alert_attempted,
            "dispatched": alert_dispatched,
            "error": alert_error,
        },
        "mttr_slo_check": mttr_slo_check,
        "checks": _normalized_ops_daily_check_rows(checks),
    }


def _build_ops_daily_check_summary_csv(summary: dict[str, Any]) -> str:
    checks = summary.get("checks")
    if not isinstance(checks, list):
        checks = []

    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "run_id",
            "checked_at",
            "trigger",
            "status",
            "overall_status",
            "check_count",
            "warning_count",
            "critical_count",
            "alert_level",
            "alert_attempted",
            "alert_dispatched",
            "alert_error",
        ]
    )
    alert = summary.get("alert", {}) if isinstance(summary.get("alert"), dict) else {}
    writer.writerow(
        [
            summary.get("run_id"),
            summary.get("checked_at"),
            summary.get("trigger"),
            summary.get("status"),
            summary.get("overall_status"),
            summary.get("check_count"),
            summary.get("warning_count"),
            summary.get("critical_count"),
            alert.get("level"),
            bool(alert.get("attempted", False)),
            bool(alert.get("dispatched", False)),
            alert.get("error"),
        ]
    )
    writer.writerow([])
    writer.writerow(["check_id", "check_status", "check_message"])
    for item in checks:
        if not isinstance(item, dict):
            continue
        writer.writerow(
            [
                item.get("id"),
                item.get("status"),
                item.get("message"),
            ]
        )
    return buffer.getvalue()


def _prune_ops_daily_check_archive_files(*, archive_dir: Path, now: datetime) -> int:
    cutoff = now - timedelta(days=max(1, OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS))
    deleted_count = 0
    for pattern in ("ops-daily-check-*.json", "ops-daily-check-*.csv"):
        for file_path in archive_dir.glob(pattern):
            try:
                modified_at = datetime.fromtimestamp(file_path.stat().st_mtime, tz=timezone.utc)
            except OSError:
                continue
            if modified_at >= cutoff:
                continue
            try:
                file_path.unlink()
                deleted_count += 1
            except OSError:
                continue
    return deleted_count


def _publish_ops_daily_check_summary_artifacts(
    *,
    summary: dict[str, Any],
    finished_at: datetime,
) -> dict[str, Any]:
    archive = {
        "enabled": OPS_DAILY_CHECK_ARCHIVE_ENABLED,
        "path": OPS_DAILY_CHECK_ARCHIVE_PATH,
        "retention_days": max(1, OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS),
        "json_file": None,
        "csv_file": None,
        "pruned_files": 0,
        "error": None,
    }
    if not OPS_DAILY_CHECK_ARCHIVE_ENABLED:
        return archive
    try:
        archive_dir = Path(OPS_DAILY_CHECK_ARCHIVE_PATH)
        archive_dir.mkdir(parents=True, exist_ok=True)
        stamp = finished_at.strftime("%Y%m%dT%H%M%SZ")
        run_id = summary.get("run_id")
        run_label = f"run-{run_id}" if run_id is not None else "run-na"
        base_name = f"ops-daily-check-{stamp}-{run_label}"
        json_file = archive_dir / f"{base_name}.json"
        csv_file = archive_dir / f"{base_name}.csv"
        json_payload = {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "summary": summary,
        }
        json_file.write_text(
            json.dumps(json_payload, ensure_ascii=False, indent=2, default=str),
            encoding="utf-8",
        )
        csv_file.write_text(_build_ops_daily_check_summary_csv(summary), encoding="utf-8")
        archive["json_file"] = str(json_file)
        archive["csv_file"] = str(csv_file)
        archive["pruned_files"] = _prune_ops_daily_check_archive_files(archive_dir=archive_dir, now=finished_at)
    except Exception as exc:  # pragma: no cover - defensive filesystem path
        archive["error"] = str(exc)
    return archive


def _build_ops_daily_check_summary_from_job_run(model: JobRunRead, detail: dict[str, Any]) -> dict[str, Any]:
    checks = detail.get("checks")
    if not isinstance(checks, list):
        checks = []
    return _build_ops_daily_check_summary(
        run_id=model.id,
        checked_at=model.finished_at,
        trigger=model.trigger,
        status=model.status,
        overall_status=str(detail.get("overall_status") or model.status),
        check_count=int(detail.get("check_count") or len(checks)),
        warning_count=int(detail.get("warning_count") or 0),
        critical_count=int(detail.get("critical_count") or 0),
        checks=[item for item in checks if isinstance(item, dict)],
        alert_level=str(detail.get("alert_level") or "critical"),
        alert_attempted=bool(detail.get("alert_attempted", False)),
        alert_dispatched=bool(detail.get("alert_dispatched", False)),
        alert_error=(str(detail.get("alert_error")) if detail.get("alert_error") is not None else None),
        mttr_slo_check=detail.get("mttr_slo_check", {}) if isinstance(detail.get("mttr_slo_check"), dict) else {},
    )


def _build_ops_daily_check_archive_rows(*, limit: int) -> list[dict[str, Any]]:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "ops_daily_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(max(1, min(limit, 365)))
        ).mappings().all()

    payload_rows: list[dict[str, Any]] = []
    for row in rows:
        model = _row_to_job_run_model(row)
        detail = model.detail if isinstance(model.detail, dict) else {}
        summary = detail.get("summary") if isinstance(detail.get("summary"), dict) else None
        if summary is None:
            summary = _build_ops_daily_check_summary_from_job_run(model, detail)
        archive = detail.get("archive") if isinstance(detail.get("archive"), dict) else {}
        payload_rows.append(
            {
                "run_id": model.id,
                "finished_at": model.finished_at.isoformat(),
                "trigger": model.trigger,
                "status": model.status,
                "overall_status": summary.get("overall_status"),
                "check_count": summary.get("check_count"),
                "warning_count": summary.get("warning_count"),
                "critical_count": summary.get("critical_count"),
                "alert_level": (summary.get("alert") or {}).get("level") if isinstance(summary.get("alert"), dict) else None,
                "alert_attempted": bool((summary.get("alert") or {}).get("attempted", False))
                if isinstance(summary.get("alert"), dict)
                else False,
                "alert_dispatched": bool((summary.get("alert") or {}).get("dispatched", False))
                if isinstance(summary.get("alert"), dict)
                else False,
                "archive_json_file": archive.get("json_file"),
                "archive_csv_file": archive.get("csv_file"),
                "archive_error": archive.get("error"),
            }
        )
    return payload_rows


def _build_ops_daily_check_archive_csv(rows: list[dict[str, Any]]) -> str:
    buffer = io.StringIO()
    writer = csv.writer(buffer)
    writer.writerow(
        [
            "run_id",
            "finished_at",
            "trigger",
            "status",
            "overall_status",
            "check_count",
            "warning_count",
            "critical_count",
            "alert_level",
            "alert_attempted",
            "alert_dispatched",
            "archive_json_file",
            "archive_csv_file",
            "archive_error",
        ]
    )
    for row in rows:
        writer.writerow(
            [
                row.get("run_id"),
                row.get("finished_at"),
                row.get("trigger"),
                row.get("status"),
                row.get("overall_status"),
                row.get("check_count"),
                row.get("warning_count"),
                row.get("critical_count"),
                row.get("alert_level"),
                bool(row.get("alert_attempted", False)),
                bool(row.get("alert_dispatched", False)),
                row.get("archive_json_file"),
                row.get("archive_csv_file"),
                row.get("archive_error"),
            ]
        )
    return buffer.getvalue()


def run_ops_daily_check_job(
    *,
    trigger: str = "manual",
) -> dict[str, Any]:
    started_at = datetime.now(timezone.utc)
    mttr_slo_result = run_alert_mttr_slo_check_job(
        trigger=f"{trigger}:ops_daily_check",
    )
    checks_snapshot = _build_ops_runbook_checks_snapshot(now=started_at)
    posture_snapshot = _build_ops_security_posture_snapshot(now=started_at)
    mttr_slo_summary = {
        "run_id": mttr_slo_result.get("run_id"),
        "status": mttr_slo_result.get("status"),
        "breach": bool(mttr_slo_result.get("breach", False)),
        "window": mttr_slo_result.get("window", {}),
        "actions": {
            "auto_recover_attempted": bool(
                (mttr_slo_result.get("actions") or {}).get("auto_recover_attempted", False)
            ),
            "notify_attempted": bool((mttr_slo_result.get("actions") or {}).get("notify_attempted", False)),
            "notify_dispatched": bool((mttr_slo_result.get("actions") or {}).get("notify_dispatched", False)),
            "notify_error": (mttr_slo_result.get("actions") or {}).get("notify_error"),
            "cooldown_active": bool((mttr_slo_result.get("actions") or {}).get("cooldown_active", False)),
        },
    }

    checks = checks_snapshot.get("checks", [])
    warning_count = sum(1 for item in checks if str(item.get("status")) == "warning")
    critical_count = sum(1 for item in checks if str(item.get("status")) == "critical")
    overall_status = str(checks_snapshot.get("overall_status") or "ok")

    alert_level = _normalize_ops_daily_check_alert_level(OPS_DAILY_CHECK_ALERT_LEVEL)
    alert_attempted = False
    alert_dispatched = False
    alert_error: str | None = None
    alert_channels: list[SlaAlertChannelResult] = []
    should_alert = (
        alert_level == "always"
        or (alert_level == "warning" and overall_status in {"warning", "critical"})
        or (alert_level == "critical" and overall_status == "critical")
    )
    if should_alert:
        payload = {
            "event": "ops_daily_check",
            "checked_at": started_at.isoformat(),
            "overall_status": overall_status,
            "check_count": len(checks),
            "warning_count": warning_count,
            "critical_count": critical_count,
            "checks": checks,
            "security_posture": {
                "rate_limit": posture_snapshot.get("rate_limit"),
                "audit_archive_signing": posture_snapshot.get("audit_archive_signing"),
                "evidence_storage_backend": posture_snapshot.get("evidence_storage_backend"),
                "token_policy": posture_snapshot.get("token_policy"),
            },
        }
        alert_attempted = True
        alert_dispatched, alert_error, alert_channels = _dispatch_alert_event(
            event_type="ops_daily_check",
            payload=payload,
        )

    if overall_status == "critical":
        status = "critical"
    elif overall_status == "warning":
        status = "warning"
    else:
        status = "success"
    if alert_attempted and alert_error is not None and status == "success":
        status = "warning"

    finished_at = datetime.now(timezone.utc)
    detail: dict[str, Any] = {
        "overall_status": overall_status,
        "check_count": len(checks),
        "warning_count": warning_count,
        "critical_count": critical_count,
        "checks": checks,
        "alert_level": alert_level,
        "alert_attempted": alert_attempted,
        "alert_dispatched": alert_dispatched,
        "alert_error": alert_error,
        "alert_channels": [channel.model_dump() for channel in alert_channels],
        "security_posture": {
            "rate_limit": posture_snapshot.get("rate_limit"),
            "audit_archive_signing": posture_snapshot.get("audit_archive_signing"),
            "evidence_storage_backend": posture_snapshot.get("evidence_storage_backend"),
            "token_policy": posture_snapshot.get("token_policy"),
        },
        "mttr_slo_check": mttr_slo_summary,
    }
    run_id = _write_job_run(
        job_name="ops_daily_check",
        trigger=trigger,
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )

    summary = _build_ops_daily_check_summary(
        run_id=run_id,
        checked_at=finished_at,
        trigger=trigger,
        status=status,
        overall_status=overall_status,
        check_count=len(checks),
        warning_count=warning_count,
        critical_count=critical_count,
        checks=checks,
        alert_level=alert_level,
        alert_attempted=alert_attempted,
        alert_dispatched=alert_dispatched,
        alert_error=alert_error,
        mttr_slo_check=mttr_slo_summary,
    )
    archive = _publish_ops_daily_check_summary_artifacts(
        summary=summary,
        finished_at=finished_at,
    )
    detail["summary"] = summary
    detail["archive"] = archive
    if run_id is not None:
        try:
            with get_conn() as conn:
                conn.execute(
                    update(job_runs)
                    .where(job_runs.c.id == run_id)
                    .values(detail_json=_to_json_text(detail))
                )
        except SQLAlchemyError:
            pass

    return {
        "run_id": run_id,
        "checked_at": finished_at.isoformat(),
        "trigger": trigger,
        "status": status,
        "overall_status": overall_status,
        "check_count": len(checks),
        "warning_count": warning_count,
        "critical_count": critical_count,
        "checks": checks,
        "alert_level": alert_level,
        "alert_attempted": alert_attempted,
        "alert_dispatched": alert_dispatched,
        "alert_error": alert_error,
        "alert_channels": [channel.model_dump() for channel in alert_channels],
        "security_posture": {
            "rate_limit": posture_snapshot.get("rate_limit"),
            "audit_archive_signing": posture_snapshot.get("audit_archive_signing"),
            "evidence_storage_backend": posture_snapshot.get("evidence_storage_backend"),
            "token_policy": posture_snapshot.get("token_policy"),
        },
        "mttr_slo_check": mttr_slo_summary,
        "summary": summary,
        "archive": archive,
    }


def simulate_sla_policy_change(
    *,
    policy: SlaPolicyUpdate,
    site: str | None = None,
    limit: int = 3000,
    include_work_order_ids: bool = True,
    sample_size: int = 200,
    recompute_due_from_policy: bool = False,
    allowed_sites: list[str] | None = None,
) -> SlaWhatIfResponse:
    now = datetime.now(timezone.utc)
    normalized_site = _normalize_site_name(site)
    normalized_limit = max(1, min(limit, 20000))
    normalized_sample_size = max(0, min(sample_size, 1000))
    simulated_policy = _normalize_sla_policy(policy.model_dump())

    stmt = (
        select(work_orders)
        .where(work_orders.c.status.in_(["open", "acked"]))
        .where(work_orders.c.is_escalated.is_(False))
        .order_by(work_orders.c.due_at.asc(), work_orders.c.id.asc())
        .limit(normalized_limit)
    )
    if normalized_site is not None:
        stmt = stmt.where(work_orders.c.site == normalized_site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return SlaWhatIfResponse(
                checked_at=now,
                site=normalized_site,
                limit=normalized_limit,
                total_candidates=0,
                baseline_escalate_count=0,
                simulated_escalate_count=0,
                delta_escalate_count=0,
                baseline_by_site={},
                simulated_by_site={},
                newly_escalated_ids=[],
                no_longer_escalated_ids=[],
                notes=["No accessible sites in current principal scope."],
            )
        stmt = stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    current_policy_cache: dict[str, dict[str, Any]] = {}

    def _current_policy_for_site(site_name: str) -> dict[str, Any]:
        key = site_name.strip()
        if key in current_policy_cache:
            return current_policy_cache[key]
        loaded, _, _, _, _ = _load_sla_policy(site=key if key else None)
        current_policy_cache[key] = loaded
        return loaded

    baseline_count = 0
    simulated_count = 0
    baseline_by_site: dict[str, int] = {}
    simulated_by_site: dict[str, int] = {}
    newly_escalated_ids: list[int] = []
    no_longer_escalated_ids: list[int] = []

    for row in rows:
        row_id = int(row["id"])
        row_site = str(row["site"] or "")
        row_priority = str(row["priority"] or "medium")

        due_at_baseline = _as_optional_datetime(row["due_at"])
        created_at = _as_optional_datetime(row["created_at"])
        if due_at_baseline is None and not recompute_due_from_policy:
            continue
        if created_at is None:
            continue

        current_policy = _current_policy_for_site(row_site)
        current_grace = int(current_policy["escalation_grace_minutes"])
        baseline_cutoff = now - timedelta(minutes=current_grace)

        simulated_applies = normalized_site is None or row_site == normalized_site
        simulated_grace = (
            int(simulated_policy["escalation_grace_minutes"])
            if simulated_applies
            else int(current_policy["escalation_grace_minutes"])
        )
        simulated_cutoff = now - timedelta(minutes=simulated_grace)

        due_at_for_baseline = due_at_baseline
        due_at_for_simulated = due_at_baseline
        if recompute_due_from_policy and simulated_applies:
            simulated_hours = int(
                simulated_policy["default_due_hours"].get(
                    row_priority, SLA_DEFAULT_DUE_HOURS.get(row_priority, SLA_DEFAULT_DUE_HOURS["medium"])
                )
            )
            due_at_for_simulated = created_at + timedelta(hours=simulated_hours)
        if due_at_for_baseline is None:
            baseline_hours = int(
                current_policy["default_due_hours"].get(
                    row_priority, SLA_DEFAULT_DUE_HOURS.get(row_priority, SLA_DEFAULT_DUE_HOURS["medium"])
                )
            )
            due_at_for_baseline = created_at + timedelta(hours=baseline_hours)
        if due_at_for_simulated is None:
            due_at_for_simulated = due_at_for_baseline

        baseline_escalates = due_at_for_baseline < baseline_cutoff
        simulated_escalates = due_at_for_simulated < simulated_cutoff

        if baseline_escalates:
            baseline_count += 1
            baseline_by_site[row_site] = baseline_by_site.get(row_site, 0) + 1
        if simulated_escalates:
            simulated_count += 1
            simulated_by_site[row_site] = simulated_by_site.get(row_site, 0) + 1

        if include_work_order_ids and normalized_sample_size > 0:
            if simulated_escalates and not baseline_escalates and len(newly_escalated_ids) < normalized_sample_size:
                newly_escalated_ids.append(row_id)
            if baseline_escalates and not simulated_escalates and len(no_longer_escalated_ids) < normalized_sample_size:
                no_longer_escalated_ids.append(row_id)

    notes = [
        "Simulation is read-only and does not mutate work-order state.",
        "Due-hours policy mainly affects future created work orders unless recompute_due_from_policy=true.",
    ]
    return SlaWhatIfResponse(
        checked_at=now,
        site=normalized_site,
        limit=normalized_limit,
        total_candidates=len(rows),
        baseline_escalate_count=baseline_count,
        simulated_escalate_count=simulated_count,
        delta_escalate_count=simulated_count - baseline_count,
        baseline_by_site=baseline_by_site,
        simulated_by_site=simulated_by_site,
        newly_escalated_ids=newly_escalated_ids,
        no_longer_escalated_ids=no_longer_escalated_ids,
        notes=notes,
    )


def build_monthly_report(
    month: str | None,
    site: str | None,
    allowed_sites: list[str] | None = None,
) -> MonthlyReportRead:
    start, end, month_label = _month_window(month)
    now = datetime.now(timezone.utc)

    inspections_stmt = (
        select(inspections)
        .where(inspections.c.inspected_at >= start)
        .where(inspections.c.inspected_at < end)
    )
    work_orders_stmt = (
        select(work_orders)
        .where(work_orders.c.created_at >= start)
        .where(work_orders.c.created_at < end)
    )
    if site is not None:
        inspections_stmt = inspections_stmt.where(inspections.c.site == site)
        work_orders_stmt = work_orders_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return MonthlyReportRead(
                month=month_label,
                site=site,
                generated_at=now,
                inspections={"total": 0, "risk_counts": {"normal": 0, "warning": 0, "danger": 0}, "top_risk_flags": {}},
                work_orders={
                    "total": 0,
                    "status_counts": {"open": 0, "acked": 0, "completed": 0, "canceled": 0},
                    "escalated_count": 0,
                    "overdue_open_count": 0,
                    "completion_rate_percent": 0.0,
                    "avg_resolution_hours": None,
                },
            )
        inspections_stmt = inspections_stmt.where(inspections.c.site.in_(allowed_sites))
        work_orders_stmt = work_orders_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        inspection_rows = conn.execute(inspections_stmt).mappings().all()
        work_order_rows = conn.execute(work_orders_stmt).mappings().all()

    risk_counts = {"normal": 0, "warning": 0, "danger": 0}
    flag_counts: dict[str, int] = {}
    for row in inspection_rows:
        risk_level = row["risk_level"] or "normal"
        risk_counts[risk_level] = risk_counts.get(risk_level, 0) + 1
        flags = (row["risk_flags"] or "").split(",")
        for flag in flags:
            if not flag:
                continue
            flag_counts[flag] = flag_counts.get(flag, 0) + 1

    status_counts = {"open": 0, "acked": 0, "completed": 0, "canceled": 0}
    escalated_count = 0
    overdue_open_count = 0
    resolution_hours: list[float] = []
    for row in work_order_rows:
        status = row["status"] or "open"
        status_counts[status] = status_counts.get(status, 0) + 1
        if row["is_escalated"]:
            escalated_count += 1

        due_at = _as_optional_datetime(row["due_at"])
        if due_at is not None and status not in {"completed", "canceled"} and due_at < now:
            overdue_open_count += 1

        created_at = _as_optional_datetime(row["created_at"])
        completed_at = _as_optional_datetime(row["completed_at"])
        if created_at is not None and completed_at is not None:
            hours = (completed_at - created_at).total_seconds() / 3600
            if hours >= 0:
                resolution_hours.append(hours)

    total_work_orders = len(work_order_rows)
    completed_count = status_counts.get("completed", 0)
    completion_rate = round((completed_count / total_work_orders * 100), 2) if total_work_orders else 0.0
    avg_resolution_hours = round(sum(resolution_hours) / len(resolution_hours), 2) if resolution_hours else None

    return MonthlyReportRead(
        month=month_label,
        site=site,
        generated_at=now,
        inspections={
            "total": len(inspection_rows),
            "risk_counts": risk_counts,
            "top_risk_flags": dict(sorted(flag_counts.items(), key=lambda x: x[1], reverse=True)[:10]),
        },
        work_orders={
            "total": total_work_orders,
            "status_counts": status_counts,
            "escalated_count": escalated_count,
            "overdue_open_count": overdue_open_count,
            "completion_rate_percent": completion_rate,
            "avg_resolution_hours": avg_resolution_hours,
        },
    )


def build_dashboard_summary(
    *,
    site: str | None,
    days: int,
    recent_job_limit: int,
    allowed_sites: list[str] | None = None,
) -> DashboardSummaryRead:
    now = datetime.now(timezone.utc)
    start = now - timedelta(days=days)

    inspections_stmt = select(inspections).where(inspections.c.inspected_at >= start)
    work_orders_window_stmt = select(work_orders).where(work_orders.c.created_at >= start)
    work_orders_open_stmt = select(work_orders).where(work_orders.c.status.in_(["open", "acked"]))
    job_runs_stmt = (
        select(job_runs)
        .where(job_runs.c.finished_at >= start)
        .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
        .limit(recent_job_limit)
    )
    report_exports_stmt = (
        select(admin_audit_logs.c.action)
        .where(admin_audit_logs.c.created_at >= start)
        .where(admin_audit_logs.c.action.in_(["report_monthly_export_csv", "report_monthly_export_pdf"]))
    )

    if site is not None:
        inspections_stmt = inspections_stmt.where(inspections.c.site == site)
        work_orders_window_stmt = work_orders_window_stmt.where(work_orders.c.site == site)
        work_orders_open_stmt = work_orders_open_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return DashboardSummaryRead(
                generated_at=now,
                site=site,
                window_days=days,
                inspections_total=0,
                inspection_risk_counts={"normal": 0, "warning": 0, "danger": 0},
                work_orders_total=0,
                work_order_status_counts={"open": 0, "acked": 0, "completed": 0, "canceled": 0},
                overdue_open_count=0,
                escalated_open_count=0,
                report_export_count=0,
                sla_recent_runs=0,
                sla_warning_runs=0,
                sla_last_run_at=None,
                recent_job_runs=[],
            )
        inspections_stmt = inspections_stmt.where(inspections.c.site.in_(allowed_sites))
        work_orders_window_stmt = work_orders_window_stmt.where(work_orders.c.site.in_(allowed_sites))
        work_orders_open_stmt = work_orders_open_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        inspection_rows = conn.execute(inspections_stmt).mappings().all()
        work_order_window_rows = conn.execute(work_orders_window_stmt).mappings().all()
        work_order_open_rows = conn.execute(work_orders_open_stmt).mappings().all()
        job_rows = conn.execute(job_runs_stmt).mappings().all()
        export_rows = conn.execute(report_exports_stmt).all()

    inspection_risk_counts = {"normal": 0, "warning": 0, "danger": 0}
    for row in inspection_rows:
        risk_level = str(row["risk_level"] or "normal")
        inspection_risk_counts[risk_level] = inspection_risk_counts.get(risk_level, 0) + 1

    work_order_status_counts = {"open": 0, "acked": 0, "completed": 0, "canceled": 0}
    for row in work_order_window_rows:
        status = str(row["status"] or "open")
        work_order_status_counts[status] = work_order_status_counts.get(status, 0) + 1

    overdue_open_count = 0
    escalated_open_count = 0
    for row in work_order_open_rows:
        if row["is_escalated"]:
            escalated_open_count += 1
        due_at = _as_optional_datetime(row["due_at"])
        if due_at is not None and due_at < now:
            overdue_open_count += 1

    recent_jobs = [_row_to_job_run_model(row) for row in job_rows]
    sla_recent_runs = [job for job in recent_jobs if job.job_name == "sla_escalation"]
    sla_last_run_at = sla_recent_runs[0].finished_at if sla_recent_runs else None
    sla_warning_runs = sum(1 for job in sla_recent_runs if job.status != "success")

    return DashboardSummaryRead(
        generated_at=now,
        site=site,
        window_days=days,
        inspections_total=len(inspection_rows),
        inspection_risk_counts=inspection_risk_counts,
        work_orders_total=len(work_order_window_rows),
        work_order_status_counts=work_order_status_counts,
        overdue_open_count=overdue_open_count,
        escalated_open_count=escalated_open_count,
        report_export_count=len(export_rows),
        sla_recent_runs=len(sla_recent_runs),
        sla_warning_runs=sla_warning_runs,
        sla_last_run_at=sla_last_run_at,
        recent_job_runs=recent_jobs,
    )


def build_dashboard_trends(
    *,
    site: str | None,
    days: int,
    allowed_sites: list[str] | None = None,
) -> DashboardTrendsRead:
    now = datetime.now(timezone.utc)
    start = (now - timedelta(days=days - 1)).replace(hour=0, minute=0, second=0, microsecond=0)

    inspections_stmt = select(inspections.c.inspected_at, inspections.c.site).where(inspections.c.inspected_at >= start)
    work_orders_stmt = select(
        work_orders.c.created_at,
        work_orders.c.completed_at,
        work_orders.c.site,
    ).where((work_orders.c.created_at >= start) | (work_orders.c.completed_at >= start))
    escalations_stmt = (
        select(job_runs.c.finished_at, job_runs.c.detail_json)
        .where(job_runs.c.job_name == "sla_escalation")
        .where(job_runs.c.finished_at >= start)
    )

    if site is not None:
        inspections_stmt = inspections_stmt.where(inspections.c.site == site)
        work_orders_stmt = work_orders_stmt.where(work_orders.c.site == site)
    elif allowed_sites is not None:
        if not allowed_sites:
            return DashboardTrendsRead(generated_at=now, site=site, window_days=days, points=[])
        inspections_stmt = inspections_stmt.where(inspections.c.site.in_(allowed_sites))
        work_orders_stmt = work_orders_stmt.where(work_orders.c.site.in_(allowed_sites))

    with get_conn() as conn:
        inspection_rows = conn.execute(inspections_stmt).mappings().all()
        work_order_rows = conn.execute(work_orders_stmt).mappings().all()
        escalation_rows = conn.execute(escalations_stmt).mappings().all()

    buckets: dict[str, dict[str, int]] = {}
    for i in range(days):
        bucket_day = (start + timedelta(days=i)).date().isoformat()
        buckets[bucket_day] = {
            "inspections_count": 0,
            "work_orders_created_count": 0,
            "work_orders_completed_count": 0,
            "work_orders_escalated_count": 0,
        }

    for row in inspection_rows:
        inspected_at = _as_optional_datetime(row["inspected_at"])
        if inspected_at is None:
            continue
        key = inspected_at.date().isoformat()
        if key in buckets:
            buckets[key]["inspections_count"] += 1

    for row in work_order_rows:
        created_at = _as_optional_datetime(row["created_at"])
        completed_at = _as_optional_datetime(row["completed_at"])
        if created_at is not None:
            key = created_at.date().isoformat()
            if key in buckets:
                buckets[key]["work_orders_created_count"] += 1
        if completed_at is not None:
            key = completed_at.date().isoformat()
            if key in buckets:
                buckets[key]["work_orders_completed_count"] += 1

    for row in escalation_rows:
        finished_at = _as_optional_datetime(row["finished_at"])
        if finished_at is None:
            continue
        key = finished_at.date().isoformat()
        if key not in buckets:
            continue

        detail = {}
        raw = str(row["detail_json"] or "{}")
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, dict):
                detail = parsed
        except json.JSONDecodeError:
            detail = {}

        detail_site = detail.get("site")
        if site is not None and detail_site not in {site, None}:
            continue
        escalated_count = int(detail.get("escalated_count", 0) or 0)
        buckets[key]["work_orders_escalated_count"] += max(0, escalated_count)

    points = [
        DashboardTrendPoint(
            date=date_key,
            inspections_count=data["inspections_count"],
            work_orders_created_count=data["work_orders_created_count"],
            work_orders_completed_count=data["work_orders_completed_count"],
            work_orders_escalated_count=data["work_orders_escalated_count"],
        )
        for date_key, data in buckets.items()
    ]
    return DashboardTrendsRead(
        generated_at=now,
        site=site,
        window_days=days,
        points=points,
    )


def build_ops_handover_brief(
    *,
    site: str | None,
    window_hours: int,
    due_soon_hours: int,
    max_items: int,
    allowed_sites: list[str] | None = None,
) -> OpsHandoverBriefRead:
    now = datetime.now(timezone.utc)
    window_start = now - timedelta(hours=window_hours)
    due_soon_cutoff = now + timedelta(hours=due_soon_hours)
    alert_window_start = now - timedelta(hours=24)

    if site is None and allowed_sites is not None and not allowed_sites:
        return OpsHandoverBriefRead(
            generated_at=now,
            site=site,
            window_hours=window_hours,
            due_soon_hours=due_soon_hours,
            open_work_orders=0,
            overdue_open_work_orders=0,
            due_soon_work_orders=0,
            escalated_open_work_orders=0,
            unassigned_high_priority_open_work_orders=0,
            new_work_orders_in_window=0,
            high_risk_inspections_in_window=0,
            failed_alert_deliveries_24h=0,
            top_work_orders=[],
            recent_high_risk_inspections=[],
            recommended_actions=["No accessible sites in current principal scope."],
        )

    open_work_orders_stmt = select(work_orders).where(work_orders.c.status.in_(["open", "acked"]))
    new_work_orders_stmt = (
        select(work_orders.c.id, work_orders.c.site)
        .where(work_orders.c.status.in_(["open", "acked"]))
        .where(work_orders.c.created_at >= window_start)
    )
    high_risk_inspections_stmt = (
        select(inspections)
        .where(inspections.c.inspected_at >= window_start)
        .where(inspections.c.risk_level.in_(["warning", "danger"]))
    )
    alert_deliveries_stmt = (
        select(alert_deliveries.c.status, alert_deliveries.c.payload_json)
        .where(alert_deliveries.c.last_attempt_at >= alert_window_start)
        .where(alert_deliveries.c.status.in_(["failed", "warning"]))
    )

    if site is not None:
        open_work_orders_stmt = open_work_orders_stmt.where(work_orders.c.site == site)
        new_work_orders_stmt = new_work_orders_stmt.where(work_orders.c.site == site)
        high_risk_inspections_stmt = high_risk_inspections_stmt.where(inspections.c.site == site)
    elif allowed_sites is not None:
        open_work_orders_stmt = open_work_orders_stmt.where(work_orders.c.site.in_(allowed_sites))
        new_work_orders_stmt = new_work_orders_stmt.where(work_orders.c.site.in_(allowed_sites))
        high_risk_inspections_stmt = high_risk_inspections_stmt.where(inspections.c.site.in_(allowed_sites))

    with get_conn() as conn:
        open_work_order_rows = conn.execute(open_work_orders_stmt).mappings().all()
        new_work_order_rows = conn.execute(new_work_orders_stmt).all()
        high_risk_inspection_rows = conn.execute(high_risk_inspections_stmt).mappings().all()
        alert_delivery_rows = conn.execute(alert_deliveries_stmt).mappings().all()

    priority_weights = {"low": 1, "medium": 2, "high": 4, "critical": 6}
    top_work_orders: list[OpsHandoverWorkOrderRead] = []
    overdue_open_work_orders = 0
    due_soon_work_orders = 0
    escalated_open_work_orders = 0
    unassigned_high_priority_open_work_orders = 0

    for row in open_work_order_rows:
        due_at = _as_optional_datetime(row["due_at"])
        created_at = _as_optional_datetime(row["created_at"]) or now
        priority = str(row["priority"] or "medium")
        is_escalated = bool(row["is_escalated"])
        is_overdue = due_at is not None and due_at < now
        is_due_soon = due_at is not None and now <= due_at <= due_soon_cutoff
        is_unassigned_high_priority = priority in {"high", "critical"} and not row["assignee"]

        if is_overdue:
            overdue_open_work_orders += 1
        if is_due_soon:
            due_soon_work_orders += 1
        if is_escalated:
            escalated_open_work_orders += 1
        if is_unassigned_high_priority:
            unassigned_high_priority_open_work_orders += 1

        urgency_score = priority_weights.get(priority, 2)
        reasons: list[str] = [f"{priority} priority"]
        if is_overdue:
            urgency_score += 6
            reasons.append("overdue")
        elif is_due_soon:
            urgency_score += 3
            reasons.append("due soon")
        if is_escalated:
            urgency_score += 4
            reasons.append("escalated")
        if is_unassigned_high_priority:
            urgency_score += 2
            reasons.append("unassigned high priority")

        age_hours = (now - created_at).total_seconds() / 3600
        if age_hours >= 72:
            urgency_score += 2
            reasons.append("open >72h")
        elif age_hours >= 24:
            urgency_score += 1
            reasons.append("open >24h")

        due_in_minutes = None
        if due_at is not None:
            due_in_minutes = int((due_at - now).total_seconds() // 60)

        top_work_orders.append(
            OpsHandoverWorkOrderRead(
                id=int(row["id"]),
                site=str(row["site"]),
                location=str(row["location"]),
                title=str(row["title"]),
                priority=priority,  # type: ignore[arg-type]
                status=str(row["status"]),  # type: ignore[arg-type]
                assignee=row["assignee"],
                due_at=due_at,
                created_at=created_at,
                is_escalated=is_escalated,
                is_overdue=is_overdue,
                due_in_minutes=due_in_minutes,
                urgency_score=urgency_score,
                reasons=reasons,
            )
        )

    far_future = now + timedelta(days=36500)
    top_work_orders.sort(
        key=lambda item: (
            -item.urgency_score,
            item.due_at or far_future,
            item.created_at,
            item.id,
        )
    )
    top_work_orders = top_work_orders[:max_items]

    risk_weights = {"danger": 2, "warning": 1}
    recent_high_risk_inspections: list[OpsHandoverInspectionRead] = []
    for row in high_risk_inspection_rows:
        risk_flags = [flag for flag in str(row["risk_flags"] or "").split(",") if flag]
        recent_high_risk_inspections.append(
            OpsHandoverInspectionRead(
                id=int(row["id"]),
                site=str(row["site"]),
                location=str(row["location"]),
                inspector=str(row["inspector"]),
                risk_level=str(row["risk_level"] or "warning"),
                inspected_at=_as_datetime(row["inspected_at"]),
                risk_flags=risk_flags,
            )
        )
    recent_high_risk_inspections.sort(
        key=lambda item: (
            risk_weights.get(item.risk_level, 0),
            item.inspected_at,
            item.id,
        ),
        reverse=True,
    )
    high_risk_inspections_in_window = len(recent_high_risk_inspections)
    recent_high_risk_inspections = recent_high_risk_inspections[:max_items]

    failed_alert_deliveries_24h = 0
    for row in alert_delivery_rows:
        payload_raw = str(row["payload_json"] or "{}")
        payload: dict[str, Any] = {}
        try:
            parsed_payload = json.loads(payload_raw)
            if isinstance(parsed_payload, dict):
                payload = parsed_payload
        except json.JSONDecodeError:
            payload = {}

        payload_site = _normalize_site_name(str(payload.get("site"))) if payload.get("site") is not None else None
        if site is not None:
            if payload_site != site:
                continue
        elif allowed_sites is not None and payload_site not in allowed_sites:
            continue
        failed_alert_deliveries_24h += 1

    recommended_actions: list[str] = []
    if overdue_open_work_orders > 0:
        recommended_actions.append(f"Resolve or reassign {overdue_open_work_orders} overdue open work orders.")
    if unassigned_high_priority_open_work_orders > 0:
        recommended_actions.append(
            f"Assign owners for {unassigned_high_priority_open_work_orders} unassigned high/critical work orders."
        )
    if high_risk_inspections_in_window > 0:
        recommended_actions.append(
            f"Review {high_risk_inspections_in_window} warning/danger inspections from last {window_hours} hours."
        )
    if due_soon_work_orders > 0:
        recommended_actions.append(f"Preempt {due_soon_work_orders} work orders due within next {due_soon_hours} hours.")
    if failed_alert_deliveries_24h > 0:
        recommended_actions.append(
            f"Investigate {failed_alert_deliveries_24h} failed/warning alert deliveries from last 24 hours."
        )
    if not recommended_actions:
        recommended_actions.append("No urgent blockers detected for this handover window.")

    return OpsHandoverBriefRead(
        generated_at=now,
        site=site,
        window_hours=window_hours,
        due_soon_hours=due_soon_hours,
        open_work_orders=len(open_work_order_rows),
        overdue_open_work_orders=overdue_open_work_orders,
        due_soon_work_orders=due_soon_work_orders,
        escalated_open_work_orders=escalated_open_work_orders,
        unassigned_high_priority_open_work_orders=unassigned_high_priority_open_work_orders,
        new_work_orders_in_window=len(new_work_order_rows),
        high_risk_inspections_in_window=high_risk_inspections_in_window,
        failed_alert_deliveries_24h=failed_alert_deliveries_24h,
        top_work_orders=top_work_orders,
        recent_high_risk_inspections=recent_high_risk_inspections,
        recommended_actions=recommended_actions[:5],
    )


def _json_or_scalar(value: Any) -> str:
    if isinstance(value, (dict, list)):
        return json.dumps(value, ensure_ascii=False)
    if value is None:
        return ""
    return str(value)


def _build_monthly_report_csv(report: MonthlyReportRead) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(["section", "key", "value"])
    writer.writerow(["meta", "month", report.month])
    writer.writerow(["meta", "site", report.site or "ALL"])
    writer.writerow(["meta", "generated_at", report.generated_at.isoformat()])
    writer.writerow(["inspections", "total", report.inspections.get("total", 0)])

    risk_counts = report.inspections.get("risk_counts", {})
    for key, value in risk_counts.items():
        writer.writerow(["inspections.risk_counts", key, value])

    top_flags = report.inspections.get("top_risk_flags", {})
    for key, value in top_flags.items():
        writer.writerow(["inspections.top_risk_flags", key, value])

    writer.writerow(["work_orders", "total", report.work_orders.get("total", 0)])
    for key, value in report.work_orders.items():
        if key == "status_counts":
            continue
        writer.writerow(["work_orders", key, _json_or_scalar(value)])

    status_counts = report.work_orders.get("status_counts", {})
    for key, value in status_counts.items():
        writer.writerow(["work_orders.status_counts", key, value])
    return out.getvalue()


def _build_monthly_report_pdf(report: MonthlyReportRead) -> bytes:
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.pdfgen import canvas
    except ImportError as exc:
        raise HTTPException(status_code=500, detail="PDF generator dependency not installed") from exc

    lines = [
        f"Monthly Audit Report ({report.month})",
        "",
        f"Site: {report.site or 'ALL'}",
        f"Generated At: {report.generated_at.isoformat()}",
        "",
        "[Inspection Summary]",
        f"Total: {report.inspections.get('total', 0)}",
        f"Risk Counts: {_json_or_scalar(report.inspections.get('risk_counts', {}))}",
        f"Top Risk Flags: {_json_or_scalar(report.inspections.get('top_risk_flags', {}))}",
        "",
        "[Work Order Summary]",
        f"Total: {report.work_orders.get('total', 0)}",
        f"Status Counts: {_json_or_scalar(report.work_orders.get('status_counts', {}))}",
        f"Escalated Count: {report.work_orders.get('escalated_count', 0)}",
        f"Overdue Open Count: {report.work_orders.get('overdue_open_count', 0)}",
        f"Completion Rate (%): {report.work_orders.get('completion_rate_percent', 0)}",
        f"Avg Resolution Hours: {report.work_orders.get('avg_resolution_hours') or '-'}",
    ]

    buf = io.BytesIO()
    pdf = canvas.Canvas(buf, pagesize=A4)
    _, height = A4
    margin_left = 36
    y = height - 40
    pdf.setFont("Helvetica", 10)
    for line in lines:
        if y < 40:
            pdf.showPage()
            pdf.setFont("Helvetica", 10)
            y = height - 40
        pdf.drawString(margin_left, y, line[:180])
        y -= 14
    pdf.save()
    return buf.getvalue()


def _build_handover_brief_csv(report: OpsHandoverBriefRead) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(["section", "key", "value"])
    writer.writerow(["meta", "site", report.site or "ALL"])
    writer.writerow(["meta", "generated_at", report.generated_at.isoformat()])
    writer.writerow(["meta", "window_hours", report.window_hours])
    writer.writerow(["meta", "due_soon_hours", report.due_soon_hours])

    writer.writerow(["summary", "open_work_orders", report.open_work_orders])
    writer.writerow(["summary", "overdue_open_work_orders", report.overdue_open_work_orders])
    writer.writerow(["summary", "due_soon_work_orders", report.due_soon_work_orders])
    writer.writerow(["summary", "escalated_open_work_orders", report.escalated_open_work_orders])
    writer.writerow(
        [
            "summary",
            "unassigned_high_priority_open_work_orders",
            report.unassigned_high_priority_open_work_orders,
        ]
    )
    writer.writerow(["summary", "new_work_orders_in_window", report.new_work_orders_in_window])
    writer.writerow(["summary", "high_risk_inspections_in_window", report.high_risk_inspections_in_window])
    writer.writerow(["summary", "failed_alert_deliveries_24h", report.failed_alert_deliveries_24h])

    writer.writerow([])
    writer.writerow(
        [
            "top_work_orders",
            "id",
            "site",
            "location",
            "title",
            "priority",
            "status",
            "assignee",
            "due_at",
            "due_in_minutes",
            "is_overdue",
            "is_escalated",
            "urgency_score",
            "reasons",
        ]
    )
    for item in report.top_work_orders:
        writer.writerow(
            [
                "top_work_orders",
                item.id,
                item.site,
                item.location,
                item.title,
                item.priority,
                item.status,
                item.assignee or "",
                item.due_at.isoformat() if item.due_at is not None else "",
                item.due_in_minutes if item.due_in_minutes is not None else "",
                item.is_overdue,
                item.is_escalated,
                item.urgency_score,
                ", ".join(item.reasons),
            ]
        )

    writer.writerow([])
    writer.writerow(
        [
            "recent_high_risk_inspections",
            "id",
            "site",
            "location",
            "inspector",
            "risk_level",
            "inspected_at",
            "risk_flags",
        ]
    )
    for item in report.recent_high_risk_inspections:
        writer.writerow(
            [
                "recent_high_risk_inspections",
                item.id,
                item.site,
                item.location,
                item.inspector,
                item.risk_level,
                item.inspected_at.isoformat(),
                ", ".join(item.risk_flags),
            ]
        )

    writer.writerow([])
    writer.writerow(["recommended_actions", "index", "action"])
    for idx, action in enumerate(report.recommended_actions, start=1):
        writer.writerow(["recommended_actions", idx, action])

    return out.getvalue()


def _build_handover_brief_pdf(report: OpsHandoverBriefRead) -> bytes:
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.pdfgen import canvas
    except ImportError as exc:
        raise HTTPException(status_code=500, detail="PDF generator dependency not installed") from exc

    lines = [
        "Ops Handover Brief",
        "",
        f"Site: {report.site or 'ALL'}",
        f"Generated At: {report.generated_at.isoformat()}",
        f"Window Hours: {report.window_hours}",
        f"Due Soon Hours: {report.due_soon_hours}",
        "",
        "[Summary]",
        f"Open Work Orders: {report.open_work_orders}",
        f"Overdue Open Work Orders: {report.overdue_open_work_orders}",
        f"Due Soon Work Orders: {report.due_soon_work_orders}",
        f"Escalated Open Work Orders: {report.escalated_open_work_orders}",
        f"Unassigned High Priority Open Work Orders: {report.unassigned_high_priority_open_work_orders}",
        f"New Work Orders In Window: {report.new_work_orders_in_window}",
        f"High Risk Inspections In Window: {report.high_risk_inspections_in_window}",
        f"Failed Alert Deliveries 24h: {report.failed_alert_deliveries_24h}",
        "",
        "[Top Work Orders]",
    ]
    for item in report.top_work_orders:
        due_text = item.due_at.isoformat() if item.due_at is not None else "-"
        lines.append(
            f"#{item.id} {item.priority}/{item.status} score={item.urgency_score} site={item.site} due={due_text}"
        )
        lines.append(f"  {item.title[:120]}")

    lines.append("")
    lines.append("[Recent High Risk Inspections]")
    for item in report.recent_high_risk_inspections:
        lines.append(f"#{item.id} {item.risk_level} site={item.site} inspected_at={item.inspected_at.isoformat()}")
        if item.risk_flags:
            lines.append(f"  flags={', '.join(item.risk_flags)[:140]}")

    lines.append("")
    lines.append("[Recommended Actions]")
    for idx, action in enumerate(report.recommended_actions, start=1):
        lines.append(f"{idx}. {action}")

    buf = io.BytesIO()
    pdf = canvas.Canvas(buf, pagesize=A4)
    _, height = A4
    margin_left = 36
    y = height - 40
    pdf.setFont("Helvetica", 10)
    for line in lines:
        if y < 40:
            pdf.showPage()
            pdf.setFont("Helvetica", 10)
            y = height - 40
        pdf.drawString(margin_left, y, line[:180])
        y -= 14
    pdf.save()
    return buf.getvalue()


def _service_info_payload() -> dict[str, str]:
    return {
        "service": "ka-facility-os",
        "status": "running",
        "main_html": "/",
        "docs": "/docs",
        "inspection_api": "/api/inspections",
        "work_order_api": "/api/work-orders",
        "work_order_events_api": "/api/work-orders/{id}/events",
        "escalation_api": "/api/work-orders/escalations/run",
        "monthly_report_api": "/api/reports/monthly",
        "monthly_report_csv_api": "/api/reports/monthly/csv",
        "monthly_report_pdf_api": "/api/reports/monthly/pdf",
        "auth_me_api": "/api/auth/me",
        "admin_tokens_api": "/api/admin/tokens",
        "admin_token_rotate_api": "/api/admin/tokens/{token_id}/rotate",
        "admin_token_policy_api": "/api/admin/token-policy",
        "admin_audit_api": "/api/admin/audit-logs",
        "admin_audit_integrity_api": "/api/admin/audit-integrity",
        "admin_audit_rebaseline_api": "/api/admin/audit-chain/rebaseline",
        "admin_audit_archive_monthly_api": "/api/admin/audit-archive/monthly",
        "admin_audit_archive_csv_api": "/api/admin/audit-archive/monthly/csv",
        "job_runs_api": "/api/ops/job-runs",
        "dashboard_summary_api": "/api/ops/dashboard/summary",
        "dashboard_trends_api": "/api/ops/dashboard/trends",
        "ops_api_latency_api": "/api/ops/performance/api-latency",
        "ops_evidence_archive_integrity_api": "/api/ops/integrity/evidence-archive",
        "ops_deploy_checklist_api": "/api/ops/deploy/checklist",
        "ops_deploy_smoke_record_api": "/api/ops/deploy/smoke/record",
        "ops_runbook_checks_api": "/api/ops/runbook/checks",
        "ops_runbook_checks_run_api": "/api/ops/runbook/checks/run",
        "ops_runbook_checks_latest_api": "/api/ops/runbook/checks/latest",
        "ops_runbook_checks_latest_summary_json_api": "/api/ops/runbook/checks/latest/summary.json",
        "ops_runbook_checks_latest_summary_csv_api": "/api/ops/runbook/checks/latest/summary.csv",
        "ops_runbook_checks_archive_json_api": "/api/ops/runbook/checks/archive.json",
        "ops_runbook_checks_archive_csv_api": "/api/ops/runbook/checks/archive.csv",
        "ops_preflight_api": "/api/ops/preflight",
        "ops_alert_noise_policy_api": "/api/ops/alerts/noise-policy",
        "ops_admin_security_dashboard_api": "/api/ops/admin/security-dashboard",
        "ops_quality_weekly_report_api": "/api/ops/reports/quality/weekly",
        "ops_quality_weekly_report_csv_api": "/api/ops/reports/quality/weekly/csv",
        "ops_quality_monthly_report_api": "/api/ops/reports/quality/monthly",
        "ops_quality_monthly_report_csv_api": "/api/ops/reports/quality/monthly/csv",
        "ops_quality_report_run_api": "/api/ops/reports/quality/run",
        "ops_quality_weekly_streak_api": "/api/ops/reports/quality/weekly/streak",
        "ops_dr_rehearsal_run_api": "/api/ops/dr/rehearsal/run",
        "ops_dr_rehearsal_latest_api": "/api/ops/dr/rehearsal/latest",
        "ops_dr_rehearsal_history_api": "/api/ops/dr/rehearsal/history",
        "ops_governance_gate_api": "/api/ops/governance/gate",
        "ops_governance_gate_run_api": "/api/ops/governance/gate/run",
        "ops_governance_gate_latest_api": "/api/ops/governance/gate/latest",
        "ops_governance_gate_history_api": "/api/ops/governance/gate/history",
        "ops_governance_gate_remediation_api": "/api/ops/governance/gate/remediation",
        "ops_governance_gate_remediation_csv_api": "/api/ops/governance/gate/remediation/csv",
        "ops_governance_remediation_tracker_sync_api": "/api/ops/governance/gate/remediation/tracker/sync",
        "ops_governance_remediation_tracker_items_api": "/api/ops/governance/gate/remediation/tracker/items",
        "ops_governance_remediation_tracker_overview_api": "/api/ops/governance/gate/remediation/tracker/overview",
        "ops_governance_remediation_tracker_readiness_api": "/api/ops/governance/gate/remediation/tracker/readiness",
        "ops_governance_remediation_tracker_completion_api": "/api/ops/governance/gate/remediation/tracker/completion",
        "ops_governance_remediation_tracker_complete_api": "/api/ops/governance/gate/remediation/tracker/complete",
        "ops_governance_remediation_tracker_sla_api": "/api/ops/governance/gate/remediation/tracker/sla",
        "ops_governance_remediation_tracker_escalate_run_api": "/api/ops/governance/gate/remediation/tracker/escalate/run",
        "ops_governance_remediation_tracker_escalate_latest_api": "/api/ops/governance/gate/remediation/tracker/escalate/latest",
        "ops_security_posture_api": "/api/ops/security/posture",
        "handover_brief_api": "/api/ops/handover/brief",
        "handover_brief_csv_api": "/api/ops/handover/brief/csv",
        "handover_brief_pdf_api": "/api/ops/handover/brief/pdf",
        "public_adoption_plan_api": "/api/public/adoption-plan",
        "public_adoption_schedule_csv_api": "/api/public/adoption-plan/schedule.csv",
        "public_adoption_schedule_ics_api": "/api/public/adoption-plan/schedule.ics",
        "public_adoption_campaign_api": "/api/public/adoption-plan/campaign",
        "public_adoption_w02_api": "/api/public/adoption-plan/w02",
        "public_adoption_w02_checklist_csv_api": "/api/public/adoption-plan/w02/checklist.csv",
        "public_adoption_w02_schedule_ics_api": "/api/public/adoption-plan/w02/schedule.ics",
        "public_adoption_w02_sample_files_api": "/api/public/adoption-plan/w02/sample-files",
        "public_adoption_w03_api": "/api/public/adoption-plan/w03",
        "public_adoption_w03_checklist_csv_api": "/api/public/adoption-plan/w03/checklist.csv",
        "public_adoption_w03_schedule_ics_api": "/api/public/adoption-plan/w03/schedule.ics",
        "public_adoption_w04_api": "/api/public/adoption-plan/w04",
        "public_adoption_w04_checklist_csv_api": "/api/public/adoption-plan/w04/checklist.csv",
        "public_adoption_w04_schedule_ics_api": "/api/public/adoption-plan/w04/schedule.ics",
        "public_adoption_w04_common_mistakes_api": "/api/public/adoption-plan/w04/common-mistakes",
        "public_adoption_w04_common_mistakes_html": "/web/adoption/w04/common-mistakes",
        "public_adoption_w05_api": "/api/public/adoption-plan/w05",
        "public_adoption_w05_missions_csv_api": "/api/public/adoption-plan/w05/missions.csv",
        "public_adoption_w05_schedule_ics_api": "/api/public/adoption-plan/w05/schedule.ics",
        "public_adoption_w05_help_docs_api": "/api/public/adoption-plan/w05/help-docs",
        "public_adoption_w06_api": "/api/public/adoption-plan/w06",
        "public_adoption_w06_checklist_csv_api": "/api/public/adoption-plan/w06/checklist.csv",
        "public_adoption_w06_schedule_ics_api": "/api/public/adoption-plan/w06/schedule.ics",
        "public_adoption_w06_rbac_audit_template_api": "/api/public/adoption-plan/w06/rbac-audit-template",
        "public_adoption_w07_api": "/api/public/adoption-plan/w07",
        "public_adoption_w07_checklist_csv_api": "/api/public/adoption-plan/w07/checklist.csv",
        "public_adoption_w07_schedule_ics_api": "/api/public/adoption-plan/w07/schedule.ics",
        "public_adoption_w07_coaching_playbook_api": "/api/public/adoption-plan/w07/coaching-playbook",
        "public_adoption_w08_api": "/api/public/adoption-plan/w08",
        "public_adoption_w08_checklist_csv_api": "/api/public/adoption-plan/w08/checklist.csv",
        "public_adoption_w08_schedule_ics_api": "/api/public/adoption-plan/w08/schedule.ics",
        "public_adoption_w08_reporting_sop_api": "/api/public/adoption-plan/w08/reporting-sop",
        "public_adoption_w09_api": "/api/public/adoption-plan/w09",
        "public_adoption_w09_checklist_csv_api": "/api/public/adoption-plan/w09/checklist.csv",
        "public_adoption_w09_schedule_ics_api": "/api/public/adoption-plan/w09/schedule.ics",
        "public_adoption_w10_api": "/api/public/adoption-plan/w10",
        "public_adoption_w10_checklist_csv_api": "/api/public/adoption-plan/w10/checklist.csv",
        "public_adoption_w10_schedule_ics_api": "/api/public/adoption-plan/w10/schedule.ics",
        "public_adoption_w11_api": "/api/public/adoption-plan/w11",
        "public_adoption_w11_checklist_csv_api": "/api/public/adoption-plan/w11/checklist.csv",
        "public_adoption_w11_schedule_ics_api": "/api/public/adoption-plan/w11/schedule.ics",
        "public_adoption_w12_api": "/api/public/adoption-plan/w12",
        "public_adoption_w12_checklist_csv_api": "/api/public/adoption-plan/w12/checklist.csv",
        "public_adoption_w12_schedule_ics_api": "/api/public/adoption-plan/w12/schedule.ics",
        "public_adoption_w13_api": "/api/public/adoption-plan/w13",
        "public_adoption_w13_checklist_csv_api": "/api/public/adoption-plan/w13/checklist.csv",
        "public_adoption_w13_schedule_ics_api": "/api/public/adoption-plan/w13/schedule.ics",
        "public_adoption_w14_api": "/api/public/adoption-plan/w14",
        "public_adoption_w14_checklist_csv_api": "/api/public/adoption-plan/w14/checklist.csv",
        "public_adoption_w14_schedule_ics_api": "/api/public/adoption-plan/w14/schedule.ics",
        "public_adoption_w15_api": "/api/public/adoption-plan/w15",
        "public_adoption_w15_checklist_csv_api": "/api/public/adoption-plan/w15/checklist.csv",
        "public_adoption_w15_schedule_ics_api": "/api/public/adoption-plan/w15/schedule.ics",
        "adoption_w02_tracker_items_api": "/api/adoption/w02/tracker/items",
        "adoption_w02_tracker_overview_api": "/api/adoption/w02/tracker/overview",
        "adoption_w02_tracker_bootstrap_api": "/api/adoption/w02/tracker/bootstrap",
        "adoption_w02_tracker_readiness_api": "/api/adoption/w02/tracker/readiness",
        "adoption_w02_tracker_completion_api": "/api/adoption/w02/tracker/completion",
        "adoption_w02_tracker_complete_api": "/api/adoption/w02/tracker/complete",
        "adoption_w03_tracker_items_api": "/api/adoption/w03/tracker/items",
        "adoption_w03_tracker_overview_api": "/api/adoption/w03/tracker/overview",
        "adoption_w03_tracker_bootstrap_api": "/api/adoption/w03/tracker/bootstrap",
        "adoption_w03_tracker_readiness_api": "/api/adoption/w03/tracker/readiness",
        "adoption_w03_tracker_completion_api": "/api/adoption/w03/tracker/completion",
        "adoption_w03_tracker_complete_api": "/api/adoption/w03/tracker/complete",
        "adoption_w04_funnel_api": "/api/ops/adoption/w04/funnel",
        "adoption_w04_blockers_api": "/api/ops/adoption/w04/blockers",
        "adoption_w04_tracker_items_api": "/api/adoption/w04/tracker/items",
        "adoption_w04_tracker_overview_api": "/api/adoption/w04/tracker/overview",
        "adoption_w04_tracker_bootstrap_api": "/api/adoption/w04/tracker/bootstrap",
        "adoption_w04_tracker_readiness_api": "/api/adoption/w04/tracker/readiness",
        "adoption_w04_tracker_completion_api": "/api/adoption/w04/tracker/completion",
        "adoption_w04_tracker_complete_api": "/api/adoption/w04/tracker/complete",
        "adoption_w07_tracker_items_api": "/api/adoption/w07/tracker/items",
        "adoption_w07_tracker_overview_api": "/api/adoption/w07/tracker/overview",
        "adoption_w07_tracker_bootstrap_api": "/api/adoption/w07/tracker/bootstrap",
        "adoption_w07_tracker_readiness_api": "/api/adoption/w07/tracker/readiness",
        "adoption_w07_tracker_completion_api": "/api/adoption/w07/tracker/completion",
        "adoption_w07_tracker_completion_package_api": "/api/adoption/w07/tracker/completion-package",
        "adoption_w07_tracker_complete_api": "/api/adoption/w07/tracker/complete",
        "adoption_w09_tracker_items_api": "/api/adoption/w09/tracker/items",
        "adoption_w09_tracker_overview_api": "/api/adoption/w09/tracker/overview",
        "adoption_w09_tracker_bootstrap_api": "/api/adoption/w09/tracker/bootstrap",
        "adoption_w09_tracker_readiness_api": "/api/adoption/w09/tracker/readiness",
        "adoption_w09_tracker_completion_api": "/api/adoption/w09/tracker/completion",
        "adoption_w09_tracker_complete_api": "/api/adoption/w09/tracker/complete",
        "adoption_w10_tracker_items_api": "/api/adoption/w10/tracker/items",
        "adoption_w10_tracker_overview_api": "/api/adoption/w10/tracker/overview",
        "adoption_w10_tracker_bootstrap_api": "/api/adoption/w10/tracker/bootstrap",
        "adoption_w10_tracker_readiness_api": "/api/adoption/w10/tracker/readiness",
        "adoption_w10_tracker_completion_api": "/api/adoption/w10/tracker/completion",
        "adoption_w10_tracker_complete_api": "/api/adoption/w10/tracker/complete",
        "adoption_w11_tracker_items_api": "/api/adoption/w11/tracker/items",
        "adoption_w11_tracker_overview_api": "/api/adoption/w11/tracker/overview",
        "adoption_w11_tracker_bootstrap_api": "/api/adoption/w11/tracker/bootstrap",
        "adoption_w11_tracker_readiness_api": "/api/adoption/w11/tracker/readiness",
        "adoption_w11_tracker_completion_api": "/api/adoption/w11/tracker/completion",
        "adoption_w11_tracker_complete_api": "/api/adoption/w11/tracker/complete",
        "adoption_w12_tracker_items_api": "/api/adoption/w12/tracker/items",
        "adoption_w12_tracker_overview_api": "/api/adoption/w12/tracker/overview",
        "adoption_w12_tracker_bootstrap_api": "/api/adoption/w12/tracker/bootstrap",
        "adoption_w12_tracker_readiness_api": "/api/adoption/w12/tracker/readiness",
        "adoption_w12_tracker_completion_api": "/api/adoption/w12/tracker/completion",
        "adoption_w12_tracker_complete_api": "/api/adoption/w12/tracker/complete",
        "adoption_w13_tracker_items_api": "/api/adoption/w13/tracker/items",
        "adoption_w13_tracker_overview_api": "/api/adoption/w13/tracker/overview",
        "adoption_w13_tracker_bootstrap_api": "/api/adoption/w13/tracker/bootstrap",
        "adoption_w13_tracker_readiness_api": "/api/adoption/w13/tracker/readiness",
        "adoption_w13_tracker_completion_api": "/api/adoption/w13/tracker/completion",
        "adoption_w13_tracker_complete_api": "/api/adoption/w13/tracker/complete",
        "adoption_w14_tracker_items_api": "/api/adoption/w14/tracker/items",
        "adoption_w14_tracker_overview_api": "/api/adoption/w14/tracker/overview",
        "adoption_w14_tracker_bootstrap_api": "/api/adoption/w14/tracker/bootstrap",
        "adoption_w14_tracker_readiness_api": "/api/adoption/w14/tracker/readiness",
        "adoption_w14_tracker_completion_api": "/api/adoption/w14/tracker/completion",
        "adoption_w14_tracker_complete_api": "/api/adoption/w14/tracker/complete",
        "adoption_w15_tracker_items_api": "/api/adoption/w15/tracker/items",
        "adoption_w15_tracker_overview_api": "/api/adoption/w15/tracker/overview",
        "adoption_w15_tracker_bootstrap_api": "/api/adoption/w15/tracker/bootstrap",
        "adoption_w15_tracker_readiness_api": "/api/adoption/w15/tracker/readiness",
        "adoption_w15_tracker_completion_api": "/api/adoption/w15/tracker/completion",
        "adoption_w15_tracker_complete_api": "/api/adoption/w15/tracker/complete",
        "adoption_w05_consistency_api": "/api/ops/adoption/w05/consistency",
        "adoption_w06_rhythm_api": "/api/ops/adoption/w06/rhythm",
        "adoption_w07_sla_quality_api": "/api/ops/adoption/w07/sla-quality",
        "adoption_w07_automation_readiness_api": "/api/ops/adoption/w07/automation-readiness",
        "adoption_w07_sla_quality_weekly_run_api": "/api/ops/adoption/w07/sla-quality/run-weekly",
        "adoption_w07_sla_quality_weekly_latest_api": "/api/ops/adoption/w07/sla-quality/latest-weekly",
        "adoption_w07_sla_quality_weekly_trends_api": "/api/ops/adoption/w07/sla-quality/trends",
        "adoption_w07_sla_quality_weekly_archive_csv_api": "/api/ops/adoption/w07/sla-quality/archive.csv",
        "adoption_w08_report_discipline_api": "/api/ops/adoption/w08/report-discipline",
        "adoption_w08_site_benchmark_api": "/api/ops/adoption/w08/site-benchmark",
        "adoption_w09_kpi_operation_api": "/api/ops/adoption/w09/kpi-operation",
        "adoption_w09_kpi_policy_api": "/api/ops/adoption/w09/kpi-policy",
        "adoption_w10_self_serve_api": "/api/ops/adoption/w10/self-serve",
        "adoption_w10_support_policy_api": "/api/ops/adoption/w10/support-policy",
        "adoption_w11_scale_readiness_api": "/api/ops/adoption/w11/scale-readiness",
        "adoption_w11_readiness_policy_api": "/api/ops/adoption/w11/readiness-policy",
        "adoption_w12_closure_handoff_api": "/api/ops/adoption/w12/closure-handoff",
        "adoption_w12_handoff_policy_api": "/api/ops/adoption/w12/handoff-policy",
        "adoption_w13_closure_handoff_api": "/api/ops/adoption/w13/closure-handoff",
        "adoption_w13_handoff_policy_api": "/api/ops/adoption/w13/handoff-policy",
        "adoption_w14_stability_sprint_api": "/api/ops/adoption/w14/stability-sprint",
        "adoption_w14_stability_policy_api": "/api/ops/adoption/w14/stability-policy",
        "adoption_w15_ops_efficiency_api": "/api/ops/adoption/w15/ops-efficiency",
        "adoption_w15_efficiency_policy_api": "/api/ops/adoption/w15/efficiency-policy",
        "public_post_mvp_plan_api": "/api/public/post-mvp",
        "public_post_mvp_backlog_csv_api": "/api/public/post-mvp/backlog.csv",
        "public_post_mvp_release_ics_api": "/api/public/post-mvp/releases.ics",
        "public_post_mvp_kpi_api": "/api/public/post-mvp/kpi-dashboard",
        "public_post_mvp_risks_api": "/api/public/post-mvp/risks",
        "public_modules_api": "/api/public/modules",
        "adoption_portal_html": "/web/adoption",
        "facility_console_html": "/web/console",
        "alert_deliveries_api": "/api/ops/alerts/deliveries",
        "alert_channel_kpi_api": "/api/ops/alerts/kpi/channels",
        "alert_channel_mttr_kpi_api": "/api/ops/alerts/kpi/mttr",
        "alert_mttr_slo_policy_api": "/api/ops/alerts/mttr-slo/policy",
        "alert_mttr_slo_run_api": "/api/ops/alerts/mttr-slo/check/run",
        "alert_mttr_slo_latest_api": "/api/ops/alerts/mttr-slo/check/latest",
        "alert_channel_guard_api": "/api/ops/alerts/channels/guard",
        "alert_channel_guard_recover_api": "/api/ops/alerts/channels/guard/recover",
        "alert_channel_guard_recover_batch_api": "/api/ops/alerts/channels/guard/recover-batch",
        "alert_channel_guard_recover_latest_api": "/api/ops/alerts/channels/guard/recover/latest",
        "alert_retry_api": "/api/ops/alerts/retries/run",
        "alert_retention_policy_api": "/api/ops/alerts/retention/policy",
        "alert_retention_latest_api": "/api/ops/alerts/retention/latest",
        "alert_retention_run_api": "/api/ops/alerts/retention/run",
        "sla_simulator_api": "/api/ops/sla/simulate",
        "sla_policy_api": "/api/admin/policies/sla",
        "sla_policy_proposals_api": "/api/admin/policies/sla/proposals",
        "sla_policy_revisions_api": "/api/admin/policies/sla/revisions",
        "workflow_locks_api": "/api/workflow-locks",
    }


def _adoption_plan_payload() -> dict[str, Any]:
    today = datetime.now(timezone.utc).date()
    next_review_date = ADOPTION_PLAN_END.isoformat()
    for item in ADOPTION_WEEKLY_EXECUTION:
        week_end = date.fromisoformat(str(item["end_date"]))
        if week_end >= today:
            next_review_date = week_end.isoformat()
            break

    return {
        "title": "KA Facility OS    (User Adoption Plan)",
        "published_on": "2026-02-27",
        "public": True,
        "timeline": {
            "start_date": ADOPTION_PLAN_START.isoformat(),
            "end_date": ADOPTION_PLAN_END.isoformat(),
            "duration_weeks": len(ADOPTION_WEEKLY_EXECUTION),
        },
        "weekly_execution": ADOPTION_WEEKLY_EXECUTION,
        "workflow_lock_matrix": ADOPTION_WORKFLOW_LOCK_MATRIX,
        "w02_sop_sandbox": _adoption_w02_payload(),
        "w03_go_live_onboarding": _adoption_w03_payload(),
        "w04_first_success_acceleration": _adoption_w04_payload(),
        "w05_usage_consistency": _adoption_w05_payload(),
        "w06_operational_rhythm": _adoption_w06_payload(),
        "w07_sla_quality": _adoption_w07_payload(),
        "w08_report_discipline": _adoption_w08_payload(),
        "w09_kpi_operation": _adoption_w09_payload(),
        "w10_self_serve_support": _adoption_w10_payload(),
        "w11_scale_readiness": _adoption_w11_payload(),
        "w12_closure_handoff": _adoption_w12_payload(),
        "w13_continuous_improvement": _adoption_w13_payload(),
        "w14_stability_sprint": _adoption_w14_payload(),
        "w15_operations_efficiency": _adoption_w15_payload(),
        "training_outline": ADOPTION_TRAINING_OUTLINE,
        "kpi_dashboard_items": ADOPTION_KPI_DASHBOARD_ITEMS,
        "campaign_kit": {
            "promotion": ADOPTION_PROMOTION_PACK,
            "education": ADOPTION_EDUCATION_PACK,
            "fun": ADOPTION_FUN_PACK,
        },
        "schedule_management": {
            "cadence": [
                "Monday 09:00: Weekly kickoff and role mission assignment",
                "Wednesday 16:00: Mid-week checkpoint and blocker removal",
                "Friday 17:00: KPI review and next-week plan confirmation",
            ],
            "downloads": {
                "schedule_csv": "/api/public/adoption-plan/schedule.csv",
                "schedule_ics": "/api/public/adoption-plan/schedule.ics",
                "w02_json": "/api/public/adoption-plan/w02",
                "w02_checklist_csv": "/api/public/adoption-plan/w02/checklist.csv",
                "w02_schedule_ics": "/api/public/adoption-plan/w02/schedule.ics",
                "w02_sample_files": "/api/public/adoption-plan/w02/sample-files",
                "w03_json": "/api/public/adoption-plan/w03",
                "w03_checklist_csv": "/api/public/adoption-plan/w03/checklist.csv",
                "w03_schedule_ics": "/api/public/adoption-plan/w03/schedule.ics",
                "w04_json": "/api/public/adoption-plan/w04",
                "w04_checklist_csv": "/api/public/adoption-plan/w04/checklist.csv",
                "w04_schedule_ics": "/api/public/adoption-plan/w04/schedule.ics",
                "w04_common_mistakes": "/api/public/adoption-plan/w04/common-mistakes",
                "w05_json": "/api/public/adoption-plan/w05",
                "w05_missions_csv": "/api/public/adoption-plan/w05/missions.csv",
                "w05_schedule_ics": "/api/public/adoption-plan/w05/schedule.ics",
                "w05_help_docs": "/api/public/adoption-plan/w05/help-docs",
                "w06_json": "/api/public/adoption-plan/w06",
                "w06_checklist_csv": "/api/public/adoption-plan/w06/checklist.csv",
                "w06_schedule_ics": "/api/public/adoption-plan/w06/schedule.ics",
                "w06_rbac_audit_template": "/api/public/adoption-plan/w06/rbac-audit-template",
                "w07_json": "/api/public/adoption-plan/w07",
                "w07_checklist_csv": "/api/public/adoption-plan/w07/checklist.csv",
                "w07_schedule_ics": "/api/public/adoption-plan/w07/schedule.ics",
                "w07_coaching_playbook": "/api/public/adoption-plan/w07/coaching-playbook",
                "w08_json": "/api/public/adoption-plan/w08",
                "w08_checklist_csv": "/api/public/adoption-plan/w08/checklist.csv",
                "w08_schedule_ics": "/api/public/adoption-plan/w08/schedule.ics",
                "w08_reporting_sop": "/api/public/adoption-plan/w08/reporting-sop",
                "w09_json": "/api/public/adoption-plan/w09",
                "w09_checklist_csv": "/api/public/adoption-plan/w09/checklist.csv",
                "w09_schedule_ics": "/api/public/adoption-plan/w09/schedule.ics",
                "w10_json": "/api/public/adoption-plan/w10",
                "w10_checklist_csv": "/api/public/adoption-plan/w10/checklist.csv",
                "w10_schedule_ics": "/api/public/adoption-plan/w10/schedule.ics",
                "w11_json": "/api/public/adoption-plan/w11",
                "w11_checklist_csv": "/api/public/adoption-plan/w11/checklist.csv",
                "w11_schedule_ics": "/api/public/adoption-plan/w11/schedule.ics",
                "w12_json": "/api/public/adoption-plan/w12",
                "w12_checklist_csv": "/api/public/adoption-plan/w12/checklist.csv",
                "w12_schedule_ics": "/api/public/adoption-plan/w12/schedule.ics",
                "w13_json": "/api/public/adoption-plan/w13",
                "w13_checklist_csv": "/api/public/adoption-plan/w13/checklist.csv",
                "w13_schedule_ics": "/api/public/adoption-plan/w13/schedule.ics",
                "w14_json": "/api/public/adoption-plan/w14",
                "w14_checklist_csv": "/api/public/adoption-plan/w14/checklist.csv",
                "w14_schedule_ics": "/api/public/adoption-plan/w14/schedule.ics",
                "w15_json": "/api/public/adoption-plan/w15",
                "w15_checklist_csv": "/api/public/adoption-plan/w15/checklist.csv",
                "w15_schedule_ics": "/api/public/adoption-plan/w15/schedule.ics",
            },
            "next_review_date": next_review_date,
        },
    }


def _adoption_w02_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 2),
        None,
    )
    if week_item is None:
        timeline = {"week": 2, "start_date": "", "end_date": "", "phase": "Preparation", "focus": "SOP and sandbox"}
    else:
        timeline = {
            "week": int(week_item.get("week", 2)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W02 Scheduled SOP and Sandbox Pack",
        "public": True,
        "timeline": timeline,
        "sop_runbooks": ADOPTION_W02_SOP_RUNBOOKS,
        "sandbox_scenarios": ADOPTION_W02_SANDBOX_SCENARIOS,
        "scheduled_events": ADOPTION_W02_SCHEDULED_EVENTS,
        "downloads": {
            "json": "/api/public/adoption-plan/w02",
            "checklist_csv": "/api/public/adoption-plan/w02/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w02/schedule.ics",
            "sample_files": "/api/public/adoption-plan/w02/sample-files",
        },
    }


def _adoption_w03_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 3),
        None,
    )
    if week_item is None:
        timeline = {"week": 3, "start_date": "", "end_date": "", "phase": "Launch", "focus": "Go-live onboarding"}
    else:
        timeline = {
            "week": int(week_item.get("week", 3)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W03 Go-live Onboarding Pack",
        "public": True,
        "timeline": timeline,
        "kickoff_agenda": ADOPTION_W03_KICKOFF_AGENDA,
        "role_workshops": ADOPTION_W03_ROLE_WORKSHOPS,
        "office_hours": ADOPTION_W03_OFFICE_HOURS,
        "scheduled_events": ADOPTION_W03_SCHEDULED_EVENTS,
        "downloads": {
            "json": "/api/public/adoption-plan/w03",
            "checklist_csv": "/api/public/adoption-plan/w03/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w03/schedule.ics",
        },
    }


def _adoption_w04_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 4),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 4,
            "start_date": "",
            "end_date": "",
            "phase": "Adaptation",
            "focus": "First success acceleration",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 4)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W04 First Success Acceleration Pack",
        "public": True,
        "timeline": timeline,
        "coaching_actions": ADOPTION_W04_COACHING_ACTIONS,
        "scheduled_events": ADOPTION_W04_SCHEDULED_EVENTS,
        "common_mistakes_reference": "/api/public/adoption-plan/w04/common-mistakes",
        "downloads": {
            "json": "/api/public/adoption-plan/w04",
            "checklist_csv": "/api/public/adoption-plan/w04/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w04/schedule.ics",
            "common_mistakes": "/api/public/adoption-plan/w04/common-mistakes",
        },
    }


def _build_adoption_w04_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "champion_role",
            "action",
            "owner",
            "due_hint",
            "objective",
            "evidence_required",
            "quick_fix",
        ]
    )
    for item in payload.get("coaching_actions", []):
        writer.writerow(
            [
                "coaching_action",
                item.get("id", ""),
                item.get("champion_role", ""),
                item.get("action", ""),
                item.get("owner", ""),
                item.get("due_hint", ""),
                item.get("objective", ""),
                item.get("evidence_required", False),
                item.get("quick_fix", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
                "",
                "",
                item.get("output", ""),
            ]
        )
    return out.getvalue()


def _build_adoption_w04_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w04-{str(item.get('id', '')).lower()}@public"
        summary = f"[W04] {str(item.get('title', 'First Success Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W04 First Success Acceleration//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _build_adoption_w03_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "name_or_role",
            "owner_or_trainer",
            "schedule",
            "objective_or_focus",
            "checklist_or_channel",
            "duration_min",
            "expected_output_or_success",
        ]
    )
    for item in payload.get("kickoff_agenda", []):
        writer.writerow(
            [
                "kickoff_agenda",
                item.get("id", ""),
                item.get("topic", ""),
                item.get("owner", ""),
                "",
                item.get("objective", ""),
                "",
                item.get("duration_min", ""),
                item.get("expected_output", ""),
            ]
        )
    for item in payload.get("role_workshops", []):
        writer.writerow(
            [
                "role_workshop",
                item.get("id", ""),
                item.get("role", ""),
                item.get("trainer", ""),
                "",
                item.get("objective", ""),
                " | ".join(str(x) for x in item.get("checklist", [])),
                item.get("duration_min", ""),
                item.get("success_criteria", ""),
            ]
        )
    for item in payload.get("office_hours", []):
        writer.writerow(
            [
                "office_hour",
                item.get("id", ""),
                "Daily office hour",
                item.get("host", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
                item.get("focus", ""),
                item.get("channel", ""),
                "",
                "",
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                item.get("title", ""),
                item.get("owner", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
                "",
                "",
                "",
                item.get("output", ""),
            ]
        )
    return out.getvalue()


def _build_adoption_w03_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w03-{str(item.get('id', '')).lower()}@public"
        summary = f"[W03] {str(item.get('title', 'Go-live Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W03 Go-live Onboarding//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w05_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 5),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 5,
            "start_date": "",
            "end_date": "",
            "phase": "Adaptation",
            "focus": "Usage consistency",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 5)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W05 Usage Consistency Pack",
        "public": True,
        "timeline": timeline,
        "role_missions": ADOPTION_W05_ROLE_MISSIONS,
        "scheduled_events": ADOPTION_W05_SCHEDULED_EVENTS,
        "help_docs": ADOPTION_W05_HELP_DOCS,
        "usage_consistency_api": "/api/ops/adoption/w05/consistency",
        "downloads": {
            "json": "/api/public/adoption-plan/w05",
            "missions_csv": "/api/public/adoption-plan/w05/missions.csv",
            "schedule_ics": "/api/public/adoption-plan/w05/schedule.ics",
            "help_docs": "/api/public/adoption-plan/w05/help-docs",
        },
    }


def _build_adoption_w05_missions_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "role",
            "mission",
            "weekly_target",
            "owner",
            "evidence_required",
            "evidence_hint",
        ]
    )
    for item in payload.get("role_missions", []):
        writer.writerow(
            [
                "role_mission",
                item.get("id", ""),
                item.get("role", ""),
                item.get("mission", ""),
                item.get("weekly_target", ""),
                item.get("owner", ""),
                item.get("evidence_required", False),
                item.get("evidence_hint", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
                item.get("owner", ""),
                "",
                item.get("output", ""),
            ]
        )
    return out.getvalue()


def _build_adoption_w05_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w05-{str(item.get('id', '')).lower()}@public"
        summary = f"[W05] {str(item.get('title', 'Usage Consistency Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W05 Usage Consistency//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w06_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 6),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 6,
            "start_date": "",
            "end_date": "",
            "phase": "Habit",
            "focus": "Operational rhythm",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 6)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W06 Operational Rhythm Pack",
        "public": True,
        "timeline": timeline,
        "rhythm_checklist": ADOPTION_W06_RHYTHM_CHECKLIST,
        "scheduled_events": ADOPTION_W06_SCHEDULED_EVENTS,
        "rbac_audit_checklist": ADOPTION_W06_RBAC_AUDIT_CHECKLIST,
        "rhythm_api": "/api/ops/adoption/w06/rhythm",
        "downloads": {
            "json": "/api/public/adoption-plan/w06",
            "checklist_csv": "/api/public/adoption-plan/w06/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w06/schedule.ics",
            "rbac_audit_template": "/api/public/adoption-plan/w06/rbac-audit-template",
        },
    }


def _build_adoption_w06_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "day_or_control",
            "routine_or_objective",
            "owner_or_api_ref",
            "definition_of_done_or_pass_criteria",
            "evidence_hint",
        ]
    )
    for item in payload.get("rhythm_checklist", []):
        writer.writerow(
            [
                "rhythm_checklist",
                item.get("id", ""),
                item.get("day", ""),
                item.get("routine", ""),
                item.get("owner_role", ""),
                item.get("definition_of_done", ""),
                item.get("evidence_hint", ""),
            ]
        )
    for item in payload.get("rbac_audit_checklist", []):
        writer.writerow(
            [
                "rbac_audit",
                item.get("id", ""),
                item.get("control", ""),
                item.get("objective", ""),
                item.get("api_ref", ""),
                item.get("pass_criteria", ""),
                "",
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                item.get("date", ""),
                item.get("title", ""),
                item.get("owner", ""),
                item.get("output", ""),
                f"{item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w06_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w06-{str(item.get('id', '')).lower()}@public"
        summary = f"[W06] {str(item.get('title', 'Operational Rhythm Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W06 Operational Rhythm//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w07_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 7),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 7,
            "start_date": "",
            "end_date": "",
            "phase": "Habit",
            "focus": "SLA quality",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 7)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W07 SLA Quality Pack",
        "public": True,
        "timeline": timeline,
        "sla_checklist": ADOPTION_W07_SLA_CHECKLIST,
        "coaching_plays": ADOPTION_W07_COACHING_PLAYS,
        "scheduled_events": ADOPTION_W07_SCHEDULED_EVENTS,
        "sla_quality_api": "/api/ops/adoption/w07/sla-quality",
        "downloads": {
            "json": "/api/public/adoption-plan/w07",
            "checklist_csv": "/api/public/adoption-plan/w07/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w07/schedule.ics",
            "coaching_playbook": "/api/public/adoption-plan/w07/coaching-playbook",
        },
    }


def _build_adoption_w07_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "cadence_or_trigger",
            "control_or_play",
            "owner",
            "target_or_expected_impact",
            "definition_of_done_or_evidence",
            "api_ref",
        ]
    )
    for item in payload.get("sla_checklist", []):
        writer.writerow(
            [
                "sla_checklist",
                item.get("id", ""),
                item.get("cadence", ""),
                item.get("control", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                item.get("definition_of_done", ""),
                "",
            ]
        )
    for item in payload.get("coaching_plays", []):
        writer.writerow(
            [
                "coaching_play",
                item.get("id", ""),
                item.get("trigger", ""),
                item.get("play", ""),
                item.get("owner", ""),
                item.get("expected_impact", ""),
                item.get("evidence_hint", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                item.get("date", ""),
                item.get("title", ""),
                item.get("owner", ""),
                item.get("output", ""),
                f"{item.get('start_time', '')}-{item.get('end_time', '')}",
                "",
            ]
        )
    return out.getvalue()


def _build_adoption_w07_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w07-{str(item.get('id', '')).lower()}@public"
        summary = f"[W07] {str(item.get('title', 'SLA Quality Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W07 SLA Quality//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w08_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 8),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 8,
            "start_date": "",
            "end_date": "",
            "phase": "Habit",
            "focus": "Report discipline",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 8)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W08 Report Discipline Pack",
        "public": True,
        "timeline": timeline,
        "report_discipline_checklist": ADOPTION_W08_REPORT_DISCIPLINE_CHECKLIST,
        "data_quality_controls": ADOPTION_W08_DATA_QUALITY_CONTROLS,
        "scheduled_events": ADOPTION_W08_SCHEDULED_EVENTS,
        "reporting_sop": ADOPTION_W08_REPORTING_SOP,
        "report_discipline_api": "/api/ops/adoption/w08/report-discipline",
        "site_benchmark_api": "/api/ops/adoption/w08/site-benchmark",
        "downloads": {
            "json": "/api/public/adoption-plan/w08",
            "checklist_csv": "/api/public/adoption-plan/w08/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w08/schedule.ics",
            "reporting_sop": "/api/public/adoption-plan/w08/reporting-sop",
        },
    }


def _build_adoption_w08_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "cadence_or_control",
            "discipline_or_objective",
            "owner_or_api_ref",
            "target_or_pass_criteria",
            "definition_of_done_or_evidence",
            "api_ref",
        ]
    )
    for item in payload.get("report_discipline_checklist", []):
        writer.writerow(
            [
                "report_discipline",
                item.get("id", ""),
                item.get("cadence", ""),
                item.get("discipline", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("data_quality_controls", []):
        writer.writerow(
            [
                "data_quality_control",
                item.get("id", ""),
                item.get("control", ""),
                item.get("objective", ""),
                item.get("api_ref", ""),
                item.get("pass_criteria", ""),
                "",
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                item.get("date", ""),
                item.get("title", ""),
                item.get("owner", ""),
                item.get("output", ""),
                f"{item.get('start_time', '')}-{item.get('end_time', '')}",
                "",
            ]
        )
    return out.getvalue()


def _build_adoption_w08_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w08-{str(item.get('id', '')).lower()}@public"
        summary = f"[W08] {str(item.get('title', 'Report Discipline Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W08 Report Discipline//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w09_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 9),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 9,
            "start_date": "",
            "end_date": "",
            "phase": "Autonomy",
            "focus": "Shift to KPI operation",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 9)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }
    return {
        "title": "W09 KPI Operation Pack",
        "public": True,
        "timeline": timeline,
        "kpi_threshold_matrix": ADOPTION_W09_KPI_THRESHOLD_MATRIX,
        "escalation_map": ADOPTION_W09_ESCALATION_MAP,
        "scheduled_events": ADOPTION_W09_SCHEDULED_EVENTS,
        "kpi_operation_api": "/api/ops/adoption/w09/kpi-operation",
        "kpi_policy_api": "/api/ops/adoption/w09/kpi-policy",
        "tracker_items_api": "/api/adoption/w09/tracker/items",
        "tracker_overview_api": "/api/adoption/w09/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w09",
            "checklist_csv": "/api/public/adoption-plan/w09/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w09/schedule.ics",
        },
    }


def _build_adoption_w09_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "kpi_or_event_key",
            "name_or_title",
            "owner_or_escalate_to",
            "direction_or_condition",
            "green_or_sla_hours",
            "yellow_or_action",
            "target_or_output",
            "source_or_time",
        ]
    )
    for item in payload.get("kpi_threshold_matrix", []):
        writer.writerow(
            [
                "kpi_threshold",
                item.get("id", ""),
                item.get("kpi_key", ""),
                item.get("kpi_name", ""),
                item.get("owner_role", ""),
                item.get("direction", ""),
                item.get("green_threshold", ""),
                item.get("yellow_threshold", ""),
                item.get("target", ""),
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("escalation_map", []):
        writer.writerow(
            [
                "escalation_map",
                item.get("id", ""),
                item.get("kpi_key", ""),
                "",
                item.get("escalate_to", ""),
                item.get("condition", ""),
                item.get("sla_hours", ""),
                item.get("action", ""),
                "",
                "",
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                "",
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w09_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w09-{str(item.get('id', '')).lower()}@public"
        summary = f"[W09] {str(item.get('title', 'KPI Operation Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W09 KPI Operation//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w10_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 10),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 10,
            "start_date": "",
            "end_date": "",
            "phase": "Autonomy",
            "focus": "Self-serve support",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 10)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W10 Self-serve Support Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W10_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W10_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W10_SCHEDULED_EVENTS,
        "self_serve_api": "/api/ops/adoption/w10/self-serve",
        "support_policy_api": "/api/ops/adoption/w10/support-policy",
        "tracker_items_api": "/api/adoption/w10/tracker/items",
        "tracker_overview_api": "/api/adoption/w10/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w10",
            "checklist_csv": "/api/public/adoption-plan/w10/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w10/schedule.ics",
        },
    }


def _build_adoption_w10_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w10_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w10-{str(item.get('id', '')).lower()}@public"
        summary = f"[W10] {str(item.get('title', 'Self-serve Support Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W10 Self-serve Support//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"



def _adoption_w11_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 11),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 11,
            "start_date": "",
            "end_date": "",
            "phase": "Autonomy",
            "focus": "Scale readiness",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 11)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W11 Scale Readiness Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W11_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W11_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W11_SCHEDULED_EVENTS,
        "scale_readiness_api": "/api/ops/adoption/w11/scale-readiness",
        "readiness_policy_api": "/api/ops/adoption/w11/readiness-policy",
        "tracker_items_api": "/api/adoption/w11/tracker/items",
        "tracker_overview_api": "/api/adoption/w11/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w11",
            "checklist_csv": "/api/public/adoption-plan/w11/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w11/schedule.ics",
        },
    }


def _build_adoption_w11_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w11_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w11-{str(item.get('id', '')).lower()}@public"
        summary = f"[W11] {str(item.get('title', 'Scale Readiness Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W11 Scale Readiness//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w12_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 12),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 12,
            "start_date": "",
            "end_date": "",
            "phase": "Autonomy",
            "focus": "Closure and handoff",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 12)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W12 Closure and Handoff Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W12_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W12_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W12_SCHEDULED_EVENTS,
        "closure_handoff_api": "/api/ops/adoption/w12/closure-handoff",
        "handoff_policy_api": "/api/ops/adoption/w12/handoff-policy",
        "tracker_items_api": "/api/adoption/w12/tracker/items",
        "tracker_overview_api": "/api/adoption/w12/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w12",
            "checklist_csv": "/api/public/adoption-plan/w12/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w12/schedule.ics",
        },
    }


def _build_adoption_w12_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w12_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w12-{str(item.get('id', '')).lower()}@public"
        summary = f"[W12] {str(item.get('title', 'Closure and Handoff Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W12 Closure and Handoff//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"



def _adoption_w13_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 13),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 13,
            "start_date": "",
            "end_date": "",
            "phase": "Autonomy",
            "focus": "Continuous improvement",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 13)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W13 Continuous Improvement Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W13_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W13_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W13_SCHEDULED_EVENTS,
        "closure_handoff_api": "/api/ops/adoption/w13/closure-handoff",
        "handoff_policy_api": "/api/ops/adoption/w13/handoff-policy",
        "tracker_items_api": "/api/adoption/w13/tracker/items",
        "tracker_overview_api": "/api/adoption/w13/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w13",
            "checklist_csv": "/api/public/adoption-plan/w13/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w13/schedule.ics",
        },
    }


def _build_adoption_w13_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w13_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w13-{str(item.get('id', '')).lower()}@public"
        summary = f"[W13] {str(item.get('title', 'Continuous Improvement Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W13 Continuous Improvement//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _adoption_w14_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 14),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 14,
            "start_date": "",
            "end_date": "",
            "phase": "Stabilize",
            "focus": "Stability sprint",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 14)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W14 Stability Sprint Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W14_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W14_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W14_SCHEDULED_EVENTS,
        "stability_sprint_api": "/api/ops/adoption/w14/stability-sprint",
        "stability_policy_api": "/api/ops/adoption/w14/stability-policy",
        "tracker_items_api": "/api/adoption/w14/tracker/items",
        "tracker_overview_api": "/api/adoption/w14/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w14",
            "checklist_csv": "/api/public/adoption-plan/w14/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w14/schedule.ics",
        },
    }


def _build_adoption_w14_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w14_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w14-{str(item.get('id', '')).lower()}@public"
        summary = f"[W14] {str(item.get('title', 'Stability Sprint Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W14 Stability Sprint//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"




def _adoption_w15_payload() -> dict[str, Any]:
    week_item = next(
        (item for item in ADOPTION_WEEKLY_EXECUTION if int(item.get("week", 0)) == 15),
        None,
    )
    if week_item is None:
        timeline = {
            "week": 15,
            "start_date": "",
            "end_date": "",
            "phase": "Optimize",
            "focus": "Operations efficiency",
        }
    else:
        timeline = {
            "week": int(week_item.get("week", 15)),
            "start_date": str(week_item.get("start_date", "")),
            "end_date": str(week_item.get("end_date", "")),
            "phase": str(week_item.get("phase", "")),
            "focus": str(week_item.get("focus", "")),
            "owner": str(week_item.get("owner", "")),
            "success_metric": str(week_item.get("success_metric", "")),
        }

    return {
        "title": "W15 Operations Efficiency Pack",
        "public": True,
        "timeline": timeline,
        "self_serve_guides": ADOPTION_W15_SELF_SERVE_GUIDES,
        "troubleshooting_runbook": ADOPTION_W15_TROUBLESHOOTING_RUNBOOK,
        "scheduled_events": ADOPTION_W15_SCHEDULED_EVENTS,
        "ops_efficiency_api": "/api/ops/adoption/w15/ops-efficiency",
        "efficiency_policy_api": "/api/ops/adoption/w15/efficiency-policy",
        "tracker_items_api": "/api/adoption/w15/tracker/items",
        "tracker_overview_api": "/api/adoption/w15/tracker/overview",
        "downloads": {
            "json": "/api/public/adoption-plan/w15",
            "checklist_csv": "/api/public/adoption-plan/w15/checklist.csv",
            "schedule_ics": "/api/public/adoption-plan/w15/schedule.ics",
        },
    }


def _build_adoption_w15_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "key_or_module",
            "name_or_symptom",
            "owner_role",
            "objective_or_target",
            "definition_or_output",
            "api_or_time",
        ]
    )
    for item in payload.get("self_serve_guides", []):
        writer.writerow(
            [
                "self_serve_guide",
                item.get("id", ""),
                item.get("problem_cluster", ""),
                item.get("title", ""),
                item.get("owner_role", ""),
                item.get("target", ""),
                "",
                item.get("source_api", ""),
            ]
        )
    for item in payload.get("troubleshooting_runbook", []):
        writer.writerow(
            [
                "troubleshooting_runbook",
                item.get("id", ""),
                item.get("module", ""),
                item.get("symptom", ""),
                item.get("owner_role", ""),
                "",
                item.get("definition_of_done", ""),
                item.get("api_ref", ""),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                "",
                item.get("title", ""),
                item.get("owner", ""),
                "",
                item.get("output", ""),
                f"{item.get('date', '')} {item.get('start_time', '')}-{item.get('end_time', '')}",
            ]
        )
    return out.getvalue()


def _build_adoption_w15_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w15-{str(item.get('id', '')).lower()}@public"
        summary = f"[W15] {str(item.get('title', 'Operations Efficiency Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W15 Operations Efficiency//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"






def _w02_sample_files_payload() -> dict[str, Any]:
    items: list[dict[str, Any]] = []
    for row in W02_SAMPLE_EVIDENCE_ARTIFACTS:
        sample_id = str(row.get("sample_id") or "").strip().lower()
        if not sample_id:
            continue
        items.append(
            {
                "sample_id": sample_id,
                "title": str(row.get("title") or ""),
                "description": str(row.get("description") or ""),
                "file_name": str(row.get("file_name") or f"{sample_id}.txt"),
                "content_type": str(row.get("content_type") or "text/plain"),
                "tracker_item_type": str(row.get("tracker_item_type") or ""),
                "tracker_item_key": str(row.get("tracker_item_key") or ""),
                "download_url": f"/api/public/adoption-plan/w02/sample-files/{sample_id}",
            }
        )

    return {
        "title": "W02 Sample Evidence Files",
        "public": True,
        "count": len(items),
        "items": items,
    }


def _find_w02_sample_file(sample_id: str) -> dict[str, Any] | None:
    normalized = sample_id.strip().lower()
    if not normalized:
        return None
    for row in W02_SAMPLE_EVIDENCE_ARTIFACTS:
        if str(row.get("sample_id") or "").strip().lower() == normalized:
            return row
    return None


def _build_adoption_w02_checklist_csv(payload: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "section",
            "id",
            "name",
            "owner",
            "target_or_module",
            "trigger_or_objective",
            "checkpoints_or_pass_criteria",
            "duration_min",
            "definition_of_done_or_output",
        ]
    )
    for item in payload.get("sop_runbooks", []):
        writer.writerow(
            [
                "sop_runbook",
                item.get("id", ""),
                item.get("name", ""),
                item.get("owner", ""),
                ", ".join(str(x) for x in item.get("target_roles", [])),
                item.get("trigger", ""),
                " | ".join(str(x) for x in item.get("checkpoints", [])),
                "",
                item.get("definition_of_done", ""),
            ]
        )
    for item in payload.get("sandbox_scenarios", []):
        writer.writerow(
            [
                "sandbox_scenario",
                item.get("id", ""),
                item.get("module", ""),
                "",
                item.get("module", ""),
                item.get("objective", ""),
                " | ".join(str(x) for x in item.get("pass_criteria", [])),
                item.get("duration_min", ""),
                " | ".join(str(x) for x in item.get("api_flow", [])),
            ]
        )
    for item in payload.get("scheduled_events", []):
        writer.writerow(
            [
                "scheduled_event",
                item.get("id", ""),
                item.get("title", ""),
                item.get("owner", ""),
                item.get("date", ""),
                f"{item.get('start_time', '')}-{item.get('end_time', '')}",
                "",
                "",
                item.get("output", ""),
            ]
        )
    return out.getvalue()


def _build_adoption_w02_schedule_ics(payload: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    for item in payload.get("scheduled_events", []):
        date_raw = str(item.get("date", ""))
        start_raw = str(item.get("start_time", "09:00"))
        end_raw = str(item.get("end_time", "10:00"))
        try:
            start_dt = datetime.strptime(f"{date_raw} {start_raw}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{date_raw} {end_raw}", "%Y-%m-%d %H:%M")
        except ValueError:
            continue
        uid = f"ka-facility-os-w02-{str(item.get('id', '')).lower()}@public"
        summary = f"[W02] {str(item.get('title', 'SOP/Sandbox Session'))}"
        description = "\n".join(
            [
                f"Owner: {str(item.get('owner', ''))}",
                f"Output: {str(item.get('output', ''))}",
            ]
        )
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{start_dt.strftime('%Y%m%dT%H%M%S')}",
                f"DTEND:{end_dt.strftime('%Y%m%dT%H%M%S')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//W02 SOP Sandbox//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _build_adoption_plan_schedule_csv(plan: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "week",
            "start_date",
            "end_date",
            "phase",
            "focus",
            "owner",
            "actions",
            "deliverables",
            "success_metric",
        ]
    )
    for item in plan.get("weekly_execution", []):
        actions = " | ".join(item.get("actions", []))
        deliverables = " | ".join(item.get("deliverables", []))
        writer.writerow(
            [
                item.get("week", ""),
                item.get("start_date", ""),
                item.get("end_date", ""),
                item.get("phase", ""),
                item.get("focus", ""),
                item.get("owner", ""),
                actions,
                deliverables,
                item.get("success_metric", ""),
            ]
        )
    return out.getvalue()


def _ics_escape(value: str) -> str:
    return value.replace("\\", "\\\\").replace(";", "\\;").replace(",", "\\,").replace("\n", "\\n")


def _build_adoption_plan_schedule_ics(plan: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []

    for item in plan.get("weekly_execution", []):
        week_num = int(item.get("week", 0))
        week_start = date.fromisoformat(str(item.get("start_date")))
        focus = str(item.get("focus", ""))
        owner = str(item.get("owner", ""))
        success_metric = str(item.get("success_metric", ""))
        actions = [str(x) for x in item.get("actions", [])]

        checkpoints = [
            (0, "Kickoff"),
            (2, "Checkpoint"),
            (4, "Review"),
        ]
        for day_offset, checkpoint_label in checkpoints:
            event_date = week_start + timedelta(days=day_offset)
            event_end = event_date + timedelta(days=1)
            summary = f"[W{week_num:02d}] {checkpoint_label} - {focus}"
            description_lines = [
                f"Phase: {item.get('phase', '')}",
                f"Owner: {owner}",
                f"Success metric: {success_metric}",
            ]
            for action in actions[:3]:
                description_lines.append(f"- {action}")
            description = "\n".join(description_lines)

            uid = f"ka-facility-os-adoption-w{week_num:02d}-{checkpoint_label.lower()}@public"
            events.extend(
                [
                    "BEGIN:VEVENT",
                    f"UID:{uid}",
                    f"DTSTAMP:{dtstamp}",
                    f"DTSTART;VALUE=DATE:{event_date.strftime('%Y%m%d')}",
                    f"DTEND;VALUE=DATE:{event_end.strftime('%Y%m%d')}",
                    f"SUMMARY:{_ics_escape(summary)}",
                    f"DESCRIPTION:{_ics_escape(description)}",
                    "END:VEVENT",
                ]
            )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//User Adoption Plan//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _post_mvp_payload() -> dict[str, Any]:
    duration_weeks = sum(int(item.get("duration_weeks", 0)) for item in POST_MVP_ROADMAP_PHASES)
    return {
        "title": "KA Facility OS Post-MVP Execution Plan",
        "published_on": "2026-02-27",
        "public": True,
        "timeline": {
            "start_date": POST_MVP_PLAN_START.isoformat(),
            "end_date": POST_MVP_PLAN_END.isoformat(),
            "duration_weeks": duration_weeks,
        },
        "roadmap": POST_MVP_ROADMAP_PHASES,
        "execution_backlog": POST_MVP_EXECUTION_BACKLOG,
        "release_calendar": {
            "milestones": POST_MVP_RELEASE_MILESTONES,
            "downloads": {
                "backlog_csv": "/api/public/post-mvp/backlog.csv",
                "release_ics": "/api/public/post-mvp/releases.ics",
            },
        },
        "kpi_dashboard_spec": POST_MVP_KPI_DASHBOARD_SPEC,
        "risk_register": POST_MVP_RISK_REGISTER,
        "governance": {
            "weekly": "Monday execution sync + Friday KPI review",
            "bi_weekly": "Risk and dependency review board",
            "monthly": "Release readiness and budget steering committee",
            "quarterly": "Executive roadmap reprioritization",
        },
    }


def _facility_modules_payload() -> dict[str, Any]:
    return {
        "title": "KA Facility OS Facility Web Modules",
        "published_on": "2026-02-27",
        "public": True,
        "main_page": "/",
        "console_html": "/web/console",
        "modules": FACILITY_WEB_MODULES,
    }


def _build_post_mvp_backlog_csv(plan: dict[str, Any]) -> str:
    out = io.StringIO()
    writer = csv.writer(out)
    writer.writerow(
        [
            "id",
            "epic",
            "item",
            "priority",
            "owner",
            "estimate_points",
            "target_release",
            "status",
            "success_kpi",
        ]
    )
    for item in plan.get("execution_backlog", []):
        writer.writerow(
            [
                item.get("id", ""),
                item.get("epic", ""),
                item.get("item", ""),
                item.get("priority", ""),
                item.get("owner", ""),
                item.get("estimate_points", ""),
                item.get("target_release", ""),
                item.get("status", ""),
                item.get("success_kpi", ""),
            ]
        )
    return out.getvalue()


def _build_post_mvp_release_ics(plan: dict[str, Any]) -> str:
    dtstamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    events: list[str] = []
    milestones = plan.get("release_calendar", {}).get("milestones", [])

    for milestone in milestones:
        release = str(milestone.get("release", ""))
        name = str(milestone.get("name", ""))
        date_raw = str(milestone.get("date", ""))
        try:
            release_date = date.fromisoformat(date_raw)
        except ValueError:
            continue

        release_end = release_date + timedelta(days=1)
        summary = f"[Post-MVP] {release} - {name}"
        description = "\n".join(
            [
                f"Owner: {milestone.get('owner', '')}",
                f"Goal: {milestone.get('goal', '')}",
            ]
        )
        uid = f"ka-facility-os-post-mvp-{release.lower().replace('.', '-')}-release@public"
        events.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART;VALUE=DATE:{release_date.strftime('%Y%m%d')}",
                f"DTEND;VALUE=DATE:{release_end.strftime('%Y%m%d')}",
                f"SUMMARY:{_ics_escape(summary)}",
                f"DESCRIPTION:{_ics_escape(description)}",
                "END:VEVENT",
            ]
        )

    calendar_lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//KA Facility OS//Post-MVP Releases//EN",
        "CALSCALE:GREGORIAN",
        "METHOD:PUBLISH",
    ]
    calendar_lines.extend(events)
    calendar_lines.append("END:VCALENDAR")
    return "\r\n".join(calendar_lines) + "\r\n"


def _build_public_main_page_html(service_info: dict[str, str], plan: dict[str, Any]) -> str:
    training = plan.get("training_outline", [])
    kpis = plan.get("kpi_dashboard_items", [])
    w02_pack = plan.get("w02_sop_sandbox", {})
    w03_pack = plan.get("w03_go_live_onboarding", {})
    w04_pack = plan.get("w04_first_success_acceleration", {})
    w05_pack = plan.get("w05_usage_consistency", {})
    w06_pack = plan.get("w06_operational_rhythm", {})
    w07_pack = plan.get("w07_sla_quality", {})
    w08_pack = plan.get("w08_report_discipline", {})
    w09_pack = plan.get("w09_kpi_operation", {})
    w10_pack = plan.get("w10_self_serve_support", {})
    w11_pack = plan.get("w11_scale_readiness", {})
    w12_pack = plan.get("w12_closure_handoff", {})
    w13_pack = plan.get("w13_continuous_improvement", {})
    w14_pack = plan.get("w14_stability_sprint", {})
    w15_pack = plan.get("w15_operations_efficiency", {})
    post_mvp = _post_mvp_payload()
    module_hub = _facility_modules_payload()
    facility_modules = module_hub.get("modules", [])

    weekly_rows: list[str] = []
    for item in plan.get("weekly_execution", []):
        actions_html = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("actions", []))
        deliverables_html = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("deliverables", []))
        weekly_rows.append(
            f"""
            <tr>
              <td>W{int(item.get('week', 0)):02d}</td>
              <td>{html.escape(str(item.get("start_date", "")))} ~ {html.escape(str(item.get("end_date", "")))}</td>
              <td>{html.escape(str(item.get("phase", "")))}</td>
              <td>{html.escape(str(item.get("focus", "")))}</td>
              <td>{actions_html}</td>
              <td>{deliverables_html}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("success_metric", "")))}</td>
            </tr>
            """
        )

    training_rows: list[str] = []
    for module in training:
        contents_html = "<br>".join(f"&middot; {html.escape(str(x))}" for x in module.get("contents", []))
        training_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(module.get("module", "")))}</td>
              <td>{html.escape(str(module.get("audience", "")))}</td>
              <td>{html.escape(str(module.get("duration_min", "")))} min</td>
              <td>{contents_html}</td>
              <td>{html.escape(str(module.get("format", "")))}</td>
            </tr>
            """
        )

    kpi_rows: list[str] = []
    for item in kpis:
        kpi_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("name", "")))}</td>
              <td>{html.escape(str(item.get("formula", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("data_source", "")))}</td>
              <td>{html.escape(str(item.get("frequency", "")))}</td>
            </tr>
            """
        )

    workflow_matrix_rows: list[str] = []
    for item in plan.get("workflow_lock_matrix", {}).get("rows", []):
        perms = item.get("permissions", {})
        workflow_matrix_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("role", "")))}</td>
              <td>{html.escape(str(perms.get("DRAFT", "")))}</td>
              <td>{html.escape(str(perms.get("REVIEW", "")))}</td>
              <td>{html.escape(str(perms.get("APPROVED", "")))}</td>
              <td>{html.escape(str(perms.get("LOCKED", "")))}</td>
            </tr>
            """
        )

    w02_sop_rows: list[str] = []
    for item in w02_pack.get("sop_runbooks", []):
        targets = ", ".join(str(x) for x in item.get("target_roles", []))
        checkpoints = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("checkpoints", []))
        w02_sop_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("name", "")))}</td>
              <td>{html.escape(targets)}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("trigger", "")))}</td>
              <td>{checkpoints}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
            </tr>
            """
        )

    w02_sandbox_rows: list[str] = []
    for item in w02_pack.get("sandbox_scenarios", []):
        api_flow = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("api_flow", []))
        pass_criteria = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("pass_criteria", []))
        w02_sandbox_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{api_flow}</td>
              <td>{pass_criteria}</td>
              <td>{html.escape(str(item.get("duration_min", "")))}</td>
            </tr>
            """
        )

    w02_schedule_rows: list[str] = []
    for item in w02_pack.get("scheduled_events", []):
        w02_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w03_kickoff_rows: list[str] = []
    for item in w03_pack.get("kickoff_agenda", []):
        w03_kickoff_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("topic", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("duration_min", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{html.escape(str(item.get("expected_output", "")))}</td>
            </tr>
            """
        )

    w03_workshop_rows: list[str] = []
    for item in w03_pack.get("role_workshops", []):
        checklist_html = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("checklist", []))
        w03_workshop_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("role", "")))}</td>
              <td>{html.escape(str(item.get("trainer", "")))}</td>
              <td>{html.escape(str(item.get("duration_min", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{checklist_html}</td>
              <td>{html.escape(str(item.get("success_criteria", "")))}</td>
            </tr>
            """
        )

    w03_office_rows: list[str] = []
    for item in w03_pack.get("office_hours", []):
        w03_office_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("host", "")))}</td>
              <td>{html.escape(str(item.get("focus", "")))}</td>
              <td>{html.escape(str(item.get("channel", "")))}</td>
            </tr>
            """
        )

    w03_schedule_rows: list[str] = []
    for item in w03_pack.get("scheduled_events", []):
        w03_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w04_action_rows: list[str] = []
    for item in w04_pack.get("coaching_actions", []):
        w04_action_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("champion_role", "")))}</td>
              <td>{html.escape(str(item.get("action", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("due_hint", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{html.escape(str(item.get("evidence_required", "")))}</td>
            </tr>
            """
        )

    w04_schedule_rows: list[str] = []
    for item in w04_pack.get("scheduled_events", []):
        w04_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w05_mission_rows: list[str] = []
    for item in w05_pack.get("role_missions", []):
        w05_mission_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("role", "")))}</td>
              <td>{html.escape(str(item.get("mission", "")))}</td>
              <td>{html.escape(str(item.get("weekly_target", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("evidence_required", "")))}</td>
              <td>{html.escape(str(item.get("evidence_hint", "")))}</td>
            </tr>
            """
        )

    w05_schedule_rows: list[str] = []
    for item in w05_pack.get("scheduled_events", []):
        w05_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w05_help_rows: list[str] = []
    for item in w05_pack.get("help_docs", []):
        quick_steps = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("quick_steps", []))
        api_refs = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("api_refs", []))
        w05_help_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("doc_id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("audience", "")))}</td>
              <td>{html.escape(str(item.get("problem", "")))}</td>
              <td>{quick_steps}</td>
              <td>{api_refs}</td>
            </tr>
            """
        )

    w06_rhythm_rows: list[str] = []
    for item in w06_pack.get("rhythm_checklist", []):
        w06_rhythm_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("day", "")))}</td>
              <td>{html.escape(str(item.get("routine", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("evidence_hint", "")))}</td>
            </tr>
            """
        )

    w06_schedule_rows: list[str] = []
    for item in w06_pack.get("scheduled_events", []):
        w06_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w06_rbac_rows: list[str] = []
    for item in w06_pack.get("rbac_audit_checklist", []):
        w06_rbac_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("control", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
              <td>{html.escape(str(item.get("pass_criteria", "")))}</td>
            </tr>
            """
        )

    w07_checklist_rows: list[str] = []
    for item in w07_pack.get("sla_checklist", []):
        w07_checklist_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("cadence", "")))}</td>
              <td>{html.escape(str(item.get("control", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("evidence_hint", "")))}</td>
            </tr>
            """
        )

    w07_coaching_rows: list[str] = []
    for item in w07_pack.get("coaching_plays", []):
        w07_coaching_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("trigger", "")))}</td>
              <td>{html.escape(str(item.get("play", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("expected_impact", "")))}</td>
              <td>{html.escape(str(item.get("evidence_hint", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w07_schedule_rows: list[str] = []
    for item in w07_pack.get("scheduled_events", []):
        w07_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w08_checklist_rows: list[str] = []
    for item in w08_pack.get("report_discipline_checklist", []):
        w08_checklist_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("cadence", "")))}</td>
              <td>{html.escape(str(item.get("discipline", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("evidence_hint", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w08_quality_rows: list[str] = []
    for item in w08_pack.get("data_quality_controls", []):
        w08_quality_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("control", "")))}</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
              <td>{html.escape(str(item.get("pass_criteria", "")))}</td>
            </tr>
            """
        )

    w08_schedule_rows: list[str] = []
    for item in w08_pack.get("scheduled_events", []):
        w08_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w09_threshold_rows: list[str] = []
    for item in w09_pack.get("kpi_threshold_matrix", []):
        w09_threshold_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("kpi_name", "")))}</td>
              <td>{html.escape(str(item.get("kpi_key", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("direction", "")))}</td>
              <td>{html.escape(str(item.get("green_threshold", "")))}</td>
              <td>{html.escape(str(item.get("yellow_threshold", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w09_escalation_rows: list[str] = []
    for item in w09_pack.get("escalation_map", []):
        w09_escalation_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("kpi_key", "")))}</td>
              <td>{html.escape(str(item.get("condition", "")))}</td>
              <td>{html.escape(str(item.get("escalate_to", "")))}</td>
              <td>{html.escape(str(item.get("sla_hours", "")))}</td>
              <td>{html.escape(str(item.get("action", "")))}</td>
            </tr>
            """
        )

    w09_schedule_rows: list[str] = []
    for item in w09_pack.get("scheduled_events", []):
        w09_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w10_guide_rows: list[str] = []
    for item in w10_pack.get("self_serve_guides", []):
        w10_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w10_runbook_rows: list[str] = []
    for item in w10_pack.get("troubleshooting_runbook", []):
        w10_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w10_schedule_rows: list[str] = []
    for item in w10_pack.get("scheduled_events", []):
        w10_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w11_guide_rows: list[str] = []
    for item in w11_pack.get("self_serve_guides", []):
        w11_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w11_runbook_rows: list[str] = []
    for item in w11_pack.get("troubleshooting_runbook", []):
        w11_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w11_schedule_rows: list[str] = []
    for item in w11_pack.get("scheduled_events", []):
        w11_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w12_guide_rows: list[str] = []
    for item in w12_pack.get("self_serve_guides", []):
        w12_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w12_runbook_rows: list[str] = []
    for item in w12_pack.get("troubleshooting_runbook", []):
        w12_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w12_schedule_rows: list[str] = []
    for item in w12_pack.get("scheduled_events", []):
        w12_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w13_guide_rows: list[str] = []
    for item in w13_pack.get("self_serve_guides", []):
        w13_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w13_runbook_rows: list[str] = []
    for item in w13_pack.get("troubleshooting_runbook", []):
        w13_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w13_schedule_rows: list[str] = []
    for item in w13_pack.get("scheduled_events", []):
        w13_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w14_guide_rows: list[str] = []
    for item in w14_pack.get("self_serve_guides", []):
        w14_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w14_runbook_rows: list[str] = []
    for item in w14_pack.get("troubleshooting_runbook", []):
        w14_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w14_schedule_rows: list[str] = []
    for item in w14_pack.get("scheduled_events", []):
        w14_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    w15_guide_rows: list[str] = []
    for item in w15_pack.get("self_serve_guides", []):
        w15_guide_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("problem_cluster", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("source_api", "")))}</td>
            </tr>
            """
        )

    w15_runbook_rows: list[str] = []
    for item in w15_pack.get("troubleshooting_runbook", []):
        w15_runbook_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("module", "")))}</td>
              <td>{html.escape(str(item.get("symptom", "")))}</td>
              <td>{html.escape(str(item.get("owner_role", "")))}</td>
              <td>{html.escape(str(item.get("definition_of_done", "")))}</td>
              <td>{html.escape(str(item.get("api_ref", "")))}</td>
            </tr>
            """
        )

    w15_schedule_rows: list[str] = []
    for item in w15_pack.get("scheduled_events", []):
        w15_schedule_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("start_time", "")))} - {html.escape(str(item.get("end_time", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("output", "")))}</td>
            </tr>
            """
        )

    post_timeline = post_mvp.get("timeline", {})
    post_roadmap_rows: list[str] = []
    for item in post_mvp.get("roadmap", []):
        outcomes_html = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("outcomes", []))
        post_roadmap_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("phase", "")))}</td>
              <td>{html.escape(str(item.get("start_date", "")))} ~ {html.escape(str(item.get("end_date", "")))}</td>
              <td>{html.escape(str(item.get("duration_weeks", "")))} weeks</td>
              <td>{html.escape(str(item.get("objective", "")))}</td>
              <td>{outcomes_html}</td>
              <td>{html.escape(str(item.get("release_gate", "")))}</td>
            </tr>
            """
        )

    post_backlog_rows: list[str] = []
    for item in post_mvp.get("execution_backlog", []):
        post_backlog_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("epic", "")))}</td>
              <td>{html.escape(str(item.get("item", "")))}</td>
              <td>{html.escape(str(item.get("priority", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("estimate_points", "")))}</td>
              <td>{html.escape(str(item.get("target_release", "")))}</td>
              <td>{html.escape(str(item.get("status", "")))}</td>
              <td>{html.escape(str(item.get("success_kpi", "")))}</td>
            </tr>
            """
        )

    post_release_rows: list[str] = []
    for item in post_mvp.get("release_calendar", {}).get("milestones", []):
        post_release_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("release", "")))}</td>
              <td>{html.escape(str(item.get("name", "")))}</td>
              <td>{html.escape(str(item.get("date", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("goal", "")))}</td>
            </tr>
            """
        )

    post_kpi_rows: list[str] = []
    for item in post_mvp.get("kpi_dashboard_spec", []):
        post_kpi_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("name", "")))}</td>
              <td>{html.escape(str(item.get("formula", "")))}</td>
              <td>{html.escape(str(item.get("target", "")))}</td>
              <td>{html.escape(str(item.get("cadence", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("alert_rule", "")))}</td>
            </tr>
            """
        )

    post_risk_rows: list[str] = []
    for item in post_mvp.get("risk_register", []):
        post_risk_rows.append(
            f"""
            <tr>
              <td>{html.escape(str(item.get("id", "")))}</td>
              <td>{html.escape(str(item.get("title", "")))}</td>
              <td>{html.escape(str(item.get("probability", "")))}</td>
              <td>{html.escape(str(item.get("impact", "")))}</td>
              <td>{html.escape(str(item.get("signal", "")))}</td>
              <td>{html.escape(str(item.get("mitigation", "")))}</td>
              <td>{html.escape(str(item.get("owner", "")))}</td>
              <td>{html.escape(str(item.get("status", "")))}</td>
              <td>{html.escape(str(item.get("review_cycle", "")))}</td>
            </tr>
            """
        )

    post_governance = post_mvp.get("governance", {})
    post_governance_items_html = "".join(
        f"<li><strong>{html.escape(str(key).replace('_', ' ').title())}:</strong> {html.escape(str(value))}</li>"
        for key, value in post_governance.items()
    )

    module_cards: list[str] = []
    for item in facility_modules:
        links_html = "".join(
            f'<a href="{html.escape(str(link.get("href", "#")))}">{html.escape(str(link.get("label", "Open")))}'
            "</a>"
            for link in item.get("links", [])
        )
        module_cards.append(
            f"""
            <div class="card module-card">
              <h3>{html.escape(str(item.get("name_ko", "")))} <span class="module-en">{html.escape(str(item.get("name", "")))}</span></h3>
              <p>{html.escape(str(item.get("description", "")))}</p>
              <p><strong>KPI Hint:</strong> {html.escape(str(item.get("kpi_hint", "")))}</p>
              <div class="module-links">{links_html}</div>
            </div>
            """
        )

    campaign_kit = plan.get("campaign_kit", {})
    promotion_cards: list[str] = []
    for item in campaign_kit.get("promotion", []):
        channels = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("channels", []))
        assets = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("assets", []))
        promotion_cards.append(
            f"""
            <div class="card">
              <h3>{html.escape(str(item.get("campaign", "")))}</h3>
              <p><strong>Goal:</strong> {html.escape(str(item.get("goal", "")))}</p>
              <p><strong>Channels:</strong><br>{channels}</p>
              <p><strong>Assets:</strong><br>{assets}</p>
              <p><strong>Cadence:</strong> {html.escape(str(item.get("cadence", "")))}</p>
            </div>
            """
        )

    education_cards: list[str] = []
    for item in campaign_kit.get("education", []):
        components = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("components", []))
        targets = ", ".join(html.escape(str(x)) for x in item.get("target_roles", []))
        education_cards.append(
            f"""
            <div class="card">
              <h3>{html.escape(str(item.get("track", "")))}</h3>
              <p><strong>Target:</strong> {targets}</p>
              <p><strong>Components:</strong><br>{components}</p>
              <p><strong>Completion:</strong> {html.escape(str(item.get("completion_rule", "")))}</p>
              <p><strong>Duration:</strong> {html.escape(str(item.get("duration_weeks", "")))} weeks</p>
            </div>
            """
        )

    fun_cards: list[str] = []
    for item in campaign_kit.get("fun", []):
        rewards = "<br>".join(f"&middot; {html.escape(str(x))}" for x in item.get("rewards", []))
        fun_cards.append(
            f"""
            <div class="card">
              <h3>{html.escape(str(item.get("program", "")))}</h3>
              <p><strong>How it works:</strong> {html.escape(str(item.get("how_it_works", "")))}</p>
              <p><strong>Rewards:</strong><br>{rewards}</p>
              <p><strong>Anti-abuse:</strong> {html.escape(str(item.get("anti_abuse_rule", "")))}</p>
            </div>
            """
        )

    cadence_list = "".join(
        f"<li>{html.escape(str(item))}</li>" for item in plan.get("schedule_management", {}).get("cadence", [])
    )
    timeline = plan.get("timeline", {})
    timeline_start = str(timeline.get("start_date", ""))
    timeline_end = str(timeline.get("end_date", ""))
    total_weeks = int(timeline.get("duration_weeks", len(plan.get("weekly_execution", [])) or 1))

    today = datetime.now(timezone.utc).date()
    weekly_items = plan.get("weekly_execution", [])
    completed_weeks = 0
    active_week_item: dict[str, Any] | None = None
    phase_keys: list[str] = []
    for item in weekly_items:
        phase = str(item.get("phase", ""))
        phase_key = "".join(ch.lower() if ch.isalnum() else "-" for ch in phase).strip("-")
        if phase_key and phase_key not in phase_keys:
            phase_keys.append(phase_key)

        start_raw = str(item.get("start_date", ""))
        end_raw = str(item.get("end_date", ""))
        try:
            start_date = date.fromisoformat(start_raw)
            end_date = date.fromisoformat(end_raw)
        except ValueError:
            continue

        if end_date < today:
            completed_weeks += 1
        elif start_date <= today <= end_date:
            active_week_item = item

    progress_percent = int(round((completed_weeks / total_weeks) * 100))
    campaign_total = (
        len(campaign_kit.get("promotion", []))
        + len(campaign_kit.get("education", []))
        + len(campaign_kit.get("fun", []))
    )

    phase_filter_buttons = ['<button class="filter-btn active" type="button" data-phase="all">All</button>']
    for key in phase_keys:
        phase_filter_buttons.append(
            f'<button class="filter-btn" type="button" data-phase="{html.escape(key)}">{html.escape(key.replace("-", " ").title())}</button>'
        )

    week_cards: list[str] = []
    for item in weekly_items:
        week = int(item.get("week", 0))
        phase = str(item.get("phase", ""))
        phase_key = "".join(ch.lower() if ch.isalnum() else "-" for ch in phase).strip("-")
        focus = str(item.get("focus", ""))
        owner = str(item.get("owner", ""))
        metric = str(item.get("success_metric", ""))
        start_raw = str(item.get("start_date", ""))
        end_raw = str(item.get("end_date", ""))
        status_label = "Scheduled"
        status_class = "scheduled"
        try:
            start_date = date.fromisoformat(start_raw)
            end_date = date.fromisoformat(end_raw)
            if end_date < today:
                status_label = "Done"
                status_class = "done"
            elif start_date <= today <= end_date:
                status_label = "Active"
                status_class = "active"
        except ValueError:
            pass

        keywords = f"{phase} {focus} {owner} {metric}".lower()
        week_cards.append(
            f"""
            <article class="week-card {status_class}" data-phase="{html.escape(phase_key)}" data-keywords="{html.escape(keywords)}">
              <div class="week-top">
                <span class="week-num">W{week:02d}</span>
                <span class="week-status">{html.escape(status_label)}</span>
              </div>
              <h4>{html.escape(focus)}</h4>
              <p>{html.escape(start_raw)} ~ {html.escape(end_raw)}</p>
              <p>Owner: {html.escape(owner)}</p>
              <p class="week-metric">{html.escape(metric)}</p>
            </article>
            """
        )

    if active_week_item is not None:
        active_focus = html.escape(str(active_week_item.get("focus", "")))
        active_week = int(active_week_item.get("week", 0))
        active_owner = html.escape(str(active_week_item.get("owner", "")))
        active_actions = "".join(
            f"<li>{html.escape(str(x))}</li>" for x in active_week_item.get("actions", [])
        )
        active_week_guide = f"""
        <div class="active-week-box">
          <h3>   : W{active_week:02d} - {active_focus}</h3>
          <p>Owner: {active_owner}</p>
          <ul>{active_actions}</ul>
        </div>
        """
    else:
        active_week_guide = """
        <div class="active-week-box">
          <h3>   </h3>
          <p>   .  Timeline Board   .</p>
        </div>
        """

    if active_week_item is not None:
        active_line = (
            f"W{int(active_week_item.get('week', 0)):02d} : "
            f"{str(active_week_item.get('focus', ''))} "
            f"(Owner: {str(active_week_item.get('owner', ''))})"
        )
    else:
        active_line = "   :     ."

    summary_lines = [
        f" {timeline_start}~{timeline_end},  {progress_percent}% ({completed_weeks}/{total_weeks} ).",
        active_line,
        f"   {len(facility_modules)}    .",
        f"  {len(training)}:      .",
        f"KPI {len(kpis)}  ,   {plan.get('schedule_management', {}).get('next_review_date', '')}.",
        f"W02 SOP {len(w02_pack.get('sop_runbooks', []))} + Sandbox {len(w02_pack.get('sandbox_scenarios', []))} +  {len(w02_pack.get('scheduled_events', []))} .",
        f"W03 Kickoff {len(w03_pack.get('kickoff_agenda', []))} + Workshop {len(w03_pack.get('role_workshops', []))} + Office hour {len(w03_pack.get('office_hours', []))} .",
        " (CSV/ICS) +   + Post-MVP    .",
    ]
    summary_lines_html = "".join(f"<li>{html.escape(line)}</li>" for line in summary_lines)

    return f"""
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KA Facility OS - Public Main</title>
  <style>
    :root {{
      --ink: #0d1f3a;
      --muted: #3f5576;
      --line: #d1dced;
      --brand: #0e6f5d;
      --accent: #d55222;
      --card: #ffffff;
      --bg: #f4f8fd;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      margin: 0;
      color: var(--ink);
      font-family: "SUIT", "Pretendard", "IBM Plex Sans KR", "Noto Sans KR", sans-serif;
      background:
        radial-gradient(1200px 500px at 10% -20%, #d8f6ff 0%, transparent 60%),
        radial-gradient(900px 400px at 100% -10%, #ffe7ca 0%, transparent 60%),
        var(--bg);
    }}
    .wrap {{ max-width: 1200px; margin: 0 auto; padding: 24px 16px 64px; }}
    .hero {{
      position: relative;
      overflow: hidden;
      border: 1px solid var(--line);
      background: linear-gradient(135deg, #ffffff 0%, #eff8f6 56%, #fff3e6 100%);
      border-radius: 16px;
      padding: 20px;
      box-shadow: 0 10px 30px rgba(16, 42, 67, 0.08);
      animation: fadeup 520ms ease-out both;
    }}
    .hero::after {{
      content: "";
      position: absolute;
      width: 220px;
      height: 220px;
      border-radius: 999px;
      right: -80px;
      top: -90px;
      background: radial-gradient(circle at center, rgba(14, 111, 93, 0.22) 0%, rgba(14, 111, 93, 0) 70%);
      pointer-events: none;
    }}
    .hero h1 {{ margin: 0 0 8px; font-size: 28px; }}
    .hero p {{ margin: 0; color: var(--muted); }}
    .summary-toggle {{
      margin-top: 10px;
      border: 1px solid #8ecfbf;
      background: #eaf9f4;
      color: #0b5c4d;
      border-radius: 10px;
      padding: 7px 10px;
      font-size: 12px;
      font-weight: 800;
      cursor: pointer;
    }}
    .summary-toggle:hover {{ background: #ddf5ec; }}
    .pill {{
      display: inline-block;
      margin-top: 12px;
      padding: 6px 10px;
      border-radius: 999px;
      background: #dcfce7;
      border: 1px solid #86efac;
      font-size: 12px;
      font-weight: 700;
    }}
    .grid {{
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      margin-top: 16px;
    }}
    .card {{
      border: 1px solid var(--line);
      border-radius: 12px;
      background: var(--card);
      padding: 14px;
    }}
    .card h3 {{ margin: 0 0 8px; font-size: 14px; color: var(--brand); }}
    .card p {{ margin: 0; font-size: 13px; color: var(--muted); }}
    .module-card .module-en {{
      color: #4c6b97;
      font-size: 12px;
      font-weight: 700;
      margin-left: 4px;
    }}
    .module-links {{
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 10px;
    }}
    .module-links a {{
      display: inline-block;
      padding: 6px 9px;
      border-radius: 8px;
      border: 1px solid #bfd5ef;
      text-decoration: none;
      color: #1f4f82;
      background: #f3f8ff;
      font-size: 12px;
      font-weight: 700;
    }}
    .module-links a:hover {{ border-color: #88add8; background: #e8f2ff; }}
    .section {{ margin-top: 24px; }}
    .section h2 {{
      margin: 0 0 10px;
      font-size: 20px;
      border-left: 4px solid var(--accent);
      padding-left: 10px;
    }}
    .section .desc {{ margin: 0 0 12px; color: var(--muted); }}
    .table-wrap {{
      overflow: auto;
      border: 1px solid var(--line);
      border-radius: 12px;
      background: #fff;
    }}
    table {{
      border-collapse: collapse;
      width: 100%;
      min-width: 900px;
      font-size: 13px;
    }}
    th, td {{
      border-bottom: 1px solid #edf2f7;
      padding: 10px;
      vertical-align: top;
      text-align: left;
    }}
    th {{
      background: #f8fafc;
      color: #1f2937;
      position: sticky;
      top: 0;
      z-index: 1;
    }}
    .links a {{
      display: inline-block;
      margin-right: 8px;
      margin-bottom: 8px;
      padding: 8px 12px;
      border-radius: 10px;
      border: 1px solid var(--line);
      text-decoration: none;
      color: var(--ink);
      background: #fff;
      font-size: 13px;
      font-weight: 600;
    }}
    .links a:hover {{ border-color: var(--brand); color: var(--brand); }}
    .chip-row {{
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-top: 10px;
    }}
    .chip {{
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid #addbcf;
      background: #edfaf5;
      color: #0d5b4d;
      font-size: 12px;
      font-weight: 700;
    }}
    .hero-stats {{
      margin-top: 14px;
      display: grid;
      gap: 10px;
      grid-template-columns: repeat(4, minmax(0, 1fr));
    }}
    .stat {{
      border: 1px solid var(--line);
      border-radius: 10px;
      background: #fff;
      padding: 10px;
    }}
    .stat .k {{ color: var(--muted); font-size: 12px; }}
    .stat .v {{ font-size: 22px; font-weight: 800; margin-top: 2px; }}
    .section .sub {{
      margin: 0 0 12px;
      color: var(--muted);
      font-size: 14px;
    }}
    .filter-row {{
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      gap: 8px;
      margin-bottom: 10px;
    }}
    .filter-btn {{
      border: 1px solid var(--line);
      background: #fff;
      color: var(--ink);
      border-radius: 999px;
      font-size: 12px;
      font-weight: 700;
      padding: 6px 11px;
      cursor: pointer;
    }}
    .filter-btn.active {{
      border-color: #8ecfbf;
      background: #e8f9f3;
      color: #0b5c4d;
    }}
    .search-input {{
      margin-left: auto;
      border: 1px solid var(--line);
      border-radius: 10px;
      padding: 8px 10px;
      min-width: 220px;
      font-size: 13px;
    }}
    .timeline-board {{
      display: grid;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      gap: 10px;
    }}
    .week-card {{
      border: 1px solid var(--line);
      border-radius: 12px;
      background: #fff;
      padding: 11px;
      transition: transform 180ms ease, box-shadow 180ms ease;
      animation: fadeup 600ms ease-out both;
    }}
    .week-card:hover {{
      transform: translateY(-2px);
      box-shadow: 0 8px 22px rgba(16, 42, 67, 0.10);
    }}
    .week-card .week-top {{
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 6px;
    }}
    .week-card .week-num {{ font-size: 12px; font-weight: 800; color: var(--muted); letter-spacing: 0.04em; }}
    .week-card .week-status {{
      font-size: 11px;
      font-weight: 700;
      border: 1px solid var(--line);
      border-radius: 999px;
      padding: 3px 8px;
    }}
    .week-card.done {{ background: linear-gradient(160deg, #f2fff7 0%, #ffffff 60%); }}
    .week-card.done .week-status {{ border-color: #9ad8bf; color: #0b6e5a; background: #ebfff4; }}
    .week-card.active {{ background: linear-gradient(160deg, #eef7ff 0%, #ffffff 60%); border-color: #a9c8e8; }}
    .week-card.active .week-status {{ border-color: #a0bee2; color: #1f5f9f; background: #f0f7ff; }}
    .week-card.scheduled {{ background: linear-gradient(160deg, #fff9f0 0%, #ffffff 60%); }}
    .week-card.scheduled .week-status {{ border-color: #f2c58d; color: #ab6100; background: #fff5e8; }}
    .week-card h4 {{ margin: 0 0 6px; font-size: 15px; }}
    .week-card p {{ margin: 0 0 4px; color: var(--muted); font-size: 12px; }}
    .week-card .week-metric {{
      margin-top: 6px;
      background: #f7fbff;
      border: 1px solid #d8e4f4;
      border-radius: 8px;
      padding: 6px;
      color: #2b3b52;
    }}
    .active-week-box {{
      margin-top: 12px;
      border: 1px solid #abc8e8;
      border-radius: 12px;
      background: #f2f9ff;
      padding: 12px;
    }}
    .active-week-box h3 {{ margin: 0 0 8px; font-size: 16px; }}
    .active-week-box p {{ margin: 0 0 8px; color: var(--muted); }}
    .active-week-box ul {{ margin: 0 0 0 18px; }}
    .active-week-box li {{ margin: 4px 0; }}
    .summary-panel {{
      display: none;
      margin-top: 12px;
      border: 1px solid #9dc4ea;
      border-radius: 12px;
      background: #eef7ff;
      padding: 12px;
    }}
    .summary-panel h3 {{ margin: 0 0 8px; font-size: 16px; }}
    .summary-panel ul {{ margin: 0 0 0 18px; }}
    .summary-panel li {{ margin: 4px 0; color: #26415f; }}
    body.summary-mode .section {{ display: none; }}
    body.summary-mode .hero .grid,
    body.summary-mode .hero .hero-stats,
    body.summary-mode .hero .chip-row,
    body.summary-mode .hero .pill {{ display: none; }}
    body.summary-mode .summary-panel {{ display: block; }}
    body.summary-mode .hero p {{ margin-top: 6px; }}
    @keyframes fadeup {{
      from {{ opacity: 0; transform: translateY(10px); }}
      to {{ opacity: 1; transform: translateY(0); }}
    }}
    ul {{ margin: 8px 0 0 18px; }}
    @media (max-width: 900px) {{
      .grid {{ grid-template-columns: 1fr; }}
      .hero-stats {{ grid-template-columns: repeat(2, minmax(0, 1fr)); }}
      .timeline-board {{ grid-template-columns: 1fr; }}
      .search-input {{ margin-left: 0; width: 100%; min-width: 0; }}
      .hero h1 {{ font-size: 22px; }}
    }}
  </style>
</head>
<body>
  <div class="wrap">
    <section class="hero">
      <h1>KA Facility OS</h1>
      <p>       . , , KPI, ,       .</p>
      <button id="summaryModeToggle" class="summary-toggle" type="button" aria-pressed="false">  ( 5): OFF</button>
      <span class="pill">Public Plan Enabled</span>
      <div class="chip-row">
        <span class="chip">User Adoption Plan</span>
        <span class="chip">Schedule Management</span>
        <span class="chip">Promotion + Education + Fun Kit</span>
      </div>
      <div id="summaryPanel" class="summary-panel">
        <h3> 5 </h3>
        <ul>{summary_lines_html}</ul>
      </div>
      <div class="hero-stats">
        <div class="stat"><div class="k">Weeks</div><div class="v">{total_weeks}</div></div>
        <div class="stat"><div class="k">Completed</div><div class="v">{completed_weeks}</div></div>
        <div class="stat"><div class="k">Progress</div><div class="v">{progress_percent}%</div></div>
        <div class="stat"><div class="k">Campaign Items</div><div class="v">{campaign_total}</div></div>
      </div>
      <div class="grid">
        <div class="card">
          <h3>Service</h3>
          <p>{html.escape(service_info.get("service", ""))}</p>
        </div>
        <div class="card">
          <h3>Status</h3>
          <p>{html.escape(service_info.get("status", ""))}</p>
        </div>
        <div class="card">
          <h3>Docs</h3>
          <p><a href="{html.escape(service_info.get("docs", "/docs"))}">{html.escape(service_info.get("docs", "/docs"))}</a></p>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>{html.escape(str(plan.get("title", "")))}</h2>
      <p class="sub">
        Timeline: {html.escape(timeline_start)} ~ {html.escape(timeline_end)} |
        Duration: {total_weeks} weeks
      </p>
      <div class="links">
        <a href="/api/public/adoption-plan">JSON API</a>
        <a href="/api/public/adoption-plan/campaign">Campaign API</a>
        <a href="/api/public/adoption-plan/schedule.csv">Schedule CSV</a>
        <a href="/api/public/adoption-plan/schedule.ics">Calendar ICS</a>
        <a href="/api/public/adoption-plan/w02">W02 JSON</a>
        <a href="/api/public/adoption-plan/w02/checklist.csv">W02 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w02/schedule.ics">W02 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w02/sample-files">W02 Sample Files</a>
        <a href="/api/public/adoption-plan/w03">W03 JSON</a>
        <a href="/api/public/adoption-plan/w03/checklist.csv">W03 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w03/schedule.ics">W03 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w04">W04 JSON</a>
        <a href="/api/public/adoption-plan/w04/checklist.csv">W04 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w04/schedule.ics">W04 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w04/common-mistakes">W04 Common Mistakes JSON</a>
        <a href="/api/public/adoption-plan/w05">W05 JSON</a>
        <a href="/api/public/adoption-plan/w05/missions.csv">W05 Missions CSV</a>
        <a href="/api/public/adoption-plan/w05/schedule.ics">W05 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w05/help-docs">W05 Help Docs</a>
        <a href="/api/public/adoption-plan/w06">W06 JSON</a>
        <a href="/api/public/adoption-plan/w06/checklist.csv">W06 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w06/schedule.ics">W06 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w06/rbac-audit-template">W06 RBAC Audit Template</a>
        <a href="/api/public/adoption-plan/w07">W07 JSON</a>
        <a href="/api/public/adoption-plan/w07/checklist.csv">W07 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w07/schedule.ics">W07 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w07/coaching-playbook">W07 Coaching Playbook</a>
        <a href="/api/public/adoption-plan/w08">W08 JSON</a>
        <a href="/api/public/adoption-plan/w08/checklist.csv">W08 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w08/schedule.ics">W08 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w08/reporting-sop">W08 Reporting SOP</a>
        <a href="/api/public/adoption-plan/w09">W09 JSON</a>
        <a href="/api/public/adoption-plan/w09/checklist.csv">W09 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w09/schedule.ics">W09 Schedule ICS</a>
        <a href="/web/adoption/w04/common-mistakes">W04 Common Mistakes HTML</a>
        <a href="/web/console">Facility Console HTML</a>
        <a href="/api/service-info">Service Info</a>
      </div>
    </section>

    <section class="section">
      <h2>Facility Web Modules</h2>
      <p class="sub">    ,     .</p>
      <div class="links">
        <a href="/api/public/modules">Modules API</a>
        <a href="/web/console">Operations Console HTML</a>
      </div>
      <div class="grid">
        {"".join(module_cards)}
      </div>
    </section>

    <section class="section">
      <h2>W01 Role Workflow Lock Matrix</h2>
      <p class="sub">DRAFT/REVIEW/APPROVED/LOCKED       .</p>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Role</th>
              <th>DRAFT</th>
              <th>REVIEW</th>
              <th>APPROVED</th>
              <th>LOCKED</th>
            </tr>
          </thead>
          <tbody>
            {"".join(workflow_matrix_rows)}
          </tbody>
        </table>
      </div>
      <div class="links" style="margin-top: 10px;">
        <a href="/api/workflow-locks">Workflow Lock API</a>
      </div>
    </section>

    <section class="section">
      <h2>W02 Scheduled SOP and Sandbox</h2>
      <p class="sub">SOP           .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w02">W02 JSON</a>
        <a href="/api/public/adoption-plan/w02/checklist.csv">W02 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w02/schedule.ics">W02 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w02/sample-files">W02 Sample Files</a>
        <a href="/api/adoption/w02/tracker/items">W02 Tracker Items API (Token)</a>
        <a href="/api/adoption/w02/tracker/overview?site=HQ">W02 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>SOP ID</th>
              <th>Name</th>
              <th>Target Roles</th>
              <th>Owner</th>
              <th>Trigger</th>
              <th>Checkpoints</th>
              <th>Definition of Done</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w02_sop_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Scenario ID</th>
              <th>Module</th>
              <th>Objective</th>
              <th>API Flow</th>
              <th>Pass Criteria</th>
              <th>Duration(min)</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w02_sandbox_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w02_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W03 Go-live Onboarding</h2>
      <p class="sub">  ( +   +  )  .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w03">W03 JSON</a>
        <a href="/api/public/adoption-plan/w03/checklist.csv">W03 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w03/schedule.ics">W03 Schedule ICS</a>
        <a href="/api/adoption/w03/tracker/items">W03 Tracker Items API (Token)</a>
        <a href="/api/adoption/w03/tracker/overview?site=HQ">W03 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Kickoff ID</th>
              <th>Topic</th>
              <th>Owner</th>
              <th>Duration(min)</th>
              <th>Objective</th>
              <th>Expected Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w03_kickoff_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Workshop ID</th>
              <th>Role</th>
              <th>Trainer</th>
              <th>Duration(min)</th>
              <th>Objective</th>
              <th>Checklist</th>
              <th>Success Criteria</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w03_workshop_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Host</th>
              <th>Focus</th>
              <th>Channel</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w03_office_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w03_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W04 First Success Acceleration</h2>
      <p class="sub">  (TTV)  Top blocker     .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w04">W04 JSON</a>
        <a href="/api/public/adoption-plan/w04/checklist.csv">W04 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w04/schedule.ics">W04 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w04/common-mistakes">W04 Common Mistakes JSON</a>
        <a href="/web/adoption/w04/common-mistakes">W04 Common Mistakes HTML</a>
        <a href="/api/ops/adoption/w04/funnel">W04 Funnel API (Token)</a>
        <a href="/api/ops/adoption/w04/blockers">W04 Blockers API (Token)</a>
        <a href="/api/adoption/w04/tracker/items">W04 Tracker Items API (Token)</a>
        <a href="/api/adoption/w04/tracker/overview?site=HQ">W04 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Action ID</th>
              <th>Champion Role</th>
              <th>Action</th>
              <th>Owner</th>
              <th>Due Hint</th>
              <th>Objective</th>
              <th>Evidence Required</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w04_action_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w04_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W05 Usage Consistency</h2>
      <p class="sub">   overdue    2    .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w05">W05 JSON</a>
        <a href="/api/public/adoption-plan/w05/missions.csv">W05 Missions CSV</a>
        <a href="/api/public/adoption-plan/w05/schedule.ics">W05 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w05/help-docs">W05 Help Docs</a>
        <a href="/api/ops/adoption/w05/consistency">W05 Consistency API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Mission ID</th>
              <th>Role</th>
              <th>Mission</th>
              <th>Weekly Target</th>
              <th>Owner</th>
              <th>Evidence Required</th>
              <th>Evidence Hint</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w05_mission_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w05_schedule_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Doc ID</th>
              <th>Title</th>
              <th>Audience</th>
              <th>Problem</th>
              <th>Quick Steps</th>
              <th>API Refs</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w05_help_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W06 Operational Rhythm</h2>
      <p class="sub">  ( ,  handover,  ) RBAC    .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w06">W06 JSON</a>
        <a href="/api/public/adoption-plan/w06/checklist.csv">W06 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w06/schedule.ics">W06 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w06/rbac-audit-template">W06 RBAC Audit Template</a>
        <a href="/api/ops/adoption/w06/rhythm">W06 Rhythm API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Day</th>
              <th>Routine</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>Evidence Hint</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w06_rhythm_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w06_schedule_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Control ID</th>
              <th>Control</th>
              <th>Objective</th>
              <th>API Ref</th>
              <th>Pass Criteria</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w06_rbac_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W07 SLA Quality</h2>
      <p class="sub">SLA  , escalation , alert        .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w07">W07 JSON</a>
        <a href="/api/public/adoption-plan/w07/checklist.csv">W07 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w07/schedule.ics">W07 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w07/coaching-playbook">W07 Coaching Playbook</a>
        <a href="/api/ops/adoption/w07/sla-quality">W07 SLA Quality API (Token)</a>
        <a href="/api/ops/adoption/w07/automation-readiness">W07 Automation Readiness API (Token)</a>
        <a href="/api/adoption/w07/tracker/items">W07 Tracker Items API (Token)</a>
        <a href="/api/adoption/w07/tracker/overview?site=HQ">W07 Tracker Overview API (Token)</a>
        <a href="/api/adoption/w07/tracker/completion-package?site=HQ">W07 Completion Package ZIP (Token)</a>
        <a href="/api/ops/adoption/w07/sla-quality/run-weekly">W07 Weekly Run API (Token)</a>
        <a href="/api/ops/adoption/w07/sla-quality/latest-weekly">W07 Weekly Latest API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Cadence</th>
              <th>Control</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Definition of Done</th>
              <th>Evidence Hint</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w07_checklist_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Play ID</th>
              <th>Trigger</th>
              <th>Play</th>
              <th>Owner</th>
              <th>Expected Impact</th>
              <th>Evidence Hint</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w07_coaching_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w07_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W08 Report Discipline</h2>
      <p class="sub">       KPI , site    .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w08">W08 JSON</a>
        <a href="/api/public/adoption-plan/w08/checklist.csv">W08 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w08/schedule.ics">W08 Schedule ICS</a>
        <a href="/api/public/adoption-plan/w08/reporting-sop">W08 Reporting SOP</a>
        <a href="/api/ops/adoption/w08/report-discipline">W08 Discipline API (Token)</a>
        <a href="/api/ops/adoption/w08/site-benchmark">W08 Site Benchmark API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Cadence</th>
              <th>Discipline</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Definition of Done</th>
              <th>Evidence Hint</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w08_checklist_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Control ID</th>
              <th>Control</th>
              <th>Objective</th>
              <th>API Ref</th>
              <th>Pass Criteria</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w08_quality_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w08_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W09 KPI Operation</h2>
      <p class="sub">KPI //         .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w09">W09 JSON</a>
        <a href="/api/public/adoption-plan/w09/checklist.csv">W09 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w09/schedule.ics">W09 Schedule ICS</a>
        <a href="/api/ops/adoption/w09/kpi-operation">W09 KPI Operation API (Token)</a>
        <a href="/api/ops/adoption/w09/kpi-policy">W09 KPI Policy API (Token)</a>
        <a href="/api/adoption/w09/tracker/items">W09 Tracker Items API (Token)</a>
        <a href="/api/adoption/w09/tracker/overview?site=HQ">W09 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>KPI ID</th>
              <th>KPI Name</th>
              <th>KPI Key</th>
              <th>Owner Role</th>
              <th>Direction</th>
              <th>Green Threshold</th>
              <th>Yellow Threshold</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w09_threshold_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Escalation ID</th>
              <th>KPI Key</th>
              <th>Condition</th>
              <th>Escalate To</th>
              <th>SLA Hours</th>
              <th>Action</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w09_escalation_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w09_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W10 Self-serve Support</h2>
      <p class="sub">   /         .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w10">W10 JSON</a>
        <a href="/api/public/adoption-plan/w10/checklist.csv">W10 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w10/schedule.ics">W10 Schedule ICS</a>
        <a href="/api/ops/adoption/w10/self-serve">W10 Self-serve API (Token)</a>
        <a href="/api/ops/adoption/w10/support-policy">W10 Support Policy API (Token)</a>
        <a href="/api/adoption/w10/tracker/items">W10 Tracker Items API (Token)</a>
        <a href="/api/adoption/w10/tracker/overview?site=HQ">W10 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Guide ID</th>
              <th>Title</th>
              <th>Problem Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w10_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Runbook ID</th>
              <th>Module</th>
              <th>Symptom</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w10_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w10_schedule_rows)}
          </tbody>
        </table>
      </div>
    <section class="section">
      <h2>W11 Scale Readiness</h2>
      <p class="sub">    //       .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w11">W11 JSON</a>
        <a href="/api/public/adoption-plan/w11/checklist.csv">W11 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w11/schedule.ics">W11 Schedule ICS</a>
        <a href="/api/ops/adoption/w11/scale-readiness">W11 Scale Readiness API (Token)</a>
        <a href="/api/ops/adoption/w11/readiness-policy">W11 Readiness Policy API (Token)</a>
        <a href="/api/adoption/w11/tracker/items">W11 Tracker Items API (Token)</a>
        <a href="/api/adoption/w11/tracker/overview?site=HQ">W11 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Title</th>
              <th>Readiness Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w11_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Simulation ID</th>
              <th>Module</th>
              <th>Scenario</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w11_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w11_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W12 Closure and Handoff</h2>
      <p class="sub">    //      .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w12">W12 JSON</a>
        <a href="/api/public/adoption-plan/w12/checklist.csv">W12 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w12/schedule.ics">W12 Schedule ICS</a>
        <a href="/api/ops/adoption/w12/closure-handoff">W12 Closure Handoff API (Token)</a>
        <a href="/api/ops/adoption/w12/handoff-policy">W12 Handoff Policy API (Token)</a>
        <a href="/api/adoption/w12/tracker/items">W12 Tracker Items API (Token)</a>
        <a href="/api/adoption/w12/tracker/overview?site=HQ">W12 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Title</th>
              <th>Handoff Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w12_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Runbook ID</th>
              <th>Module</th>
              <th>Symptom</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w12_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w12_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W13 Continuous Improvement</h2>
      <p class="sub">W12           .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w13">W13 JSON</a>
        <a href="/api/public/adoption-plan/w13/checklist.csv">W13 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w13/schedule.ics">W13 Schedule ICS</a>
        <a href="/api/ops/adoption/w13/closure-handoff">W13 Closure Handoff API (Token)</a>
        <a href="/api/ops/adoption/w13/handoff-policy">W13 Handoff Policy API (Token)</a>
        <a href="/api/adoption/w13/tracker/items">W13 Tracker Items API (Token)</a>
        <a href="/api/adoption/w13/tracker/overview?site=HQ">W13 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Title</th>
              <th>Handoff Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w13_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Runbook ID</th>
              <th>Module</th>
              <th>Symptom</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w13_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w13_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W14 Stability Sprint</h2>
      <p class="sub">W13     API  ,  ,    .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w14">W14 JSON</a>
        <a href="/api/public/adoption-plan/w14/checklist.csv">W14 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w14/schedule.ics">W14 Schedule ICS</a>
        <a href="/api/ops/adoption/w14/stability-sprint">W14 Stability Sprint API (Token)</a>
        <a href="/api/ops/adoption/w14/stability-policy">W14 Stability Policy API (Token)</a>
        <a href="/api/adoption/w14/tracker/items">W14 Tracker Items API (Token)</a>
        <a href="/api/adoption/w14/tracker/overview?site=HQ">W14 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Title</th>
              <th>Stability Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w14_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Runbook ID</th>
              <th>Module</th>
              <th>Symptom</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w14_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w14_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>W15 Operations Efficiency</h2>
      <p class="sub">     UI ,   ,     .</p>
      <div class="links">
        <a href="/api/public/adoption-plan/w15">W15 JSON</a>
        <a href="/api/public/adoption-plan/w15/checklist.csv">W15 Checklist CSV</a>
        <a href="/api/public/adoption-plan/w15/schedule.ics">W15 Schedule ICS</a>
        <a href="/api/ops/adoption/w15/ops-efficiency">W15 Ops Efficiency API (Token)</a>
        <a href="/api/ops/adoption/w15/efficiency-policy">W15 Efficiency Policy API (Token)</a>
        <a href="/api/adoption/w15/tracker/items">W15 Tracker Items API (Token)</a>
        <a href="/api/adoption/w15/tracker/overview?site=HQ">W15 Tracker Overview API (Token)</a>
      </div>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Checklist ID</th>
              <th>Title</th>
              <th>Efficiency Cluster</th>
              <th>Owner Role</th>
              <th>Target</th>
              <th>Source API</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w15_guide_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Runbook ID</th>
              <th>Module</th>
              <th>Symptom</th>
              <th>Owner Role</th>
              <th>Definition of Done</th>
              <th>API Ref</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w15_runbook_rows)}
          </tbody>
        </table>
      </div>
      <div class="table-wrap" style="margin-top: 12px;">
        <table>
          <thead>
            <tr>
              <th>Date</th>
              <th>Time</th>
              <th>Session</th>
              <th>Owner</th>
              <th>Output</th>
            </tr>
          </thead>
          <tbody>
            {"".join(w15_schedule_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>Weekly Execution Table</h2>
      <p class="sub">     ,     .</p>
      <div class="filter-row">
        {"".join(phase_filter_buttons)}
        <input id="weekSearch" class="search-input" type="text" placeholder="phase/focus/owner " />
      </div>
      <div id="timelineBoard" class="timeline-board">
        {"".join(week_cards)}
      </div>
      {active_week_guide}
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Week</th>
              <th>Date</th>
              <th>Phase</th>
              <th>Focus</th>
              <th>Actions</th>
              <th>Deliverables</th>
              <th>Owner</th>
              <th>Success Metric</th>
            </tr>
          </thead>
          <tbody>
            {"".join(weekly_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>Training Materials Outline</h2>
      <p class="sub">        .</p>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Module</th>
              <th>Audience</th>
              <th>Duration</th>
              <th>Contents</th>
              <th>Format</th>
            </tr>
          </thead>
          <tbody>
            {"".join(training_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>KPI Dashboard Items</h2>
      <p class="sub">    KPI      .</p>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>Name</th>
              <th>Formula</th>
              <th>Target</th>
              <th>Data Source</th>
              <th>Frequency</th>
            </tr>
          </thead>
          <tbody>
            {"".join(kpi_rows)}
          </tbody>
        </table>
      </div>
    </section>

    <section class="section">
      <h2>Promotion + Education + Fun Kit</h2>
      <p class="sub"> +  +         .</p>
      <h3>Promotion</h3>
      <div class="grid">
        {"".join(promotion_cards)}
      </div>
      <h3>Education</h3>
      <div class="grid">
        {"".join(education_cards)}
      </div>
      <h3>Fun</h3>
      <div class="grid">
        {"".join(fun_cards)}
      </div>
      <div class="links" style="margin-top: 12px;">
        <a href="/api/public/adoption-plan/campaign">Campaign API</a>
      </div>
    </section>

    <section class="section">
      <h2>Schedule Management</h2>
      <p class="sub">Next review date: {html.escape(str(plan.get("schedule_management", {}).get("next_review_date", "")))}</p>
      <div class="card">
        <h3>Operating Cadence</h3>
        <ul>{cadence_list}</ul>
      </div>
    </section>

    <section class="section">
      <h2>Post-MVP Execution Pack</h2>
      <p class="sub">
        Timeline: {html.escape(str(post_timeline.get("start_date", "")))} ~
        {html.escape(str(post_timeline.get("end_date", "")))} |
        Duration: {html.escape(str(post_timeline.get("duration_weeks", "")))} weeks
      </p>
      <div class="links">
        <a href="/api/public/post-mvp">Post-MVP JSON API</a>
        <a href="/api/public/post-mvp/backlog.csv">Backlog CSV</a>
        <a href="/api/public/post-mvp/releases.ics">Release ICS</a>
        <a href="/api/public/post-mvp/kpi-dashboard">KPI Spec API</a>
        <a href="/api/public/post-mvp/risks">Risk Register API</a>
      </div>
      <div class="card">
        <h3>Governance Cadence</h3>
        <ul>{post_governance_items_html}</ul>
      </div>
      <h3>Roadmap Phases</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Phase</th>
              <th>Period</th>
              <th>Duration</th>
              <th>Objective</th>
              <th>Outcomes</th>
              <th>Release Gate</th>
            </tr>
          </thead>
          <tbody>
            {"".join(post_roadmap_rows)}
          </tbody>
        </table>
      </div>
      <h3>Execution Backlog</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>Epic</th>
              <th>Item</th>
              <th>Priority</th>
              <th>Owner</th>
              <th>Points</th>
              <th>Target Release</th>
              <th>Status</th>
              <th>Success KPI</th>
            </tr>
          </thead>
          <tbody>
            {"".join(post_backlog_rows)}
          </tbody>
        </table>
      </div>
      <h3>Release Calendar</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Release</th>
              <th>Name</th>
              <th>Date</th>
              <th>Owner</th>
              <th>Goal</th>
            </tr>
          </thead>
          <tbody>
            {"".join(post_release_rows)}
          </tbody>
        </table>
      </div>
      <h3>Post-MVP KPI Dashboard Spec</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>Name</th>
              <th>Formula</th>
              <th>Target</th>
              <th>Cadence</th>
              <th>Owner</th>
              <th>Alert Rule</th>
            </tr>
          </thead>
          <tbody>
            {"".join(post_kpi_rows)}
          </tbody>
        </table>
      </div>
      <h3>Risk Register</h3>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>Risk</th>
              <th>Probability</th>
              <th>Impact</th>
              <th>Signal</th>
              <th>Mitigation</th>
              <th>Owner</th>
              <th>Status</th>
              <th>Review</th>
            </tr>
          </thead>
          <tbody>
            {"".join(post_risk_rows)}
          </tbody>
        </table>
      </div>
    </section>
  </div>
  <script>
    (function() {{
      const buttons = Array.from(document.querySelectorAll(".filter-btn"));
      const cards = Array.from(document.querySelectorAll(".week-card"));
      const searchInput = document.getElementById("weekSearch");
      let selectedPhase = "all";

      function applyFilters() {{
        const query = ((searchInput && searchInput.value) || "").toLowerCase().trim();
        cards.forEach((card) => {{
          const phase = (card.dataset.phase || "").toLowerCase();
          const keywords = (card.dataset.keywords || "").toLowerCase();
          const phaseMatched = selectedPhase === "all" || phase === selectedPhase;
          const queryMatched = query === "" || keywords.includes(query);
          card.style.display = phaseMatched && queryMatched ? "" : "none";
        }});
      }}

      buttons.forEach((btn) => {{
        btn.addEventListener("click", () => {{
          selectedPhase = (btn.dataset.phase || "all").toLowerCase();
          buttons.forEach((b) => b.classList.remove("active"));
          btn.classList.add("active");
          applyFilters();
        }});
      }});

      if (searchInput) {{
        searchInput.addEventListener("input", applyFilters);
      }}
      applyFilters();

      const summaryToggle = document.getElementById("summaryModeToggle");
      if (summaryToggle) {{
        summaryToggle.addEventListener("click", () => {{
          const enabled = document.body.classList.toggle("summary-mode");
          summaryToggle.setAttribute("aria-pressed", enabled ? "true" : "false");
          summaryToggle.textContent = enabled
            ? "  ( 5): ON"
            : "  ( 5): OFF";
          if (enabled) {{
            window.scrollTo({{ top: 0, behavior: "smooth" }});
          }}
        }});
      }}
    }})();
  </script>
</body>
</html>
"""


def _build_facility_console_html(service_info: dict[str, str], modules_payload: dict[str, Any]) -> str:
    modules = modules_payload.get("modules", [])
    module_cards: list[str] = []
    for item in modules:
        links = "".join(
            f'<a href="{html.escape(str(link.get("href", "#")))}">{html.escape(str(link.get("label", "Open")))}'
            "</a>"
            for link in item.get("links", [])
        )
        module_cards.append(
            f"""
            <article class="module-card">
              <h3>{html.escape(str(item.get("name_ko", "")))}</h3>
              <p class="en">{html.escape(str(item.get("name", "")))}</p>
              <p>{html.escape(str(item.get("description", "")))}</p>
              <p class="hint"><strong>KPI Hint:</strong> {html.escape(str(item.get("kpi_hint", "")))}</p>
              <div class="module-links">{links}</div>
            </article>
            """
        )

    module_cards_html = "".join(module_cards) or '<p class="empty">  .</p>'

    template = """<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KA Facility OS - Facility Console</title>
  <style>
    :root {
      --ink: #0f1e36;
      --muted: #4a607f;
      --line: #d4dfef;
      --card: #ffffff;
      --bg: #f2f7ff;
      --brand: #0a6d58;
      --accent: #cb4f20;
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      color: var(--ink);
      font-family: "SUIT", "Pretendard", "IBM Plex Sans KR", "Noto Sans KR", sans-serif;
      background:
        radial-gradient(900px 380px at 0% -20%, #dcf6ff 0%, transparent 60%),
        radial-gradient(700px 320px at 100% -20%, #ffefd9 0%, transparent 60%),
        var(--bg);
    }
    .wrap { max-width: 1280px; margin: 0 auto; padding: 18px 14px 56px; }
    .hero {
      border: 1px solid var(--line);
      border-radius: 16px;
      background: linear-gradient(145deg, #ffffff 0%, #eff8f5 54%, #fff5ea 100%);
      box-shadow: 0 10px 28px rgba(13, 38, 76, 0.09);
      padding: 16px;
    }
    .hero h1 { margin: 0; font-size: 24px; }
    .hero p { margin: 7px 0 0; color: var(--muted); }
    .hero-links { margin-top: 11px; display: flex; flex-wrap: wrap; gap: 8px; }
    .hero-links a {
      text-decoration: none;
      font-size: 12px;
      font-weight: 700;
      border: 1px solid #b8cfea;
      border-radius: 999px;
      padding: 6px 10px;
      color: #1f4f82;
      background: #f4f8ff;
    }
    .hero-links a:hover { border-color: #87addb; background: #e8f2ff; }
    .section {
      border: 1px solid var(--line);
      border-radius: 14px;
      background: var(--card);
      margin-top: 14px;
      padding: 14px;
    }
    .section h2 {
      margin: 0 0 8px;
      font-size: 18px;
      border-left: 4px solid var(--accent);
      padding-left: 8px;
    }
    .sub { margin: 0; color: var(--muted); font-size: 13px; }
    .auth-row {
      margin-top: 10px;
      display: grid;
      grid-template-columns: 1fr auto auto auto;
      gap: 8px;
    }
    .auth-row input, .query-card input {
      width: 100%;
      border: 1px solid var(--line);
      border-radius: 10px;
      padding: 8px 10px;
      font-size: 13px;
      background: #fff;
      color: var(--ink);
    }
    .btn {
      border: 1px solid #86b7d8;
      background: #eff7ff;
      color: #1a4d7d;
      border-radius: 10px;
      padding: 8px 10px;
      font-size: 12px;
      font-weight: 800;
      cursor: pointer;
      white-space: nowrap;
    }
    .btn:hover { background: #e3f0ff; }
    .btn.run {
      border-color: #85cab7;
      background: #e9f8f3;
      color: #0d5f4f;
    }
    .btn.run:hover { background: #def5ed; }
    .token-state {
      margin-top: 8px;
      font-size: 12px;
      color: #234565;
      background: #eef5ff;
      border: 1px solid #c7d8ef;
      border-radius: 8px;
      padding: 6px 8px;
    }
    .module-grid {
      margin-top: 12px;
      display: grid;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      gap: 9px;
    }
    .module-card {
      border: 1px solid var(--line);
      border-radius: 12px;
      background: #fff;
      padding: 10px;
    }
    .module-card h3 { margin: 0; font-size: 14px; color: var(--brand); }
    .module-card .en { margin: 4px 0 7px; font-size: 12px; color: #3d5b82; font-weight: 700; }
    .module-card p { margin: 4px 0; font-size: 12px; color: var(--muted); }
    .module-card .hint { margin-top: 6px; color: #254a73; }
    .module-links {
      margin-top: 8px;
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
    }
    .module-links a {
      text-decoration: none;
      border: 1px solid #bdd3ec;
      border-radius: 8px;
      padding: 5px 8px;
      font-size: 11px;
      font-weight: 700;
      color: #225385;
      background: #f4f9ff;
    }
    .module-links a:hover { border-color: #8bb0da; background: #eaf2ff; }
    .workspace {
      margin-top: 12px;
      display: grid;
      grid-template-columns: 420px minmax(0, 1fr);
      gap: 12px;
      align-items: start;
    }
    .query-grid {
      display: grid;
      gap: 8px;
    }
    .query-card {
      border: 1px solid var(--line);
      border-radius: 10px;
      background: #fff;
      padding: 10px;
    }
    .query-card h3 { margin: 0 0 7px; font-size: 14px; color: #0e5f50; }
    .query-card p { margin: 0 0 8px; color: var(--muted); font-size: 12px; }
    .query-fields { display: grid; gap: 6px; margin-bottom: 7px; }
    .query-inline { display: grid; gap: 6px; grid-template-columns: repeat(2, minmax(0, 1fr)); }
    .result-panel {
      border: 1px solid var(--line);
      border-radius: 10px;
      background: #fff;
      padding: 12px;
      min-height: 740px;
    }
    .result-meta {
      font-size: 12px;
      color: #26496d;
      background: #eef5ff;
      border: 1px solid #c8d8ee;
      border-radius: 8px;
      padding: 7px 8px;
      margin-bottom: 10px;
    }
    .empty {
      border: 1px dashed #bcd0e8;
      border-radius: 10px;
      color: var(--muted);
      background: #f8fbff;
      padding: 16px;
      text-align: center;
      font-size: 13px;
    }
    .kv-table, .arr-table {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #dbe5f2;
      border-radius: 8px;
      overflow: hidden;
      font-size: 12px;
    }
    .kv-table th, .kv-table td, .arr-table th, .arr-table td {
      border-bottom: 1px solid #eaf0f8;
      padding: 7px 8px;
      vertical-align: top;
      text-align: left;
      word-break: break-word;
    }
    .kv-table th, .arr-table th {
      background: #f6f9ff;
      color: #27486f;
    }
    .mono {
      font-family: "Consolas", "D2Coding", "IBM Plex Mono", monospace;
      font-size: 12px;
      color: #183858;
      white-space: pre-wrap;
      margin: 0;
      background: #f4f8ff;
      border: 1px solid #d8e4f4;
      border-radius: 8px;
      padding: 9px;
      max-height: 280px;
      overflow: auto;
    }
    details { margin-top: 10px; }
    details summary { cursor: pointer; color: #2c4d76; font-weight: 700; font-size: 12px; }
    .download-links {
      margin-top: 6px;
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
    }
    .download-links a {
      text-decoration: none;
      border: 1px solid #b6cce5;
      border-radius: 8px;
      padding: 5px 8px;
      font-size: 11px;
      font-weight: 700;
      color: #25517d;
      background: #f4f9ff;
    }
    @media (max-width: 1000px) {
      .module-grid { grid-template-columns: 1fr; }
      .workspace { grid-template-columns: 1fr; }
      .result-panel { min-height: 500px; }
      .auth-row { grid-template-columns: 1fr; }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <header class="hero">
      <h1>KA Facility OS   </h1>
      <p>: __SERVICE_NAME__ | API   /   HTML . JSON API  ,      .</p>
      <div class="hero-links">
        <a href="/">Public Main</a>
        <a href="/docs">Swagger Docs</a>
        <a href="/api/service-info">Service Info API</a>
        <a href="/api/public/modules">Modules API</a>
      </div>
    </header>

    <section class="section">
      <h2>1)  </h2>
      <p class="sub">  (//SLA/)  (X-Admin-Token) .</p>
      <div class="auth-row">
        <input id="adminTokenInput" type="password" placeholder="X-Admin-Token " autocomplete="off" />
        <button id="saveTokenBtn" class="btn" type="button"> </button>
        <button id="testTokenBtn" class="btn run" type="button">  (/api/auth/me)</button>
        <button id="clearTokenBtn" class="btn" type="button"> </button>
      </div>
      <div id="tokenState" class="token-state"> : </div>
    </section>

    <section class="section">
      <h2>2)   </h2>
      <p class="sub">  (__MODULE_COUNT__)  API  .</p>
      <div class="module-grid">__MODULE_CARDS__</div>
    </section>

    <section class="section">
      <h2>3)   HTML </h2>
      <p class="sub">   ,        .</p>
      <div class="workspace">
        <div class="query-grid">
          <article class="query-card">
            <h3>:  </h3>
            <p>     .</p>
            <button class="btn run run-btn" data-panel="serviceInfo" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>:  </h3>
            <p>    JSON  HTML .</p>
            <button class="btn run run-btn" data-panel="publicModules" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>:   </h3>
            <p>  //site scope .</p>
            <button class="btn run run-btn" data-panel="authMe" type="button"> </button>
          </article>

          <article class="query-card">
            <h3> </h3>
            <div class="query-fields">
              <input id="q-inspection-site" placeholder="site (optional)" />
              <div class="query-inline">
                <input id="q-inspection-limit" placeholder="limit (default 20)" value="20" />
                <input id="q-inspection-offset" placeholder="offset (default 0)" value="0" />
              </div>
            </div>
            <button class="btn run run-btn" data-panel="inspections" type="button"> </button>
          </article>

          <article class="query-card">
            <h3> </h3>
            <div class="query-fields">
              <div class="query-inline">
                <input id="q-work-status" placeholder="status (open/acked/...)" />
                <input id="q-work-site" placeholder="site (optional)" />
              </div>
              <div class="query-inline">
                <input id="q-work-limit" placeholder="limit (default 20)" value="20" />
                <input id="q-work-offset" placeholder="offset (default 0)" value="0" />
              </div>
            </div>
            <button class="btn run run-btn" data-panel="workOrders" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>  </h3>
            <div class="query-fields">
              <input id="q-dash-site" placeholder="site (optional)" />
              <div class="query-inline">
                <input id="q-dash-days" placeholder="days (default 30)" value="30" />
                <input id="q-dash-jobs" placeholder="job_limit (default 10)" value="10" />
              </div>
            </div>
            <button class="btn run run-btn" data-panel="dashboardSummary" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>  KPI (7/30)</h3>
            <div class="query-fields">
              <input id="q-alert-event-type" placeholder="event_type (optional)" />
            </div>
            <button class="btn run run-btn" data-panel="alertChannelKpi" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>  </h3>
            <div class="query-fields">
              <div class="query-inline">
                <input id="q-alert-guard-lookback" placeholder="lookback_days (default 30)" value="30" />
                <input id="q-alert-guard-max-targets" placeholder="max_targets (default 100)" value="100" />
              </div>
            </div>
            <button class="btn run run-btn" data-panel="alertChannelGuard" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>  </h3>
            <p>/      .</p>
            <div class="query-inline">
              <button class="btn run run-btn" data-panel="alertRetentionPolicy" type="button"> </button>
              <button class="btn run run-btn" data-panel="alertRetentionLatest" type="button">  </button>
            </div>
          </article>

          <article class="query-card">
            <h3> </h3>
            <div class="query-fields">
              <input id="q-handover-site" placeholder="site (optional)" />
              <div class="query-inline">
                <input id="q-handover-window" placeholder="window_hours (default 12)" value="12" />
                <input id="q-handover-due-soon" placeholder="due_soon_hours (default 6)" value="6" />
              </div>
              <input id="q-handover-max-items" placeholder="max_items (default 10)" value="10" />
            </div>
            <button class="btn run run-btn" data-panel="handoverBrief" type="button"> </button>
          </article>

          <article class="query-card">
            <h3>  </h3>
            <div class="query-fields">
              <div class="query-inline">
                <input id="q-report-month" placeholder="month (YYYY-MM)" />
                <input id="q-report-site" placeholder="site (optional)" />
              </div>
            </div>
            <button class="btn run run-btn" data-panel="monthlyReport" type="button">JSON </button>
            <div class="download-links">
              <a id="reportPrintLink" href="/reports/monthly/print" target="_blank" rel="noopener">Print HTML</a>
              <a id="reportCsvLink" href="/api/reports/monthly/csv" target="_blank" rel="noopener">CSV </a>
              <a id="reportPdfLink" href="/api/reports/monthly/pdf" target="_blank" rel="noopener">PDF </a>
            </div>
          </article>

          <article class="query-card">
            <h3>SLA  </h3>
            <div class="query-fields">
              <input id="q-sla-site" placeholder="site (optional)" />
            </div>
            <button class="btn run run-btn" data-panel="slaPolicy" type="button"> </button>
          </article>
        </div>

        <div class="result-panel">
          <h3>Result Viewer</h3>
          <p id="resultMeta" class="result-meta">  .</p>
          <div id="resultView" class="empty">   .</div>
          <details>
            <summary>Raw JSON </summary>
            <pre id="resultRaw" class="mono">{}</pre>
          </details>
        </div>
      </div>
    </section>
  </div>

  <script>
    (function() {
      const TOKEN_KEY = 'kaFacilityAdminToken';
      const tokenInput = document.getElementById('adminTokenInput');
      const tokenState = document.getElementById('tokenState');
      const resultMeta = document.getElementById('resultMeta');
      const resultView = document.getElementById('resultView');
      const resultRaw = document.getElementById('resultRaw');

      const panelDefs = {
        serviceInfo: { path: '/api/service-info', auth: false, params: [] },
        publicModules: { path: '/api/public/modules', auth: false, params: [] },
        authMe: { path: '/api/auth/me', auth: true, params: [] },
        inspections: {
          path: '/api/inspections',
          auth: true,
          params: [
            { key: 'site', id: 'q-inspection-site' },
            { key: 'limit', id: 'q-inspection-limit' },
            { key: 'offset', id: 'q-inspection-offset' }
          ]
        },
        workOrders: {
          path: '/api/work-orders',
          auth: true,
          params: [
            { key: 'status', id: 'q-work-status' },
            { key: 'site', id: 'q-work-site' },
            { key: 'limit', id: 'q-work-limit' },
            { key: 'offset', id: 'q-work-offset' }
          ]
        },
        dashboardSummary: {
          path: '/api/ops/dashboard/summary',
          auth: true,
          params: [
            { key: 'site', id: 'q-dash-site' },
            { key: 'days', id: 'q-dash-days' },
            { key: 'job_limit', id: 'q-dash-jobs' }
          ]
        },
        alertChannelKpi: {
          path: '/api/ops/alerts/kpi/channels',
          auth: true,
          params: [{ key: 'event_type', id: 'q-alert-event-type' }]
        },
        alertChannelGuard: {
          path: '/api/ops/alerts/channels/guard',
          auth: true,
          params: [
            { key: 'event_type', id: 'q-alert-event-type' },
            { key: 'lookback_days', id: 'q-alert-guard-lookback' },
            { key: 'max_targets', id: 'q-alert-guard-max-targets' }
          ]
        },
        alertRetentionPolicy: {
          path: '/api/ops/alerts/retention/policy',
          auth: true,
          params: []
        },
        alertRetentionLatest: {
          path: '/api/ops/alerts/retention/latest',
          auth: true,
          params: []
        },
        handoverBrief: {
          path: '/api/ops/handover/brief',
          auth: true,
          params: [
            { key: 'site', id: 'q-handover-site' },
            { key: 'window_hours', id: 'q-handover-window' },
            { key: 'due_soon_hours', id: 'q-handover-due-soon' },
            { key: 'max_items', id: 'q-handover-max-items' }
          ]
        },
        monthlyReport: {
          path: '/api/reports/monthly',
          auth: true,
          params: [
            { key: 'month', id: 'q-report-month' },
            { key: 'site', id: 'q-report-site' }
          ]
        },
        slaPolicy: {
          path: '/api/admin/policies/sla',
          auth: true,
          params: [{ key: 'site', id: 'q-sla-site' }]
        }
      };

      function escapeHtml(value) {
        return String(value)
          .replaceAll('&', '&amp;')
          .replaceAll('<', '&lt;')
          .replaceAll('>', '&gt;')
          .replaceAll('"', '&quot;')
          .replaceAll("'", '&#39;');
      }

      function getToken() {
        const sessionToken = window.sessionStorage.getItem(TOKEN_KEY) || '';
        if (sessionToken) return sessionToken;
        const legacyLocalToken = window.localStorage.getItem(TOKEN_KEY) || '';
        if (legacyLocalToken) {
          // Migrate legacy persistent token to session-only storage.
          window.sessionStorage.setItem(TOKEN_KEY, legacyLocalToken);
          window.localStorage.removeItem(TOKEN_KEY);
        }
        return legacyLocalToken;
      }

      function updateTokenState() {
        const token = getToken();
        tokenState.textContent = token
          ? ' :  ( ' + token.length + ')'
          : ' : ';
      }

      function readInput(id) {
        const node = document.getElementById(id);
        if (!node) return '';
        return (node.value || '').trim();
      }

      function buildPath(def) {
        const params = new URLSearchParams();
        (def.params || []).forEach((item) => {
          const value = readInput(item.id);
          if (value !== '') {
            params.set(item.key, value);
          }
        });
        const query = params.toString();
        return query ? def.path + '?' + query : def.path;
      }

      function renderArray(arr) {
        if (!arr.length) {
          return '<div class="empty">   .</div>';
        }
        const allObjects = arr.every((item) => item !== null && typeof item === 'object' && !Array.isArray(item));
        if (!allObjects) {
          const list = arr.map((item) => '<li>' + escapeHtml(typeof item === 'object' ? JSON.stringify(item, null, 2) : item) + '</li>').join('');
          return '<ul>' + list + '</ul>';
        }

        const keys = [];
        arr.forEach((row) => {
          Object.keys(row).forEach((key) => {
            if (!keys.includes(key)) keys.push(key);
          });
        });
        const head = keys.map((key) => '<th>' + escapeHtml(key) + '</th>').join('');
        const body = arr.map((row) => {
          const cells = keys.map((key) => {
            const value = row[key];
            if (value === null || value === undefined) return '<td></td>';
            if (typeof value === 'object') return '<td>' + escapeHtml(JSON.stringify(value)) + '</td>';
            return '<td>' + escapeHtml(value) + '</td>';
          }).join('');
          return '<tr>' + cells + '</tr>';
        }).join('');
        return '<table class="arr-table"><thead><tr>' + head + '</tr></thead><tbody>' + body + '</tbody></table>';
      }

      function renderObject(obj) {
        const rows = Object.keys(obj).map((key) => {
          const value = obj[key];
          let valueHtml = '';
          if (Array.isArray(value)) {
            valueHtml = renderArray(value);
          } else if (value !== null && typeof value === 'object') {
            valueHtml = '<pre class="mono">' + escapeHtml(JSON.stringify(value, null, 2)) + '</pre>';
          } else if (value === null || value === undefined) {
            valueHtml = '';
          } else {
            valueHtml = escapeHtml(value);
          }
          return '<tr><th>' + escapeHtml(key) + '</th><td>' + valueHtml + '</td></tr>';
        }).join('');
        return '<table class="kv-table"><tbody>' + rows + '</tbody></table>';
      }

      function renderData(data) {
        if (Array.isArray(data)) return renderArray(data);
        if (data !== null && typeof data === 'object') return renderObject(data);
        if (data === null || data === undefined) return '<div class="empty"> .</div>';
        return '<pre class="mono">' + escapeHtml(String(data)) + '</pre>';
      }

      async function runPanel(panelId) {
        const def = panelDefs[panelId];
        if (!def) return;
        const path = buildPath(def);
        const headers = { 'Accept': 'application/json' };
        if (def.auth) {
          const token = getToken();
          if (!token) {
            resultMeta.textContent = ' :    .';
            resultView.innerHTML = '<div class="empty">     .</div>';
            return;
          }
          headers['X-Admin-Token'] = token;
        }

        resultMeta.textContent = ' ... ' + path;
        try {
          const res = await fetch(path, { headers });
          const rawText = await res.text();
          let data = rawText;
          try {
            data = JSON.parse(rawText);
          } catch (err) {
            data = rawText;
          }
          resultRaw.textContent = typeof data === 'string' ? data : JSON.stringify(data, null, 2);

          if (!res.ok) {
            resultMeta.textContent = ': HTTP ' + res.status + ' | ' + path;
            resultView.innerHTML = renderData(data);
            return;
          }

          resultMeta.textContent = ': HTTP ' + res.status + ' | ' + path;
          resultView.innerHTML = renderData(data);
        } catch (err) {
          resultMeta.textContent = ' : ' + (err && err.message ? err.message : 'unknown error');
          resultView.innerHTML = '<div class="empty">    .</div>';
        }
      }

      function updateReportLinks() {
        const month = readInput('q-report-month');
        const site = readInput('q-report-site');
        const params = new URLSearchParams();
        if (month) params.set('month', month);
        if (site) params.set('site', site);
        const suffix = params.toString() ? '?' + params.toString() : '';
        document.getElementById('reportPrintLink').setAttribute('href', '/reports/monthly/print' + suffix);
        document.getElementById('reportCsvLink').setAttribute('href', '/api/reports/monthly/csv' + suffix);
        document.getElementById('reportPdfLink').setAttribute('href', '/api/reports/monthly/pdf' + suffix);
      }

      document.querySelectorAll('.run-btn').forEach((btn) => {
        btn.addEventListener('click', () => runPanel(btn.dataset.panel));
      });

      document.getElementById('saveTokenBtn').addEventListener('click', () => {
        const token = (tokenInput.value || '').trim();
        if (!token) {
          tokenState.textContent = ' :     .';
          return;
        }
        window.sessionStorage.setItem(TOKEN_KEY, token);
        window.localStorage.removeItem(TOKEN_KEY);
        updateTokenState();
      });

      document.getElementById('clearTokenBtn').addEventListener('click', () => {
        window.sessionStorage.removeItem(TOKEN_KEY);
        window.localStorage.removeItem(TOKEN_KEY);
        tokenInput.value = '';
        updateTokenState();
      });

      document.getElementById('testTokenBtn').addEventListener('click', () => runPanel('authMe'));
      ['q-report-month', 'q-report-site'].forEach((id) => {
        const node = document.getElementById(id);
        if (node) node.addEventListener('input', updateReportLinks);
      });

      const storedToken = getToken();
      if (storedToken) tokenInput.value = storedToken;
      updateTokenState();
      updateReportLinks();
      runPanel('serviceInfo');
    })();
  </script>
</body>
</html>
"""

    rendered = template
    rendered = rendered.replace("__MODULE_CARDS__", module_cards_html)
    rendered = rendered.replace("__MODULE_COUNT__", str(len(modules)))
    rendered = rendered.replace("__SERVICE_NAME__", html.escape(service_info.get("service", "ka-facility-os")))
    return rendered


def _build_public_modules_html(modules_payload: dict[str, Any]) -> str:
    modules = modules_payload.get("modules", [])
    cards: list[str] = []
    for item in modules:
        links_html = "".join(
            f'<a href="{html.escape(str(link.get("href", "#")))}">{html.escape(str(link.get("label", "Open")))}'
            "</a>"
            for link in item.get("links", [])
        )
        cards.append(
            f"""
            <article class="module-card">
              <h3>{html.escape(str(item.get("name_ko", "")))}</h3>
              <p class="en">{html.escape(str(item.get("name", "")))}</p>
              <p class="desc">{html.escape(str(item.get("description", "")))}</p>
              <p class="hint"><strong>KPI Hint:</strong> {html.escape(str(item.get("kpi_hint", "")))}</p>
              <div class="links">{links_html}</div>
            </article>
            """
        )

    cards_html = "".join(cards) or "<p>  .</p>"
    return f"""
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KA Facility OS - Public Modules</title>
  <style>
    :root {{
      --ink: #0f1f37;
      --muted: #49617f;
      --line: #d5e0ef;
      --bg: #f4f8ff;
      --card: #fff;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      margin: 0;
      color: var(--ink);
      font-family: "SUIT", "Pretendard", "IBM Plex Sans KR", "Noto Sans KR", sans-serif;
      background:
        radial-gradient(820px 320px at 10% -20%, #dff6ff 0%, transparent 58%),
        radial-gradient(740px 320px at 95% -20%, #ffecd8 0%, transparent 58%),
        var(--bg);
    }}
    .wrap {{ max-width: 1200px; margin: 0 auto; padding: 18px 14px 48px; }}
    .hero {{
      border: 1px solid var(--line);
      border-radius: 14px;
      background: linear-gradient(145deg, #fff 0%, #eef8f5 52%, #fff4e8 100%);
      padding: 14px;
      box-shadow: 0 10px 24px rgba(15, 35, 63, 0.08);
    }}
    .hero h1 {{ margin: 0; font-size: 24px; }}
    .hero p {{ margin: 7px 0 0; color: var(--muted); font-size: 14px; }}
    .hero-links {{ margin-top: 10px; display: flex; flex-wrap: wrap; gap: 7px; }}
    .hero-links a {{
      text-decoration: none;
      font-size: 12px;
      border: 1px solid #b7cde7;
      border-radius: 999px;
      padding: 6px 10px;
      color: #1f4d7c;
      background: #f3f8ff;
      font-weight: 700;
    }}
    .grid {{
      margin-top: 14px;
      display: grid;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      gap: 10px;
    }}
    .module-card {{
      border: 1px solid var(--line);
      border-radius: 12px;
      background: var(--card);
      padding: 12px;
    }}
    .module-card h3 {{ margin: 0; font-size: 15px; color: #0c654f; }}
    .module-card .en {{ margin: 4px 0 8px; font-size: 12px; color: #3e5f84; font-weight: 700; }}
    .module-card .desc {{ margin: 0; color: var(--muted); font-size: 12px; }}
    .module-card .hint {{ margin: 8px 0 0; color: #264d77; font-size: 12px; }}
    .module-card .links {{
      margin-top: 8px;
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
    }}
    .module-card .links a {{
      text-decoration: none;
      border: 1px solid #bdd2eb;
      border-radius: 8px;
      padding: 5px 8px;
      font-size: 11px;
      font-weight: 700;
      color: #245281;
      background: #f3f8ff;
    }}
    @media (max-width: 900px) {{
      .grid {{ grid-template-columns: 1fr; }}
      .hero h1 {{ font-size: 20px; }}
    }}
  </style>
</head>
<body>
  <div class="wrap">
    <header class="hero">
      <h1>Facility Web Modules</h1>
      <p> API JSON       .</p>
      <div class="hero-links">
        <a href="/">Public Main</a>
        <a href="/web/console">Operations Console</a>
        <a href="/api/public/modules">Same URL (JSON/HTML)</a>
      </div>
    </header>
    <section class="grid">
      {cards_html}
    </section>
  </div>
</body>
</html>
"""


def _build_shared_tracker_execution_box_html(phase_code: str, phase_label: str) -> str:
    code = phase_code.lower()
    label = phase_label.upper()
    return f"""
          <div class="box">
            <h3>{label}   (  /  /  )</h3>
            <div class="filter-row">
              <input id="{code}TrackSite" placeholder="site (required, : HQ)" />
              <input id="{code}TrackItemId" placeholder="tracker_item_id" />
              <input id="{code}TrackAssignee" placeholder="assignee" />
              <select id="{code}TrackStatus">
                <option value="">status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="{code}TrackBootstrapBtn" class="btn run" type="button">{label}  </button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="{code}TrackCompleted" type="checkbox" />
                 
              </label>
              <input id="{code}TrackNote" placeholder="completion note (optional)" />
              <input id="{code}EvidenceNote" placeholder="evidence note (optional)" />
              <input id="{code}EvidenceFile" type="file" />
              <button id="{code}TrackUpdateBtn" class="btn" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="{code}EvidenceListItemId" placeholder="evidence  tracker_item_id" />
              <input id="{code}Reserved1" value="token required for write actions" disabled />
              <input id="{code}Reserved2" value="site scope enforced" disabled />
              <input id="{code}Reserved3" value="max file 5MB" disabled />
              <button id="{code}TrackRefreshBtn" class="btn run" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="{code}CompletionNote" placeholder="completion note (optional)" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="{code}CompletionForce" type="checkbox" />
                 (owner/admin)
              </label>
              <input id="{code}Reserved4" value="readiness gate required" disabled />
              <button id="{code}ReadinessBtn" class="btn run" type="button"> </button>
              <button id="{code}CompleteBtn" class="btn" type="button">{label}  </button>
            </div>
            <div id="{code}TrackerMeta" class="meta"> </div>
            <div id="{code}TrackerSummary" class="cards"></div>
            <div id="{code}TrackerTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">{label}   </h4>
            <div id="{code}ReadinessMeta" class="meta"> </div>
            <div id="{code}ReadinessCards" class="cards"></div>
            <div id="{code}ReadinessBlockers" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="{code}EvidenceTable" class="empty"> </div>
          </div>
"""


def _build_system_main_tabs_html(service_info: dict[str, str], *, initial_tab: str) -> str:
    allowed_tabs = {"overview", "workorders", "inspections", "reports", "adoption"}
    selected_tab = initial_tab if initial_tab in allowed_tabs else "overview"
    w09_tracker_box_html = _build_shared_tracker_execution_box_html("w09", "W09")
    w10_tracker_box_html = _build_shared_tracker_execution_box_html("w10", "W10")
    w11_tracker_box_html = _build_shared_tracker_execution_box_html("w11", "W11")
    w15_tracker_box_html = _build_shared_tracker_execution_box_html("w15", "W15")
    return f"""
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KA Facility OS - Main</title>
  <style>
    :root {{
      --ink: #0d203b;
      --muted: #496081;
      --line: #d6e1ef;
      --bg: #f4f8ff;
      --card: #fff;
      --brand: #0e6f5d;
      --accent: #d25c2e;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      margin: 0;
      color: var(--ink);
      font-family: "SUIT", "Pretendard", "IBM Plex Sans KR", "Noto Sans KR", sans-serif;
      background:
        radial-gradient(860px 320px at 10% -20%, #ddf6ff 0%, transparent 58%),
        radial-gradient(760px 320px at 95% -20%, #ffedd7 0%, transparent 58%),
        var(--bg);
    }}
    .wrap {{ max-width: 1300px; margin: 0 auto; padding: 18px 14px 44px; }}
    .hero {{
      border: 1px solid var(--line);
      border-radius: 16px;
      padding: 16px;
      background: linear-gradient(140deg, #fff 0%, #eef8f5 54%, #fff4e8 100%);
      box-shadow: 0 10px 26px rgba(12, 34, 64, 0.08);
    }}
    .hero h1 {{ margin: 0; font-size: 26px; }}
    .hero p {{ margin: 8px 0 0; color: var(--muted); }}
    .links {{
      margin-top: 10px;
      display: flex;
      flex-wrap: wrap;
      gap: 7px;
    }}
    .links a {{
      text-decoration: none;
      border: 1px solid #b9cfe8;
      border-radius: 999px;
      padding: 6px 10px;
      font-size: 12px;
      font-weight: 700;
      color: #1f4f7e;
      background: #f3f8ff;
    }}
    .tabs {{
      margin-top: 14px;
      border: 1px solid var(--line);
      border-radius: 14px;
      background: var(--card);
      overflow: hidden;
    }}
    .tab-head {{
      display: flex;
      flex-wrap: wrap;
      gap: 0;
      border-bottom: 1px solid #e4edf8;
      background: #f8fbff;
    }}
    .tab-btn {{
      appearance: none;
      border: 0;
      border-right: 1px solid #e4edf8;
      background: transparent;
      color: #35587f;
      font-size: 14px;
      font-weight: 800;
      padding: 12px 14px;
      cursor: pointer;
    }}
    .tab-btn.active {{
      color: #0b5f4e;
      background: #ebfaf5;
      box-shadow: inset 0 -2px 0 #77c7b4;
    }}
    .shell {{
      padding: 12px;
    }}
    .auth-row {{
      display: grid;
      grid-template-columns: 1fr auto auto auto;
      gap: 8px;
      margin-bottom: 9px;
    }}
    .auth-row input, .filter-row input {{
      width: 100%;
      border: 1px solid #c8d8ec;
      border-radius: 10px;
      padding: 8px 10px;
      font-size: 13px;
      color: var(--ink);
      background: #fff;
    }}
    .btn {{
      border: 1px solid #97badf;
      border-radius: 10px;
      padding: 8px 10px;
      background: #f2f8ff;
      color: #1f4e7c;
      font-size: 12px;
      font-weight: 800;
      cursor: pointer;
      white-space: nowrap;
    }}
    .btn:hover {{ background: #e7f2ff; }}
    .btn.run {{
      border-color: #84cab6;
      color: #0c614f;
      background: #e9f8f2;
    }}
    .btn.run:hover {{ background: #e0f5ed; }}
    .btn.soft {{
      border-color: #c3d6ea;
      color: #2f567c;
      background: #f7fbff;
    }}
    .btn.soft:hover {{ background: #eef6ff; }}
    .auth-state {{
      margin-bottom: 12px;
      border: 1px solid #c7d8ee;
      border-radius: 10px;
      background: #f2f8ff;
      color: #264b70;
      font-size: 12px;
      padding: 7px 8px;
    }}
    .tab-panel {{
      display: none;
      animation: fadeup 200ms ease-out both;
    }}
    .tab-panel.active {{ display: block; }}
    .tab-caption {{
      margin: 0 0 10px;
      color: var(--muted);
      font-size: 13px;
    }}
    .filter-row {{
      display: grid;
      grid-template-columns: repeat(4, minmax(0, 1fr)) auto;
      gap: 8px;
      margin-bottom: 10px;
    }}
    .cards {{
      display: grid;
      grid-template-columns: repeat(4, minmax(0, 1fr));
      gap: 8px;
      margin-bottom: 10px;
    }}
    .card {{
      border: 1px solid #d8e4f4;
      border-radius: 10px;
      background: #fff;
      padding: 10px;
    }}
    .card .k {{ color: var(--muted); font-size: 12px; }}
    .card .v {{ margin-top: 4px; font-size: 22px; font-weight: 800; }}
    .card .sub {{ margin-top: 6px; font-size: 12px; color: #35587f; }}
    .card.status-ok {{ border-color: #9ed9c3; background: #effaf4; }}
    .card.status-warning {{ border-color: #f3d59e; background: #fff7ea; }}
    .card.status-critical {{ border-color: #e8a8aa; background: #fff1f2; }}
    .card.status-info {{ border-color: #d0ddf0; background: #f5f9ff; }}
    .status-chip {{
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      font-size: 11px;
      font-weight: 800;
      border: 1px solid #bdd3eb;
      color: #2a5680;
      background: #f3f8ff;
    }}
    .status-chip.ok {{ border-color: #8ecfb4; color: #0d654f; background: #e8f8f1; }}
    .status-chip.warning {{ border-color: #e9c786; color: #926016; background: #fff6e6; }}
    .status-chip.critical {{ border-color: #e09ca0; color: #9a2e36; background: #fff0f1; }}
    .status-chip.info {{ border-color: #bdd3eb; color: #2a5680; background: #f3f8ff; }}
    .w07-readiness-card {{
      cursor: pointer;
      transition: transform 140ms ease, box-shadow 140ms ease, border-color 140ms ease;
    }}
    .w07-readiness-card:hover {{
      transform: translateY(-1px);
      box-shadow: 0 8px 16px rgba(28, 62, 102, 0.09);
    }}
    .w07-readiness-card.active {{
      border-color: #5f9dd8;
      box-shadow: 0 0 0 2px rgba(95, 157, 216, 0.2);
    }}
    .w07-track-row {{
      cursor: pointer;
    }}
    .w07-track-row.active {{
      background: #eaf5ff;
    }}
    .w07-track-row td:first-child {{
      width: 36px;
    }}
    .w07-filter-hint {{
      margin-bottom: 8px;
      border: 1px solid #c7d8ee;
      border-radius: 8px;
      background: #f2f8ff;
      color: #264b70;
      font-size: 12px;
      padding: 6px 8px;
    }}
    .dropzone {{
      border: 1px dashed #8ab5de;
      border-radius: 10px;
      padding: 10px;
      font-size: 12px;
      color: #35587f;
      background: #f7fbff;
      text-align: center;
      cursor: pointer;
      user-select: none;
    }}
    .dropzone.dragover {{
      border-color: #0f6a57;
      background: #e8f7f1;
      color: #0f6a57;
    }}
    .modal {{
      position: fixed;
      inset: 0;
      display: none;
      align-items: center;
      justify-content: center;
      padding: 16px;
      z-index: 9999;
      background: rgba(9, 21, 37, 0.45);
    }}
    .modal.open {{
      display: flex;
    }}
    .modal-card {{
      width: min(640px, 100%);
      border: 1px solid #c5d8ed;
      border-radius: 12px;
      background: #fff;
      box-shadow: 0 20px 36px rgba(10, 33, 59, 0.24);
      padding: 14px;
    }}
    .modal-card h4 {{
      margin: 0 0 8px;
      font-size: 16px;
      color: #0c614f;
    }}
    .modal-actions {{
      margin-top: 10px;
      display: flex;
      justify-content: flex-end;
      gap: 8px;
    }}
    .box {{
      border: 1px solid #d8e4f4;
      border-radius: 10px;
      background: #fff;
      padding: 10px;
      margin-bottom: 10px;
    }}
    .box h3 {{ margin: 0 0 8px; font-size: 15px; color: #0b6150; }}
    .table-wrap {{
      overflow: auto;
      border: 1px solid #dbe6f5;
      border-radius: 10px;
      background: #fff;
    }}
    table {{
      border-collapse: collapse;
      width: 100%;
      min-width: 720px;
      font-size: 12px;
    }}
    th, td {{
      border-bottom: 1px solid #edf3fb;
      text-align: left;
      padding: 8px;
      vertical-align: top;
      word-break: break-word;
    }}
    th {{ background: #f7fbff; color: #274c75; }}
    .empty {{
      border: 1px dashed #c5d8ee;
      border-radius: 10px;
      padding: 14px;
      text-align: center;
      color: var(--muted);
      background: #f8fbff;
      font-size: 13px;
    }}
    .meta {{
      margin-bottom: 10px;
      border: 1px solid #c7d8ee;
      border-radius: 10px;
      background: #f2f8ff;
      color: #264b70;
      font-size: 12px;
      padding: 7px 8px;
    }}
    .mini-links {{
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 8px;
    }}
    .mini-links a {{
      text-decoration: none;
      border: 1px solid #bdd3eb;
      border-radius: 8px;
      padding: 5px 8px;
      font-size: 11px;
      font-weight: 700;
      color: #235281;
      background: #f3f8ff;
    }}
    .adopt-grid {{
      display: grid;
      grid-template-columns: repeat(3, minmax(0, 1fr));
      gap: 8px;
    }}
    .mono {{
      margin: 8px 0 0;
      max-height: 280px;
      overflow: auto;
      border: 1px solid #dbe6f5;
      border-radius: 10px;
      background: #f7fbff;
      padding: 10px;
      font-family: "Consolas", "D2Coding", "IBM Plex Mono", monospace;
      font-size: 12px;
      white-space: pre-wrap;
      word-break: break-word;
      color: #224a72;
    }}
    @keyframes fadeup {{
      from {{ opacity: 0; transform: translateY(8px); }}
      to {{ opacity: 1; transform: translateY(0); }}
    }}
    @media (max-width: 900px) {{
      .hero h1 {{ font-size: 21px; }}
      .tab-btn {{ font-size: 13px; padding: 10px; }}
      .auth-row {{ grid-template-columns: 1fr; }}
      .filter-row {{ grid-template-columns: 1fr; }}
      .cards {{ grid-template-columns: repeat(2, minmax(0, 1fr)); }}
      .adopt-grid {{ grid-template-columns: 1fr; }}
    }}
  </style>
</head>
<body>
  <div class="wrap">
    <header class="hero">
      <h1> </h1>
      <p>    .        ,     URL  .</p>
      <div class="links">
        <a href="{html.escape(service_info.get("docs", "/docs"))}">Swagger Docs</a>
        <a href="/api/service-info">Service Info</a>
        <a href="/web/console">Legacy Console</a>
        <a href="/web/adoption">Legacy Adoption</a>
      </div>
    </header>

    <section class="tabs">
      <div class="tab-head" role="tablist" aria-label="Main tabs">
        <button class="tab-btn" type="button" role="tab" data-tab="overview"></button>
        <button class="tab-btn" type="button" role="tab" data-tab="workorders"></button>
        <button class="tab-btn" type="button" role="tab" data-tab="inspections"></button>
        <button class="tab-btn" type="button" role="tab" data-tab="reports"></button>
        <button class="tab-btn" type="button" role="tab" data-tab="adoption">  </button>
      </div>
      <div class="shell">
        <div class="auth-row">
          <input id="adminTokenInput" type="password" placeholder="X-Admin-Token " autocomplete="off" />
          <button id="saveTokenBtn" class="btn" type="button"> </button>
          <button id="testTokenBtn" class="btn run" type="button"> </button>
          <button id="clearTokenBtn" class="btn" type="button"> </button>
        </div>
        <div id="authState" class="auth-state"> : </div>

        <div id="panelOverview" class="tab-panel" role="tabpanel">
          <p class="tab-caption">SLA//    .</p>
          <div class="filter-row">
            <input id="ovSite" placeholder="site (optional)" />
            <input id="ovDays" value="30" placeholder="days (default 30)" />
            <input id="ovJobLimit" value="10" placeholder="job_limit (default 10)" />
            <input id="ovReserved" value="overview" disabled />
            <button id="runOverviewBtn" class="btn run" type="button"> </button>
          </div>
          <div id="overviewMeta" class="meta">  .</div>
          <div id="overviewCards" class="cards"></div>
          <div class="box">
            <h3>   </h3>
            <div id="overviewTopWorkOrders" class="empty"> </div>
          </div>
          <div class="box">
            <h3>  KPI ( 7/30)</h3>
            <div id="overviewAlertKpiSummary" class="cards"></div>
            <div id="overviewAlertKpiChannels" class="empty"> </div>
          </div>
          <div class="box">
            <h3>  MTTR (,  7/30)</h3>
            <div id="overviewAlertMttrSummary" class="cards"></div>
            <div id="overviewAlertMttrChannels" class="empty"> </div>
            <div class="mini-links">
              <a href="/api/ops/alerts/kpi/mttr">MTTR KPI API</a>
            </div>
          </div>
          <div class="box">
            <h3>  / </h3>
            <div id="overviewAlertGuardMeta" class="meta"> </div>
            <div id="overviewAlertGuardTable" class="empty"> </div>
            <div class="filter-row">
              <select id="overviewGuardRecoverState">
                <option value="quarantined">state=quarantined</option>
                <option value="warning">state=warning</option>
                <option value="all">state=all</option>
              </select>
              <input id="overviewGuardRecoverMaxTargets" value="20" placeholder="max_targets" />
              <button id="runOverviewGuardRecoverDryBtn" class="btn" type="button"> </button>
              <button id="runOverviewGuardRecoverRunBtn" class="btn run" type="button"> </button>
              <button id="runOverviewGuardRecoverLatestBtn" class="btn" type="button"> </button>
            </div>
            <div id="overviewGuardRecoverMeta" class="meta">  </div>
            <div id="overviewGuardRecoverTable" class="empty"> </div>
            <div class="mini-links">
              <a href="/api/ops/alerts/channels/guard">Guard API</a>
              <a href="/api/ops/alerts/channels/guard/recover-batch">Guard Recover Batch API</a>
              <a href="/api/ops/alerts/channels/guard/recover/latest">Guard Recover Latest API</a>
              <a href="/api/ops/alerts/mttr-slo/policy">MTTR SLO Policy API</a>
              <a href="/api/ops/alerts/mttr-slo/check/run">MTTR SLO Run API</a>
              <a href="/api/ops/alerts/mttr-slo/check/latest">MTTR SLO Latest API</a>
              <a href="/api/ops/alerts/retention/policy">Retention Policy API</a>
              <a href="/api/ops/alerts/retention/latest">Retention Latest API</a>
            </div>
          </div>
        </div>

        <div id="panelWorkorders" class="tab-panel" role="tabpanel">
          <p class="tab-caption"> /  .</p>
          <div class="filter-row">
            <input id="woStatus" placeholder="status (open/acked/completed/...)" />
            <input id="woSite" placeholder="site (optional)" />
            <input id="woLimit" value="20" placeholder="limit" />
            <input id="woOffset" value="0" placeholder="offset" />
            <button id="runWorkordersBtn" class="btn run" type="button"> </button>
          </div>
          <div id="workordersMeta" class="meta"> </div>
          <div id="workordersTable" class="empty"> </div>
        </div>

        <div id="panelInspections" class="tab-panel" role="tabpanel">
          <p class="tab-caption">    .</p>
          <div class="filter-row">
            <input id="inSite" placeholder="site (optional)" />
            <input id="inLimit" value="20" placeholder="limit" />
            <input id="inOffset" value="0" placeholder="offset" />
            <input id="inReserved" value="inspections" disabled />
            <button id="runInspectionsBtn" class="btn run" type="button"> </button>
          </div>
          <div id="inspectionsMeta" class="meta"> </div>
          <div id="inspectionsTable" class="empty"> </div>
        </div>

        <div id="panelReports" class="tab-panel" role="tabpanel">
          <p class="tab-caption">     .</p>
          <div class="filter-row">
            <input id="rpMonth" placeholder="month (YYYY-MM)" />
            <input id="rpSite" placeholder="site (optional)" />
            <input id="rpReserved1" value="reports" disabled />
            <input id="rpReserved2" value="summary" disabled />
            <button id="runReportsBtn" class="btn run" type="button"> </button>
          </div>
          <div id="reportsMeta" class="meta"> </div>
          <div id="reportsSummary" class="cards"></div>
          <div class="box">
            <h3> /</h3>
            <div class="mini-links">
              <a id="reportPrintLink" href="/reports/monthly/print" target="_blank" rel="noopener">Print HTML</a>
              <a id="reportCsvLink" href="/api/reports/monthly/csv" target="_blank" rel="noopener">CSV</a>
              <a id="reportPdfLink" href="/api/reports/monthly/pdf" target="_blank" rel="noopener">PDF</a>
            </div>
            <pre id="reportsRaw" class="mono">{{}}</pre>
          </div>
        </div>

        <div id="panelAdoption" class="tab-panel" role="tabpanel">
          <p class="tab-caption">  +  + KPI +       .</p>
          <div class="filter-row">
            <input id="adoptReserved1" value="public adoption plan" disabled />
            <input id="adoptReserved2" value="training + kpi + schedule" disabled />
            <input id="adoptReserved3" value="campaign ready" disabled />
            <input id="adoptReserved4" value="weekly execution" disabled />
            <button id="runAdoptionBtn" class="btn run" type="button">  </button>
          </div>
          <div id="adoptionMeta" class="meta"> </div>
          <div id="adoptionTop" class="adopt-grid"></div>
          <div class="box">
            <h3>W01 Role Workflow Lock Matrix</h3>
            <div id="adoptionWorkflowMatrix" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W02 Scheduled SOP and Sandbox</h3>
            <div id="adoptionW02Top" class="cards"></div>
            <div id="adoptionW02Sop" class="empty"> </div>
            <div id="adoptionW02Sandbox" class="empty"> </div>
            <div id="adoptionW02Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW02Json" href="/api/public/adoption-plan/w02">W02 JSON</a>
              <a id="adoptW02ChecklistCsv" href="/api/public/adoption-plan/w02/checklist.csv">W02 Checklist CSV</a>
              <a id="adoptW02ScheduleIcs" href="/api/public/adoption-plan/w02/schedule.ics">W02 Schedule ICS</a>
              <a id="adoptW02SampleFiles" href="/api/public/adoption-plan/w02/sample-files">W02 Sample Files</a>
            </div>
          </div>
          <div class="box">
            <h3>W03 Go-live Onboarding</h3>
            <div id="adoptionW03Top" class="cards"></div>
            <div id="adoptionW03Kickoff" class="empty"> </div>
            <div id="adoptionW03Workshops" class="empty"> </div>
            <div id="adoptionW03OfficeHours" class="empty"> </div>
            <div id="adoptionW03Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW03Json" href="/api/public/adoption-plan/w03">W03 JSON</a>
              <a id="adoptW03ChecklistCsv" href="/api/public/adoption-plan/w03/checklist.csv">W03 Checklist CSV</a>
              <a id="adoptW03ScheduleIcs" href="/api/public/adoption-plan/w03/schedule.ics">W03 Schedule ICS</a>
            </div>
          </div>
          <div class="box">
            <h3>W04 First Success Acceleration</h3>
            <div id="adoptionW04Top" class="cards"></div>
            <div id="adoptionW04Actions" class="empty"> </div>
            <div id="adoptionW04Schedule" class="empty"> </div>
            <div id="adoptionW04Mistakes" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW04Json" href="/api/public/adoption-plan/w04">W04 JSON</a>
              <a id="adoptW04ChecklistCsv" href="/api/public/adoption-plan/w04/checklist.csv">W04 Checklist CSV</a>
              <a id="adoptW04ScheduleIcs" href="/api/public/adoption-plan/w04/schedule.ics">W04 Schedule ICS</a>
              <a id="adoptW04MistakesJson" href="/api/public/adoption-plan/w04/common-mistakes">W04 Common Mistakes JSON</a>
              <a id="adoptW04MistakesHtml" href="/web/adoption/w04/common-mistakes">W04 Common Mistakes HTML</a>
            </div>
          </div>
          <div class="box">
            <h3>W02   (  /  /  )</h3>
            <div class="filter-row">
              <input id="w02TrackSite" placeholder="site (required, : HQ)" />
              <input id="w02TrackItemId" placeholder="tracker_item_id" />
              <input id="w02TrackAssignee" placeholder="assignee" />
              <select id="w02TrackStatus">
                <option value="">status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="w02TrackBootstrapBtn" class="btn run" type="button">W02  </button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w02TrackCompleted" type="checkbox" />
                 
              </label>
              <input id="w02TrackNote" placeholder="completion note (optional)" />
              <input id="w02EvidenceNote" placeholder="evidence note (optional)" />
              <input id="w02EvidenceFile" type="file" />
              <button id="w02TrackUpdateBtn" class="btn" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w02EvidenceListItemId" placeholder="evidence  tracker_item_id" />
              <input id="w02Reserved1" value="token required for write actions" disabled />
              <input id="w02Reserved2" value="site scope enforced" disabled />
              <input id="w02Reserved3" value="max file 5MB" disabled />
              <button id="w02TrackRefreshBtn" class="btn run" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w02CompletionNote" placeholder="completion note (optional)" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w02CompletionForce" type="checkbox" />
                 (owner/admin)
              </label>
              <input id="w02Reserved4" value="readiness gate required" disabled />
              <button id="w02ReadinessBtn" class="btn run" type="button"> </button>
              <button id="w02CompleteBtn" class="btn" type="button">W02  </button>
            </div>
            <div id="w02TrackerMeta" class="meta"> </div>
            <div id="w02TrackerSummary" class="cards"></div>
            <div id="w02TrackerTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">W02   </h4>
            <div id="w02ReadinessMeta" class="meta"> </div>
            <div id="w02ReadinessCards" class="cards"></div>
            <div id="w02ReadinessBlockers" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="w02EvidenceTable" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W03   (  /  /  )</h3>
            <div class="filter-row">
              <input id="w03TrackSite" placeholder="site (required, : HQ)" />
              <input id="w03TrackItemId" placeholder="tracker_item_id" />
              <input id="w03TrackAssignee" placeholder="assignee" />
              <select id="w03TrackStatus">
                <option value="">status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="w03TrackBootstrapBtn" class="btn run" type="button">W03  </button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w03TrackCompleted" type="checkbox" />
                 
              </label>
              <input id="w03TrackNote" placeholder="completion note (optional)" />
              <input id="w03EvidenceNote" placeholder="evidence note (optional)" />
              <input id="w03EvidenceFile" type="file" />
              <button id="w03TrackUpdateBtn" class="btn" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w03EvidenceListItemId" placeholder="evidence  tracker_item_id" />
              <input id="w03Reserved1" value="token required for write actions" disabled />
              <input id="w03Reserved2" value="site scope enforced" disabled />
              <input id="w03Reserved3" value="max file 5MB" disabled />
              <button id="w03TrackRefreshBtn" class="btn run" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w03CompletionNote" placeholder="completion note (optional)" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w03CompletionForce" type="checkbox" />
                 (owner/admin)
              </label>
              <input id="w03Reserved4" value="readiness gate required" disabled />
              <button id="w03ReadinessBtn" class="btn run" type="button"> </button>
              <button id="w03CompleteBtn" class="btn" type="button">W03  </button>
            </div>
            <div id="w03TrackerMeta" class="meta"> </div>
            <div id="w03TrackerSummary" class="cards"></div>
            <div id="w03TrackerTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">W03   </h4>
            <div id="w03ReadinessMeta" class="meta"> </div>
            <div id="w03ReadinessCards" class="cards"></div>
            <div id="w03ReadinessBlockers" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="w03EvidenceTable" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W04 First-Success Funnel + Top Blockers</h3>
            <div class="filter-row">
              <input id="w04FunnelSite" placeholder="site (required, : HQ)" />
              <input id="w04FunnelDays" value="30" placeholder="window days (1-90)" />
              <input id="w04FunnelMaxBlockers" value="3" placeholder="max blockers (1-10)" />
              <input id="w04FunnelReserved" value="token required" disabled />
              <button id="w04FunnelRefreshBtn" class="btn run" type="button">W04  </button>
            </div>
            <div id="w04FunnelMeta" class="meta"> </div>
            <div id="w04FunnelSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;"> </h4>
            <div id="w04FunnelStages" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Top Blockers</h4>
            <div id="w04BlockerTable" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W04   (  /  /  )</h3>
            <div class="filter-row">
              <input id="w04TrackSite" placeholder="site (required, : HQ)" />
              <input id="w04TrackItemId" placeholder="tracker_item_id" />
              <input id="w04TrackAssignee" placeholder="assignee" />
              <select id="w04TrackStatus">
                <option value="">status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="w04TrackBootstrapBtn" class="btn run" type="button">W04  </button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w04TrackCompleted" type="checkbox" />
                 
              </label>
              <input id="w04TrackNote" placeholder="completion note (optional)" />
              <input id="w04EvidenceNote" placeholder="evidence note (optional)" />
              <input id="w04EvidenceFile" type="file" />
              <button id="w04TrackUpdateBtn" class="btn" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w04EvidenceListItemId" placeholder="evidence  tracker_item_id" />
              <input id="w04Reserved1" value="token required for write actions" disabled />
              <input id="w04Reserved2" value="site scope enforced" disabled />
              <input id="w04Reserved3" value="max file 5MB" disabled />
              <button id="w04TrackRefreshBtn" class="btn run" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w04CompletionNote" placeholder="completion note (optional)" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w04CompletionForce" type="checkbox" />
                 (owner/admin)
              </label>
              <input id="w04Reserved4" value="readiness gate required" disabled />
              <button id="w04ReadinessBtn" class="btn run" type="button"> </button>
              <button id="w04CompleteBtn" class="btn" type="button">W04  </button>
            </div>
            <div id="w04TrackerMeta" class="meta"> </div>
            <div id="w04TrackerSummary" class="cards"></div>
            <div id="w04TrackerTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">W04   </h4>
            <div id="w04ReadinessMeta" class="meta"> </div>
            <div id="w04ReadinessCards" class="cards"></div>
            <div id="w04ReadinessBlockers" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="w04EvidenceTable" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W05 Usage Consistency</h3>
            <div id="adoptionW05Top" class="cards"></div>
            <div id="adoptionW05Missions" class="empty"> </div>
            <div id="adoptionW05Schedule" class="empty"> </div>
            <div id="adoptionW05HelpDocs" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW05Json" href="/api/public/adoption-plan/w05">W05 JSON</a>
              <a id="adoptW05MissionsCsv" href="/api/public/adoption-plan/w05/missions.csv">W05 Missions CSV</a>
              <a id="adoptW05ScheduleIcs" href="/api/public/adoption-plan/w05/schedule.ics">W05 Schedule ICS</a>
              <a id="adoptW05HelpDocs" href="/api/public/adoption-plan/w05/help-docs">W05 Help Docs</a>
              <a id="adoptW05ConsistencyApi" href="/api/ops/adoption/w05/consistency">W05 Consistency API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W05 Usage Consistency Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w05ConsistencySite" placeholder="site (optional,   )" />
              <input id="w05ConsistencyDays" value="28" placeholder="window days (14-90)" />
              <input id="w05ConsistencyReserved1" value="token required" disabled />
              <input id="w05ConsistencyReserved2" value="site scope enforced" disabled />
              <button id="w05ConsistencyRefreshBtn" class="btn run" type="button">W05  </button>
            </div>
            <div id="w05ConsistencyMeta" class="meta"> </div>
            <div id="w05ConsistencySummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Site Overdue Top</h4>
            <div id="w05ConsistencyTopSites" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Mission Recommendations</h4>
            <div id="w05ConsistencyRecommendations" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W06 Operational Rhythm</h3>
            <div id="adoptionW06Top" class="cards"></div>
            <div id="adoptionW06Checklist" class="empty"> </div>
            <div id="adoptionW06Schedule" class="empty"> </div>
            <div id="adoptionW06RbacAudit" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW06Json" href="/api/public/adoption-plan/w06">W06 JSON</a>
              <a id="adoptW06ChecklistCsv" href="/api/public/adoption-plan/w06/checklist.csv">W06 Checklist CSV</a>
              <a id="adoptW06ScheduleIcs" href="/api/public/adoption-plan/w06/schedule.ics">W06 Schedule ICS</a>
              <a id="adoptW06RbacAuditTemplate" href="/api/public/adoption-plan/w06/rbac-audit-template">W06 RBAC Audit Template</a>
              <a id="adoptW06RhythmApi" href="/api/ops/adoption/w06/rhythm">W06 Rhythm API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W06 Operational Rhythm Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w06RhythmSite" placeholder="site (optional,   )" />
              <input id="w06RhythmDays" value="14" placeholder="window days (7-90)" />
              <input id="w06RhythmReserved1" value="token required" disabled />
              <input id="w06RhythmReserved2" value="site scope enforced" disabled />
              <button id="w06RhythmRefreshBtn" class="btn run" type="button">W06  </button>
            </div>
            <div id="w06RhythmMeta" class="meta"> </div>
            <div id="w06RhythmSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Role Coverage</h4>
            <div id="w06RhythmRoleCoverage" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Site Activity</h4>
            <div id="w06RhythmSiteActivity" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w06RhythmRecommendations" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W07 SLA Quality</h3>
            <div id="adoptionW07Top" class="cards"></div>
            <div id="adoptionW07Checklist" class="empty"> </div>
            <div id="adoptionW07Coaching" class="empty"> </div>
            <div id="adoptionW07Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW07Json" href="/api/public/adoption-plan/w07">W07 JSON</a>
              <a id="adoptW07ChecklistCsv" href="/api/public/adoption-plan/w07/checklist.csv">W07 Checklist CSV</a>
              <a id="adoptW07ScheduleIcs" href="/api/public/adoption-plan/w07/schedule.ics">W07 Schedule ICS</a>
              <a id="adoptW07CoachingPlaybook" href="/api/public/adoption-plan/w07/coaching-playbook">W07 Coaching Playbook</a>
              <a id="adoptW07QualityApi" href="/api/ops/adoption/w07/sla-quality">W07 SLA Quality API (Token)</a>
              <a id="adoptW07AutomationReadinessApi" href="/api/ops/adoption/w07/automation-readiness">W07 Automation Readiness API (Token)</a>
              <a id="adoptW07TrackerItemsApi" href="/api/adoption/w07/tracker/items">W07 Tracker Items API (Token)</a>
              <a id="adoptW07TrackerOverviewApi" href="/api/adoption/w07/tracker/overview?site=HQ">W07 Tracker Overview API (Token)</a>
              <a id="adoptW07CompletionPackageApi" href="/api/adoption/w07/tracker/completion-package?site=HQ">W07 Completion Package ZIP (Token)</a>
              <a id="adoptW07WeeklyRunApi" href="/api/ops/adoption/w07/sla-quality/run-weekly">W07 Weekly Run API (Token)</a>
              <a id="adoptW07WeeklyLatestApi" href="/api/ops/adoption/w07/sla-quality/latest-weekly">W07 Weekly Latest API (Token)</a>
              <a id="adoptW07WeeklyTrendsApi" href="/api/ops/adoption/w07/sla-quality/trends">W07 Weekly Trends API (Token)</a>
              <a id="adoptW07WeeklyArchiveApi" href="/api/ops/adoption/w07/sla-quality/archive.csv">W07 Weekly Archive CSV (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W07 SLA Quality Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w07QualitySite" placeholder="site (optional,   )" />
              <input id="w07QualityDays" value="14" placeholder="window days (7-90)" />
              <input id="w07QualityReserved1" value="token required" disabled />
              <input id="w07QualityReserved2" value="site scope enforced" disabled />
              <button id="w07QualityRefreshBtn" class="btn run" type="button">W07  </button>
            </div>
            <div id="w07QualityMeta" class="meta"> </div>
            <div id="w07QualitySummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Automation Readiness</h4>
            <div id="w07AutomationReadiness" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Top Risk Sites</h4>
            <div id="w07QualityTopSites" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w07QualityRecommendations" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W08 Report Discipline</h3>
            <div id="adoptionW08Top" class="cards"></div>
            <div id="adoptionW08Checklist" class="empty"> </div>
            <div id="adoptionW08Quality" class="empty"> </div>
            <div id="adoptionW08Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW08Json" href="/api/public/adoption-plan/w08">W08 JSON</a>
              <a id="adoptW08ChecklistCsv" href="/api/public/adoption-plan/w08/checklist.csv">W08 Checklist CSV</a>
              <a id="adoptW08ScheduleIcs" href="/api/public/adoption-plan/w08/schedule.ics">W08 Schedule ICS</a>
              <a id="adoptW08ReportingSop" href="/api/public/adoption-plan/w08/reporting-sop">W08 Reporting SOP</a>
              <a id="adoptW08DisciplineApi" href="/api/ops/adoption/w08/report-discipline">W08 Discipline API (Token)</a>
              <a id="adoptW08BenchmarkApi" href="/api/ops/adoption/w08/site-benchmark">W08 Site Benchmark API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W08 Report Discipline Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w08DisciplineSite" placeholder="site (optional,   )" />
              <input id="w08DisciplineDays" value="30" placeholder="window days (14-120)" />
              <input id="w08DisciplineReserved1" value="token required" disabled />
              <input id="w08DisciplineReserved2" value="site scope enforced" disabled />
              <button id="w08DisciplineRefreshBtn" class="btn run" type="button">W08  </button>
            </div>
            <div id="w08DisciplineMeta" class="meta"> </div>
            <div id="w08DisciplineSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Top Risk Sites</h4>
            <div id="w08DisciplineTopSites" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Site Benchmark</h4>
            <div id="w08DisciplineBenchmark" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w08DisciplineRecommendations" class="empty"> </div>
          </div>
          <div class="box">
            <h3>W09 KPI Operation</h3>
            <div id="adoptionW09Top" class="cards"></div>
            <div id="adoptionW09Thresholds" class="empty"> </div>
            <div id="adoptionW09Escalation" class="empty"> </div>
            <div id="adoptionW09Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW09Json" href="/api/public/adoption-plan/w09">W09 JSON</a>
              <a id="adoptW09ChecklistCsv" href="/api/public/adoption-plan/w09/checklist.csv">W09 Checklist CSV</a>
              <a id="adoptW09ScheduleIcs" href="/api/public/adoption-plan/w09/schedule.ics">W09 Schedule ICS</a>
              <a id="adoptW09KpiOperationApi" href="/api/ops/adoption/w09/kpi-operation">W09 KPI Operation API (Token)</a>
              <a id="adoptW09KpiPolicyApi" href="/api/ops/adoption/w09/kpi-policy">W09 KPI Policy API (Token)</a>
              <a id="adoptW09TrackerItemsApi" href="/api/adoption/w09/tracker/items">W09 Tracker Items API (Token)</a>
              <a id="adoptW09TrackerOverviewApi" href="/api/adoption/w09/tracker/overview?site=HQ">W09 Tracker Overview API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W09 KPI Operation Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w09KpiSite" placeholder="site (optional,  )" />
              <input id="w09KpiDays" value="30" placeholder="window days (14-120)" />
              <input id="w09KpiReserved1" value="token required" disabled />
              <input id="w09KpiReserved2" value="site scope enforced" disabled />
              <button id="w09KpiRefreshBtn" class="btn run" type="button">W09 KPI </button>
            </div>
            <div id="w09KpiMeta" class="meta"> </div>
            <div id="w09KpiSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">KPI Status</h4>
            <div id="w09KpiTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Escalation Candidates</h4>
            <div id="w09EscalationTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w09KpiRecommendations" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Policy Snapshot</h4>
            <div id="w09PolicyMeta" class="meta"> </div>
            <div id="w09PolicyTable" class="empty"> </div>
          </div>
          {w09_tracker_box_html}
          <div class="box">
            <h3>W10 Self-serve Support</h3>
            <div id="adoptionW10Top" class="cards"></div>
            <div id="adoptionW10Guides" class="empty"> </div>
            <div id="adoptionW10Runbook" class="empty"> </div>
            <div id="adoptionW10Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW10Json" href="/api/public/adoption-plan/w10">W10 JSON</a>
              <a id="adoptW10ChecklistCsv" href="/api/public/adoption-plan/w10/checklist.csv">W10 Checklist CSV</a>
              <a id="adoptW10ScheduleIcs" href="/api/public/adoption-plan/w10/schedule.ics">W10 Schedule ICS</a>
              <a id="adoptW10SelfServeApi" href="/api/ops/adoption/w10/self-serve">W10 Self-serve API (Token)</a>
              <a id="adoptW10SupportPolicyApi" href="/api/ops/adoption/w10/support-policy">W10 Support Policy API (Token)</a>
              <a id="adoptW10TrackerItemsApi" href="/api/adoption/w10/tracker/items">W10 Tracker Items API (Token)</a>
              <a id="adoptW10TrackerOverviewApi" href="/api/adoption/w10/tracker/overview?site=HQ">W10 Tracker Overview API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W10 Self-serve Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w10KpiSite" placeholder="site (optional,  )" />
              <input id="w10KpiDays" value="30" placeholder="window days (14-120)" />
              <input id="w10KpiReserved1" value="token required" disabled />
              <input id="w10KpiReserved2" value="site scope enforced" disabled />
              <button id="w10KpiRefreshBtn" class="btn run" type="button">W10  </button>
            </div>
            <div id="w10KpiMeta" class="meta"> </div>
            <div id="w10KpiSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Support KPI Status</h4>
            <div id="w10KpiTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Top Repeat Titles</h4>
            <div id="w10EscalationTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w10KpiRecommendations" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Policy Snapshot</h4>
            <div id="w10PolicyMeta" class="meta"> </div>
            <div id="w10PolicyTable" class="empty"> </div>
          </div>
          {w10_tracker_box_html}
          <div class="box">
            <h3>W11 Scale Readiness</h3>
            <div id="adoptionW11Top" class="cards"></div>
            <div id="adoptionW11Guides" class="empty"> </div>
            <div id="adoptionW11Runbook" class="empty"> </div>
            <div id="adoptionW11Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW11Json" href="/api/public/adoption-plan/w11">W11 JSON</a>
              <a id="adoptW11ChecklistCsv" href="/api/public/adoption-plan/w11/checklist.csv">W11 Checklist CSV</a>
              <a id="adoptW11ScheduleIcs" href="/api/public/adoption-plan/w11/schedule.ics">W11 Schedule ICS</a>
              <a id="adoptW11SelfServeApi" href="/api/ops/adoption/w11/scale-readiness">W11 Scale Readiness API (Token)</a>
              <a id="adoptW11SupportPolicyApi" href="/api/ops/adoption/w11/readiness-policy">W11 Readiness Policy API (Token)</a>
              <a id="adoptW11TrackerItemsApi" href="/api/adoption/w11/tracker/items">W11 Tracker Items API (Token)</a>
              <a id="adoptW11TrackerOverviewApi" href="/api/adoption/w11/tracker/overview?site=HQ">W11 Tracker Overview API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W11 Scale Readiness Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w11KpiSite" placeholder="site (optional,  )" />
              <input id="w11KpiDays" value="30" placeholder="window days (14-120)" />
              <input id="w11KpiReserved1" value="token required" disabled />
              <input id="w11KpiReserved2" value="site scope enforced" disabled />
              <button id="w11KpiRefreshBtn" class="btn run" type="button">W11  </button>
            </div>
            <div id="w11KpiMeta" class="meta"> </div>
            <div id="w11KpiSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Scale KPI Status</h4>
            <div id="w11KpiTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Top Expansion Risks</h4>
            <div id="w11EscalationTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w11KpiRecommendations" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Policy Snapshot</h4>
            <div id="w11PolicyMeta" class="meta"> </div>
            <div id="w11PolicyTable" class="empty"> </div>
          </div>
          {w11_tracker_box_html}
          <div class="box">
            <h3>W15 Operations Efficiency</h3>
            <div id="adoptionW15Top" class="cards"></div>
            <div id="adoptionW15Guides" class="empty"> </div>
            <div id="adoptionW15Runbook" class="empty"> </div>
            <div id="adoptionW15Schedule" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptW15Json" href="/api/public/adoption-plan/w15">W15 JSON</a>
              <a id="adoptW15ChecklistCsv" href="/api/public/adoption-plan/w15/checklist.csv">W15 Checklist CSV</a>
              <a id="adoptW15ScheduleIcs" href="/api/public/adoption-plan/w15/schedule.ics">W15 Schedule ICS</a>
              <a id="adoptW15OpsEfficiencyApi" href="/api/ops/adoption/w15/ops-efficiency">W15 Ops Efficiency API (Token)</a>
              <a id="adoptW15EfficiencyPolicyApi" href="/api/ops/adoption/w15/efficiency-policy">W15 Efficiency Policy API (Token)</a>
              <a id="adoptW15TrackerItemsApi" href="/api/adoption/w15/tracker/items">W15 Tracker Items API (Token)</a>
              <a id="adoptW15TrackerOverviewApi" href="/api/adoption/w15/tracker/overview?site=HQ">W15 Tracker Overview API (Token)</a>
            </div>
          </div>
          <div class="box">
            <h3>W15 Operations Efficiency Dashboard (Token)</h3>
            <div class="filter-row">
              <input id="w15KpiSite" placeholder="site (optional,  )" />
              <input id="w15KpiDays" value="30" placeholder="window days (14-120)" />
              <input id="w15KpiReserved1" value="token required" disabled />
              <input id="w15KpiReserved2" value="site scope enforced" disabled />
              <button id="w15KpiRefreshBtn" class="btn run" type="button">W15  </button>
            </div>
            <div id="w15KpiMeta" class="meta"> </div>
            <div id="w15KpiSummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;">Efficiency KPI Status</h4>
            <div id="w15KpiTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Top Repeat Incidents</h4>
            <div id="w15EscalationTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Recommendations</h4>
            <div id="w15KpiRecommendations" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">Policy Snapshot</h4>
            <div id="w15PolicyMeta" class="meta"> </div>
            <div id="w15PolicyTable" class="empty"> </div>
          </div>
          {w15_tracker_box_html}
          <div class="box">
            <h3>W07   (  /  /  )</h3>
            <div class="filter-row">
              <input id="w07TrackSite" placeholder="site (required, : HQ)" />
              <input id="w07TrackItemId" placeholder="tracker_item_id (  )" readonly />
              <input id="w07TrackAssignee" placeholder="assignee" />
              <select id="w07TrackStatus">
                <option value="">status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="w07TrackBootstrapBtn" class="btn run" type="button">W07  </button>
            </div>
            <div class="filter-row">
              <button id="w07TrackNextBtn" class="btn soft" type="button"> </button>
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07TrackCompleted" type="checkbox" />
                 
              </label>
              <input id="w07TrackNote" placeholder="completion note (optional)" />
              <input id="w07EvidenceNote" placeholder="evidence note (optional)" />
              <input id="w07EvidenceFile" type="file" />
              <button id="w07TrackUpdateBtn" class="btn" type="button"> </button>
            </div>
            <div class="filter-row">
              <input id="w07EvidenceListItemId" placeholder="evidence  tracker_item_id ( )" />
              <div id="w07EvidenceDropzone" class="dropzone" title="   "> /  </div>
              <input id="w07Reserved1" value="token required for write actions" disabled />
              <input id="w07Reserved2" value="site scope enforced" disabled />
              <input id="w07Reserved3" value="max file 5MB" disabled />
              <button id="w07TrackRefreshBtn" class="btn run" type="button"> </button>
            </div>
            <div class="filter-row">
              <button id="w07SelectVisibleBtn" class="btn soft" type="button">   </button>
              <button id="w07ClearSelectionBtn" class="btn soft" type="button"> </button>
              <input id="w07BulkAssignee" placeholder=" assignee (optional)" />
              <select id="w07BulkStatus">
                <option value=""> status()</option>
                <option value="pending">pending</option>
                <option value="in_progress">in_progress</option>
                <option value="done">done</option>
                <option value="blocked">blocked</option>
              </select>
              <button id="w07BulkApplyBtn" class="btn run" type="button">   </button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07BulkChecked" type="checkbox" checked />
                   
              </label>
              <input id="w07BulkReserved1" value="multi-select enabled" disabled />
              <input id="w07BulkReserved2" value="row click fills form" disabled />
              <input id="w07BulkReserved3" value="blocker card filter supported" disabled />
              <input id="w07BulkReserved4" value="force complete needs note" disabled />
            </div>
            <div class="filter-row">
              <input id="w07CompletionNote" placeholder="completion note (force  )" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07CompletionForce" type="checkbox" />
                 (owner/admin)
              </label>
              <input id="w07Reserved4" value="readiness gate required" disabled />
              <button id="w07ReadinessBtn" class="btn run" type="button"> </button>
              <button id="w07CompleteBtn" class="btn" type="button">W07  </button>
            </div>
            <div class="filter-row">
              <input id="w07CompleteReserved1" value=":   " disabled />
              <input id="w07CompleteReserved2" value="  W07  /  " disabled />
              <input id="w07CompleteReserved3" value="site  site  " disabled />
              <input id="w07CompleteReserved4" value="    " disabled />
              <button id="w07CompleteAndWeeklyBtn" class="btn run" type="button">W07 +</button>
            </div>
            <div class="filter-row">
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07PackageIncludeEvidence" type="checkbox" checked />
                evidence 
              </label>
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07PackageIncludeWeekly" type="checkbox" checked />
                weekly 
              </label>
              <input id="w07PackageWeeklyLimit" value="26" placeholder="weekly limit (1-104)" />
              <input id="w07PackageReserved1" value="ZIP: completion + readiness + tracker + optional evidence/weekly" disabled />
              <button id="w07DownloadPackageBtn" class="btn run" type="button">W07   </button>
            </div>
            <div id="w07TrackerMeta" class="meta"> </div>
            <div id="w07SelectionMeta" class="w07-filter-hint">: ALL | : 0/0 | : 0</div>
            <div id="w07TrackerSummary" class="cards"></div>
            <div id="w07TrackerTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">W07   </h4>
            <div id="w07ReadinessMeta" class="meta"> </div>
            <div id="w07ReadinessCards" class="cards"></div>
            <div id="w07ReadinessBlockers" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="w07EvidenceTable" class="empty"> </div>
            <h4 style="margin:10px 0 6px;">  </h4>
            <div id="w07ActionResults" class="empty">   </div>
          </div>
          <div id="w07CompleteModal" class="modal" aria-hidden="true" role="dialog" aria-modal="true" aria-labelledby="w07CompleteModalTitle">
            <div class="modal-card">
              <h4 id="w07CompleteModalTitle">W07    </h4>
              <div id="w07CompleteModalSummary" class="mono"> ...</div>
              <div class="modal-actions">
                <button id="w07CompleteModalCancel" class="btn soft" type="button"></button>
                <button id="w07CompleteModalConfirm" class="btn run" type="button"> </button>
              </div>
            </div>
          </div>
          <div class="box">
            <h3>W07  /</h3>
            <div class="filter-row">
              <input id="w07WeeklySite" placeholder="site (optional,   )" />
              <input id="w07WeeklyDays" value="14" placeholder="window days (7-90)" />
              <input id="w07WeeklyLimit" value="26" placeholder="trend points (1-104)" />
              <label style="display:flex; align-items:center; gap:6px; font-size:12px;">
                <input id="w07WeeklyForceNotify" type="checkbox" />
                force notify
              </label>
              <button id="w07WeeklyRunBtn" class="btn run" type="button">W07  </button>
            </div>
            <div class="filter-row">
              <input id="w07WeeklyReserved1" value="token required" disabled />
              <input id="w07WeeklyReserved2" value="site scope enforced" disabled />
              <input id="w07WeeklyReserved3" value="cooldown protected alerting" disabled />
              <button id="w07WeeklyLatestBtn" class="btn run" type="button">  </button>
              <button id="w07WeeklyTrendsBtn" class="btn run" type="button"> </button>
            </div>
            <div id="w07WeeklyMeta" class="meta"> </div>
            <div id="w07WeeklySummary" class="cards"></div>
            <h4 style="margin:10px 0 6px;"> </h4>
            <div id="w07WeeklyLatest" class="empty"> </div>
            <h4 style="margin:10px 0 6px;"></h4>
            <div id="w07WeeklyTrends" class="empty"> </div>
          </div>
          <div class="box">
            <h3> </h3>
            <div id="adoptionWeekly" class="empty"> </div>
          </div>
          <div class="box">
            <h3> </h3>
            <div id="adoptionTraining" class="empty"> </div>
          </div>
          <div class="box">
            <h3>KPI  </h3>
            <div id="adoptionKpi" class="empty"> </div>
            <div class="mini-links">
              <a id="adoptScheduleCsv" href="/api/public/adoption-plan/schedule.csv">Schedule CSV</a>
              <a id="adoptScheduleIcs" href="/api/public/adoption-plan/schedule.ics">Schedule ICS</a>
              <a href="/api/public/adoption-plan/campaign">Campaign Kit</a>
            </div>
          </div>
        </div>
      </div>
    </section>
  </div>
  <script>
    (function() {{
      const TOKEN_KEY = "kaFacilityMainToken";
      const buttons = Array.from(document.querySelectorAll(".tab-btn"));
      const panels = {{
        overview: document.getElementById("panelOverview"),
        workorders: document.getElementById("panelWorkorders"),
        inspections: document.getElementById("panelInspections"),
        reports: document.getElementById("panelReports"),
        adoption: document.getElementById("panelAdoption")
      }};
      const url = new URL(window.location.href);
      const authState = document.getElementById("authState");
      const tokenInput = document.getElementById("adminTokenInput");
      let authProfile = null;
      let w07TrackerItemsCache = [];
      let w07TrackerFilter = "all";
      let w07SelectedItemIds = new Set();
      let w07ActiveItemId = null;
      let w07LastReadiness = null;
      let w07LastCompletion = null;
      let w07ActionResults = [];
      let w07CompleteModalResolver = null;

      function getToken() {{
        const sessionToken = window.sessionStorage.getItem(TOKEN_KEY) || "";
        if (sessionToken) {{
          return sessionToken;
        }}
        const legacyLocalToken = window.localStorage.getItem(TOKEN_KEY) || "";
        if (legacyLocalToken) {{
          // Migrate legacy persistent token to session-only storage.
          window.sessionStorage.setItem(TOKEN_KEY, legacyLocalToken);
          window.localStorage.removeItem(TOKEN_KEY);
        }}
        return legacyLocalToken;
      }}

      function setAuthState(text) {{
        authState.textContent = text;
      }}

      function updateAuthStateFromToken() {{
        const token = getToken();
        if (!token) {{
          setAuthState(" : ");
          return;
        }}
        if (authProfile) {{
          const role = authProfile.role || "unknown";
          const username = authProfile.username || "unknown";
          setAuthState(" :  | : " + username + " | : " + role);
          return;
        }}
        setAuthState(" :  (  )");
      }}

      function escapeHtml(value) {{
        return String(value)
          .replaceAll("&", "&amp;")
          .replaceAll("<", "&lt;")
          .replaceAll(">", "&gt;")
          .replaceAll('"', "&quot;")
          .replaceAll("'", "&#39;");
      }}

      function renderEmpty(text) {{
        return '<div class="empty">' + escapeHtml(text) + "</div>";
      }}

      function normalizeUiStatus(value) {{
        const normalized = String(value || "").trim().toLowerCase();
        if (normalized === "ok" || normalized === "success" || normalized === "ready") {{
          return "ok";
        }}
        if (normalized === "warning" || normalized === "warn") {{
          return "warning";
        }}
        if (normalized === "critical" || normalized === "error" || normalized === "fail") {{
          return "critical";
        }}
        return "info";
      }}

      function uiStatusLabel(status) {{
        const tone = normalizeUiStatus(status);
        if (tone === "ok") return "OK";
        if (tone === "warning") return "WARNING";
        if (tone === "critical") return "CRITICAL";
        return "INFO";
      }}

      function renderUiStatusChip(status) {{
        const tone = normalizeUiStatus(status);
        return '<span class="status-chip ' + tone + '">' + escapeHtml(uiStatusLabel(tone)) + "</span>";
      }}

      function formatDateLocal(value) {{
        if (!value) return "-";
        const parsed = new Date(value);
        if (Number.isNaN(parsed.getTime())) {{
          return String(value);
        }}
        return parsed.toLocaleString("ko-KR", {{
          year: "numeric",
          month: "2-digit",
          day: "2-digit",
          hour: "2-digit",
          minute: "2-digit",
          second: "2-digit",
          hour12: false,
        }});
      }}

      function renderUiStatusCard(title, status, value, subtext) {{
        const tone = normalizeUiStatus(status);
        return (
          '<div class="card status-' + tone + '">'
          + '<div class="k">' + escapeHtml(title) + "</div>"
          + '<div class="v">' + escapeHtml(value) + "</div>"
          + '<div class="sub">' + renderUiStatusChip(tone) + " " + escapeHtml(subtext || "") + "</div>"
          + "</div>"
        );
      }}

      function asInt(value, fallback = 0) {{
        const parsed = Number(value);
        if (!Number.isFinite(parsed)) return fallback;
        return Math.trunc(parsed);
      }}

      function isW07EvidenceRequired(row) {{
        const itemType = String((row && row.item_type) || "").trim().toLowerCase();
        return itemType === "sla_checklist" || itemType === "coaching_play";
      }}

      function isW07MissingAssignee(row) {{
        return !String((row && row.assignee) || "").trim();
      }}

      function isW07MissingChecked(row) {{
        return !Boolean(row && row.completion_checked);
      }}

      function isW07MissingEvidence(row) {{
        return isW07EvidenceRequired(row) && asInt(row && row.evidence_count, 0) <= 0;
      }}

      function isW07IncompleteRow(row) {{
        const status = String((row && row.status) || "").trim().toLowerCase();
        return (
          status !== "done"
          || isW07MissingAssignee(row)
          || isW07MissingChecked(row)
          || isW07MissingEvidence(row)
        );
      }}

      function getW07FilterLabel(filterKey) {{
        const labels = {{
          all: "ALL",
          pending: "PENDING",
          in_progress: "IN PROGRESS",
          blocked: "BLOCKED",
          not_done: "NOT DONE",
          missing_assignee: "MISSING ASSIGNEE",
          missing_checked: "MISSING CHECKED",
          missing_evidence: "MISSING EVIDENCE",
        }};
        return labels[String(filterKey || "all")] || "ALL";
      }}

      function getW07FilteredItems(rows) {{
        const source = Array.isArray(rows) ? rows : w07TrackerItemsCache;
        const key = String(w07TrackerFilter || "all");
        return source.filter((row) => {{
          if (key === "pending") return String(row.status || "") === "pending";
          if (key === "in_progress") return String(row.status || "") === "in_progress";
          if (key === "blocked") return String(row.status || "") === "blocked";
          if (key === "not_done") return String(row.status || "") !== "done";
          if (key === "missing_assignee") return isW07MissingAssignee(row);
          if (key === "missing_checked") return isW07MissingChecked(row);
          if (key === "missing_evidence") return isW07MissingEvidence(row);
          return true;
        }});
      }}

      function getW07ItemById(itemId) {{
        const targetId = asInt(itemId, -1);
        if (targetId <= 0) return null;
        const found = w07TrackerItemsCache.find((row) => asInt(row.id, -1) === targetId);
        return found || null;
      }}

      function fillW07FormFromItem(item, options = {{}}) {{
        if (!item) return;
        const keepCurrentNote = Boolean(options.keepCurrentNote);
        const trackerItemId = asInt(item.id, 0);
        if (trackerItemId <= 0) return;
        w07ActiveItemId = trackerItemId;
        document.getElementById("w07TrackItemId").value = String(trackerItemId);
        document.getElementById("w07TrackAssignee").value = String(item.assignee || "");
        document.getElementById("w07TrackStatus").value = String(item.status || "");
        document.getElementById("w07TrackCompleted").checked = Boolean(item.completion_checked);
        document.getElementById("w07EvidenceListItemId").value = String(trackerItemId);
        if (!keepCurrentNote) {{
          document.getElementById("w07TrackNote").value = String(item.completion_note || "");
        }}
      }}

      function renderW07SelectionMeta() {{
        const meta = document.getElementById("w07SelectionMeta");
        if (!meta) return;
        const filteredCount = getW07FilteredItems().length;
        const totalCount = Array.isArray(w07TrackerItemsCache) ? w07TrackerItemsCache.length : 0;
        meta.textContent =
          ": " + getW07FilterLabel(w07TrackerFilter)
          + " | : " + String(filteredCount) + "/" + String(totalCount)
          + " | : " + String(w07SelectedItemIds.size);
      }}

      function pushW07ActionResult(entry) {{
        const base = {{
          at: new Date().toISOString(),
          action: "action",
          tracker_item_id: "-",
          result: "ok",
          detail: "",
        }};
        const row = Object.assign(base, entry || {{}});
        w07ActionResults = [row].concat(w07ActionResults).slice(0, 80);
      }}

      function renderW07ActionResultsPanel() {{
        const panel = document.getElementById("w07ActionResults");
        if (!panel) return;
        if (!Array.isArray(w07ActionResults) || w07ActionResults.length === 0) {{
          panel.innerHTML = renderEmpty("   ");
          return;
        }}
        const rows = w07ActionResults.map((row, idx) => ({{
          no: idx + 1,
          at: formatDateLocal(row.at),
          action: row.action || "-",
          tracker_item_id: row.tracker_item_id || "-",
          result: String(row.result || "-").toUpperCase(),
          detail: row.detail || "",
        }}));
        panel.innerHTML = renderTable(
          rows,
          [
            {{ key: "no", label: "#" }},
            {{ key: "at", label: "At" }},
            {{ key: "action", label: "Action" }},
            {{ key: "tracker_item_id", label: "Tracker ID" }},
            {{ key: "result", label: "Result" }},
            {{ key: "detail", label: "Detail" }},
          ]
        );
      }}

      function renderW07ReadinessCards(readiness, completion) {{
        const cards = [
          {{
            label: "Readiness Ready",
            value: readiness && readiness.ready ? "YES" : "NO",
            status: readiness && readiness.ready ? "ok" : "warning",
            sub: "  ",
            filter: "all",
          }},
          {{
            label: "Readiness %",
            value: String((readiness && readiness.readiness_score_percent) ?? 0),
            status: (readiness && readiness.ready) ? "ok" : "info",
            sub: " ",
            filter: "all",
          }},
          {{
            label: "Missing Assignee",
            value: String((readiness && readiness.missing_assignee_count) ?? 0),
            status: ((readiness && readiness.missing_assignee_count) ?? 0) > 0 ? "warning" : "ok",
            sub: "  ",
            filter: "missing_assignee",
          }},
          {{
            label: "Missing Checked",
            value: String((readiness && readiness.missing_completion_checked_count) ?? 0),
            status: ((readiness && readiness.missing_completion_checked_count) ?? 0) > 0 ? "warning" : "ok",
            sub: "  ",
            filter: "missing_checked",
          }},
          {{
            label: "Missing Evidence",
            value: String((readiness && readiness.missing_required_evidence_count) ?? 0),
            status: ((readiness && readiness.missing_required_evidence_count) ?? 0) > 0 ? "critical" : "ok",
            sub: "  ",
            filter: "missing_evidence",
          }},
          {{
            label: "Pending",
            value: String((readiness && readiness.pending_count) ?? 0),
            status: ((readiness && readiness.pending_count) ?? 0) > 0 ? "warning" : "ok",
            sub: " pending",
            filter: "pending",
          }},
          {{
            label: "In Progress",
            value: String((readiness && readiness.in_progress_count) ?? 0),
            status: ((readiness && readiness.in_progress_count) ?? 0) > 0 ? "warning" : "ok",
            sub: " in_progress",
            filter: "in_progress",
          }},
          {{
            label: "Blocked",
            value: String((readiness && readiness.blocked_count) ?? 0),
            status: ((readiness && readiness.blocked_count) ?? 0) > 0 ? "critical" : "ok",
            sub: " blocked",
            filter: "blocked",
          }},
          {{
            label: "Completion Status",
            value: String((completion && completion.status) || "active"),
            status: ((completion && completion.status) || "active").startsWith("completed") ? "ok" : "info",
            sub: "completed_at=" + String((completion && completion.completed_at) || "-"),
            filter: "all",
          }},
        ];
        return cards.map((card) => {{
          const tone = normalizeUiStatus(card.status);
          const active = String(card.filter || "all") === String(w07TrackerFilter || "all");
          return (
            '<div class="card w07-readiness-card status-' + tone + (active ? " active" : "") + '" data-filter="' + escapeHtml(card.filter || "all") + '" tabindex="0" role="button">'
            + '<div class="k">' + escapeHtml(card.label) + "</div>"
            + '<div class="v">' + escapeHtml(card.value) + "</div>"
            + '<div class="sub">' + renderUiStatusChip(tone) + " " + escapeHtml(card.sub || "") + "</div>"
            + "</div>"
          );
        }}).join("");
      }}

      function renderW07TrackerTableMarkup(rows) {{
        if (!Array.isArray(rows) || rows.length === 0) {{
          return renderEmpty(" .");
        }}
        const head =
          "<th></th><th>ID</th><th>Type</th><th>Key</th><th>Name</th><th>Assignee</th><th>Status</th><th>Checked</th><th>Evidence</th><th>Updated At</th>";
        const body = rows.map((row) => {{
          const trackerId = asInt(row.id, 0);
          const selected = w07SelectedItemIds.has(trackerId);
          const requiredEvidence = isW07EvidenceRequired(row);
          const evidenceCount = asInt(row.evidence_count, 0);
          const evidenceChip = requiredEvidence
            ? (evidenceCount > 0 ? renderUiStatusChip("ok") : renderUiStatusChip("critical"))
            : renderUiStatusChip("info");
          const statusValue = String(row.status || "");
          const statusTone = statusValue === "done"
            ? "ok"
            : (statusValue === "blocked" ? "critical" : (statusValue === "in_progress" ? "warning" : "info"));
          const checkedTone = Boolean(row.completion_checked) ? "ok" : "warning";
          const rowClass = "w07-track-row" + (trackerId === w07ActiveItemId ? " active" : "");
          const typeLabel = String(row.item_type || "");
          const requiredBadge = requiredEvidence
            ? (' <span class="status-chip ' + (evidenceCount > 0 ? "ok" : "critical") + '">' + (evidenceCount > 0 ? "REQ OK" : "REQ MISS") + "</span>")
            : "";
          return (
            '<tr class="' + rowClass + '" data-item-id="' + escapeHtml(trackerId) + '">'
              + '<td><input class="w07-select-item" type="checkbox" data-item-id="' + escapeHtml(trackerId) + '"' + (selected ? " checked" : "") + " /></td>"
              + '<td><button type="button" class="btn soft w07-pick-item" data-item-id="' + escapeHtml(trackerId) + '">' + escapeHtml(trackerId) + "</button></td>"
              + "<td>" + escapeHtml(typeLabel) + requiredBadge + "</td>"
              + "<td>" + escapeHtml(row.item_key ?? "") + "</td>"
              + "<td>" + escapeHtml(row.item_name ?? "") + "</td>"
              + "<td>" + escapeHtml(row.assignee ?? "") + "</td>"
              + "<td>" + renderUiStatusChip(statusTone) + " " + escapeHtml(statusValue) + "</td>"
              + "<td>" + renderUiStatusChip(checkedTone) + " " + escapeHtml(Boolean(row.completion_checked)) + "</td>"
              + "<td>" + evidenceChip + " " + escapeHtml(evidenceCount) + "</td>"
              + "<td>" + escapeHtml(row.updated_at ?? "") + "</td>"
            + "</tr>"
          );
        }}).join("");
        return '<div class="table-wrap"><table><thead><tr>' + head + "</tr></thead><tbody>" + body + "</tbody></table></div>";
      }}

      function renderW07TrackerTablePanel() {{
        const table = document.getElementById("w07TrackerTable");
        const validIds = new Set((Array.isArray(w07TrackerItemsCache) ? w07TrackerItemsCache : []).map((row) => asInt(row.id, -1)));
        w07SelectedItemIds = new Set(Array.from(w07SelectedItemIds).filter((itemId) => validIds.has(asInt(itemId, -1))));
        if (w07ActiveItemId !== null && !validIds.has(asInt(w07ActiveItemId, -1))) {{
          w07ActiveItemId = null;
        }}
        const rows = getW07FilteredItems();
        table.innerHTML = renderW07TrackerTableMarkup(rows);
        renderW07SelectionMeta();
      }}

      function setW07TrackerFilter(filterKey, options = {{}}) {{
        const requested = String(filterKey || "all");
        const allowed = new Set(["all", "pending", "in_progress", "blocked", "not_done", "missing_assignee", "missing_checked", "missing_evidence"]);
        w07TrackerFilter = allowed.has(requested) ? requested : "all";
        renderW07TrackerTablePanel();
        if (w07LastReadiness && w07LastCompletion) {{
          const readinessCards = document.getElementById("w07ReadinessCards");
          readinessCards.innerHTML = renderW07ReadinessCards(w07LastReadiness, w07LastCompletion);
        }}
        const autoPick = Boolean(options.autoPick);
        if (autoPick) {{
          const rows = getW07FilteredItems();
          if (rows.length > 0) {{
            fillW07FormFromItem(rows[0], {{ keepCurrentNote: true }});
            renderW07TrackerTablePanel();
          }}
        }}
      }}

      function pickW07NextIncompleteItem() {{
        const source = getW07FilteredItems();
        const target = source.find((row) => isW07IncompleteRow(row));
        if (!target) return null;
        fillW07FormFromItem(target, {{ keepCurrentNote: true }});
        renderW07TrackerTablePanel();
        return target;
      }}

      function openW07CompleteModal(summaryText) {{
        const modal = document.getElementById("w07CompleteModal");
        const summary = document.getElementById("w07CompleteModalSummary");
        summary.textContent = summaryText;
        modal.classList.add("open");
        modal.setAttribute("aria-hidden", "false");
        return new Promise((resolve) => {{
          w07CompleteModalResolver = resolve;
        }});
      }}

      function closeW07CompleteModal(confirmed) {{
        const modal = document.getElementById("w07CompleteModal");
        modal.classList.remove("open");
        modal.setAttribute("aria-hidden", "true");
        const resolver = w07CompleteModalResolver;
        w07CompleteModalResolver = null;
        if (resolver) {{
          resolver(Boolean(confirmed));
        }}
      }}

      function assignW07EvidenceFile(file) {{
        const input = document.getElementById("w07EvidenceFile");
        if (!file) return;
        try {{
          const transfer = new DataTransfer();
          transfer.items.add(file);
          input.files = transfer.files;
        }} catch (err) {{
          // Some browsers restrict programmatic assignment; fallback to manual selection.
        }}
        document.getElementById("w07TrackerMeta").textContent =
          "  : " + String(file.name || "unknown") + " (" + String(asInt(file.size, 0)) + " bytes)";
      }}

      function renderTable(rows, columns) {{
        if (!Array.isArray(rows) || rows.length === 0) {{
          return renderEmpty(" .");
        }}
        const head = columns.map((c) => "<th>" + escapeHtml(c.label) + "</th>").join("");
        const body = rows.map((row) => {{
          const tds = columns.map((c) => {{
            const value = c.render ? c.render(row[c.key], row) : row[c.key];
            if (value === null || value === undefined) return "<td></td>";
            return "<td>" + escapeHtml(value) + "</td>";
          }}).join("");
          return "<tr>" + tds + "</tr>";
        }}).join("");
        return '<div class="table-wrap"><table><thead><tr>' + head + '</tr></thead><tbody>' + body + "</tbody></table></div>";
      }}

      function renderEvidenceTable(rows, trackerPhase) {{
        if (!Array.isArray(rows) || rows.length === 0) {{
          return renderEmpty("  .");
        }}
        const phase = trackerPhase === "w10"
          ? "w10"
          : (trackerPhase === "w09"
          ? "w09"
          : (trackerPhase === "w07"
            ? "w07"
            : (trackerPhase === "w04" ? "w04" : (trackerPhase === "w03" ? "w03" : "w02"))));
        const body = rows.map((row) => {{
          const downloadHref = "/api/adoption/" + phase + "/tracker/evidence/" + encodeURIComponent(String(row.id || "")) + "/download";
          return (
            "<tr>" +
              "<td>" + escapeHtml(row.id ?? "") + "</td>" +
              "<td>" + escapeHtml(row.file_name ?? "") + "</td>" +
              "<td>" + escapeHtml(row.file_size ?? "") + "</td>" +
              "<td>" + escapeHtml(row.uploaded_by ?? "") + "</td>" +
              "<td>" + escapeHtml(row.uploaded_at ?? "") + "</td>" +
              "<td>" + escapeHtml(row.note ?? "") + "</td>" +
              '<td><a href="' + downloadHref + '" target="_blank" rel="noopener">download</a></td>' +
            "</tr>"
          );
        }}).join("");
        return (
          '<div class="table-wrap"><table><thead><tr>' +
          "<th>ID</th><th>File</th><th>Size</th><th>Uploaded By</th><th>Uploaded At</th><th>Note</th><th>Download</th>" +
          "</tr></thead><tbody>" + body + "</tbody></table></div>"
        );
      }}

      function buildQuery(pairs) {{
        const params = new URLSearchParams();
        pairs.forEach((pair) => {{
          const node = document.getElementById(pair.id);
          if (!node) return;
          const value = (node.value || "").trim();
          if (value !== "") {{
            params.set(pair.key, value);
          }}
        }});
        return params.toString();
      }}

      async function fetchJson(path, requiresAuth, options = {{}}) {{
        const headers = {{ "Accept": "application/json" }};
        const optionHeaders = options.headers || {{}};
        Object.keys(optionHeaders).forEach((key) => {{
          headers[key] = optionHeaders[key];
        }});
        if (requiresAuth) {{
          const token = getToken();
          if (!token) {{
            throw new Error("  .");
          }}
          headers["X-Admin-Token"] = token;
        }}
        const requestOptions = {{
          method: options.method || "GET",
          headers,
        }};
        if (Object.prototype.hasOwnProperty.call(options, "body")) {{
          requestOptions.body = options.body;
        }}
        const response = await fetch(path, requestOptions);
        const text = await response.text();
        let data = null;
        try {{
          data = text ? JSON.parse(text) : null;
        }} catch (err) {{
          data = text;
        }}
        if (!response.ok) {{
          throw new Error("HTTP " + response.status + " | " + (typeof data === "string" ? data : JSON.stringify(data)));
        }}
        return data;
      }}

      function parseContentDispositionFilename(value) {{
        const raw = String(value || "");
        if (!raw) return "";
        const utfMatch = raw.match(/filename\\*=UTF-8''([^;]+)/i);
        if (utfMatch && utfMatch[1]) {{
          try {{
            return decodeURIComponent(utfMatch[1]);
          }} catch (err) {{
            return utfMatch[1];
          }}
        }}
        const basicMatch = raw.match(/filename=\"?([^\";]+)\"?/i);
        if (basicMatch && basicMatch[1]) {{
          return basicMatch[1];
        }}
        return "";
      }}

      async function downloadAuthFile(path, defaultFilename) {{
        const token = getToken();
        if (!token) {{
          throw new Error("  .");
        }}
        const response = await fetch(path, {{
          method: "GET",
          headers: {{
            "X-Admin-Token": token,
            "Accept": "application/octet-stream",
          }},
        }});
        if (!response.ok) {{
          const text = await response.text();
          throw new Error("HTTP " + response.status + " | " + text);
        }}
        const blob = await response.blob();
        const headerName = parseContentDispositionFilename(response.headers.get("Content-Disposition"));
        const fileName = headerName || defaultFilename || "download.bin";
        const objectUrl = window.URL.createObjectURL(blob);
        const anchor = document.createElement("a");
        anchor.href = objectUrl;
        anchor.download = fileName;
        anchor.rel = "noopener";
        document.body.appendChild(anchor);
        anchor.click();
        anchor.remove();
        window.setTimeout(() => window.URL.revokeObjectURL(objectUrl), 1000);
        return {{
          fileName,
          size: blob.size,
          sha256: response.headers.get("X-Archive-SHA256") || "",
        }};
      }}

      function activate(tab, updateUrl) {{
        const selected = panels[tab] ? tab : "overview";
        buttons.forEach((btn) => {{
          const active = btn.dataset.tab === selected;
          btn.classList.toggle("active", active);
          btn.setAttribute("aria-selected", active ? "true" : "false");
        }});
        Object.entries(panels).forEach(([key, panel]) => {{
          const active = key === selected;
          panel.classList.toggle("active", active);
          panel.setAttribute("aria-hidden", active ? "false" : "true");
        }});
        if (updateUrl) {{
          url.searchParams.set("tab", selected);
          window.history.replaceState(null, "", url.pathname + (url.search || ""));
        }}
      }}

      async function runAuthMe() {{
        try {{
          authProfile = await fetchJson("/api/auth/me", true);
          updateAuthStateFromToken();
          return authProfile;
        }} catch (err) {{
          authProfile = null;
          updateAuthStateFromToken();
          throw err;
        }}
      }}

      async function runOverview() {{
        const query = buildQuery([
          {{ key: "site", id: "ovSite" }},
          {{ key: "days", id: "ovDays" }},
          {{ key: "job_limit", id: "ovJobLimit" }}
        ]);
        const path = "/api/ops/dashboard/summary" + (query ? "?" + query : "");
        const siteValue = (document.getElementById("ovSite").value || "").trim();
        const handoverParams = new URLSearchParams();
        if (siteValue) {{
          handoverParams.set("site", siteValue);
        }}
        handoverParams.set("window_hours", "12");
        handoverParams.set("due_soon_hours", "6");
        handoverParams.set("max_items", "10");
        const handoverPath = "/api/ops/handover/brief?" + handoverParams.toString();
        const meta = document.getElementById("overviewMeta");
        const cards = document.getElementById("overviewCards");
        const topTable = document.getElementById("overviewTopWorkOrders");
        const alertKpiSummary = document.getElementById("overviewAlertKpiSummary");
        const alertKpiChannels = document.getElementById("overviewAlertKpiChannels");
        const alertMttrSummary = document.getElementById("overviewAlertMttrSummary");
        const alertMttrChannels = document.getElementById("overviewAlertMttrChannels");
        const alertGuardMeta = document.getElementById("overviewAlertGuardMeta");
        const alertGuardTable = document.getElementById("overviewAlertGuardTable");
        const alertGuardRecoverMeta = document.getElementById("overviewGuardRecoverMeta");
        const alertGuardRecoverTable = document.getElementById("overviewGuardRecoverTable");
        try {{
          meta.textContent = " ... " + path;
          const [data, handover, kpi, mttr, guard, guardRecoverLatest, retentionPolicy, retentionLatest] = await Promise.all([
            fetchJson(path, true),
            fetchJson(handoverPath, true).catch(() => null),
            fetchJson("/api/ops/alerts/kpi/channels", true).catch(() => null),
            fetchJson("/api/ops/alerts/kpi/mttr", true).catch(() => null),
            fetchJson("/api/ops/alerts/channels/guard", true).catch(() => null),
            fetchJson("/api/ops/alerts/channels/guard/recover/latest", true).catch(() => null),
            fetchJson("/api/ops/alerts/retention/policy", true).catch(() => null),
            fetchJson("/api/ops/alerts/retention/latest", true).catch(() => null),
          ]);
          meta.textContent = ": " + path;
          const stats = [
            ["Inspections", data.inspections_total ?? 0],
            ["Work Orders", data.work_orders_total ?? 0],
            ["Overdue Open", data.overdue_open_count ?? 0],
            ["Escalated Open", data.escalated_open_count ?? 0],
            ["Report Exports", data.report_export_count ?? 0],
            ["SLA Runs", data.sla_recent_runs ?? 0],
            ["SLA Warning Runs", data.sla_warning_runs ?? 0],
            ["Last SLA Run", data.sla_last_run_at || "-"],
          ];
          cards.innerHTML = stats.map((s) => (
            '<div class="card"><div class="k">' + escapeHtml(s[0]) + '</div><div class="v">' + escapeHtml(s[1] || 0) + "</div></div>"
          )).join("");

          if (handover && Array.isArray(handover.top_work_orders)) {{
            topTable.innerHTML = renderTable(
              handover.top_work_orders || [],
              [
                {{ key: "id", label: "ID" }},
                {{ key: "site", label: "Site" }},
                {{ key: "title", label: "Title" }},
                {{ key: "priority", label: "Priority" }},
                {{ key: "status", label: "Status" }},
                {{ key: "urgency_score", label: "Score" }}
              ]
            );
          }} else {{
            topTable.innerHTML = renderTable(
              data.recent_job_runs || [],
              [
                {{ key: "job_name", label: "Job" }},
                {{ key: "status", label: "Status" }},
                {{ key: "finished_at", label: "Finished At" }},
                {{ key: "trigger", label: "Trigger" }},
              ]
            );
          }}

          const windows = (kpi && Array.isArray(kpi.windows)) ? kpi.windows : [];
          const sortedWindows = windows.slice().sort((a, b) => Number(a.days || 0) - Number(b.days || 0));
          if (sortedWindows.length > 0) {{
            const kpiCards = [];
            sortedWindows.forEach((win) => {{
              kpiCards.push(["" + String(win.days || 0) + "d Success %", (win.success_rate_percent ?? 0) + "%"]);
              kpiCards.push(["" + String(win.days || 0) + "d Deliveries", win.total_deliveries ?? 0]);
            }});
            alertKpiSummary.innerHTML = kpiCards.map((x) => (
              '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
            )).join("");

            const window30 = sortedWindows.find((item) => Number(item.days || 0) === 30) || sortedWindows[sortedWindows.length - 1];
            const channels = Array.isArray(window30.channels) ? window30.channels : [];
            alertKpiChannels.innerHTML = renderTable(
              channels.slice(0, 20),
              [
                {{ key: "target", label: "Target" }},
                {{ key: "total_deliveries", label: "Total" }},
                {{ key: "success_count", label: "Success" }},
                {{ key: "warning_count", label: "Warning" }},
                {{ key: "failed_count", label: "Failed" }},
                {{ key: "success_rate_percent", label: "Success %" }},
                {{ key: "last_attempt_at", label: "Last Attempt" }},
              ]
            );
          }} else {{
            alertKpiSummary.innerHTML = "";
            alertKpiChannels.innerHTML = renderEmpty(" KPI  .");
          }}

          const mttrWindows = (mttr && Array.isArray(mttr.windows)) ? mttr.windows : [];
          const sortedMttrWindows = mttrWindows.slice().sort((a, b) => Number(a.days || 0) - Number(b.days || 0));
          if (sortedMttrWindows.length > 0) {{
            const mttrCards = [];
            sortedMttrWindows.forEach((win) => {{
              mttrCards.push(["" + String(win.days || 0) + "d MTTR(min)", win.mttr_minutes ?? "-"]);
              mttrCards.push(["" + String(win.days || 0) + "d Recovered", win.recovered_incidents ?? 0]);
              mttrCards.push(["" + String(win.days || 0) + "d Unresolved", win.unresolved_incidents ?? 0]);
            }});
            alertMttrSummary.innerHTML = mttrCards.map((x) => (
              '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
            )).join("");

            const window30Mttr = sortedMttrWindows.find((item) => Number(item.days || 0) === 30) || sortedMttrWindows[sortedMttrWindows.length - 1];
            const mttrChannels = Array.isArray(window30Mttr.channels) ? window30Mttr.channels : [];
            alertMttrChannels.innerHTML = renderTable(
              mttrChannels.slice(0, 20),
              [
                {{ key: "target", label: "Target" }},
                {{ key: "incident_count", label: "Incidents" }},
                {{ key: "recovered_incidents", label: "Recovered" }},
                {{ key: "unresolved_incidents", label: "Unresolved" }},
                {{ key: "mttr_minutes", label: "MTTR(min)" }},
                {{ key: "median_recovery_minutes", label: "Median(min)" }},
                {{ key: "longest_recovery_minutes", label: "Longest(min)" }},
                {{ key: "last_recovery_at", label: "Last Recovery" }},
              ]
            );
          }} else {{
            alertMttrSummary.innerHTML = "";
            alertMttrChannels.innerHTML = renderEmpty(" MTTR  .");
          }}

          if (guard && guard.summary) {{
            const summary = guard.summary || {{}};
            const latestRetention = retentionLatest && retentionLatest.run_id
              ? (" : run#" + String(retentionLatest.run_id) + " deleted=" + String(retentionLatest.deleted_count || 0))
              : " : ";
            const latestRecover = guardRecoverLatest && guardRecoverLatest.run_id
              ? (" |  : run#" + String(guardRecoverLatest.run_id) + " processed=" + String(guardRecoverLatest.processed_count || 0) + " failed=" + String(guardRecoverLatest.failed_count || 0))
              : " |  : ";
            const policyText = retentionPolicy
              ? (" | retention=" + String(retentionPolicy.retention_days || "-") + "d archive=" + String(retentionPolicy.archive_enabled))
              : "";
            alertGuardMeta.textContent =
              "Guard=" + String(summary.status || "-")
              + " | quarantined=" + String(summary.quarantined_count || 0)
              + " | warning=" + String(summary.warning_count || 0)
              + " | targets=" + String(summary.target_count || 0)
              + " | " + latestRetention
              + latestRecover
              + policyText;
            alertGuardTable.innerHTML = renderTable(
              (guard.channels || []).slice(0, 20),
              [
                {{ key: "target", label: "Target" }},
                {{ key: "state", label: "State" }},
                {{ key: "consecutive_failures", label: "Consecutive Failures" }},
                {{ key: "quarantined_until", label: "Quarantined Until" }},
                {{ key: "last_status", label: "Last Status" }},
                {{ key: "last_attempt_at", label: "Last Attempt" }},
              ]
            );
          }} else {{
            alertGuardMeta.textContent = "      ";
            alertGuardTable.innerHTML = renderEmpty("     .");
          }}

          if (guardRecoverLatest && guardRecoverLatest.run_id) {{
            alertGuardRecoverMeta.textContent =
              "  run#" + String(guardRecoverLatest.run_id)
              + " | status=" + String(guardRecoverLatest.status || "-")
              + " | processed=" + String(guardRecoverLatest.processed_count || 0)
              + " | success=" + String(guardRecoverLatest.success_count || 0)
              + " | failed=" + String(guardRecoverLatest.failed_count || 0)
              + " | skipped=" + String(guardRecoverLatest.skipped_count || 0);
            alertGuardRecoverTable.innerHTML = renderTable(
              (guardRecoverLatest.results || []).slice(0, 20),
              [
                {{ key: "target", label: "Target" }},
                {{ key: "status", label: "Probe" }},
                {{ key: "before_state", label: "Before" }},
                {{ key: "after_state", label: "After" }},
                {{ key: "delivery_id", label: "Delivery ID" }},
                {{ key: "error", label: "Error" }},
              ]
            );
          }} else {{
            alertGuardRecoverMeta.textContent = "   ";
            alertGuardRecoverTable.innerHTML = renderEmpty("   .");
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          cards.innerHTML = "";
          topTable.innerHTML = renderEmpty(err.message);
          alertKpiSummary.innerHTML = "";
          alertKpiChannels.innerHTML = renderEmpty(err.message);
          alertMttrSummary.innerHTML = "";
          alertMttrChannels.innerHTML = renderEmpty(err.message);
          alertGuardMeta.textContent = ": " + err.message;
          alertGuardTable.innerHTML = renderEmpty(err.message);
          alertGuardRecoverMeta.textContent = ": " + err.message;
          alertGuardRecoverTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runOverviewGuardRecover(dryRun) {{
        const meta = document.getElementById("overviewGuardRecoverMeta");
        const table = document.getElementById("overviewGuardRecoverTable");
        const state = (document.getElementById("overviewGuardRecoverState").value || "quarantined").trim() || "quarantined";
        const maxTargetsRaw = (document.getElementById("overviewGuardRecoverMaxTargets").value || "").trim();
        const params = new URLSearchParams();
        params.set("state", state);
        if (maxTargetsRaw !== "") {{
          params.set("max_targets", maxTargetsRaw);
        }}
        params.set("dry_run", dryRun ? "true" : "false");
        const path = "/api/ops/alerts/channels/guard/recover-batch?" + params.toString();
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(
            path,
            true,
            {{
              method: "POST",
            }}
          );
          meta.textContent =
            ": run#" + String(data.run_id || "-")
            + " | status=" + String(data.status || "-")
            + " | processed=" + String(data.processed_count || 0)
            + " | success=" + String(data.success_count || 0)
            + " | failed=" + String(data.failed_count || 0)
            + " | skipped=" + String(data.skipped_count || 0);
          table.innerHTML = renderTable(
            (data.results || []).slice(0, 30),
            [
              {{ key: "target", label: "Target" }},
              {{ key: "status", label: "Probe" }},
              {{ key: "before_state", label: "Before" }},
              {{ key: "after_state", label: "After" }},
              {{ key: "delivery_id", label: "Delivery ID" }},
              {{ key: "error", label: "Error" }},
            ]
          );
          await runOverview();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          table.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runOverviewGuardRecoverLatest() {{
        const meta = document.getElementById("overviewGuardRecoverMeta");
        const table = document.getElementById("overviewGuardRecoverTable");
        try {{
          meta.textContent = " ... /api/ops/alerts/channels/guard/recover/latest";
          const data = await fetchJson("/api/ops/alerts/channels/guard/recover/latest", true);
          meta.textContent =
            " run#" + String(data.run_id || "-")
            + " | status=" + String(data.status || "-")
            + " | processed=" + String(data.processed_count || 0)
            + " | success=" + String(data.success_count || 0)
            + " | failed=" + String(data.failed_count || 0)
            + " | skipped=" + String(data.skipped_count || 0);
          table.innerHTML = renderTable(
            (data.results || []).slice(0, 30),
            [
              {{ key: "target", label: "Target" }},
              {{ key: "status", label: "Probe" }},
              {{ key: "before_state", label: "Before" }},
              {{ key: "after_state", label: "After" }},
              {{ key: "delivery_id", label: "Delivery ID" }},
              {{ key: "error", label: "Error" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          table.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runWorkorders() {{
        const query = buildQuery([
          {{ key: "status", id: "woStatus" }},
          {{ key: "site", id: "woSite" }},
          {{ key: "limit", id: "woLimit" }},
          {{ key: "offset", id: "woOffset" }}
        ]);
        const path = "/api/work-orders" + (query ? "?" + query : "");
        const meta = document.getElementById("workordersMeta");
        const table = document.getElementById("workordersTable");
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(path, true);
          meta.textContent = ": " + path + " | count=" + data.length;
          table.innerHTML = renderTable(
            data,
            [
              {{ key: "id", label: "ID" }},
              {{ key: "site", label: "Site" }},
              {{ key: "title", label: "Title" }},
              {{ key: "priority", label: "Priority" }},
              {{ key: "status", label: "Status" }},
              {{ key: "assignee", label: "Assignee" }},
              {{ key: "due_at", label: "Due At" }},
              {{ key: "is_escalated", label: "Escalated" }}
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          table.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runInspections() {{
        const query = buildQuery([
          {{ key: "site", id: "inSite" }},
          {{ key: "limit", id: "inLimit" }},
          {{ key: "offset", id: "inOffset" }}
        ]);
        const path = "/api/inspections" + (query ? "?" + query : "");
        const meta = document.getElementById("inspectionsMeta");
        const table = document.getElementById("inspectionsTable");
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(path, true);
          meta.textContent = ": " + path + " | count=" + data.length;
          table.innerHTML = renderTable(
            data,
            [
              {{ key: "id", label: "ID" }},
              {{ key: "site", label: "Site" }},
              {{ key: "location", label: "Location" }},
              {{ key: "inspector", label: "Inspector" }},
              {{ key: "risk_level", label: "Risk" }},
              {{ key: "inspected_at", label: "Inspected At" }}
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          table.innerHTML = renderEmpty(err.message);
        }}
      }}

      function updateReportLinks() {{
        const query = buildQuery([
          {{ key: "month", id: "rpMonth" }},
          {{ key: "site", id: "rpSite" }}
        ]);
        const suffix = query ? "?" + query : "";
        document.getElementById("reportPrintLink").setAttribute("href", "/reports/monthly/print" + suffix);
        document.getElementById("reportCsvLink").setAttribute("href", "/api/reports/monthly/csv" + suffix);
        document.getElementById("reportPdfLink").setAttribute("href", "/api/reports/monthly/pdf" + suffix);
      }}

      async function runReports() {{
        const query = buildQuery([
          {{ key: "month", id: "rpMonth" }},
          {{ key: "site", id: "rpSite" }}
        ]);
        const path = "/api/reports/monthly" + (query ? "?" + query : "");
        const meta = document.getElementById("reportsMeta");
        const summary = document.getElementById("reportsSummary");
        const raw = document.getElementById("reportsRaw");
        updateReportLinks();
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(path, true);
          meta.textContent = ": " + path;
          const summaryItems = [
            ["Month", data.month],
            ["Site", data.site || "ALL"],
            ["Total Inspections", data.total_inspections],
            ["High Risk Inspections", data.high_risk_inspections],
            ["Total Work Orders", data.total_work_orders],
            ["Escalated Work Orders", data.escalated_work_orders],
            ["Completed Work Orders", data.completed_work_orders],
            ["Overdue Open Work Orders", data.overdue_open_work_orders]
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1] ?? "") + "</div></div>"
          )).join("");
          raw.textContent = JSON.stringify(data, null, 2);
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          raw.textContent = err.message;
        }}
      }}

      async function runW02Tracker() {{
        const meta = document.getElementById("w02TrackerMeta");
        const summary = document.getElementById("w02TrackerSummary");
        const table = document.getElementById("w02TrackerTable");
        const readinessMeta = document.getElementById("w02ReadinessMeta");
        const readinessCards = document.getElementById("w02ReadinessCards");
        const readinessBlockers = document.getElementById("w02ReadinessBlockers");
        const evidenceTable = document.getElementById("w02EvidenceTable");
        const site = (document.getElementById("w02TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          summary.innerHTML = "";
          table.innerHTML = renderEmpty("site  .");
          readinessMeta.textContent = "site  .";
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty("site  .");
          evidenceTable.innerHTML = renderEmpty("site  .");
          return;
        }}
        try {{
          meta.textContent = " ... W02 tracker";
          readinessMeta.textContent = " ... W02 readiness";
          const [trackerOverview, trackerItems, readiness, completion] = await Promise.all([
            fetchJson("/api/adoption/w02/tracker/overview?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w02/tracker/items?site=" + encodeURIComponent(site) + "&limit=500", true),
            fetchJson("/api/adoption/w02/tracker/readiness?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w02/tracker/completion?site=" + encodeURIComponent(site), true),
          ]);
          meta.textContent = ": W02 tracker (" + site + ")";
          readinessMeta.textContent =
            ": " + String(completion.status || "active")
            + " | ready=" + (readiness.ready ? "YES" : "NO")
            + " |  =" + String(readiness.checked_at || "-");
          const summaryItems = [
            ["Total", trackerOverview.total_items || 0],
            ["Pending", trackerOverview.pending_count || 0],
            ["In Progress", trackerOverview.in_progress_count || 0],
            ["Done", trackerOverview.done_count || 0],
            ["Blocked", trackerOverview.blocked_count || 0],
            ["Completion %", trackerOverview.completion_rate_percent || 0],
            ["Evidence", trackerOverview.evidence_total_count || 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const readinessItems = [
            ["Readiness Ready", readiness.ready ? "YES" : "NO"],
            ["Readiness %", readiness.readiness_score_percent || 0],
            ["Missing Assignee", readiness.missing_assignee_count || 0],
            ["Missing Checked", readiness.missing_completion_checked_count || 0],
            ["Missing Evidence", readiness.missing_required_evidence_count || 0],
            ["Completion Status", completion.status || "active"],
            ["Completed At", completion.completed_at || "-"],
            ["Completed By", completion.completed_by || "-"],
          ];
          readinessCards.innerHTML = readinessItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const blockers = Array.isArray(readiness.blockers) ? readiness.blockers : [];
          if (blockers.length > 0) {{
            readinessBlockers.innerHTML = (
              '<div class="table-wrap"><table><thead><tr><th>#</th><th>Blocker</th></tr></thead><tbody>'
              + blockers.map((item, idx) => (
                "<tr><td>" + escapeHtml(idx + 1) + "</td><td>" + escapeHtml(item) + "</td></tr>"
              )).join("")
              + "</tbody></table></div>"
            );
          }} else {{
            readinessBlockers.innerHTML = renderEmpty("  ");
          }}
          table.innerHTML = renderTable(
            trackerItems || [],
            [
              {{ key: "id", label: "ID" }},
              {{ key: "item_type", label: "Type" }},
              {{ key: "item_key", label: "Key" }},
              {{ key: "item_name", label: "Name" }},
              {{ key: "assignee", label: "Assignee" }},
              {{ key: "status", label: "Status" }},
              {{ key: "completion_checked", label: "Checked" }},
              {{ key: "evidence_count", label: "Evidence" }},
              {{ key: "updated_at", label: "Updated At" }},
            ]
          );

          let evidenceItemId = (document.getElementById("w02EvidenceListItemId").value || "").trim();
          if (!evidenceItemId) {{
            evidenceItemId = (document.getElementById("w02TrackItemId").value || "").trim();
          }}
          if (evidenceItemId) {{
            const evidences = await fetchJson(
              "/api/adoption/w02/tracker/items/" + encodeURIComponent(evidenceItemId) + "/evidence",
              true
            );
            evidenceTable.innerHTML = renderEvidenceTable(evidences || [], "w02");
          }} else {{
            evidenceTable.innerHTML = renderEmpty("tracker_item_id      .");
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          table.innerHTML = renderEmpty(err.message);
          readinessMeta.textContent = ": " + err.message;
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty(err.message);
          evidenceTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW02Readiness() {{
        await runW02Tracker();
      }}

      async function runW02TrackerBootstrap() {{
        const meta = document.getElementById("w02TrackerMeta");
        const site = (document.getElementById("w02TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        try {{
          meta.textContent = " ... W02 tracker bootstrap";
          const data = await fetchJson(
            "/api/adoption/w02/tracker/bootstrap",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify({{ site }}),
            }}
          );
          meta.textContent = ":  " + String(data.created_count || 0) + "";
          await runW02Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW02Complete() {{
        const meta = document.getElementById("w02ReadinessMeta");
        const site = (document.getElementById("w02TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        const completionNote = (document.getElementById("w02CompletionNote").value || "").trim();
        const force = !!document.getElementById("w02CompletionForce").checked;
        const payload = {{
          site: site,
          force: force,
        }};
        if (completionNote) {{
          payload.completion_note = completionNote;
        }}
        try {{
          meta.textContent = " ... W02  ";
          const result = await fetchJson(
            "/api/adoption/w02/tracker/complete",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify(payload),
            }}
          );
          meta.textContent =
            ": status=" + String(result.status || "-")
            + " | ready=" + String(result.readiness && result.readiness.ready ? "YES" : "NO")
            + " | completed_at=" + String(result.completed_at || "-");
          await runW02Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          await runW02Tracker().catch(() => null);
        }}
      }}

      async function runW02TrackerUpdateAndUpload() {{
        const meta = document.getElementById("w02TrackerMeta");
        const trackerItemIdRaw = (document.getElementById("w02TrackItemId").value || "").trim();
        const trackerItemId = Number(trackerItemIdRaw);
        if (!trackerItemIdRaw || !Number.isFinite(trackerItemId) || trackerItemId <= 0) {{
          meta.textContent = " tracker_item_id .";
          return;
        }}

        const assignee = (document.getElementById("w02TrackAssignee").value || "").trim();
        const status = (document.getElementById("w02TrackStatus").value || "").trim();
        const completionChecked = !!document.getElementById("w02TrackCompleted").checked;
        const note = (document.getElementById("w02TrackNote").value || "").trim();
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (completionChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (note) payload.completion_note = note;
        const fileInput = document.getElementById("w02EvidenceFile");
        const file = fileInput && fileInput.files ? fileInput.files[0] : null;
        const hasTrackerUpdate = Object.keys(payload).length > 0;
        if (!hasTrackerUpdate && !file) {{
          meta.textContent = "     .";
          return;
        }}

        try {{
          meta.textContent = " ... tracker update";
          if (hasTrackerUpdate) {{
            await fetchJson(
              "/api/adoption/w02/tracker/items/" + encodeURIComponent(trackerItemIdRaw),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
          }}

          if (file) {{
            const formData = new FormData();
            formData.append("file", file);
            const evidenceNote = (document.getElementById("w02EvidenceNote").value || "").trim();
            formData.append("note", evidenceNote);
            const token = getToken();
            if (!token) {{
              throw new Error("  .");
            }}
            const uploadResp = await fetch(
              "/api/adoption/w02/tracker/items/" + encodeURIComponent(trackerItemIdRaw) + "/evidence",
              {{
                method: "POST",
                headers: {{
                  "X-Admin-Token": token,
                  "Accept": "application/json",
                }},
                body: formData,
              }}
            );
            const uploadText = await uploadResp.text();
            if (!uploadResp.ok) {{
              throw new Error("Evidence upload failed: HTTP " + uploadResp.status + " | " + uploadText);
            }}
            document.getElementById("w02EvidenceFile").value = "";
          }}

          meta.textContent = ": tracker  ";
          await runW02Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW03Tracker() {{
        const meta = document.getElementById("w03TrackerMeta");
        const summary = document.getElementById("w03TrackerSummary");
        const table = document.getElementById("w03TrackerTable");
        const readinessMeta = document.getElementById("w03ReadinessMeta");
        const readinessCards = document.getElementById("w03ReadinessCards");
        const readinessBlockers = document.getElementById("w03ReadinessBlockers");
        const evidenceTable = document.getElementById("w03EvidenceTable");
        const site = (document.getElementById("w03TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          summary.innerHTML = "";
          table.innerHTML = renderEmpty("site  .");
          readinessMeta.textContent = "site  .";
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty("site  .");
          evidenceTable.innerHTML = renderEmpty("site  .");
          return;
        }}
        try {{
          meta.textContent = " ... W03 tracker";
          readinessMeta.textContent = " ... W03 readiness";
          const [trackerOverview, trackerItems, readiness, completion] = await Promise.all([
            fetchJson("/api/adoption/w03/tracker/overview?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w03/tracker/items?site=" + encodeURIComponent(site) + "&limit=500", true),
            fetchJson("/api/adoption/w03/tracker/readiness?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w03/tracker/completion?site=" + encodeURIComponent(site), true),
          ]);
          meta.textContent = ": W03 tracker (" + site + ")";
          readinessMeta.textContent =
            ": " + String(completion.status || "active")
            + " | ready=" + (readiness.ready ? "YES" : "NO")
            + " |  =" + String(readiness.checked_at || "-");
          const summaryItems = [
            ["Total", trackerOverview.total_items || 0],
            ["Pending", trackerOverview.pending_count || 0],
            ["In Progress", trackerOverview.in_progress_count || 0],
            ["Done", trackerOverview.done_count || 0],
            ["Blocked", trackerOverview.blocked_count || 0],
            ["Completion %", trackerOverview.completion_rate_percent || 0],
            ["Evidence", trackerOverview.evidence_total_count || 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const readinessItems = [
            ["Readiness Ready", readiness.ready ? "YES" : "NO"],
            ["Readiness %", readiness.readiness_score_percent || 0],
            ["Missing Assignee", readiness.missing_assignee_count || 0],
            ["Missing Checked", readiness.missing_completion_checked_count || 0],
            ["Missing Evidence", readiness.missing_required_evidence_count || 0],
            ["Completion Status", completion.status || "active"],
            ["Completed At", completion.completed_at || "-"],
            ["Completed By", completion.completed_by || "-"],
          ];
          readinessCards.innerHTML = readinessItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const blockers = Array.isArray(readiness.blockers) ? readiness.blockers : [];
          if (blockers.length > 0) {{
            readinessBlockers.innerHTML = (
              '<div class="table-wrap"><table><thead><tr><th>#</th><th>Blocker</th></tr></thead><tbody>'
              + blockers.map((item, idx) => (
                "<tr><td>" + escapeHtml(idx + 1) + "</td><td>" + escapeHtml(item) + "</td></tr>"
              )).join("")
              + "</tbody></table></div>"
            );
          }} else {{
            readinessBlockers.innerHTML = renderEmpty("  ");
          }}
          table.innerHTML = renderTable(
            trackerItems || [],
            [
              {{ key: "id", label: "ID" }},
              {{ key: "item_type", label: "Type" }},
              {{ key: "item_key", label: "Key" }},
              {{ key: "item_name", label: "Name" }},
              {{ key: "assignee", label: "Assignee" }},
              {{ key: "status", label: "Status" }},
              {{ key: "completion_checked", label: "Checked" }},
              {{ key: "evidence_count", label: "Evidence" }},
              {{ key: "updated_at", label: "Updated At" }},
            ]
          );

          let evidenceItemId = (document.getElementById("w03EvidenceListItemId").value || "").trim();
          if (!evidenceItemId) {{
            evidenceItemId = (document.getElementById("w03TrackItemId").value || "").trim();
          }}
          if (evidenceItemId) {{
            const evidences = await fetchJson(
              "/api/adoption/w03/tracker/items/" + encodeURIComponent(evidenceItemId) + "/evidence",
              true
            );
            evidenceTable.innerHTML = renderEvidenceTable(evidences || [], "w03");
          }} else {{
            evidenceTable.innerHTML = renderEmpty("tracker_item_id      .");
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          table.innerHTML = renderEmpty(err.message);
          readinessMeta.textContent = ": " + err.message;
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty(err.message);
          evidenceTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW03Readiness() {{
        await runW03Tracker();
      }}

      async function runW03TrackerBootstrap() {{
        const meta = document.getElementById("w03TrackerMeta");
        const site = (document.getElementById("w03TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        try {{
          meta.textContent = " ... W03 tracker bootstrap";
          const data = await fetchJson(
            "/api/adoption/w03/tracker/bootstrap",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify({{ site }}),
            }}
          );
          meta.textContent = ":  " + String(data.created_count || 0) + "";
          await runW03Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW03Complete() {{
        const meta = document.getElementById("w03ReadinessMeta");
        const site = (document.getElementById("w03TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        const completionNote = (document.getElementById("w03CompletionNote").value || "").trim();
        const force = !!document.getElementById("w03CompletionForce").checked;
        const payload = {{
          site: site,
          force: force,
        }};
        if (completionNote) {{
          payload.completion_note = completionNote;
        }}
        try {{
          meta.textContent = " ... W03  ";
          const result = await fetchJson(
            "/api/adoption/w03/tracker/complete",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify(payload),
            }}
          );
          meta.textContent =
            ": status=" + String(result.status || "-")
            + " | ready=" + String(result.readiness && result.readiness.ready ? "YES" : "NO")
            + " | completed_at=" + String(result.completed_at || "-");
          await runW03Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          await runW03Tracker().catch(() => null);
        }}
      }}

      async function runW03TrackerUpdateAndUpload() {{
        const meta = document.getElementById("w03TrackerMeta");
        const trackerItemIdRaw = (document.getElementById("w03TrackItemId").value || "").trim();
        const trackerItemId = Number(trackerItemIdRaw);
        if (!trackerItemIdRaw || !Number.isFinite(trackerItemId) || trackerItemId <= 0) {{
          meta.textContent = " tracker_item_id .";
          return;
        }}

        const assignee = (document.getElementById("w03TrackAssignee").value || "").trim();
        const status = (document.getElementById("w03TrackStatus").value || "").trim();
        const completionChecked = !!document.getElementById("w03TrackCompleted").checked;
        const note = (document.getElementById("w03TrackNote").value || "").trim();
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (completionChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (note) payload.completion_note = note;
        const fileInput = document.getElementById("w03EvidenceFile");
        const file = fileInput && fileInput.files ? fileInput.files[0] : null;
        const hasTrackerUpdate = Object.keys(payload).length > 0;
        if (!hasTrackerUpdate && !file) {{
          meta.textContent = "     .";
          return;
        }}

        try {{
          meta.textContent = " ... tracker update";
          if (hasTrackerUpdate) {{
            await fetchJson(
              "/api/adoption/w03/tracker/items/" + encodeURIComponent(trackerItemIdRaw),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
          }}

          if (file) {{
            const formData = new FormData();
            formData.append("file", file);
            const evidenceNote = (document.getElementById("w03EvidenceNote").value || "").trim();
            formData.append("note", evidenceNote);
            const token = getToken();
            if (!token) {{
              throw new Error("  .");
            }}
            const uploadResp = await fetch(
              "/api/adoption/w03/tracker/items/" + encodeURIComponent(trackerItemIdRaw) + "/evidence",
              {{
                method: "POST",
                headers: {{
                  "X-Admin-Token": token,
                  "Accept": "application/json",
                }},
                body: formData,
              }}
            );
            const uploadText = await uploadResp.text();
            if (!uploadResp.ok) {{
              throw new Error("Evidence upload failed: HTTP " + uploadResp.status + " | " + uploadText);
            }}
            document.getElementById("w03EvidenceFile").value = "";
          }}

          meta.textContent = ": tracker  ";
          await runW03Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW04FunnelBlockers() {{
        const meta = document.getElementById("w04FunnelMeta");
        const summary = document.getElementById("w04FunnelSummary");
        const stages = document.getElementById("w04FunnelStages");
        const blockers = document.getElementById("w04BlockerTable");
        const site = (document.getElementById("w04FunnelSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          summary.innerHTML = "";
          stages.innerHTML = renderEmpty("site  .");
          blockers.innerHTML = renderEmpty("site  .");
          return;
        }}
        const daysRaw = (document.getElementById("w04FunnelDays").value || "").trim();
        const maxItemsRaw = (document.getElementById("w04FunnelMaxBlockers").value || "").trim();
        const params = new URLSearchParams();
        params.set("site", site);
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        if (maxItemsRaw) {{
          params.set("max_items", maxItemsRaw);
        }}
        try {{
          meta.textContent = " ... W04 funnel + blockers";
          const [funnel, topBlockers] = await Promise.all([
            fetchJson("/api/ops/adoption/w04/funnel?" + params.toString(), true),
            fetchJson("/api/ops/adoption/w04/blockers?" + params.toString(), true),
          ]);
          const metrics = funnel.metrics || {{}};
          const timings = funnel.stage_timings_minutes || {{}};
          meta.textContent =
            ": W04 funnel (" + site + ")"
            + " | median_ttv=" + String(metrics.median_ttv_minutes ?? "-")
            + " | target_met=" + String(metrics.target_met ? "YES" : "NO");
          const summaryItems = [
            ["Target TTV(min)", funnel.target_ttv_minutes ?? 15],
            ["Median TTV(min)", metrics.median_ttv_minutes ?? "-"],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
            ["Total Users", metrics.total_users ?? 0],
            ["Inspection Conv %", metrics.inspection_conversion_rate_percent ?? 0],
            ["WO Complete Conv %", metrics.work_order_completion_rate_percent ?? 0],
            ["Auth->Inspection(min)", timings.auth_to_first_inspection ?? "-"],
            ["Inspection->Complete(min)", timings.inspection_to_first_work_order_complete ?? "-"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          stages.innerHTML = renderTable(
            funnel.stages || [],
            [
              {{ key: "stage_id", label: "Stage ID" }},
              {{ key: "label", label: "Label" }},
              {{ key: "user_count", label: "Users" }},
              {{ key: "conversion_rate_percent", label: "Conv %" }},
            ]
          );
          blockers.innerHTML = renderTable(
            topBlockers.top || [],
            [
              {{ key: "blocker_key", label: "Blocker Key" }},
              {{ key: "title", label: "Title" }},
              {{ key: "count", label: "Count" }},
              {{ key: "source", label: "Source" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          stages.innerHTML = renderEmpty(err.message);
          blockers.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW04Tracker() {{
        const meta = document.getElementById("w04TrackerMeta");
        const summary = document.getElementById("w04TrackerSummary");
        const table = document.getElementById("w04TrackerTable");
        const readinessMeta = document.getElementById("w04ReadinessMeta");
        const readinessCards = document.getElementById("w04ReadinessCards");
        const readinessBlockers = document.getElementById("w04ReadinessBlockers");
        const evidenceTable = document.getElementById("w04EvidenceTable");
        const site = (document.getElementById("w04TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          summary.innerHTML = "";
          table.innerHTML = renderEmpty("site  .");
          readinessMeta.textContent = "site  .";
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty("site  .");
          evidenceTable.innerHTML = renderEmpty("site  .");
          return;
        }}
        try {{
          meta.textContent = " ... W04 tracker";
          readinessMeta.textContent = " ... W04 readiness";
          const [trackerOverview, trackerItems, readiness, completion] = await Promise.all([
            fetchJson("/api/adoption/w04/tracker/overview?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w04/tracker/items?site=" + encodeURIComponent(site) + "&limit=500", true),
            fetchJson("/api/adoption/w04/tracker/readiness?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w04/tracker/completion?site=" + encodeURIComponent(site), true),
          ]);
          meta.textContent = ": W04 tracker (" + site + ")";
          readinessMeta.textContent =
            ": " + String(completion.status || "active")
            + " | ready=" + (readiness.ready ? "YES" : "NO")
            + " |  =" + String(readiness.checked_at || "-");
          const summaryItems = [
            ["Total", trackerOverview.total_items || 0],
            ["Pending", trackerOverview.pending_count || 0],
            ["In Progress", trackerOverview.in_progress_count || 0],
            ["Done", trackerOverview.done_count || 0],
            ["Blocked", trackerOverview.blocked_count || 0],
            ["Completion %", trackerOverview.completion_rate_percent || 0],
            ["Evidence", trackerOverview.evidence_total_count || 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const readinessItems = [
            ["Readiness Ready", readiness.ready ? "YES" : "NO"],
            ["Readiness %", readiness.readiness_score_percent || 0],
            ["Missing Assignee", readiness.missing_assignee_count || 0],
            ["Missing Checked", readiness.missing_completion_checked_count || 0],
            ["Missing Evidence", readiness.missing_required_evidence_count || 0],
            ["Completion Status", completion.status || "active"],
            ["Completed At", completion.completed_at || "-"],
            ["Completed By", completion.completed_by || "-"],
          ];
          readinessCards.innerHTML = readinessItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const blockers = Array.isArray(readiness.blockers) ? readiness.blockers : [];
          if (blockers.length > 0) {{
            readinessBlockers.innerHTML = (
              '<div class="table-wrap"><table><thead><tr><th>#</th><th>Blocker</th></tr></thead><tbody>'
              + blockers.map((item, idx) => (
                "<tr><td>" + escapeHtml(idx + 1) + "</td><td>" + escapeHtml(item) + "</td></tr>"
              )).join("")
              + "</tbody></table></div>"
            );
          }} else {{
            readinessBlockers.innerHTML = renderEmpty("  ");
          }}
          table.innerHTML = renderTable(
            trackerItems || [],
            [
              {{ key: "id", label: "ID" }},
              {{ key: "item_type", label: "Type" }},
              {{ key: "item_key", label: "Key" }},
              {{ key: "item_name", label: "Name" }},
              {{ key: "assignee", label: "Assignee" }},
              {{ key: "status", label: "Status" }},
              {{ key: "completion_checked", label: "Checked" }},
              {{ key: "evidence_count", label: "Evidence" }},
              {{ key: "updated_at", label: "Updated At" }},
            ]
          );

          let evidenceItemId = (document.getElementById("w04EvidenceListItemId").value || "").trim();
          if (!evidenceItemId) {{
            evidenceItemId = (document.getElementById("w04TrackItemId").value || "").trim();
          }}
          if (evidenceItemId) {{
            const evidences = await fetchJson(
              "/api/adoption/w04/tracker/items/" + encodeURIComponent(evidenceItemId) + "/evidence",
              true
            );
            evidenceTable.innerHTML = renderEvidenceTable(evidences || [], "w04");
          }} else {{
            evidenceTable.innerHTML = renderEmpty("tracker_item_id      .");
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          table.innerHTML = renderEmpty(err.message);
          readinessMeta.textContent = ": " + err.message;
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty(err.message);
          evidenceTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW04Readiness() {{
        await runW04Tracker();
      }}

      async function runW04TrackerBootstrap() {{
        const meta = document.getElementById("w04TrackerMeta");
        const site = (document.getElementById("w04TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        try {{
          meta.textContent = " ... W04 tracker bootstrap";
          const data = await fetchJson(
            "/api/adoption/w04/tracker/bootstrap",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify({{ site }}),
            }}
          );
          meta.textContent = ":  " + String(data.created_count || 0) + "";
          await runW04Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW04Complete() {{
        const meta = document.getElementById("w04ReadinessMeta");
        const site = (document.getElementById("w04TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        const completionNote = (document.getElementById("w04CompletionNote").value || "").trim();
        const force = !!document.getElementById("w04CompletionForce").checked;
        const payload = {{
          site: site,
          force: force,
        }};
        if (completionNote) {{
          payload.completion_note = completionNote;
        }}
        try {{
          meta.textContent = " ... W04  ";
          const result = await fetchJson(
            "/api/adoption/w04/tracker/complete",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify(payload),
            }}
          );
          meta.textContent =
            ": status=" + String(result.status || "-")
            + " | ready=" + String(result.readiness && result.readiness.ready ? "YES" : "NO")
            + " | completed_at=" + String(result.completed_at || "-");
          await runW04Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          await runW04Tracker().catch(() => null);
        }}
      }}

      async function runW04TrackerUpdateAndUpload() {{
        const meta = document.getElementById("w04TrackerMeta");
        const trackerItemIdRaw = (document.getElementById("w04TrackItemId").value || "").trim();
        const trackerItemId = Number(trackerItemIdRaw);
        if (!trackerItemIdRaw || !Number.isFinite(trackerItemId) || trackerItemId <= 0) {{
          meta.textContent = " tracker_item_id .";
          return;
        }}

        const assignee = (document.getElementById("w04TrackAssignee").value || "").trim();
        const status = (document.getElementById("w04TrackStatus").value || "").trim();
        const completionChecked = !!document.getElementById("w04TrackCompleted").checked;
        const note = (document.getElementById("w04TrackNote").value || "").trim();
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (completionChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (note) payload.completion_note = note;
        const fileInput = document.getElementById("w04EvidenceFile");
        const file = fileInput && fileInput.files ? fileInput.files[0] : null;
        const hasTrackerUpdate = Object.keys(payload).length > 0;
        if (!hasTrackerUpdate && !file) {{
          meta.textContent = "     .";
          return;
        }}

        try {{
          meta.textContent = " ... tracker update";
          if (hasTrackerUpdate) {{
            await fetchJson(
              "/api/adoption/w04/tracker/items/" + encodeURIComponent(trackerItemIdRaw),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
          }}

          if (file) {{
            const formData = new FormData();
            formData.append("file", file);
            const evidenceNote = (document.getElementById("w04EvidenceNote").value || "").trim();
            formData.append("note", evidenceNote);
            const token = getToken();
            if (!token) {{
              throw new Error("  .");
            }}
            const uploadResp = await fetch(
              "/api/adoption/w04/tracker/items/" + encodeURIComponent(trackerItemIdRaw) + "/evidence",
              {{
                method: "POST",
                headers: {{
                  "X-Admin-Token": token,
                  "Accept": "application/json",
                }},
                body: formData,
              }}
            );
            const uploadText = await uploadResp.text();
            if (!uploadResp.ok) {{
              throw new Error("Evidence upload failed: HTTP " + uploadResp.status + " | " + uploadText);
            }}
            document.getElementById("w04EvidenceFile").value = "";
          }}

          meta.textContent = ": tracker  ";
          await runW04Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW05Consistency() {{
        const meta = document.getElementById("w05ConsistencyMeta");
        const summary = document.getElementById("w05ConsistencySummary");
        const topSites = document.getElementById("w05ConsistencyTopSites");
        const recommendations = document.getElementById("w05ConsistencyRecommendations");
        const site = (document.getElementById("w05ConsistencySite").value || "").trim();
        const daysRaw = (document.getElementById("w05ConsistencyDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w05/consistency" + (params.toString() ? ("?" + params.toString()) : "");
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(path, true);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | retention=" + String(metrics.two_week_retention_percent ?? 0) + "%"
            + " | target=" + String(data.target_retention_percent ?? 65) + "%";
          const summaryItems = [
            ["Active Users", metrics.active_users ?? 0],
            ["Early Period Users", metrics.early_period_users ?? 0],
            ["Retained Users", metrics.retained_users ?? 0],
            ["2-week Retention %", metrics.two_week_retention_percent ?? 0],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
            ["Inspection Activity Users", metrics.inspection_activity_users ?? 0],
            ["Open Work Orders", metrics.open_work_orders ?? 0],
            ["Overdue Open", metrics.overdue_open_work_orders ?? 0],
            ["Overdue Ratio %", metrics.overdue_ratio_percent ?? 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          topSites.innerHTML = renderTable(
            data.top_sites_by_overdue || [],
            [
              {{ key: "site", label: "Site" }},
              {{ key: "open_work_orders", label: "Open Work Orders" }},
              {{ key: "overdue_open_work_orders", label: "Overdue Open" }},
              {{ key: "overdue_ratio_percent", label: "Overdue Ratio %" }},
            ]
          );
          const recRows = Array.isArray(data.mission_recommendations)
            ? data.mission_recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          topSites.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW06Rhythm() {{
        const meta = document.getElementById("w06RhythmMeta");
        const summary = document.getElementById("w06RhythmSummary");
        const roleCoverage = document.getElementById("w06RhythmRoleCoverage");
        const siteActivity = document.getElementById("w06RhythmSiteActivity");
        const recommendations = document.getElementById("w06RhythmRecommendations");
        const site = (document.getElementById("w06RhythmSite").value || "").trim();
        const daysRaw = (document.getElementById("w06RhythmDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w06/rhythm" + (params.toString() ? ("?" + params.toString()) : "");
        try {{
          meta.textContent = " ... " + path;
          const data = await fetchJson(path, true);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | weekly_active_rate=" + String(metrics.weekly_active_rate_percent ?? 0) + "%"
            + " | target=" + String(data.target_weekly_active_rate_percent ?? 75) + "%";
          const summaryItems = [
            ["Eligible Users", metrics.eligible_users ?? 0],
            ["Active Users", metrics.active_users ?? 0],
            ["Weekly Active Rate %", metrics.weekly_active_rate_percent ?? 0],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
            ["Handover Views", metrics.handover_brief_views ?? 0],
            ["Handover Days", metrics.handover_days_covered ?? 0],
            ["Cadence Adherence %", metrics.cadence_adherence_percent ?? 0],
            ["Overdue Open WOs", metrics.overdue_open_work_orders ?? 0],
            ["Active Tokens", metrics.active_tokens ?? 0],
            ["Expiring Tokens(7d)", metrics.tokens_expiring_7d ?? 0],
            ["Stale Tokens(14d)", metrics.tokens_stale_14d ?? 0],
            ["Users Without Token", metrics.users_without_active_token ?? 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          roleCoverage.innerHTML = renderTable(
            data.role_coverage || [],
            [
              {{ key: "role", label: "Role" }},
              {{ key: "user_count", label: "Users" }},
              {{ key: "active_user_count", label: "Active Users" }},
            ]
          );
          siteActivity.innerHTML = renderTable(
            data.site_activity || [],
            [
              {{ key: "site", label: "Site" }},
              {{ key: "activity_events", label: "Activity Events" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          roleCoverage.innerHTML = renderEmpty(err.message);
          siteActivity.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW07SlaQuality() {{
        const meta = document.getElementById("w07QualityMeta");
        const summary = document.getElementById("w07QualitySummary");
        const readinessCards = document.getElementById("w07AutomationReadiness");
        const topSites = document.getElementById("w07QualityTopSites");
        const recommendations = document.getElementById("w07QualityRecommendations");
        const site = (document.getElementById("w07QualitySite").value || "").trim();
        const daysRaw = (document.getElementById("w07QualityDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w07/sla-quality" + (params.toString() ? ("?" + params.toString()) : "");
        const readinessParams = new URLSearchParams();
        if (site) {{
          readinessParams.set("site", site);
        }}
        const readinessPath = "/api/ops/adoption/w07/automation-readiness"
          + (readinessParams.toString() ? ("?" + readinessParams.toString()) : "");
        try {{
          meta.textContent = " ... " + path;
          const [data, readiness] = await Promise.all([
            fetchJson(path, true),
            fetchJson(readinessPath, true).catch((err) => ({{ __error: err.message }})),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | ack_improvement=" + String(metrics.response_time_improvement_percent ?? "-") + "%";
          const summaryItems = [
            ["Created WOs", metrics.created_work_orders ?? 0],
            ["Acked WOs", metrics.acked_work_orders ?? 0],
            ["Completed WOs", metrics.completed_work_orders ?? 0],
            ["Median ACK(min)", metrics.median_ack_minutes ?? "-"],
            ["p90 ACK(min)", metrics.p90_ack_minutes ?? "-"],
            ["Baseline ACK(min)", metrics.baseline_median_ack_minutes ?? "-"],
            ["ACK Improvement %", metrics.response_time_improvement_percent ?? "-"],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
            ["Median MTTR(min)", metrics.median_mttr_minutes ?? "-"],
            ["SLA Violation %", metrics.sla_violation_rate_percent ?? 0],
            ["Open WOs", metrics.open_work_orders ?? 0],
            ["Overdue Open", metrics.overdue_open_work_orders ?? 0],
            ["Escalated Open", metrics.escalated_open_work_orders ?? 0],
            ["Escalation Rate %", metrics.escalation_rate_percent ?? 0],
            ["Alert Success %", metrics.alert_success_rate_percent ?? 0],
            ["DQ Gate", metrics.data_quality_gate_pass ? "PASS" : "FAIL"],
            ["DQ Issue %", metrics.data_quality_issue_rate_percent ?? 0],
            ["SLA Runs", metrics.sla_run_count ?? 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          if (readiness && !readiness.__error) {{
            const runtime = readiness.runtime || {{}};
            const integration = readiness.integration || {{}};
            const overallStatus = normalizeUiStatus(readiness.overall_status || "info");
            const latestRunStatus = normalizeUiStatus(
              runtime.latest_run_recent
                ? "ok"
                : (runtime.latest_run_at ? "warning" : "critical")
            );
            const webhookStatus = normalizeUiStatus(
              integration.webhook_configured ? "ok" : "warning"
            );
            const checkCount = Array.isArray(readiness.checks) ? readiness.checks.length : 0;
            readinessCards.innerHTML = [
              renderUiStatusCard(
                "Overall Status",
                overallStatus,
                uiStatusLabel(overallStatus),
                "  " + String(checkCount) + ""
              ),
              renderUiStatusCard(
                "  ",
                latestRunStatus,
                formatDateLocal(runtime.latest_run_at),
                runtime.latest_run_recent ? "8  " : "8     "
              ),
              renderUiStatusCard(
                "  ",
                webhookStatus,
                integration.webhook_configured ? "" : "",
                " " + String(integration.webhook_target_count || 0) + ""
              ),
            ].join("");
          }} else {{
            readinessCards.innerHTML = renderEmpty(
              "Automation Readiness  : " + String(readiness && readiness.__error ? readiness.__error : "unknown")
            );
          }}
          topSites.innerHTML = renderTable(
            data.top_risk_sites || [],
            [
              {{ key: "site", label: "Site" }},
              {{ key: "open_work_orders", label: "Open WOs" }},
              {{ key: "overdue_open_work_orders", label: "Overdue Open" }},
              {{ key: "escalated_open_work_orders", label: "Escalated Open" }},
              {{ key: "escalation_rate_percent", label: "Escalation %" }},
              {{ key: "sla_violation_rate_percent", label: "Violation %" }},
              {{ key: "median_ack_minutes", label: "Median ACK(min)" }},
              {{ key: "p90_ack_minutes", label: "p90 ACK(min)" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          readinessCards.innerHTML = renderEmpty(err.message);
          topSites.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW08ReportDiscipline() {{
        const meta = document.getElementById("w08DisciplineMeta");
        const summary = document.getElementById("w08DisciplineSummary");
        const topSites = document.getElementById("w08DisciplineTopSites");
        const benchmark = document.getElementById("w08DisciplineBenchmark");
        const recommendations = document.getElementById("w08DisciplineRecommendations");
        const site = (document.getElementById("w08DisciplineSite").value || "").trim();
        const daysRaw = (document.getElementById("w08DisciplineDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w08/report-discipline" + (params.toString() ? ("?" + params.toString()) : "");
        const benchmarkParams = new URLSearchParams();
        if (site) {{
          benchmarkParams.set("site", site);
        }}
        if (daysRaw) {{
          benchmarkParams.set("days", daysRaw);
        }}
        benchmarkParams.set("limit", "10");
        const benchmarkPath = "/api/ops/adoption/w08/site-benchmark?" + benchmarkParams.toString();
        try {{
          meta.textContent = " ... " + path;
          const [data, benchmarkData] = await Promise.all([
            fetchJson(path, true),
            fetchJson(benchmarkPath, true).catch((err) => ({{ __error: err.message }})),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | discipline_score=" + String(metrics.discipline_score ?? 0)
            + " | coverage=" + String(metrics.report_export_coverage_percent ?? 0) + "%";
          const summaryItems = [
            ["Site Count", metrics.site_count ?? 0],
            ["Created WOs", metrics.work_orders_created ?? 0],
            ["Completed WOs", metrics.work_orders_completed ?? 0],
            ["Missing due_at", metrics.work_orders_missing_due_at ?? 0],
            ["Missing due_at %", metrics.missing_due_rate_percent ?? 0],
            ["Invalid Priority", metrics.invalid_priority_count ?? 0],
            ["Completed w/o TS", metrics.completed_without_completed_at_count ?? 0],
            ["Overdue Open", metrics.open_overdue_count ?? 0],
            ["Overdue Rate %", metrics.overdue_rate_percent ?? 0],
            ["SLA Violation %", metrics.sla_violation_rate_percent ?? 0],
            ["DQ Issue %", metrics.data_quality_issue_rate_percent ?? 0],
            ["Inspections", metrics.inspections_created ?? 0],
            ["High Risk Inspections", metrics.inspections_high_risk ?? 0],
            ["Report Exports", metrics.report_export_count ?? 0],
            ["Report Coverage %", metrics.report_export_coverage_percent ?? 0],
            ["Discipline Score", metrics.discipline_score ?? 0],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          topSites.innerHTML = renderTable(
            data.top_risk_sites || [],
            [
              {{ key: "site", label: "Site" }},
              {{ key: "risk_score", label: "Risk Score" }},
              {{ key: "discipline_score", label: "Discipline Score" }},
              {{ key: "missing_due_rate_percent", label: "Missing due %" }},
              {{ key: "overdue_rate_percent", label: "Overdue %" }},
              {{ key: "sla_violation_rate_percent", label: "Violation %" }},
              {{ key: "report_export_coverage_percent", label: "Coverage %" }},
            ]
          );
          const benchmarkItems = benchmarkData && !benchmarkData.__error
            ? (benchmarkData.items || [])
            : (data.site_benchmark || []);
          benchmark.innerHTML = renderTable(
            benchmarkItems,
            [
              {{ key: "site", label: "Site" }},
              {{ key: "discipline_score", label: "Discipline Score" }},
              {{ key: "risk_score", label: "Risk Score" }},
              {{ key: "work_orders_created", label: "Created WOs" }},
              {{ key: "data_quality_issue_rate_percent", label: "DQ Issue %" }},
              {{ key: "report_export_count", label: "Export Count" }},
              {{ key: "report_export_last_at", label: "Last Export At" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          topSites.innerHTML = renderEmpty(err.message);
          benchmark.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW09KpiOperation() {{
        const meta = document.getElementById("w09KpiMeta");
        const summary = document.getElementById("w09KpiSummary");
        const kpiTable = document.getElementById("w09KpiTable");
        const escalationTable = document.getElementById("w09EscalationTable");
        const recommendations = document.getElementById("w09KpiRecommendations");
        const policyMeta = document.getElementById("w09PolicyMeta");
        const policyTable = document.getElementById("w09PolicyTable");
        const site = (document.getElementById("w09KpiSite").value || "").trim();
        const daysRaw = (document.getElementById("w09KpiDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w09/kpi-operation" + (params.toString() ? ("?" + params.toString()) : "");
        const policyPath = site
          ? "/api/ops/adoption/w09/kpi-policy?site=" + encodeURIComponent(site)
          : "";
        try {{
          meta.textContent = " .. " + path;
          if (policyPath) {{
            policyMeta.textContent = " .. " + policyPath;
          }} else {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }}
          const [data, policyPayload] = await Promise.all([
            fetchJson(path, true),
            policyPath
              ? fetchJson(policyPath, true).catch((err) => ({{ __error: err.message }}))
              : Promise.resolve({{ __skipped: true }}),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | overall=" + String(metrics.overall_status || "-")
            + " | red=" + String(metrics.red_count || 0)
            + " | yellow=" + String(metrics.yellow_count || 0)
            + " | green=" + String(metrics.green_count || 0);
          const summaryItems = [
            ["KPI Count", metrics.kpi_count ?? 0],
            ["Owner Assigned", metrics.owner_assigned_count ?? 0],
            ["Owner Coverage %", metrics.owner_coverage_percent ?? 0],
            ["Overall Status", metrics.overall_status || "-"],
            ["Green", metrics.green_count ?? 0],
            ["Yellow", metrics.yellow_count ?? 0],
            ["Red", metrics.red_count ?? 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          kpiTable.innerHTML = renderTable(
            data.kpis || [],
            [
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "actual_value", label: "Actual" }},
              {{ key: "target", label: "Target" }},
              {{ key: "green_threshold", label: "Green" }},
              {{ key: "yellow_threshold", label: "Yellow" }},
              {{ key: "status", label: "Status" }},
              {{ key: "source_api", label: "Source API" }},
            ]
          );
          escalationTable.innerHTML = renderTable(
            data.escalation_candidates || [],
            [
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "actual_value", label: "Actual" }},
              {{ key: "condition", label: "Condition" }},
              {{ key: "escalate_to", label: "Escalate To" }},
              {{ key: "sla_hours", label: "SLA Hours" }},
              {{ key: "action", label: "Action" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
          if (policyPayload && !policyPayload.__error && !policyPayload.__skipped) {{
            const policy = policyPayload.policy || {{}};
            policyMeta.textContent =
              ": key=" + String(policyPayload.policy_key || "-")
              + " | site=" + String(policyPayload.site || "default")
              + " | updated_at=" + String(policyPayload.updated_at || "-");
            policyTable.innerHTML = renderTable(
              policy.kpis || [],
              [
                {{ key: "kpi_key", label: "KPI Key" }},
                {{ key: "kpi_name", label: "KPI Name" }},
                {{ key: "owner_role", label: "Owner Role" }},
                {{ key: "direction", label: "Direction" }},
                {{ key: "green_threshold", label: "Green" }},
                {{ key: "yellow_threshold", label: "Yellow" }},
                {{ key: "target", label: "Target" }},
              ]
            );
          }} else if (policyPayload && policyPayload.__error) {{
            policyMeta.textContent = "  : " + String(policyPayload.__error);
            policyTable.innerHTML = renderEmpty(String(policyPayload.__error));
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          kpiTable.innerHTML = renderEmpty(err.message);
          escalationTable.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
          if (!site) {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }} else {{
            policyMeta.textContent = ": " + err.message;
            policyTable.innerHTML = renderEmpty(err.message);
          }}
        }}
      }}

      function buildSharedTrackerConfig(phaseCode, phaseLabel) {{
        return {{
          phaseCode: phaseCode,
          phaseLabel: phaseLabel,
          apiBase: "/api/adoption/" + phaseCode + "/tracker",
          evidenceNamespace: phaseCode,
          ids: {{
            site: phaseCode + "TrackSite",
            trackerItemId: phaseCode + "TrackItemId",
            assignee: phaseCode + "TrackAssignee",
            status: phaseCode + "TrackStatus",
            completionChecked: phaseCode + "TrackCompleted",
            trackerNote: phaseCode + "TrackNote",
            evidenceFile: phaseCode + "EvidenceFile",
            evidenceNote: phaseCode + "EvidenceNote",
            evidenceListItemId: phaseCode + "EvidenceListItemId",
            completionNote: phaseCode + "CompletionNote",
            completionForce: phaseCode + "CompletionForce",
            trackerMeta: phaseCode + "TrackerMeta",
            trackerSummary: phaseCode + "TrackerSummary",
            trackerTable: phaseCode + "TrackerTable",
            readinessMeta: phaseCode + "ReadinessMeta",
            readinessCards: phaseCode + "ReadinessCards",
            readinessBlockers: phaseCode + "ReadinessBlockers",
            evidenceTable: phaseCode + "EvidenceTable",
          }},
        }};
      }}

      const SHARED_TRACKER_CONFIGS = {{
        w09: buildSharedTrackerConfig("w09", "W09"),
        w10: buildSharedTrackerConfig("w10", "W10"),
        w11: buildSharedTrackerConfig("w11", "W11"),
        w15: buildSharedTrackerConfig("w15", "W15"),
      }};

      const SHARED_TRACKER_ITEM_COLUMNS = [
        {{ key: "id", label: "ID" }},
        {{ key: "item_type", label: "Type" }},
        {{ key: "item_key", label: "Key" }},
        {{ key: "item_name", label: "Name" }},
        {{ key: "assignee", label: "Assignee" }},
        {{ key: "status", label: "Status" }},
        {{ key: "completion_checked", label: "Checked" }},
        {{ key: "evidence_count", label: "Evidence" }},
        {{ key: "updated_at", label: "Updated At" }},
      ];

      function getSharedTrackerConfig(phaseCode) {{
        const config = SHARED_TRACKER_CONFIGS[phaseCode];
        if (!config) {{
          throw new Error("Unknown shared tracker phase: " + String(phaseCode));
        }}
        return config;
      }}

      function getSharedTrackerElements(config) {{
        return {{
          meta: document.getElementById(config.ids.trackerMeta),
          summary: document.getElementById(config.ids.trackerSummary),
          table: document.getElementById(config.ids.trackerTable),
          readinessMeta: document.getElementById(config.ids.readinessMeta),
          readinessCards: document.getElementById(config.ids.readinessCards),
          readinessBlockers: document.getElementById(config.ids.readinessBlockers),
          evidenceTable: document.getElementById(config.ids.evidenceTable),
        }};
      }}

      function setSharedTrackerAuthRequired(config) {{
        const el = getSharedTrackerElements(config);
        el.meta.textContent = "   " + config.phaseLabel + " tracker API   .";
        el.summary.innerHTML = "";
        el.table.innerHTML = renderEmpty("  ");
        el.readinessMeta.textContent = "     API   .";
        el.readinessCards.innerHTML = "";
        el.readinessBlockers.innerHTML = renderEmpty("  ");
        el.evidenceTable.innerHTML = renderEmpty("  ");
      }}

      function setSharedTrackerError(config, message) {{
        const el = getSharedTrackerElements(config);
        el.meta.textContent = ": " + message;
        el.summary.innerHTML = "";
        el.table.innerHTML = renderEmpty(message);
        el.readinessMeta.textContent = ": " + message;
        el.readinessCards.innerHTML = "";
        el.readinessBlockers.innerHTML = renderEmpty(message);
        el.evidenceTable.innerHTML = renderEmpty(message);
      }}

      function setSharedTrackerSiteDefault(config, siteValue = "HQ") {{
        const node = document.getElementById(config.ids.site);
        if (node && !node.value) {{
          node.value = siteValue;
        }}
      }}

      async function runSharedTracker(config) {{
        const el = getSharedTrackerElements(config);
        const site = (document.getElementById(config.ids.site).value || "").trim();
        if (!site) {{
          el.meta.textContent = "site  ";
          el.summary.innerHTML = "";
          el.table.innerHTML = renderEmpty("site  .");
          el.readinessMeta.textContent = "site  ";
          el.readinessCards.innerHTML = "";
          el.readinessBlockers.innerHTML = renderEmpty("site  .");
          el.evidenceTable.innerHTML = renderEmpty("site  .");
          return;
        }}
        try {{
          el.meta.textContent = " .. " + config.phaseLabel + " tracker";
          el.readinessMeta.textContent = " .. " + config.phaseLabel + " readiness";
          const [trackerOverview, trackerItems, readiness, completion] = await Promise.all([
            fetchJson(config.apiBase + "/overview?site=" + encodeURIComponent(site), true),
            fetchJson(config.apiBase + "/items?site=" + encodeURIComponent(site) + "&limit=500", true),
            fetchJson(config.apiBase + "/readiness?site=" + encodeURIComponent(site), true),
            fetchJson(config.apiBase + "/completion?site=" + encodeURIComponent(site), true),
          ]);
          el.meta.textContent = ": " + config.phaseLabel + " tracker (" + site + ")";
          el.readinessMeta.textContent =
            ": " + String(completion.status || "active")
            + " | ready=" + (readiness.ready ? "YES" : "NO")
            + " |  =" + String(readiness.checked_at || "-");
          const summaryItems = [
            ["Total", trackerOverview.total_items || 0],
            ["Pending", trackerOverview.pending_count || 0],
            ["In Progress", trackerOverview.in_progress_count || 0],
            ["Done", trackerOverview.done_count || 0],
            ["Blocked", trackerOverview.blocked_count || 0],
            ["Completion %", trackerOverview.completion_rate_percent || 0],
            ["Evidence", trackerOverview.evidence_total_count || 0],
          ];
          el.summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const readinessItems = [
            ["Readiness Ready", readiness.ready ? "YES" : "NO"],
            ["Readiness %", readiness.readiness_score_percent || 0],
            ["Missing Assignee", readiness.missing_assignee_count || 0],
            ["Missing Checked", readiness.missing_completion_checked_count || 0],
            ["Missing Evidence", readiness.missing_required_evidence_count || 0],
            ["Completion Status", completion.status || "active"],
            ["Completed At", completion.completed_at || "-"],
            ["Completed By", completion.completed_by || "-"],
          ];
          el.readinessCards.innerHTML = readinessItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          const blockers = Array.isArray(readiness.blockers) ? readiness.blockers : [];
          if (blockers.length > 0) {{
            el.readinessBlockers.innerHTML = (
              '<div class="table-wrap"><table><thead><tr><th>#</th><th>Blocker</th></tr></thead><tbody>'
              + blockers.map((item, idx) => (
                "<tr><td>" + escapeHtml(idx + 1) + "</td><td>" + escapeHtml(item) + "</td></tr>"
              )).join("")
              + "</tbody></table></div>"
            );
          }} else {{
            el.readinessBlockers.innerHTML = renderEmpty("  ");
          }}
          el.table.innerHTML = renderTable(trackerItems || [], SHARED_TRACKER_ITEM_COLUMNS);

          let evidenceItemId = (document.getElementById(config.ids.evidenceListItemId).value || "").trim();
          if (!evidenceItemId) {{
            evidenceItemId = (document.getElementById(config.ids.trackerItemId).value || "").trim();
          }}
          if (evidenceItemId) {{
            const evidences = await fetchJson(
              config.apiBase + "/items/" + encodeURIComponent(evidenceItemId) + "/evidence",
              true
            );
            el.evidenceTable.innerHTML = renderEvidenceTable(evidences || [], config.evidenceNamespace);
          }} else {{
            el.evidenceTable.innerHTML = renderEmpty("tracker_item_id      .");
          }}
        }} catch (err) {{
          setSharedTrackerError(config, err.message);
        }}
      }}

      async function runSharedTrackerBootstrap(config) {{
        const meta = document.getElementById(config.ids.trackerMeta);
        const site = (document.getElementById(config.ids.site).value || "").trim();
        if (!site) {{
          meta.textContent = "site  ";
          return;
        }}
        try {{
          meta.textContent = " .. " + config.phaseLabel + " tracker bootstrap";
          const data = await fetchJson(
            config.apiBase + "/bootstrap",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify({{ site }}),
            }}
          );
          meta.textContent = ":  " + String(data.created_count || 0) + "";
          await runSharedTracker(config);
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runSharedTrackerComplete(config) {{
        const meta = document.getElementById(config.ids.readinessMeta);
        const site = (document.getElementById(config.ids.site).value || "").trim();
        if (!site) {{
          meta.textContent = "site  ";
          return;
        }}
        const completionNote = (document.getElementById(config.ids.completionNote).value || "").trim();
        const force = !!document.getElementById(config.ids.completionForce).checked;
        const payload = {{
          site: site,
          force: force,
        }};
        if (completionNote) {{
          payload.completion_note = completionNote;
        }}
        try {{
          meta.textContent = " .. " + config.phaseLabel + "  ";
          const result = await fetchJson(
            config.apiBase + "/complete",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify(payload),
            }}
          );
          meta.textContent =
            ": status=" + String(result.status || "-")
            + " | ready=" + String(result.readiness && result.readiness.ready ? "YES" : "NO")
            + " | completed_at=" + String(result.completed_at || "-");
          await runSharedTracker(config);
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          await runSharedTracker(config).catch(() => null);
        }}
      }}

      async function runSharedTrackerUpdateAndUpload(config) {{
        const meta = document.getElementById(config.ids.trackerMeta);
        const trackerItemIdRaw = (document.getElementById(config.ids.trackerItemId).value || "").trim();
        const trackerItemId = Number(trackerItemIdRaw);
        if (!trackerItemIdRaw || !Number.isFinite(trackerItemId) || trackerItemId <= 0) {{
          meta.textContent = " tracker_item_id .";
          return;
        }}

        const assignee = (document.getElementById(config.ids.assignee).value || "").trim();
        const status = (document.getElementById(config.ids.status).value || "").trim();
        const completionChecked = !!document.getElementById(config.ids.completionChecked).checked;
        const note = (document.getElementById(config.ids.trackerNote).value || "").trim();
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (completionChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (note) payload.completion_note = note;
        const fileInput = document.getElementById(config.ids.evidenceFile);
        const file = fileInput && fileInput.files ? fileInput.files[0] : null;
        const hasTrackerUpdate = Object.keys(payload).length > 0;
        if (!hasTrackerUpdate && !file) {{
          meta.textContent = "     .";
          return;
        }}

        try {{
          meta.textContent = " .. tracker update";
          if (hasTrackerUpdate) {{
            await fetchJson(
              config.apiBase + "/items/" + encodeURIComponent(trackerItemIdRaw),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
          }}

          if (file) {{
            const formData = new FormData();
            formData.append("file", file);
            const evidenceNote = (document.getElementById(config.ids.evidenceNote).value || "").trim();
            formData.append("note", evidenceNote);
            const token = getToken();
            if (!token) {{
              throw new Error("  .");
            }}
            const uploadResp = await fetch(
              config.apiBase + "/items/" + encodeURIComponent(trackerItemIdRaw) + "/evidence",
              {{
                method: "POST",
                headers: {{
                  "X-Admin-Token": token,
                  "Accept": "application/json",
                }},
                body: formData,
              }}
            );
            const uploadText = await uploadResp.text();
            if (!uploadResp.ok) {{
              throw new Error("Evidence upload failed: HTTP " + uploadResp.status + " | " + uploadText);
            }}
            fileInput.value = "";
          }}

          meta.textContent = ": tracker  ";
          await runSharedTracker(config);
        }} catch (err) {{
          meta.textContent = ": " + err.message;
        }}
      }}

      async function runW09Tracker() {{
        await runSharedTracker(getSharedTrackerConfig("w09"));
      }}

      async function runW09Readiness() {{
        await runW09Tracker();
      }}

      async function runW09TrackerBootstrap() {{
        await runSharedTrackerBootstrap(getSharedTrackerConfig("w09"));
      }}

      async function runW09Complete() {{
        await runSharedTrackerComplete(getSharedTrackerConfig("w09"));
      }}

      async function runW09TrackerUpdateAndUpload() {{
        await runSharedTrackerUpdateAndUpload(getSharedTrackerConfig("w09"));
      }}

      async function runW10KpiOperation() {{
        const meta = document.getElementById("w10KpiMeta");
        const summary = document.getElementById("w10KpiSummary");
        const kpiTable = document.getElementById("w10KpiTable");
        const escalationTable = document.getElementById("w10EscalationTable");
        const recommendations = document.getElementById("w10KpiRecommendations");
        const policyMeta = document.getElementById("w10PolicyMeta");
        const policyTable = document.getElementById("w10PolicyTable");
        const site = (document.getElementById("w10KpiSite").value || "").trim();
        const daysRaw = (document.getElementById("w10KpiDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w10/self-serve" + (params.toString() ? ("?" + params.toString()) : "");
        const policyPath = site
          ? "/api/ops/adoption/w10/support-policy?site=" + encodeURIComponent(site)
          : "";
        try {{
          meta.textContent = " .. " + path;
          if (policyPath) {{
            policyMeta.textContent = " .. " + policyPath;
          }} else {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }}
          const [data, policyPayload] = await Promise.all([
            fetchJson(path, true),
            policyPath
              ? fetchJson(policyPath, true).catch((err) => ({{ __error: err.message }}))
              : Promise.resolve({{ __skipped: true }}),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | overall=" + String(metrics.overall_status || "-")
            + " | repeat_rate=" + String(metrics.repeat_rate_percent ?? 0) + "%"
            + " | readiness=" + String(metrics.self_serve_readiness_score ?? 0);
          const summaryItems = [
            ["WO Count", metrics.work_orders_count ?? 0],
            ["Unique Titles", metrics.unique_titles ?? 0],
            ["Repeat WOs", metrics.repeated_work_orders_count ?? 0],
            ["Repeat Rate %", metrics.repeat_rate_percent ?? 0],
            ["Guide Publish %", metrics.guide_publish_rate_percent ?? 0],
            ["Runbook Completion %", metrics.runbook_completion_rate_percent ?? 0],
            ["Readiness Score", metrics.self_serve_readiness_score ?? 0],
            ["Overall Status", metrics.overall_status || "-"],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          kpiTable.innerHTML = renderTable(
            data.kpis || [],
            [
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "actual_value", label: "Actual" }},
              {{ key: "target", label: "Target" }},
              {{ key: "green_threshold", label: "Green" }},
              {{ key: "yellow_threshold", label: "Yellow" }},
              {{ key: "status", label: "Status" }},
            ]
          );
          escalationTable.innerHTML = renderTable(
            data.top_repeat_titles || [],
            [
              {{ key: "title", label: "Title" }},
              {{ key: "count", label: "Count" }},
              {{ key: "share_percent", label: "Share %" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
          if (policyPayload && !policyPayload.__error && !policyPayload.__skipped) {{
            const policy = policyPayload.policy || {{}};
            policyMeta.textContent =
              ": key=" + String(policyPayload.policy_key || "-")
              + " | site=" + String(policyPayload.site || "default")
              + " | updated_at=" + String(policyPayload.updated_at || "-");
            policyTable.innerHTML = renderTable(
              [policy],
              [
                {{ key: "repeat_rate_green_threshold", label: "Repeat Green <= %" }},
                {{ key: "repeat_rate_yellow_threshold", label: "Repeat Yellow <= %" }},
                {{ key: "guide_publish_green_threshold", label: "Guide Green >= %" }},
                {{ key: "guide_publish_yellow_threshold", label: "Guide Yellow >= %" }},
                {{ key: "runbook_completion_green_threshold", label: "Runbook Green >= %" }},
                {{ key: "runbook_completion_yellow_threshold", label: "Runbook Yellow >= %" }},
                {{ key: "readiness_target", label: "Readiness Target" }},
                {{ key: "enabled", label: "Enabled" }},
              ]
            );
          }} else if (policyPayload && policyPayload.__error) {{
            policyMeta.textContent = "  : " + String(policyPayload.__error);
            policyTable.innerHTML = renderEmpty(String(policyPayload.__error));
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          kpiTable.innerHTML = renderEmpty(err.message);
          escalationTable.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
          if (!site) {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }} else {{
            policyMeta.textContent = ": " + err.message;
            policyTable.innerHTML = renderEmpty(err.message);
          }}
        }}
      }}

      async function runW10Tracker() {{
        await runSharedTracker(getSharedTrackerConfig("w10"));
      }}

      async function runW10Readiness() {{
        await runW10Tracker();
      }}

      async function runW10TrackerBootstrap() {{
        await runSharedTrackerBootstrap(getSharedTrackerConfig("w10"));
      }}

      async function runW10Complete() {{
        await runSharedTrackerComplete(getSharedTrackerConfig("w10"));
      }}

      async function runW10TrackerUpdateAndUpload() {{
        await runSharedTrackerUpdateAndUpload(getSharedTrackerConfig("w10"));
      }}

      async function runW11KpiOperation() {{
        const meta = document.getElementById("w11KpiMeta");
        const summary = document.getElementById("w11KpiSummary");
        const kpiTable = document.getElementById("w11KpiTable");
        const escalationTable = document.getElementById("w11EscalationTable");
        const recommendations = document.getElementById("w11KpiRecommendations");
        const policyMeta = document.getElementById("w11PolicyMeta");
        const policyTable = document.getElementById("w11PolicyTable");
        const site = (document.getElementById("w11KpiSite").value || "").trim();
        const daysRaw = (document.getElementById("w11KpiDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w11/scale-readiness" + (params.toString() ? ("?" + params.toString()) : "");
        const policyPath = site
          ? "/api/ops/adoption/w11/readiness-policy?site=" + encodeURIComponent(site)
          : "";
        try {{
          meta.textContent = " .. " + path;
          if (policyPath) {{
            policyMeta.textContent = " .. " + policyPath;
          }} else {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }}
          const [data, policyPayload] = await Promise.all([
            fetchJson(path, true),
            policyPath
              ? fetchJson(policyPath, true).catch((err) => ({{ __error: err.message }}))
              : Promise.resolve({{ __skipped: true }}),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | overall=" + String(metrics.overall_status || "-")
            + " | repeat_rate=" + String(metrics.repeat_rate_percent ?? 0) + "%"
            + " | readiness=" + String(metrics.self_serve_readiness_score ?? 0);
          const summaryItems = [
            ["WO Count", metrics.work_orders_count ?? 0],
            ["Unique Titles", metrics.unique_titles ?? 0],
            ["Repeat WOs", metrics.repeated_work_orders_count ?? 0],
            ["Repeat Rate %", metrics.repeat_rate_percent ?? 0],
            ["Guide Publish %", metrics.guide_publish_rate_percent ?? 0],
            ["Runbook Completion %", metrics.runbook_completion_rate_percent ?? 0],
            ["Readiness Score", metrics.self_serve_readiness_score ?? 0],
            ["Overall Status", metrics.overall_status || "-"],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          kpiTable.innerHTML = renderTable(
            data.kpis || [],
            [
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "actual_value", label: "Actual" }},
              {{ key: "target", label: "Target" }},
              {{ key: "green_threshold", label: "Green" }},
              {{ key: "yellow_threshold", label: "Yellow" }},
              {{ key: "status", label: "Status" }},
            ]
          );
          escalationTable.innerHTML = renderTable(
            data.top_repeat_titles || [],
            [
              {{ key: "title", label: "Title" }},
              {{ key: "count", label: "Count" }},
              {{ key: "share_percent", label: "Share %" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
          if (policyPayload && !policyPayload.__error && !policyPayload.__skipped) {{
            const policy = policyPayload.policy || {{}};
            policyMeta.textContent =
              ": key=" + String(policyPayload.policy_key || "-")
              + " | site=" + String(policyPayload.site || "default")
              + " | updated_at=" + String(policyPayload.updated_at || "-");
            policyTable.innerHTML = renderTable(
              [policy],
              [
                {{ key: "repeat_rate_green_threshold", label: "Repeat Green <= %" }},
                {{ key: "repeat_rate_yellow_threshold", label: "Repeat Yellow <= %" }},
                {{ key: "guide_publish_green_threshold", label: "Guide Green >= %" }},
                {{ key: "guide_publish_yellow_threshold", label: "Guide Yellow >= %" }},
                {{ key: "runbook_completion_green_threshold", label: "Runbook Green >= %" }},
                {{ key: "runbook_completion_yellow_threshold", label: "Runbook Yellow >= %" }},
                {{ key: "readiness_target", label: "Readiness Target" }},
                {{ key: "enabled", label: "Enabled" }},
              ]
            );
          }} else if (policyPayload && policyPayload.__error) {{
            policyMeta.textContent = "  : " + String(policyPayload.__error);
            policyTable.innerHTML = renderEmpty(String(policyPayload.__error));
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          kpiTable.innerHTML = renderEmpty(err.message);
          escalationTable.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
          if (!site) {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }} else {{
            policyMeta.textContent = ": " + err.message;
            policyTable.innerHTML = renderEmpty(err.message);
          }}
        }}
      }}

      async function runW11Tracker() {{
        await runSharedTracker(getSharedTrackerConfig("w11"));
      }}

      async function runW11Readiness() {{
        await runW11Tracker();
      }}

      async function runW11TrackerBootstrap() {{
        await runSharedTrackerBootstrap(getSharedTrackerConfig("w11"));
      }}

      async function runW11Complete() {{
        await runSharedTrackerComplete(getSharedTrackerConfig("w11"));
      }}

      async function runW11TrackerUpdateAndUpload() {{
        await runSharedTrackerUpdateAndUpload(getSharedTrackerConfig("w11"));
      }}

      async function runW15KpiOperation() {{
        const meta = document.getElementById("w15KpiMeta");
        const summary = document.getElementById("w15KpiSummary");
        const kpiTable = document.getElementById("w15KpiTable");
        const escalationTable = document.getElementById("w15EscalationTable");
        const recommendations = document.getElementById("w15KpiRecommendations");
        const policyMeta = document.getElementById("w15PolicyMeta");
        const policyTable = document.getElementById("w15PolicyTable");
        const site = (document.getElementById("w15KpiSite").value || "").trim();
        const daysRaw = (document.getElementById("w15KpiDays").value || "").trim();
        const params = new URLSearchParams();
        if (site) {{
          params.set("site", site);
        }}
        if (daysRaw) {{
          params.set("days", daysRaw);
        }}
        const path = "/api/ops/adoption/w15/ops-efficiency" + (params.toString() ? ("?" + params.toString()) : "");
        const policyPath = site
          ? "/api/ops/adoption/w15/efficiency-policy?site=" + encodeURIComponent(site)
          : "";
        try {{
          meta.textContent = " .. " + path;
          if (policyPath) {{
            policyMeta.textContent = " .. " + policyPath;
          }} else {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }}
          const [data, policyPayload] = await Promise.all([
            fetchJson(path, true),
            policyPath
              ? fetchJson(policyPath, true).catch((err) => ({{ __error: err.message }}))
              : Promise.resolve({{ __skipped: true }}),
          ]);
          const metrics = data.metrics || {{}};
          meta.textContent =
            ": site=" + String(data.site || "ALL")
            + " | window_days=" + String(data.window_days || "-")
            + " | overall=" + String(metrics.overall_status || "-")
            + " | repeat_rate=" + String(metrics.incident_repeat_rate_percent ?? 0) + "%"
            + " | readiness=" + String(metrics.ops_efficiency_readiness_score ?? 0);
          const summaryItems = [
            ["Incidents", metrics.incidents_count ?? 0],
            ["Unique Titles", metrics.unique_titles ?? 0],
            ["Repeated Incidents", metrics.repeated_incidents_count ?? 0],
            ["Repeat Rate %", metrics.incident_repeat_rate_percent ?? 0],
            ["Checklist %", metrics.checklist_completion_rate_percent ?? 0],
            ["Runbook %", metrics.simulation_success_rate_percent ?? 0],
            ["Readiness Score", metrics.ops_efficiency_readiness_score ?? 0],
            ["Overall Status", metrics.overall_status || "-"],
            ["Target Met", metrics.target_met ? "YES" : "NO"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          kpiTable.innerHTML = renderTable(
            data.kpis || [],
            [
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "actual_value", label: "Actual" }},
              {{ key: "target", label: "Target" }},
              {{ key: "green_threshold", label: "Green" }},
              {{ key: "yellow_threshold", label: "Yellow" }},
              {{ key: "status", label: "Status" }},
            ]
          );
          escalationTable.innerHTML = renderTable(
            data.top_repeat_incidents || [],
            [
              {{ key: "title", label: "Title" }},
              {{ key: "count", label: "Count" }},
              {{ key: "share_percent", label: "Share %" }},
            ]
          );
          const recRows = Array.isArray(data.recommendations)
            ? data.recommendations.map((item, idx) => ({{
                no: idx + 1,
                recommendation: item,
              }}))
            : [];
          recommendations.innerHTML = renderTable(
            recRows,
            [
              {{ key: "no", label: "#" }},
              {{ key: "recommendation", label: "Recommendation" }},
            ]
          );
          if (policyPayload && !policyPayload.__error && !policyPayload.__skipped) {{
            const policy = policyPayload.policy || {{}};
            policyMeta.textContent =
              ": key=" + String(policyPayload.policy_key || "-")
              + " | site=" + String(policyPayload.site || "default")
              + " | updated_at=" + String(policyPayload.updated_at || "-");
            policyTable.innerHTML = renderTable(
              [policy],
              [
                {{ key: "risk_rate_green_threshold", label: "Risk Green <= %" }},
                {{ key: "risk_rate_yellow_threshold", label: "Risk Yellow <= %" }},
                {{ key: "checklist_completion_green_threshold", label: "Checklist Green >= %" }},
                {{ key: "checklist_completion_yellow_threshold", label: "Checklist Yellow >= %" }},
                {{ key: "simulation_success_green_threshold", label: "Simulation Green >= %" }},
                {{ key: "simulation_success_yellow_threshold", label: "Simulation Yellow >= %" }},
                {{ key: "readiness_target", label: "Readiness Target" }},
                {{ key: "enabled", label: "Enabled" }},
              ]
            );
          }} else if (policyPayload && policyPayload.__error) {{
            policyMeta.textContent = "  : " + String(policyPayload.__error);
            policyTable.innerHTML = renderEmpty(String(policyPayload.__error));
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          kpiTable.innerHTML = renderEmpty(err.message);
          escalationTable.innerHTML = renderEmpty(err.message);
          recommendations.innerHTML = renderEmpty(err.message);
          if (!site) {{
            policyMeta.textContent = "site     ";
            policyTable.innerHTML = renderEmpty("site    .");
          }} else {{
            policyMeta.textContent = ": " + err.message;
            policyTable.innerHTML = renderEmpty(err.message);
          }}
        }}
      }}

      async function runW15Tracker() {{
        await runSharedTracker(getSharedTrackerConfig("w15"));
      }}

      async function runW15Readiness() {{
        await runW15Tracker();
      }}

      async function runW15TrackerBootstrap() {{
        await runSharedTrackerBootstrap(getSharedTrackerConfig("w15"));
      }}

      async function runW15Complete() {{
        await runSharedTrackerComplete(getSharedTrackerConfig("w15"));
      }}

      async function runW15TrackerUpdateAndUpload() {{
        await runSharedTrackerUpdateAndUpload(getSharedTrackerConfig("w15"));
      }}

      async function runW07Tracker() {{
        const meta = document.getElementById("w07TrackerMeta");
        const summary = document.getElementById("w07TrackerSummary");
        const table = document.getElementById("w07TrackerTable");
        const readinessMeta = document.getElementById("w07ReadinessMeta");
        const readinessCards = document.getElementById("w07ReadinessCards");
        const readinessBlockers = document.getElementById("w07ReadinessBlockers");
        const evidenceTable = document.getElementById("w07EvidenceTable");
        const site = (document.getElementById("w07TrackSite").value || "").trim();
        if (!site) {{
          w07TrackerItemsCache = [];
          w07SelectedItemIds = new Set();
          w07ActiveItemId = null;
          w07LastReadiness = null;
          w07LastCompletion = null;
          meta.textContent = "site  .";
          summary.innerHTML = "";
          table.innerHTML = renderEmpty("site  .");
          readinessMeta.textContent = "site  .";
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty("site  .");
          evidenceTable.innerHTML = renderEmpty("site  .");
          renderW07SelectionMeta();
          renderW07ActionResultsPanel();
          return;
        }}
        try {{
          meta.textContent = " ... W07 tracker";
          readinessMeta.textContent = " ... W07 readiness";
          const [trackerOverview, trackerItems, readiness, completion] = await Promise.all([
            fetchJson("/api/adoption/w07/tracker/overview?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w07/tracker/items?site=" + encodeURIComponent(site) + "&limit=500", true),
            fetchJson("/api/adoption/w07/tracker/readiness?site=" + encodeURIComponent(site), true),
            fetchJson("/api/adoption/w07/tracker/completion?site=" + encodeURIComponent(site), true),
          ]);
          w07TrackerItemsCache = Array.isArray(trackerItems) ? trackerItems : [];
          w07LastReadiness = readiness;
          w07LastCompletion = completion;
          meta.textContent = ": W07 tracker (" + site + ")";
          readinessMeta.textContent =
            ": " + String(completion.status || "active")
            + " | ready=" + (readiness.ready ? "YES" : "NO")
            + " |  =" + String(readiness.checked_at || "-")
            + " | filter=" + getW07FilterLabel(w07TrackerFilter);
          const summaryItems = [
            ["Total", trackerOverview.total_items || 0],
            ["Pending", trackerOverview.pending_count || 0],
            ["In Progress", trackerOverview.in_progress_count || 0],
            ["Done", trackerOverview.done_count || 0],
            ["Blocked", trackerOverview.blocked_count || 0],
            ["Completion %", trackerOverview.completion_rate_percent || 0],
            ["Evidence", trackerOverview.evidence_total_count || 0],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          readinessCards.innerHTML = renderW07ReadinessCards(readiness, completion);
          const blockers = Array.isArray(readiness.blockers) ? readiness.blockers : [];
          if (blockers.length > 0) {{
            readinessBlockers.innerHTML = (
              '<div class="table-wrap"><table><thead><tr><th>#</th><th>Blocker</th></tr></thead><tbody>'
              + blockers.map((item, idx) => (
                "<tr><td>" + escapeHtml(idx + 1) + "</td><td>" + escapeHtml(item) + "</td></tr>"
              )).join("")
              + "</tbody></table></div>"
            );
          }} else {{
            readinessBlockers.innerHTML = renderEmpty("  ");
          }}
          if (w07ActiveItemId === null) {{
            const firstIncomplete = w07TrackerItemsCache.find((row) => isW07IncompleteRow(row));
            if (firstIncomplete) {{
              fillW07FormFromItem(firstIncomplete, {{ keepCurrentNote: true }});
            }}
          }} else {{
            const activeItem = getW07ItemById(w07ActiveItemId);
            if (activeItem) {{
              fillW07FormFromItem(activeItem, {{ keepCurrentNote: true }});
            }} else {{
              w07ActiveItemId = null;
            }}
          }}
          renderW07TrackerTablePanel();

          let evidenceItemId = (document.getElementById("w07EvidenceListItemId").value || "").trim();
          if (!evidenceItemId) {{
            evidenceItemId = (document.getElementById("w07TrackItemId").value || "").trim();
          }}
          if (evidenceItemId) {{
            const evidences = await fetchJson(
              "/api/adoption/w07/tracker/items/" + encodeURIComponent(evidenceItemId) + "/evidence",
              true
            );
            evidenceTable.innerHTML = renderEvidenceTable(evidences || [], "w07");
          }} else {{
            evidenceTable.innerHTML = renderEmpty("      tracker_item_id  .");
          }}
          renderW07ActionResultsPanel();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          table.innerHTML = renderEmpty(err.message);
          readinessMeta.textContent = ": " + err.message;
          readinessCards.innerHTML = "";
          readinessBlockers.innerHTML = renderEmpty(err.message);
          evidenceTable.innerHTML = renderEmpty(err.message);
          renderW07SelectionMeta();
          renderW07ActionResultsPanel();
        }}
      }}

      async function runW07Readiness() {{
        await runW07Tracker();
      }}

      async function runW07TrackerBootstrap() {{
        const meta = document.getElementById("w07TrackerMeta");
        const site = (document.getElementById("w07TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        try {{
          meta.textContent = " ... W07 tracker bootstrap";
          const data = await fetchJson(
            "/api/adoption/w07/tracker/bootstrap",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify({{ site }}),
            }}
          );
          meta.textContent = ":  " + String(data.created_count || 0) + "";
          pushW07ActionResult({{
            action: "bootstrap",
            tracker_item_id: "-",
            result: "ok",
            detail: "created=" + String(data.created_count || 0),
          }});
          renderW07ActionResultsPanel();
          await runW07Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          pushW07ActionResult({{
            action: "bootstrap",
            tracker_item_id: "-",
            result: "failed",
            detail: err.message,
          }});
          renderW07ActionResultsPanel();
        }}
      }}

      function runW07SelectVisible() {{
        const rows = getW07FilteredItems();
        rows.forEach((row) => {{
          const itemId = asInt(row.id, -1);
          if (itemId > 0) {{
            w07SelectedItemIds.add(itemId);
          }}
        }});
        renderW07TrackerTablePanel();
        document.getElementById("w07TrackerMeta").textContent =
          ":   " + String(rows.length) + " ";
      }}

      function runW07ClearSelection() {{
        w07SelectedItemIds = new Set();
        renderW07TrackerTablePanel();
        document.getElementById("w07TrackerMeta").textContent = "   .";
      }}

      function runW07NextIncomplete() {{
        const meta = document.getElementById("w07TrackerMeta");
        const picked = pickW07NextIncompleteItem();
        if (!picked) {{
          meta.textContent = "    .";
          return;
        }}
        meta.textContent =
          ": tracker_item_id=" + String(picked.id || "-")
          + " | status=" + String(picked.status || "-")
          + " | assignee=" + String(picked.assignee || "-");
      }}

      async function runW07BulkApply() {{
        const meta = document.getElementById("w07TrackerMeta");
        const selectedIds = Array.from(w07SelectedItemIds);
        if (selectedIds.length === 0) {{
          meta.textContent = "    .";
          return;
        }}
        const assignee = (document.getElementById("w07BulkAssignee").value || "").trim();
        const status = (document.getElementById("w07BulkStatus").value || "").trim();
        const bulkChecked = !!document.getElementById("w07BulkChecked").checked;
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (bulkChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (Object.keys(payload).length === 0) {{
          meta.textContent = "   . assignee/status/ .";
          return;
        }}
        let successCount = 0;
        let failedCount = 0;
        meta.textContent = "  ... " + String(selectedIds.length) + "";
        for (const itemId of selectedIds) {{
          try {{
            await fetchJson(
              "/api/adoption/w07/tracker/items/" + encodeURIComponent(String(itemId)),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
            successCount += 1;
            pushW07ActionResult({{
              action: "bulk_patch",
              tracker_item_id: String(itemId),
              result: "ok",
              detail: "saved",
            }});
          }} catch (err) {{
            failedCount += 1;
            pushW07ActionResult({{
              action: "bulk_patch",
              tracker_item_id: String(itemId),
              result: "failed",
              detail: err.message,
            }});
          }}
        }}
        renderW07ActionResultsPanel();
        meta.textContent =
          "  : success=" + String(successCount) + " | failed=" + String(failedCount);
        await runW07Tracker();
      }}

      async function runW07Complete(options = {{}}) {{
        const meta = document.getElementById("w07ReadinessMeta");
        const settings = Object.assign({{ triggerWeeklyAfterComplete: false }}, options || {{}});
        const site = (document.getElementById("w07TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        const completionNote = (document.getElementById("w07CompletionNote").value || "").trim();
        const force = !!document.getElementById("w07CompletionForce").checked;
        if (force && !completionNote) {{
          meta.textContent = " (force)  completion note  .";
          return;
        }}
        if (!w07LastReadiness || String(w07LastReadiness.site || "") !== site) {{
          await runW07Tracker();
        }}
        const readiness = w07LastReadiness || {{}};
        const completion = w07LastCompletion || {{}};
        const summaryLines = [
          "Site: " + site,
          " : " + String(completion.status || "active"),
          "Ready: " + String(readiness.ready ? "YES" : "NO"),
          "Pending/InProgress/Blocked: "
            + String(readiness.pending_count || 0) + "/"
            + String(readiness.in_progress_count || 0) + "/"
            + String(readiness.blocked_count || 0),
          "Missing Assignee/Checked/Evidence: "
            + String(readiness.missing_assignee_count || 0) + "/"
            + String(readiness.missing_completion_checked_count || 0) + "/"
            + String(readiness.missing_required_evidence_count || 0),
          "Completion Note: " + (completionNote || "-"),
          "Force: " + String(force),
        ];
        const confirmed = await openW07CompleteModal(summaryLines.join("\\n"));
        if (!confirmed) {{
          meta.textContent = ": W07   .";
          return;
        }}
        const payload = {{
          site: site,
          force: force,
        }};
        if (completionNote) {{
          payload.completion_note = completionNote;
        }}
        try {{
          meta.textContent = " ... W07  ";
          const result = await fetchJson(
            "/api/adoption/w07/tracker/complete",
            true,
            {{
              method: "POST",
              headers: {{ "Content-Type": "application/json" }},
              body: JSON.stringify(payload),
            }}
          );
          meta.textContent =
            ": status=" + String(result.status || "-")
            + " | ready=" + String(result.readiness && result.readiness.ready ? "YES" : "NO")
            + " | completed_at=" + String(result.completed_at || "-");
          pushW07ActionResult({{
            action: "complete_site",
            tracker_item_id: "-",
            result: "ok",
            detail: "status=" + String(result.status || "-"),
          }});
          if (settings.triggerWeeklyAfterComplete) {{
            const statusValue = String(result.status || "");
            if (!statusValue.startsWith("completed")) {{
              pushW07ActionResult({{
                action: "complete_then_weekly",
                tracker_item_id: "-",
                result: "skipped",
                detail: "status=" + statusValue + " (weekly skipped)",
              }});
              meta.textContent += " | :    ";
            }} else {{
              const weeklySiteInput = document.getElementById("w07WeeklySite");
              if (weeklySiteInput) {{
                weeklySiteInput.value = site;
              }}
              try {{
                const weeklyRunResult = await runW07WeeklyJob();
                if (!weeklyRunResult || weeklyRunResult.ok !== true) {{
                  throw new Error((weeklyRunResult && weeklyRunResult.error) || "weekly run failed");
                }}
                pushW07ActionResult({{
                  action: "complete_then_weekly",
                  tracker_item_id: "-",
                  result: "ok",
                  detail: "weekly run triggered",
                }});
                meta.textContent += " | : ";
              }} catch (weeklyErr) {{
                pushW07ActionResult({{
                  action: "complete_then_weekly",
                  tracker_item_id: "-",
                  result: "failed",
                  detail: weeklyErr.message || String(weeklyErr),
                }});
                meta.textContent += " | : ";
              }}
            }}
          }}
          renderW07ActionResultsPanel();
          await runW07Tracker();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          pushW07ActionResult({{
            action: "complete_site",
            tracker_item_id: "-",
            result: "failed",
            detail: err.message,
          }});
          renderW07ActionResultsPanel();
          await runW07Tracker().catch(() => null);
        }}
      }}

      async function runW07CompleteAndWeekly() {{
        await runW07Complete({{ triggerWeeklyAfterComplete: true }});
      }}

      async function runW07DownloadCompletionPackage() {{
        const meta = document.getElementById("w07TrackerMeta");
        const site = (document.getElementById("w07TrackSite").value || "").trim();
        if (!site) {{
          meta.textContent = "site  .";
          return;
        }}
        const includeEvidence = !!document.getElementById("w07PackageIncludeEvidence").checked;
        const includeWeekly = !!document.getElementById("w07PackageIncludeWeekly").checked;
        const weeklyLimitRaw = (document.getElementById("w07PackageWeeklyLimit").value || "").trim();
        const weeklyLimit = Math.max(1, Math.min(104, asInt(weeklyLimitRaw || "26", 26)));
        const params = new URLSearchParams();
        params.set("site", site);
        params.set("include_evidence", includeEvidence ? "true" : "false");
        params.set("include_weekly", includeWeekly ? "true" : "false");
        params.set("weekly_limit", String(weeklyLimit));
        const path = "/api/adoption/w07/tracker/completion-package?" + params.toString();
        try {{
          meta.textContent = "  ... " + path;
          const result = await downloadAuthFile(
            path,
            "ka-facility-os-w07-completion-package-" + site.replaceAll(" ", "_") + ".zip"
          );
          meta.textContent =
            ":    | file=" + String(result.fileName || "-")
            + " | bytes=" + String(result.size || 0)
            + " | sha256=" + String(result.sha256 || "-");
          pushW07ActionResult({{
            action: "completion_package_download",
            tracker_item_id: "-",
            result: "ok",
            detail: String(result.fileName || "downloaded"),
          }});
          renderW07ActionResultsPanel();
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          pushW07ActionResult({{
            action: "completion_package_download",
            tracker_item_id: "-",
            result: "failed",
            detail: err.message,
          }});
          renderW07ActionResultsPanel();
        }}
      }}

      async function runW07TrackerUpdateAndUpload() {{
        const meta = document.getElementById("w07TrackerMeta");
        const trackerItemIdRaw = (document.getElementById("w07TrackItemId").value || "").trim();
        const trackerItemId = Number(trackerItemIdRaw);
        if (!trackerItemIdRaw || !Number.isFinite(trackerItemId) || trackerItemId <= 0) {{
          meta.textContent = " tracker  . (ID  )";
          return;
        }}

        const assignee = (document.getElementById("w07TrackAssignee").value || "").trim();
        const status = (document.getElementById("w07TrackStatus").value || "").trim();
        const completionChecked = !!document.getElementById("w07TrackCompleted").checked;
        const note = (document.getElementById("w07TrackNote").value || "").trim();
        const payload = {{}};
        if (assignee) payload.assignee = assignee;
        if (status) payload.status = status;
        if (completionChecked) {{
          payload.completion_checked = true;
        }} else if (status && status !== "done") {{
          payload.completion_checked = false;
        }}
        if (note) payload.completion_note = note;
        const fileInput = document.getElementById("w07EvidenceFile");
        const file = fileInput && fileInput.files ? fileInput.files[0] : null;
        const hasTrackerUpdate = Object.keys(payload).length > 0;
        if (!hasTrackerUpdate && !file) {{
          meta.textContent = "     .";
          return;
        }}

        let successCount = 0;
        let failedCount = 0;
        meta.textContent = " ... tracker update";

        if (hasTrackerUpdate) {{
          try {{
            await fetchJson(
              "/api/adoption/w07/tracker/items/" + encodeURIComponent(trackerItemIdRaw),
              true,
              {{
                method: "PATCH",
                headers: {{ "Content-Type": "application/json" }},
                body: JSON.stringify(payload),
              }}
            );
            successCount += 1;
            pushW07ActionResult({{
              action: "single_patch",
              tracker_item_id: trackerItemIdRaw,
              result: "ok",
              detail: "saved",
            }});
          }} catch (err) {{
            failedCount += 1;
            pushW07ActionResult({{
              action: "single_patch",
              tracker_item_id: trackerItemIdRaw,
              result: "failed",
              detail: err.message,
            }});
          }}
        }}

        if (file) {{
          try {{
            const formData = new FormData();
            formData.append("file", file);
            const evidenceNote = (document.getElementById("w07EvidenceNote").value || "").trim();
            formData.append("note", evidenceNote);
            const token = getToken();
            if (!token) {{
              throw new Error("  .");
            }}
            const uploadResp = await fetch(
              "/api/adoption/w07/tracker/items/" + encodeURIComponent(trackerItemIdRaw) + "/evidence",
              {{
                method: "POST",
                headers: {{
                  "X-Admin-Token": token,
                  "Accept": "application/json",
                }},
                body: formData,
              }}
            );
            const uploadText = await uploadResp.text();
            if (!uploadResp.ok) {{
              throw new Error("Evidence upload failed: HTTP " + uploadResp.status + " | " + uploadText);
            }}
            document.getElementById("w07EvidenceFile").value = "";
            successCount += 1;
            pushW07ActionResult({{
              action: "evidence_upload",
              tracker_item_id: trackerItemIdRaw,
              result: "ok",
              detail: String(file.name || "uploaded"),
            }});
          }} catch (err) {{
            failedCount += 1;
            pushW07ActionResult({{
              action: "evidence_upload",
              tracker_item_id: trackerItemIdRaw,
              result: "failed",
              detail: err.message,
            }});
          }}
        }}

        renderW07ActionResultsPanel();
        meta.textContent =
          " : success=" + String(successCount) + " | failed=" + String(failedCount);
        await runW07Tracker();
      }}

      async function runW07WeeklyJob() {{
        const meta = document.getElementById("w07WeeklyMeta");
        const summary = document.getElementById("w07WeeklySummary");
        const latestTable = document.getElementById("w07WeeklyLatest");
        const site = (document.getElementById("w07WeeklySite").value || "").trim();
        const daysRaw = (document.getElementById("w07WeeklyDays").value || "").trim();
        const forceNotify = !!document.getElementById("w07WeeklyForceNotify").checked;
        const params = new URLSearchParams();
        if (site) params.set("site", site);
        if (daysRaw) params.set("days", daysRaw);
        if (forceNotify) params.set("force_notify", "true");
        try {{
          meta.textContent = " ... W07 weekly run";
          const data = await fetchJson(
            "/api/ops/adoption/w07/sla-quality/run-weekly" + (params.toString() ? ("?" + params.toString()) : ""),
            true,
            {{
              method: "POST",
            }}
          );
          const signals = (data.degradation && data.degradation.signals) || {{}};
          meta.textContent =
            ": run#" + String(data.run_id || "-")
            + " | status=" + String(data.status || "-")
            + " | degraded=" + String(data.degradation && data.degradation.degraded ? "YES" : "NO")
            + " | cooldown=" + String(data.cooldown_active ? ("ON(" + String(data.cooldown_remaining_minutes || 0) + "m)") : "OFF");
          const summaryItems = [
            ["Run ID", data.run_id || "-"],
            ["Site", data.site || "ALL"],
            ["Window Days", data.window_days || "-"],
            ["Degraded", data.degradation && data.degradation.degraded ? "YES" : "NO"],
            ["Escalation Rate %", signals.escalation_rate_percent ?? "-"],
            ["Alert Success %", signals.alert_success_rate_percent ?? "-"],
            ["SLA Violation %", signals.sla_violation_rate_percent ?? "-"],
            ["DQ Gate", signals.data_quality_gate_pass ? "PASS" : "FAIL"],
            ["Alert Attempted", data.alert_attempted ? "YES" : "NO"],
            ["Alert Dispatched", data.alert_dispatched ? "YES" : "NO"],
            ["Archive File", data.archive_file || "-"],
          ];
          summary.innerHTML = summaryItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");
          latestTable.innerHTML = renderTable(
            [{{ run_id: data.run_id, status: data.status, finished_at: data.finished_at, site: data.site || "ALL", degraded: !!(data.degradation && data.degradation.degraded), reasons: Array.isArray(data.degradation && data.degradation.reasons) ? data.degradation.reasons.join(" | ") : "" }}],
            [
              {{ key: "run_id", label: "Run ID" }},
              {{ key: "status", label: "Status" }},
              {{ key: "finished_at", label: "Finished At" }},
              {{ key: "site", label: "Site" }},
              {{ key: "degraded", label: "Degraded" }},
              {{ key: "reasons", label: "Reasons" }},
            ]
          );
          await runW07WeeklyLatest();
          await runW07WeeklyTrends();
          return {{ ok: true, data }};
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          summary.innerHTML = "";
          latestTable.innerHTML = renderEmpty(err.message);
          return {{ ok: false, error: err.message }};
        }}
      }}

      async function runW07WeeklyLatest() {{
        const meta = document.getElementById("w07WeeklyMeta");
        const latestTable = document.getElementById("w07WeeklyLatest");
        const site = (document.getElementById("w07WeeklySite").value || "").trim();
        const params = new URLSearchParams();
        if (site) params.set("site", site);
        const path = "/api/ops/adoption/w07/sla-quality/latest-weekly" + (params.toString() ? ("?" + params.toString()) : "");
        try {{
          const data = await fetchJson(path, true);
          meta.textContent =
            ": latest run#" + String(data.run_id || "-")
            + " | status=" + String(data.status || "-")
            + " | degraded=" + String(data.degradation && data.degradation.degraded ? "YES" : "NO");
          latestTable.innerHTML = renderTable(
            [{{ run_id: data.run_id, status: data.status, finished_at: data.finished_at, site: data.site || "ALL", degraded: !!(data.degradation && data.degradation.degraded), reasons: Array.isArray(data.degradation && data.degradation.reasons) ? data.degradation.reasons.join(" | ") : "" }}],
            [
              {{ key: "run_id", label: "Run ID" }},
              {{ key: "status", label: "Status" }},
              {{ key: "finished_at", label: "Finished At" }},
              {{ key: "site", label: "Site" }},
              {{ key: "degraded", label: "Degraded" }},
              {{ key: "reasons", label: "Reasons" }},
            ]
          );
        }} catch (err) {{
          latestTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runW07WeeklyTrends() {{
        const trendsTable = document.getElementById("w07WeeklyTrends");
        const site = (document.getElementById("w07WeeklySite").value || "").trim();
        const limitRaw = (document.getElementById("w07WeeklyLimit").value || "").trim();
        const params = new URLSearchParams();
        if (site) params.set("site", site);
        if (limitRaw) params.set("limit", limitRaw);
        const path = "/api/ops/adoption/w07/sla-quality/trends" + (params.toString() ? ("?" + params.toString()) : "");
        try {{
          const data = await fetchJson(path, true);
          trendsTable.innerHTML = renderTable(
            data.points || [],
            [
              {{ key: "run_id", label: "Run ID" }},
              {{ key: "finished_at", label: "Finished At" }},
              {{ key: "site", label: "Site" }},
              {{ key: "status", label: "Status" }},
              {{ key: "degraded", label: "Degraded" }},
              {{ key: "escalation_rate_percent", label: "Escalation %" }},
              {{ key: "alert_success_rate_percent", label: "Alert Success %" }},
              {{ key: "sla_violation_rate_percent", label: "Violation %" }},
              {{ key: "median_ack_minutes", label: "Median ACK(min)" }},
              {{ key: "p90_ack_minutes", label: "p90 ACK(min)" }},
              {{ key: "median_mttr_minutes", label: "Median MTTR(min)" }},
              {{ key: "data_quality_gate_pass", label: "DQ Gate" }},
            ]
          );
        }} catch (err) {{
          trendsTable.innerHTML = renderEmpty(err.message);
        }}
      }}

      async function runAdoption() {{
        const meta = document.getElementById("adoptionMeta");
        const top = document.getElementById("adoptionTop");
        const matrix = document.getElementById("adoptionWorkflowMatrix");
        const w02Top = document.getElementById("adoptionW02Top");
        const w02Sop = document.getElementById("adoptionW02Sop");
        const w02Sandbox = document.getElementById("adoptionW02Sandbox");
        const w02Schedule = document.getElementById("adoptionW02Schedule");
        const w03Top = document.getElementById("adoptionW03Top");
        const w03Kickoff = document.getElementById("adoptionW03Kickoff");
        const w03Workshops = document.getElementById("adoptionW03Workshops");
        const w03OfficeHours = document.getElementById("adoptionW03OfficeHours");
        const w03Schedule = document.getElementById("adoptionW03Schedule");
        const w04Top = document.getElementById("adoptionW04Top");
        const w04Actions = document.getElementById("adoptionW04Actions");
        const w04Schedule = document.getElementById("adoptionW04Schedule");
        const w04Mistakes = document.getElementById("adoptionW04Mistakes");
        const w05Top = document.getElementById("adoptionW05Top");
        const w05Missions = document.getElementById("adoptionW05Missions");
        const w05Schedule = document.getElementById("adoptionW05Schedule");
        const w05HelpDocs = document.getElementById("adoptionW05HelpDocs");
        const w06Top = document.getElementById("adoptionW06Top");
        const w06Checklist = document.getElementById("adoptionW06Checklist");
        const w06Schedule = document.getElementById("adoptionW06Schedule");
        const w06RbacAudit = document.getElementById("adoptionW06RbacAudit");
        const w07Top = document.getElementById("adoptionW07Top");
        const w07Checklist = document.getElementById("adoptionW07Checklist");
        const w07Coaching = document.getElementById("adoptionW07Coaching");
        const w07Schedule = document.getElementById("adoptionW07Schedule");
        const w08Top = document.getElementById("adoptionW08Top");
        const w08Checklist = document.getElementById("adoptionW08Checklist");
        const w08Quality = document.getElementById("adoptionW08Quality");
        const w08Schedule = document.getElementById("adoptionW08Schedule");
        const w09Top = document.getElementById("adoptionW09Top");
        const w09Thresholds = document.getElementById("adoptionW09Thresholds");
        const w09Escalation = document.getElementById("adoptionW09Escalation");
        const w09Schedule = document.getElementById("adoptionW09Schedule");
        const w10Top = document.getElementById("adoptionW10Top");
        const w10Guides = document.getElementById("adoptionW10Guides");
        const w10Runbook = document.getElementById("adoptionW10Runbook");
        const w10Schedule = document.getElementById("adoptionW10Schedule");
        const w11Top = document.getElementById("adoptionW11Top");
        const w11Guides = document.getElementById("adoptionW11Guides");
        const w11Runbook = document.getElementById("adoptionW11Runbook");
        const w11Schedule = document.getElementById("adoptionW11Schedule");
        const w15Top = document.getElementById("adoptionW15Top");
        const w15Guides = document.getElementById("adoptionW15Guides");
        const w15Runbook = document.getElementById("adoptionW15Runbook");
        const w15Schedule = document.getElementById("adoptionW15Schedule");
        const weekly = document.getElementById("adoptionWeekly");
        const training = document.getElementById("adoptionTraining");
        const kpi = document.getElementById("adoptionKpi");
        try {{
          meta.textContent = " ... /api/public/adoption-plan";
          const data = await fetchJson("/api/public/adoption-plan", false);
          meta.textContent = ": /api/public/adoption-plan";
          const topItems = [
            ["Start", data.timeline?.start_date || ""],
            ["End", data.timeline?.end_date || ""],
            ["Weeks", data.timeline?.duration_weeks || 0],
            ["Training Modules", (data.training_outline || []).length],
            ["KPI Items", (data.kpi_dashboard_items || []).length],
            ["Next Review", data.schedule_management?.next_review_date || ""]
          ];
          top.innerHTML = topItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          const workflowRows = (data.workflow_lock_matrix && data.workflow_lock_matrix.rows) || [];
          matrix.innerHTML = renderTable(
            workflowRows.map((row) => {{
              const perms = row.permissions || {{}};
              return {{
                role: row.role || "",
                draft: perms.DRAFT || "",
                review: perms.REVIEW || "",
                approved: perms.APPROVED || "",
                locked: perms.LOCKED || "",
              }};
            }}),
            [
              {{ key: "role", label: "Role" }},
              {{ key: "draft", label: "DRAFT" }},
              {{ key: "review", label: "REVIEW" }},
              {{ key: "approved", label: "APPROVED" }},
              {{ key: "locked", label: "LOCKED" }},
            ]
          );

          const w02 = data.w02_sop_sandbox || {{}};
          const w02TopItems = [
            ["Week", "W" + String(w02.timeline?.week || 2).padStart(2, "0")],
            ["Focus", w02.timeline?.focus || "SOP and sandbox"],
            ["SOP Count", (w02.sop_runbooks || []).length],
            ["Sandbox Count", (w02.sandbox_scenarios || []).length],
            ["Sessions", (w02.scheduled_events || []).length],
            ["Metric", w02.timeline?.success_metric || ""]
          ];
          w02Top.innerHTML = w02TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w02Sop.innerHTML = renderTable(
            w02.sop_runbooks || [],
            [
              {{ key: "id", label: "SOP ID" }},
              {{ key: "name", label: "Name" }},
              {{ key: "target_roles", label: "Target Roles", render: (v) => Array.isArray(v) ? v.join(", ") : "" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "definition_of_done", label: "Definition of Done" }}
            ]
          );
          w02Sandbox.innerHTML = renderTable(
            (w02.sandbox_scenarios || []).map((row) => ({{
              id: row.id || "",
              module: row.module || "",
              objective: row.objective || "",
              duration_min: row.duration_min ?? "",
              pass_criteria: Array.isArray(row.pass_criteria) ? row.pass_criteria.join(" | ") : "",
            }})),
            [
              {{ key: "id", label: "Scenario ID" }},
              {{ key: "module", label: "Module" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "duration_min", label: "Duration(min)" }},
              {{ key: "pass_criteria", label: "Pass Criteria" }}
            ]
          );
          w02Schedule.innerHTML = renderTable(
            (w02.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }}
            ]
          );

          const w03 = data.w03_go_live_onboarding || {{}};
          const w03TopItems = [
            ["Week", "W" + String(w03.timeline?.week || 3).padStart(2, "0")],
            ["Focus", w03.timeline?.focus || "Go-live onboarding"],
            ["Kickoff Agenda", (w03.kickoff_agenda || []).length],
            ["Role Workshops", (w03.role_workshops || []).length],
            ["Office Hours", (w03.office_hours || []).length],
            ["Sessions", (w03.scheduled_events || []).length],
          ];
          w03Top.innerHTML = w03TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w03Kickoff.innerHTML = renderTable(
            (w03.kickoff_agenda || []).map((row) => ({{
              id: row.id || "",
              topic: row.topic || "",
              owner: row.owner || "",
              duration_min: row.duration_min ?? "",
              objective: row.objective || "",
              expected_output: row.expected_output || "",
            }})),
            [
              {{ key: "id", label: "Kickoff ID" }},
              {{ key: "topic", label: "Topic" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "duration_min", label: "Duration(min)" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "expected_output", label: "Expected Output" }},
            ]
          );

          w03Workshops.innerHTML = renderTable(
            (w03.role_workshops || []).map((row) => ({{
              id: row.id || "",
              role: row.role || "",
              trainer: row.trainer || "",
              duration_min: row.duration_min ?? "",
              objective: row.objective || "",
              checklist: Array.isArray(row.checklist) ? row.checklist.join(" | ") : "",
              success_criteria: row.success_criteria || "",
            }})),
            [
              {{ key: "id", label: "Workshop ID" }},
              {{ key: "role", label: "Role" }},
              {{ key: "trainer", label: "Trainer" }},
              {{ key: "duration_min", label: "Duration(min)" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "checklist", label: "Checklist" }},
              {{ key: "success_criteria", label: "Success Criteria" }},
            ]
          );

          w03OfficeHours.innerHTML = renderTable(
            (w03.office_hours || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              host: row.host || "",
              focus: row.focus || "",
              channel: row.channel || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "host", label: "Host" }},
              {{ key: "focus", label: "Focus" }},
              {{ key: "channel", label: "Channel" }},
            ]
          );

          w03Schedule.innerHTML = renderTable(
            (w03.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w04 = data.w04_first_success_acceleration || {{}};
          const w04TopItems = [
            ["Week", "W" + String(w04.timeline?.week || 4).padStart(2, "0")],
            ["Focus", w04.timeline?.focus || "First success acceleration"],
            ["Coaching Actions", (w04.coaching_actions || []).length],
            ["Sessions", (w04.scheduled_events || []).length],
            ["Metric", w04.timeline?.success_metric || "Median TTV <= 15m"],
            ["Common Mistakes", "Published"],
          ];
          w04Top.innerHTML = w04TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w04Actions.innerHTML = renderTable(
            (w04.coaching_actions || []).map((row) => ({{
              id: row.id || "",
              champion_role: row.champion_role || "",
              action: row.action || "",
              owner: row.owner || "",
              due_hint: row.due_hint || "",
              objective: row.objective || "",
              evidence_required: String(Boolean(row.evidence_required)),
            }})),
            [
              {{ key: "id", label: "Action ID" }},
              {{ key: "champion_role", label: "Champion Role" }},
              {{ key: "action", label: "Action" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "due_hint", label: "Due Hint" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "evidence_required", label: "Evidence Required" }},
            ]
          );
          w04Schedule.innerHTML = renderTable(
            (w04.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const commonMistakesPath = String(w04.common_mistakes_reference || "/api/public/adoption-plan/w04/common-mistakes");
          const mistakesPayload = await fetchJson(commonMistakesPath, false).catch(() => null);
          const mistakeRows = mistakesPayload && Array.isArray(mistakesPayload.items) ? mistakesPayload.items : [];
          w04Mistakes.innerHTML = renderTable(
            mistakeRows.slice(0, 6).map((row) => ({{
              mistake: row.mistake || "",
              symptom: row.symptom || "",
              quick_fix: row.quick_fix || "",
              observed_count: row.observed_count ?? 0,
            }})),
            [
              {{ key: "mistake", label: "Mistake" }},
              {{ key: "symptom", label: "Symptom" }},
              {{ key: "quick_fix", label: "Quick Fix" }},
              {{ key: "observed_count", label: "Observed" }},
            ]
          );

          const w05 = data.w05_usage_consistency || {{}};
          const w05TopItems = [
            ["Week", "W" + String(w05.timeline?.week || 5).padStart(2, "0")],
            ["Focus", w05.timeline?.focus || "Usage consistency"],
            ["Role Missions", (w05.role_missions || []).length],
            ["Sessions", (w05.scheduled_events || []).length],
            ["Help Docs", (w05.help_docs || []).length],
            ["Metric", w05.timeline?.success_metric || "2-week retention >= 65%"],
          ];
          w05Top.innerHTML = w05TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w05Missions.innerHTML = renderTable(
            (w05.role_missions || []).map((row) => ({{
              id: row.id || "",
              role: row.role || "",
              mission: row.mission || "",
              weekly_target: row.weekly_target || "",
              owner: row.owner || "",
              evidence_required: String(Boolean(row.evidence_required)),
              evidence_hint: row.evidence_hint || "",
            }})),
            [
              {{ key: "id", label: "Mission ID" }},
              {{ key: "role", label: "Role" }},
              {{ key: "mission", label: "Mission" }},
              {{ key: "weekly_target", label: "Weekly Target" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "evidence_required", label: "Evidence Required" }},
              {{ key: "evidence_hint", label: "Evidence Hint" }},
            ]
          );

          w05Schedule.innerHTML = renderTable(
            (w05.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          w05HelpDocs.innerHTML = renderTable(
            (w05.help_docs || []).map((row) => ({{
              doc_id: row.doc_id || "",
              title: row.title || "",
              audience: row.audience || "",
              problem: row.problem || "",
              quick_steps: Array.isArray(row.quick_steps) ? row.quick_steps.join(" | ") : "",
              api_refs: Array.isArray(row.api_refs) ? row.api_refs.join(", ") : "",
            }})),
            [
              {{ key: "doc_id", label: "Doc ID" }},
              {{ key: "title", label: "Title" }},
              {{ key: "audience", label: "Audience" }},
              {{ key: "problem", label: "Problem" }},
              {{ key: "quick_steps", label: "Quick Steps" }},
              {{ key: "api_refs", label: "API Refs" }},
            ]
          );

          const w06 = data.w06_operational_rhythm || {{}};
          const w06TopItems = [
            ["Week", "W" + String(w06.timeline?.week || 6).padStart(2, "0")],
            ["Focus", w06.timeline?.focus || "Operational rhythm"],
            ["Rhythm Checklist", (w06.rhythm_checklist || []).length],
            ["Sessions", (w06.scheduled_events || []).length],
            ["RBAC Audit Controls", (w06.rbac_audit_checklist || []).length],
            ["Metric", w06.timeline?.success_metric || "Weekly active rate >= 75%"],
          ];
          w06Top.innerHTML = w06TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w06Checklist.innerHTML = renderTable(
            (w06.rhythm_checklist || []).map((row) => ({{
              id: row.id || "",
              day: row.day || "",
              routine: row.routine || "",
              owner_role: row.owner_role || "",
              definition_of_done: row.definition_of_done || "",
              evidence_hint: row.evidence_hint || "",
            }})),
            [
              {{ key: "id", label: "Checklist ID" }},
              {{ key: "day", label: "Day" }},
              {{ key: "routine", label: "Routine" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "evidence_hint", label: "Evidence Hint" }},
            ]
          );

          w06Schedule.innerHTML = renderTable(
            (w06.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          w06RbacAudit.innerHTML = renderTable(
            (w06.rbac_audit_checklist || []).map((row) => ({{
              id: row.id || "",
              control: row.control || "",
              objective: row.objective || "",
              api_ref: row.api_ref || "",
              pass_criteria: row.pass_criteria || "",
            }})),
            [
              {{ key: "id", label: "Control ID" }},
              {{ key: "control", label: "Control" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "api_ref", label: "API Ref" }},
              {{ key: "pass_criteria", label: "Pass Criteria" }},
            ]
          );

          const w07 = data.w07_sla_quality || {{}};
          const w07TopItems = [
            ["Week", "W" + String(w07.timeline?.week || 7).padStart(2, "0")],
            ["Focus", w07.timeline?.focus || "SLA quality"],
            ["SLA Checklist", (w07.sla_checklist || []).length],
            ["Coaching Plays", (w07.coaching_plays || []).length],
            ["Sessions", (w07.scheduled_events || []).length],
            ["Metric", w07.timeline?.success_metric || "SLA response time improves >= 10%"],
          ];
          w07Top.innerHTML = w07TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w07Checklist.innerHTML = renderTable(
            (w07.sla_checklist || []).map((row) => ({{
              id: row.id || "",
              cadence: row.cadence || "",
              control: row.control || "",
              owner_role: row.owner_role || "",
              target: row.target || "",
              definition_of_done: row.definition_of_done || "",
              evidence_hint: row.evidence_hint || "",
            }})),
            [
              {{ key: "id", label: "Checklist ID" }},
              {{ key: "cadence", label: "Cadence" }},
              {{ key: "control", label: "Control" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "target", label: "Target" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "evidence_hint", label: "Evidence Hint" }},
            ]
          );

          w07Coaching.innerHTML = renderTable(
            (w07.coaching_plays || []).map((row) => ({{
              id: row.id || "",
              trigger: row.trigger || "",
              play: row.play || "",
              owner: row.owner || "",
              expected_impact: row.expected_impact || "",
              evidence_hint: row.evidence_hint || "",
              api_ref: row.api_ref || "",
            }})),
            [
              {{ key: "id", label: "Play ID" }},
              {{ key: "trigger", label: "Trigger" }},
              {{ key: "play", label: "Play" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "expected_impact", label: "Expected Impact" }},
              {{ key: "evidence_hint", label: "Evidence Hint" }},
              {{ key: "api_ref", label: "API Ref" }},
            ]
          );

          w07Schedule.innerHTML = renderTable(
            (w07.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w08 = data.w08_report_discipline || {{}};
          const w08TopItems = [
            ["Week", "W" + String(w08.timeline?.week || 8).padStart(2, "0")],
            ["Focus", w08.timeline?.focus || "Report discipline"],
            ["Checklist", (w08.report_discipline_checklist || []).length],
            ["DQ Controls", (w08.data_quality_controls || []).length],
            ["Sessions", (w08.scheduled_events || []).length],
            ["Metric", w08.timeline?.success_metric || "Monthly report on-time rate >= 95%"],
          ];
          w08Top.innerHTML = w08TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w08Checklist.innerHTML = renderTable(
            (w08.report_discipline_checklist || []).map((row) => ({{
              id: row.id || "",
              cadence: row.cadence || "",
              discipline: row.discipline || "",
              owner_role: row.owner_role || "",
              target: row.target || "",
              definition_of_done: row.definition_of_done || "",
              api_ref: row.api_ref || "",
            }})),
            [
              {{ key: "id", label: "Checklist ID" }},
              {{ key: "cadence", label: "Cadence" }},
              {{ key: "discipline", label: "Discipline" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "target", label: "Target" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "api_ref", label: "API Ref" }},
            ]
          );

          w08Quality.innerHTML = renderTable(
            (w08.data_quality_controls || []).map((row) => ({{
              id: row.id || "",
              control: row.control || "",
              objective: row.objective || "",
              api_ref: row.api_ref || "",
              pass_criteria: row.pass_criteria || "",
            }})),
            [
              {{ key: "id", label: "Control ID" }},
              {{ key: "control", label: "Control" }},
              {{ key: "objective", label: "Objective" }},
              {{ key: "api_ref", label: "API Ref" }},
              {{ key: "pass_criteria", label: "Pass Criteria" }},
            ]
          );

          w08Schedule.innerHTML = renderTable(
            (w08.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w09 = data.w09_kpi_operation || {{}};
          const w09TopItems = [
            ["Week", "W" + String(w09.timeline?.week || 9).padStart(2, "0")],
            ["Focus", w09.timeline?.focus || "KPI operation"],
            ["Threshold KPIs", (w09.kpi_threshold_matrix || []).length],
            ["Escalation Rules", (w09.escalation_map || []).length],
            ["Sessions", (w09.scheduled_events || []).length],
            ["Metric", w09.timeline?.success_metric || "Green ratio >= 80%"],
          ];
          w09Top.innerHTML = w09TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w09Thresholds.innerHTML = renderTable(
            (w09.kpi_threshold_matrix || []).map((row) => ({{
              id: row.id || "",
              kpi_name: row.kpi_name || "",
              kpi_key: row.kpi_key || "",
              owner_role: row.owner_role || "",
              direction: row.direction || "",
              green_threshold: row.green_threshold ?? "",
              yellow_threshold: row.yellow_threshold ?? "",
              target: row.target || "",
              source_api: row.source_api || "",
            }})),
            [
              {{ key: "id", label: "KPI ID" }},
              {{ key: "kpi_name", label: "KPI Name" }},
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "direction", label: "Direction" }},
              {{ key: "green_threshold", label: "Green" }},
              {{ key: "yellow_threshold", label: "Yellow" }},
              {{ key: "target", label: "Target" }},
              {{ key: "source_api", label: "Source API" }},
            ]
          );

          w09Escalation.innerHTML = renderTable(
            (w09.escalation_map || []).map((row) => ({{
              id: row.id || "",
              kpi_key: row.kpi_key || "",
              condition: row.condition || "",
              escalate_to: row.escalate_to || "",
              sla_hours: row.sla_hours ?? "",
              action: row.action || "",
            }})),
            [
              {{ key: "id", label: "Rule ID" }},
              {{ key: "kpi_key", label: "KPI Key" }},
              {{ key: "condition", label: "Condition" }},
              {{ key: "escalate_to", label: "Escalate To" }},
              {{ key: "sla_hours", label: "SLA Hours" }},
              {{ key: "action", label: "Action" }},
            ]
          );

          w09Schedule.innerHTML = renderTable(
            (w09.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w10 = data.w10_self_serve_support || {{}};
          const w10TopItems = [
            ["Week", "W" + String(w10.timeline?.week || 10).padStart(2, "0")],
            ["Focus", w10.timeline?.focus || "Self-serve support"],
            ["Guides", (w10.self_serve_guides || []).length],
            ["Runbook", (w10.troubleshooting_runbook || []).length],
            ["Sessions", (w10.scheduled_events || []).length],
            ["Metric", w10.timeline?.success_metric || "Support repeat rate down >= 20%"],
          ];
          w10Top.innerHTML = w10TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w10Guides.innerHTML = renderTable(
            (w10.self_serve_guides || []).map((row) => ({{
              id: row.id || "",
              title: row.title || "",
              problem_cluster: row.problem_cluster || "",
              owner_role: row.owner_role || "",
              target: row.target || "",
              source_api: row.source_api || "",
            }})),
            [
              {{ key: "id", label: "Guide ID" }},
              {{ key: "title", label: "Title" }},
              {{ key: "problem_cluster", label: "Problem Cluster" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "target", label: "Target" }},
              {{ key: "source_api", label: "Source API" }},
            ]
          );

          w10Runbook.innerHTML = renderTable(
            (w10.troubleshooting_runbook || []).map((row) => ({{
              id: row.id || "",
              module: row.module || "",
              symptom: row.symptom || "",
              owner_role: row.owner_role || "",
              definition_of_done: row.definition_of_done || "",
              api_ref: row.api_ref || "",
            }})),
            [
              {{ key: "id", label: "Runbook ID" }},
              {{ key: "module", label: "Module" }},
              {{ key: "symptom", label: "Symptom" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "api_ref", label: "API Ref" }},
            ]
          );

          w10Schedule.innerHTML = renderTable(
            (w10.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w11 = data.w11_scale_readiness || {{}};
          const w11TopItems = [
            ["Week", "W" + String(w11.timeline?.week || 11).padStart(2, "0")],
            ["Focus", w11.timeline?.focus || "Scale readiness"],
            ["Guides", (w11.self_serve_guides || []).length],
            ["Runbook", (w11.troubleshooting_runbook || []).length],
            ["Sessions", (w11.scheduled_events || []).length],
            ["Metric", w11.timeline?.success_metric || "New-site simulation success >= 90%"],
          ];
          w11Top.innerHTML = w11TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w11Guides.innerHTML = renderTable(
            (w11.self_serve_guides || []).map((row) => ({{
              id: row.id || "",
              title: row.title || "",
              problem_cluster: row.problem_cluster || "",
              owner_role: row.owner_role || "",
              target: row.target || "",
              source_api: row.source_api || "",
            }})),
            [
              {{ key: "id", label: "Checklist ID" }},
              {{ key: "title", label: "Title" }},
              {{ key: "problem_cluster", label: "Readiness Cluster" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "target", label: "Target" }},
              {{ key: "source_api", label: "Source API" }},
            ]
          );

          w11Runbook.innerHTML = renderTable(
            (w11.troubleshooting_runbook || []).map((row) => ({{
              id: row.id || "",
              module: row.module || "",
              symptom: row.symptom || "",
              owner_role: row.owner_role || "",
              definition_of_done: row.definition_of_done || "",
              api_ref: row.api_ref || "",
            }})),
            [
              {{ key: "id", label: "Simulation ID" }},
              {{ key: "module", label: "Module" }},
              {{ key: "symptom", label: "Scenario" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "api_ref", label: "API Ref" }},
            ]
          );

          w11Schedule.innerHTML = renderTable(
            (w11.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          const w15 = data.w15_operations_efficiency || {{}};
          const w15TopItems = [
            ["Week", "W" + String(w15.timeline?.week || 15).padStart(2, "0")],
            ["Focus", w15.timeline?.focus || "Operations efficiency"],
            ["Guides", (w15.self_serve_guides || []).length],
            ["Runbook", (w15.troubleshooting_runbook || []).length],
            ["Sessions", (w15.scheduled_events || []).length],
            ["Metric", w15.timeline?.success_metric || "Operations efficiency readiness >= 75"],
          ];
          w15Top.innerHTML = w15TopItems.map((x) => (
            '<div class="card"><div class="k">' + escapeHtml(x[0]) + '</div><div class="v">' + escapeHtml(x[1]) + "</div></div>"
          )).join("");

          w15Guides.innerHTML = renderTable(
            (w15.self_serve_guides || []).map((row) => ({{
              id: row.id || "",
              title: row.title || "",
              problem_cluster: row.problem_cluster || "",
              owner_role: row.owner_role || "",
              target: row.target || "",
              source_api: row.source_api || "",
            }})),
            [
              {{ key: "id", label: "Guide ID" }},
              {{ key: "title", label: "Title" }},
              {{ key: "problem_cluster", label: "Problem Cluster" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "target", label: "Target" }},
              {{ key: "source_api", label: "Source API" }},
            ]
          );

          w15Runbook.innerHTML = renderTable(
            (w15.troubleshooting_runbook || []).map((row) => ({{
              id: row.id || "",
              module: row.module || "",
              symptom: row.symptom || "",
              owner_role: row.owner_role || "",
              definition_of_done: row.definition_of_done || "",
              api_ref: row.api_ref || "",
            }})),
            [
              {{ key: "id", label: "Runbook ID" }},
              {{ key: "module", label: "Module" }},
              {{ key: "symptom", label: "Scenario" }},
              {{ key: "owner_role", label: "Owner Role" }},
              {{ key: "definition_of_done", label: "Definition of Done" }},
              {{ key: "api_ref", label: "API Ref" }},
            ]
          );

          w15Schedule.innerHTML = renderTable(
            (w15.scheduled_events || []).map((row) => ({{
              date: row.date || "",
              time: (row.start_time || "") + " - " + (row.end_time || ""),
              title: row.title || "",
              owner: row.owner || "",
              output: row.output || "",
            }})),
            [
              {{ key: "date", label: "Date" }},
              {{ key: "time", label: "Time" }},
              {{ key: "title", label: "Session" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "output", label: "Output" }},
            ]
          );

          weekly.innerHTML = renderTable(
            data.weekly_execution || [],
            [
              {{ key: "week", label: "Week", render: (v) => "W" + String(v).padStart(2, "0") }},
              {{ key: "phase", label: "Phase" }},
              {{ key: "focus", label: "Focus" }},
              {{ key: "owner", label: "Owner" }},
              {{ key: "success_metric", label: "Success Metric" }}
            ]
          );
          training.innerHTML = renderTable(
            data.training_outline || [],
            [
              {{ key: "module", label: "Module" }},
              {{ key: "audience", label: "Audience" }},
              {{ key: "duration_min", label: "Duration(min)" }},
              {{ key: "format", label: "Format" }}
            ]
          );
          kpi.innerHTML = renderTable(
            data.kpi_dashboard_items || [],
            [
              {{ key: "id", label: "ID" }},
              {{ key: "name", label: "Name" }},
              {{ key: "target", label: "Target" }},
              {{ key: "frequency", label: "Frequency" }}
            ]
          );
          if (getToken()) {{
            runW02Tracker().catch(() => null);
            runW03Tracker().catch(() => null);
            runW04Tracker().catch(() => null);
            runW04FunnelBlockers().catch(() => null);
            runW05Consistency().catch(() => null);
            runW06Rhythm().catch(() => null);
            runW07SlaQuality().catch(() => null);
            runW08ReportDiscipline().catch(() => null);
            runW09KpiOperation().catch(() => null);
            runW09Tracker().catch(() => null);
            runW10KpiOperation().catch(() => null);
            runW10Tracker().catch(() => null);
            runW11KpiOperation().catch(() => null);
            runW11Tracker().catch(() => null);
            runW15KpiOperation().catch(() => null);
            runW15Tracker().catch(() => null);
          }} else {{
            const w02TrackerMeta = document.getElementById("w02TrackerMeta");
            const w02TrackerSummary = document.getElementById("w02TrackerSummary");
            const w02TrackerTable = document.getElementById("w02TrackerTable");
            const w02ReadinessMeta = document.getElementById("w02ReadinessMeta");
            const w02ReadinessCards = document.getElementById("w02ReadinessCards");
            const w02ReadinessBlockers = document.getElementById("w02ReadinessBlockers");
            const w02EvidenceTable = document.getElementById("w02EvidenceTable");
            w02TrackerMeta.textContent = "     API   .";
            w02TrackerSummary.innerHTML = "";
            w02TrackerTable.innerHTML = renderEmpty("  ");
            w02ReadinessMeta.textContent = "     API   .";
            w02ReadinessCards.innerHTML = "";
            w02ReadinessBlockers.innerHTML = renderEmpty("  ");
            w02EvidenceTable.innerHTML = renderEmpty("  ");

            const w03TrackerMeta = document.getElementById("w03TrackerMeta");
            const w03TrackerSummary = document.getElementById("w03TrackerSummary");
            const w03TrackerTable = document.getElementById("w03TrackerTable");
            const w03ReadinessMeta = document.getElementById("w03ReadinessMeta");
            const w03ReadinessCards = document.getElementById("w03ReadinessCards");
            const w03ReadinessBlockers = document.getElementById("w03ReadinessBlockers");
            const w03EvidenceTable = document.getElementById("w03EvidenceTable");
            w03TrackerMeta.textContent = "     API   .";
            w03TrackerSummary.innerHTML = "";
            w03TrackerTable.innerHTML = renderEmpty("  ");
            w03ReadinessMeta.textContent = "     API   .";
            w03ReadinessCards.innerHTML = "";
            w03ReadinessBlockers.innerHTML = renderEmpty("  ");
            w03EvidenceTable.innerHTML = renderEmpty("  ");

            const w04FunnelMeta = document.getElementById("w04FunnelMeta");
            const w04FunnelSummary = document.getElementById("w04FunnelSummary");
            const w04FunnelStages = document.getElementById("w04FunnelStages");
            const w04BlockerTable = document.getElementById("w04BlockerTable");
            w04FunnelMeta.textContent = "   W04 funnel API   .";
            w04FunnelSummary.innerHTML = "";
            w04FunnelStages.innerHTML = renderEmpty("  ");
            w04BlockerTable.innerHTML = renderEmpty("  ");

            const w04TrackerMeta = document.getElementById("w04TrackerMeta");
            const w04TrackerSummary = document.getElementById("w04TrackerSummary");
            const w04TrackerTable = document.getElementById("w04TrackerTable");
            const w04ReadinessMeta = document.getElementById("w04ReadinessMeta");
            const w04ReadinessCards = document.getElementById("w04ReadinessCards");
            const w04ReadinessBlockers = document.getElementById("w04ReadinessBlockers");
            const w04EvidenceTable = document.getElementById("w04EvidenceTable");
            w04TrackerMeta.textContent = "     API   .";
            w04TrackerSummary.innerHTML = "";
            w04TrackerTable.innerHTML = renderEmpty("  ");
            w04ReadinessMeta.textContent = "     API   .";
            w04ReadinessCards.innerHTML = "";
            w04ReadinessBlockers.innerHTML = renderEmpty("  ");
            w04EvidenceTable.innerHTML = renderEmpty("  ");

            const w05ConsistencyMeta = document.getElementById("w05ConsistencyMeta");
            const w05ConsistencySummary = document.getElementById("w05ConsistencySummary");
            const w05ConsistencyTopSites = document.getElementById("w05ConsistencyTopSites");
            const w05ConsistencyRecommendations = document.getElementById("w05ConsistencyRecommendations");
            w05ConsistencyMeta.textContent = "   W05 consistency API   .";
            w05ConsistencySummary.innerHTML = "";
            w05ConsistencyTopSites.innerHTML = renderEmpty("  ");
            w05ConsistencyRecommendations.innerHTML = renderEmpty("  ");

            const w06RhythmMeta = document.getElementById("w06RhythmMeta");
            const w06RhythmSummary = document.getElementById("w06RhythmSummary");
            const w06RhythmRoleCoverage = document.getElementById("w06RhythmRoleCoverage");
            const w06RhythmSiteActivity = document.getElementById("w06RhythmSiteActivity");
            const w06RhythmRecommendations = document.getElementById("w06RhythmRecommendations");
            w06RhythmMeta.textContent = "   W06 rhythm API   .";
            w06RhythmSummary.innerHTML = "";
            w06RhythmRoleCoverage.innerHTML = renderEmpty("  ");
            w06RhythmSiteActivity.innerHTML = renderEmpty("  ");
            w06RhythmRecommendations.innerHTML = renderEmpty("  ");

            const w07QualityMeta = document.getElementById("w07QualityMeta");
            const w07QualitySummary = document.getElementById("w07QualitySummary");
            const w07AutomationReadiness = document.getElementById("w07AutomationReadiness");
            const w07QualityTopSites = document.getElementById("w07QualityTopSites");
            const w07QualityRecommendations = document.getElementById("w07QualityRecommendations");
            w07QualityMeta.textContent = "   W07 SLA quality API   .";
            w07QualitySummary.innerHTML = "";
            w07AutomationReadiness.innerHTML = renderEmpty("  ");
            w07QualityTopSites.innerHTML = renderEmpty("  ");
            w07QualityRecommendations.innerHTML = renderEmpty("  ");

            const w08DisciplineMeta = document.getElementById("w08DisciplineMeta");
            const w08DisciplineSummary = document.getElementById("w08DisciplineSummary");
            const w08DisciplineTopSites = document.getElementById("w08DisciplineTopSites");
            const w08DisciplineBenchmark = document.getElementById("w08DisciplineBenchmark");
            const w08DisciplineRecommendations = document.getElementById("w08DisciplineRecommendations");
            w08DisciplineMeta.textContent = "   W08 report discipline API   .";
            w08DisciplineSummary.innerHTML = "";
            w08DisciplineTopSites.innerHTML = renderEmpty("  ");
            w08DisciplineBenchmark.innerHTML = renderEmpty("  ");
            w08DisciplineRecommendations.innerHTML = renderEmpty("  ");

            const sharedKpiAuthConfigs = [
              {{ phaseCode: "w09", kpiApiLabel: "W09 KPI operation", policyApiLabel: "W09 policy" }},
              {{ phaseCode: "w10", kpiApiLabel: "W10 self-serve", policyApiLabel: "W10 support policy" }},
              {{ phaseCode: "w11", kpiApiLabel: "W11 scale-readiness", policyApiLabel: "W11 readiness policy" }},
              {{ phaseCode: "w15", kpiApiLabel: "W15 ops-efficiency", policyApiLabel: "W15 efficiency policy" }},
            ];
            sharedKpiAuthConfigs.forEach((item) => {{
              document.getElementById(item.phaseCode + "KpiMeta").textContent =
                "   " + item.kpiApiLabel + " API   .";
              document.getElementById(item.phaseCode + "KpiSummary").innerHTML = "";
              document.getElementById(item.phaseCode + "KpiTable").innerHTML = renderEmpty("  ");
              document.getElementById(item.phaseCode + "EscalationTable").innerHTML = renderEmpty("  ");
              document.getElementById(item.phaseCode + "KpiRecommendations").innerHTML = renderEmpty("  ");
              document.getElementById(item.phaseCode + "PolicyMeta").textContent =
                "   " + item.policyApiLabel + " API   .";
              document.getElementById(item.phaseCode + "PolicyTable").innerHTML = renderEmpty("  ");
            }});
            ["w09", "w10", "w11", "w15"].forEach((phaseCode) => {{
              setSharedTrackerAuthRequired(getSharedTrackerConfig(phaseCode));
            }});

            w07TrackerItemsCache = [];
            w07SelectedItemIds = new Set();
            w07ActiveItemId = null;
            w07LastReadiness = null;
            w07LastCompletion = null;
            document.getElementById("w07TrackerMeta").textContent = "   W07 tracker API   .";
            document.getElementById("w07SelectionMeta").textContent = ": ALL | : 0/0 | : 0";
            document.getElementById("w07TrackerSummary").innerHTML = "";
            document.getElementById("w07TrackerTable").innerHTML = renderEmpty("  ");
            document.getElementById("w07ReadinessMeta").textContent = "     API   .";
            document.getElementById("w07ReadinessCards").innerHTML = "";
            document.getElementById("w07ReadinessBlockers").innerHTML = renderEmpty("  ");
            document.getElementById("w07EvidenceTable").innerHTML = renderEmpty("  ");
            renderW07ActionResultsPanel();
          }}
        }} catch (err) {{
          meta.textContent = ": " + err.message;
          top.innerHTML = "";
          matrix.innerHTML = renderEmpty(err.message);
          w02Top.innerHTML = "";
          w02Sop.innerHTML = renderEmpty(err.message);
          w02Sandbox.innerHTML = renderEmpty(err.message);
          w02Schedule.innerHTML = renderEmpty(err.message);
          w03Top.innerHTML = "";
          w03Kickoff.innerHTML = renderEmpty(err.message);
          w03Workshops.innerHTML = renderEmpty(err.message);
          w03OfficeHours.innerHTML = renderEmpty(err.message);
          w03Schedule.innerHTML = renderEmpty(err.message);
          w04Top.innerHTML = "";
          w04Actions.innerHTML = renderEmpty(err.message);
          w04Schedule.innerHTML = renderEmpty(err.message);
          w04Mistakes.innerHTML = renderEmpty(err.message);
          w05Top.innerHTML = "";
          w05Missions.innerHTML = renderEmpty(err.message);
          w05Schedule.innerHTML = renderEmpty(err.message);
          w05HelpDocs.innerHTML = renderEmpty(err.message);
          w06Top.innerHTML = "";
          w06Checklist.innerHTML = renderEmpty(err.message);
          w06Schedule.innerHTML = renderEmpty(err.message);
          w06RbacAudit.innerHTML = renderEmpty(err.message);
          w07Top.innerHTML = "";
          w07Checklist.innerHTML = renderEmpty(err.message);
          w07Coaching.innerHTML = renderEmpty(err.message);
          w07Schedule.innerHTML = renderEmpty(err.message);
          w08Top.innerHTML = "";
          w08Checklist.innerHTML = renderEmpty(err.message);
          w08Quality.innerHTML = renderEmpty(err.message);
          w08Schedule.innerHTML = renderEmpty(err.message);
          w10Top.innerHTML = "";
          w10Guides.innerHTML = renderEmpty(err.message);
          w10Runbook.innerHTML = renderEmpty(err.message);
          w10Schedule.innerHTML = renderEmpty(err.message);
          w11Top.innerHTML = "";
          w11Guides.innerHTML = renderEmpty(err.message);
          w11Runbook.innerHTML = renderEmpty(err.message);
          w11Schedule.innerHTML = renderEmpty(err.message);
          w15Top.innerHTML = "";
          w15Guides.innerHTML = renderEmpty(err.message);
          w15Runbook.innerHTML = renderEmpty(err.message);
          w15Schedule.innerHTML = renderEmpty(err.message);
          document.getElementById("w05ConsistencyMeta").textContent = ": " + err.message;
          document.getElementById("w05ConsistencySummary").innerHTML = "";
          document.getElementById("w05ConsistencyTopSites").innerHTML = renderEmpty(err.message);
          document.getElementById("w05ConsistencyRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w06RhythmMeta").textContent = ": " + err.message;
          document.getElementById("w06RhythmSummary").innerHTML = "";
          document.getElementById("w06RhythmRoleCoverage").innerHTML = renderEmpty(err.message);
          document.getElementById("w06RhythmSiteActivity").innerHTML = renderEmpty(err.message);
          document.getElementById("w06RhythmRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w07QualityMeta").textContent = ": " + err.message;
          document.getElementById("w07QualitySummary").innerHTML = "";
          document.getElementById("w07AutomationReadiness").innerHTML = renderEmpty(err.message);
          document.getElementById("w07QualityTopSites").innerHTML = renderEmpty(err.message);
          document.getElementById("w07QualityRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w08DisciplineMeta").textContent = ": " + err.message;
          document.getElementById("w08DisciplineSummary").innerHTML = "";
          document.getElementById("w08DisciplineTopSites").innerHTML = renderEmpty(err.message);
          document.getElementById("w08DisciplineBenchmark").innerHTML = renderEmpty(err.message);
          document.getElementById("w08DisciplineRecommendations").innerHTML = renderEmpty(err.message);
          w09Top.innerHTML = "";
          w09Thresholds.innerHTML = renderEmpty(err.message);
          w09Escalation.innerHTML = renderEmpty(err.message);
          w09Schedule.innerHTML = renderEmpty(err.message);
          document.getElementById("w09KpiMeta").textContent = ": " + err.message;
          document.getElementById("w09KpiSummary").innerHTML = "";
          document.getElementById("w09KpiTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w09EscalationTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w09KpiRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w09PolicyMeta").textContent = ": " + err.message;
          document.getElementById("w09PolicyTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w10KpiMeta").textContent = ": " + err.message;
          document.getElementById("w10KpiSummary").innerHTML = "";
          document.getElementById("w10KpiTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w10EscalationTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w10KpiRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w10PolicyMeta").textContent = ": " + err.message;
          document.getElementById("w10PolicyTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w11KpiMeta").textContent = ": " + err.message;
          document.getElementById("w11KpiSummary").innerHTML = "";
          document.getElementById("w11KpiTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w11EscalationTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w11KpiRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w11PolicyMeta").textContent = ": " + err.message;
          document.getElementById("w11PolicyTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w15KpiMeta").textContent = ": " + err.message;
          document.getElementById("w15KpiSummary").innerHTML = "";
          document.getElementById("w15KpiTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w15EscalationTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w15KpiRecommendations").innerHTML = renderEmpty(err.message);
          document.getElementById("w15PolicyMeta").textContent = ": " + err.message;
          document.getElementById("w15PolicyTable").innerHTML = renderEmpty(err.message);
          ["w09", "w10", "w11", "w15"].forEach((phaseCode) => {{
            setSharedTrackerError(getSharedTrackerConfig(phaseCode), err.message);
          }});
          document.getElementById("w07TrackerMeta").textContent = ": " + err.message;
          document.getElementById("w07TrackerSummary").innerHTML = "";
          document.getElementById("w07TrackerTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w07ReadinessMeta").textContent = ": " + err.message;
          document.getElementById("w07ReadinessCards").innerHTML = "";
          document.getElementById("w07ReadinessBlockers").innerHTML = renderEmpty(err.message);
          document.getElementById("w07EvidenceTable").innerHTML = renderEmpty(err.message);
          document.getElementById("w07SelectionMeta").textContent = ": ALL | : 0/0 | : 0";
          renderW07ActionResultsPanel();
          weekly.innerHTML = renderEmpty(err.message);
          training.innerHTML = renderEmpty(err.message);
          kpi.innerHTML = renderEmpty(err.message);
        }}
      }}

      function roleDefaultTab(profile) {{
        const role = (profile && profile.role) || "";
        if (role === "operator") return "workorders";
        if (role === "auditor") return "reports";
        return "overview";
      }}

      buttons.forEach((btn) => {{
        btn.addEventListener("click", () => activate(btn.dataset.tab, true));
      }});

      document.getElementById("saveTokenBtn").addEventListener("click", () => {{
        const token = (tokenInput.value || "").trim();
        if (!token) {{
          setAuthState(" :     .");
          return;
        }}
        window.sessionStorage.setItem(TOKEN_KEY, token);
        window.localStorage.removeItem(TOKEN_KEY);
        authProfile = null;
        updateAuthStateFromToken();
      }});
      document.getElementById("clearTokenBtn").addEventListener("click", () => {{
        window.sessionStorage.removeItem(TOKEN_KEY);
        window.localStorage.removeItem(TOKEN_KEY);
        tokenInput.value = "";
        authProfile = null;
        updateAuthStateFromToken();
      }});
      document.getElementById("testTokenBtn").addEventListener("click", async () => {{
        try {{
          const profile = await runAuthMe();
          setAuthState(" :   | : " + profile.username + " | : " + profile.role);
          if (!url.searchParams.get("tab")) {{
            activate(roleDefaultTab(profile), true);
          }}
        }} catch (err) {{
          setAuthState(" :   | " + err.message);
        }}
      }});

      const w07TrackerTableContainer = document.getElementById("w07TrackerTable");
      if (w07TrackerTableContainer) {{
        w07TrackerTableContainer.addEventListener("click", (event) => {{
          const pickBtn = event.target.closest(".w07-pick-item");
          if (pickBtn) {{
            const item = getW07ItemById(pickBtn.getAttribute("data-item-id"));
            if (item) {{
              fillW07FormFromItem(item, {{ keepCurrentNote: true }});
              renderW07TrackerTablePanel();
            }}
            return;
          }}
          if (event.target.closest("input,button,a,label")) {{
            return;
          }}
          const rowEl = event.target.closest("tr.w07-track-row");
          if (!rowEl) return;
          const item = getW07ItemById(rowEl.getAttribute("data-item-id"));
          if (!item) return;
          fillW07FormFromItem(item, {{ keepCurrentNote: true }});
          renderW07TrackerTablePanel();
        }});
        w07TrackerTableContainer.addEventListener("change", (event) => {{
          const checkbox = event.target.closest(".w07-select-item");
          if (!checkbox) return;
          const itemId = asInt(checkbox.getAttribute("data-item-id"), -1);
          if (itemId <= 0) return;
          if (checkbox.checked) {{
            w07SelectedItemIds.add(itemId);
          }} else {{
            w07SelectedItemIds.delete(itemId);
          }}
          renderW07SelectionMeta();
        }});
      }}

      const w07ReadinessCardsPanel = document.getElementById("w07ReadinessCards");
      if (w07ReadinessCardsPanel) {{
        w07ReadinessCardsPanel.addEventListener("click", (event) => {{
          const card = event.target.closest(".w07-readiness-card");
          if (!card) return;
          const filterKey = card.getAttribute("data-filter") || "all";
          setW07TrackerFilter(filterKey, {{ autoPick: true }});
          const readinessMeta = document.getElementById("w07ReadinessMeta");
          readinessMeta.textContent =
            ": " + String((w07LastCompletion && w07LastCompletion.status) || "active")
            + " | ready=" + String(w07LastReadiness && w07LastReadiness.ready ? "YES" : "NO")
            + " | filter=" + getW07FilterLabel(filterKey);
        }});
        w07ReadinessCardsPanel.addEventListener("keydown", (event) => {{
          if (!(event.key === "Enter" || event.key === " ")) return;
          const card = event.target.closest(".w07-readiness-card");
          if (!card) return;
          event.preventDefault();
          const filterKey = card.getAttribute("data-filter") || "all";
          setW07TrackerFilter(filterKey, {{ autoPick: true }});
        }});
      }}

      const w07EvidenceFileInput = document.getElementById("w07EvidenceFile");
      const w07EvidenceDropzone = document.getElementById("w07EvidenceDropzone");
      if (w07EvidenceDropzone && w07EvidenceFileInput) {{
        w07EvidenceDropzone.addEventListener("click", () => w07EvidenceFileInput.click());
        w07EvidenceFileInput.addEventListener("change", () => {{
          const file = (w07EvidenceFileInput.files && w07EvidenceFileInput.files[0]) || null;
          if (file) {{
            assignW07EvidenceFile(file);
          }}
        }});
        w07EvidenceDropzone.addEventListener("dragover", (event) => {{
          event.preventDefault();
          w07EvidenceDropzone.classList.add("dragover");
        }});
        w07EvidenceDropzone.addEventListener("dragleave", () => {{
          w07EvidenceDropzone.classList.remove("dragover");
        }});
        w07EvidenceDropzone.addEventListener("drop", (event) => {{
          event.preventDefault();
          w07EvidenceDropzone.classList.remove("dragover");
          const files = event.dataTransfer && event.dataTransfer.files ? event.dataTransfer.files : null;
          const file = files && files.length > 0 ? files[0] : null;
          if (!file) return;
          assignW07EvidenceFile(file);
        }});
      }}

      const w07CompleteModal = document.getElementById("w07CompleteModal");
      document.getElementById("w07CompleteModalCancel").addEventListener("click", () => closeW07CompleteModal(false));
      document.getElementById("w07CompleteModalConfirm").addEventListener("click", () => closeW07CompleteModal(true));
      if (w07CompleteModal) {{
        w07CompleteModal.addEventListener("click", (event) => {{
          if (event.target === w07CompleteModal) {{
            closeW07CompleteModal(false);
          }}
        }});
      }}
      window.addEventListener("keydown", (event) => {{
        if (event.key === "Escape" && w07CompleteModal && w07CompleteModal.classList.contains("open")) {{
          closeW07CompleteModal(false);
        }}
      }});

      document.getElementById("runOverviewBtn").addEventListener("click", runOverview);
      document.getElementById("runOverviewGuardRecoverDryBtn").addEventListener("click", () => runOverviewGuardRecover(true));
      document.getElementById("runOverviewGuardRecoverRunBtn").addEventListener("click", () => runOverviewGuardRecover(false));
      document.getElementById("runOverviewGuardRecoverLatestBtn").addEventListener("click", runOverviewGuardRecoverLatest);
      document.getElementById("runWorkordersBtn").addEventListener("click", runWorkorders);
      document.getElementById("runInspectionsBtn").addEventListener("click", runInspections);
      document.getElementById("runReportsBtn").addEventListener("click", runReports);
      document.getElementById("runAdoptionBtn").addEventListener("click", runAdoption);
      document.getElementById("w02TrackBootstrapBtn").addEventListener("click", runW02TrackerBootstrap);
      document.getElementById("w02TrackRefreshBtn").addEventListener("click", runW02Tracker);
      document.getElementById("w02ReadinessBtn").addEventListener("click", runW02Readiness);
      document.getElementById("w02CompleteBtn").addEventListener("click", runW02Complete);
      document.getElementById("w02TrackUpdateBtn").addEventListener("click", runW02TrackerUpdateAndUpload);
      document.getElementById("w03TrackBootstrapBtn").addEventListener("click", runW03TrackerBootstrap);
      document.getElementById("w03TrackRefreshBtn").addEventListener("click", runW03Tracker);
      document.getElementById("w03ReadinessBtn").addEventListener("click", runW03Readiness);
      document.getElementById("w03CompleteBtn").addEventListener("click", runW03Complete);
      document.getElementById("w03TrackUpdateBtn").addEventListener("click", runW03TrackerUpdateAndUpload);
      document.getElementById("w04FunnelRefreshBtn").addEventListener("click", runW04FunnelBlockers);
      document.getElementById("w04TrackBootstrapBtn").addEventListener("click", runW04TrackerBootstrap);
      document.getElementById("w04TrackRefreshBtn").addEventListener("click", runW04Tracker);
      document.getElementById("w04ReadinessBtn").addEventListener("click", runW04Readiness);
      document.getElementById("w04CompleteBtn").addEventListener("click", runW04Complete);
      document.getElementById("w04TrackUpdateBtn").addEventListener("click", runW04TrackerUpdateAndUpload);
      document.getElementById("w05ConsistencyRefreshBtn").addEventListener("click", runW05Consistency);
      document.getElementById("w06RhythmRefreshBtn").addEventListener("click", runW06Rhythm);
      document.getElementById("w07QualityRefreshBtn").addEventListener("click", runW07SlaQuality);
      document.getElementById("w07TrackBootstrapBtn").addEventListener("click", runW07TrackerBootstrap);
      document.getElementById("w07TrackNextBtn").addEventListener("click", runW07NextIncomplete);
      document.getElementById("w07SelectVisibleBtn").addEventListener("click", runW07SelectVisible);
      document.getElementById("w07ClearSelectionBtn").addEventListener("click", runW07ClearSelection);
      document.getElementById("w07BulkApplyBtn").addEventListener("click", runW07BulkApply);
      document.getElementById("w07TrackRefreshBtn").addEventListener("click", runW07Tracker);
      document.getElementById("w07ReadinessBtn").addEventListener("click", runW07Readiness);
      document.getElementById("w07CompleteBtn").addEventListener("click", () => runW07Complete());
      document.getElementById("w07CompleteAndWeeklyBtn").addEventListener("click", runW07CompleteAndWeekly);
      document.getElementById("w07DownloadPackageBtn").addEventListener("click", runW07DownloadCompletionPackage);
      document.getElementById("w07TrackUpdateBtn").addEventListener("click", runW07TrackerUpdateAndUpload);
      document.getElementById("w07WeeklyRunBtn").addEventListener("click", runW07WeeklyJob);
      document.getElementById("w07WeeklyLatestBtn").addEventListener("click", runW07WeeklyLatest);
      document.getElementById("w07WeeklyTrendsBtn").addEventListener("click", runW07WeeklyTrends);
      document.getElementById("w08DisciplineRefreshBtn").addEventListener("click", runW08ReportDiscipline);
      const sharedKpiRefreshHandlers = {{
        w09: runW09KpiOperation,
        w10: runW10KpiOperation,
        w11: runW11KpiOperation,
        w15: runW15KpiOperation,
      }};
      Object.keys(sharedKpiRefreshHandlers).forEach((phaseCode) => {{
        document.getElementById(phaseCode + "KpiRefreshBtn")
          .addEventListener("click", sharedKpiRefreshHandlers[phaseCode]);
      }});
      const sharedTrackerHandlers = {{
        w09: {{
          bootstrap: runW09TrackerBootstrap,
          refresh: runW09Tracker,
          readiness: runW09Readiness,
          complete: runW09Complete,
          update: runW09TrackerUpdateAndUpload,
        }},
        w10: {{
          bootstrap: runW10TrackerBootstrap,
          refresh: runW10Tracker,
          readiness: runW10Readiness,
          complete: runW10Complete,
          update: runW10TrackerUpdateAndUpload,
        }},
        w11: {{
          bootstrap: runW11TrackerBootstrap,
          refresh: runW11Tracker,
          readiness: runW11Readiness,
          complete: runW11Complete,
          update: runW11TrackerUpdateAndUpload,
        }},
        w15: {{
          bootstrap: runW15TrackerBootstrap,
          refresh: runW15Tracker,
          readiness: runW15Readiness,
          complete: runW15Complete,
          update: runW15TrackerUpdateAndUpload,
        }},
      }};
      Object.keys(sharedTrackerHandlers).forEach((phaseCode) => {{
        const handlers = sharedTrackerHandlers[phaseCode];
        document.getElementById(phaseCode + "TrackBootstrapBtn").addEventListener("click", handlers.bootstrap);
        document.getElementById(phaseCode + "TrackRefreshBtn").addEventListener("click", handlers.refresh);
        document.getElementById(phaseCode + "ReadinessBtn").addEventListener("click", handlers.readiness);
        document.getElementById(phaseCode + "CompleteBtn").addEventListener("click", handlers.complete);
        document.getElementById(phaseCode + "TrackUpdateBtn").addEventListener("click", handlers.update);
      }});
      ["rpMonth", "rpSite"].forEach((id) => {{
        const node = document.getElementById(id);
        if (node) node.addEventListener("input", updateReportLinks);
      }});

      const savedToken = getToken();
      if (savedToken) {{
        tokenInput.value = savedToken;
      }}
      updateAuthStateFromToken();
      updateReportLinks();
      if (!document.getElementById("w02TrackSite").value) {{
        document.getElementById("w02TrackSite").value = "HQ";
      }}
      if (!document.getElementById("w03TrackSite").value) {{
        document.getElementById("w03TrackSite").value = "HQ";
      }}
      if (!document.getElementById("w04TrackSite").value) {{
        document.getElementById("w04TrackSite").value = "HQ";
      }}
      if (!document.getElementById("w04FunnelSite").value) {{
        document.getElementById("w04FunnelSite").value = "HQ";
      }}
      if (!document.getElementById("w05ConsistencySite").value) {{
        document.getElementById("w05ConsistencySite").value = "HQ";
      }}
      if (!document.getElementById("w06RhythmSite").value) {{
        document.getElementById("w06RhythmSite").value = "HQ";
      }}
      if (!document.getElementById("w07QualitySite").value) {{
        document.getElementById("w07QualitySite").value = "HQ";
      }}
      if (!document.getElementById("w07TrackSite").value) {{
        document.getElementById("w07TrackSite").value = "HQ";
      }}
      if (!document.getElementById("w07WeeklySite").value) {{
        document.getElementById("w07WeeklySite").value = "HQ";
      }}
      if (!document.getElementById("w08DisciplineSite").value) {{
        document.getElementById("w08DisciplineSite").value = "HQ";
      }}
      ["w09KpiSite", "w10KpiSite", "w11KpiSite", "w15KpiSite"].forEach((id) => {{
        const node = document.getElementById(id);
        if (node && !node.value) {{
          node.value = "HQ";
        }}
      }});
      ["w09", "w10", "w11", "w15"].forEach((phaseCode) => {{
        setSharedTrackerSiteDefault(getSharedTrackerConfig(phaseCode), "HQ");
      }});
      renderW07SelectionMeta();
      renderW07ActionResultsPanel();
      activate("{selected_tab}", false);

      runAdoption();
      if (savedToken) {{
        runAuthMe().then(() => runOverview()).catch(() => {{
          setAuthState(" :    .   .");
        }});
      }}
    }})();
  </script>
</body>
</html>
"""


@app.get("/api/service-info")
def service_info() -> dict[str, str]:
    return _service_info_payload()


@app.get("/web/console", response_model=None)
def facility_console() -> HTMLResponse:
    return HTMLResponse(_build_facility_console_html(_service_info_payload(), _facility_modules_payload()))


@app.get("/web/adoption", response_model=None)
def adoption_portal() -> HTMLResponse:
    return HTMLResponse(_build_public_main_page_html(_service_info_payload(), _adoption_plan_payload()))


@app.get("/", response_model=None)
def root(request: Request) -> Any:
    accept = request.headers.get("accept", "").lower()
    if "text/html" in accept:
        selected_tab = request.query_params.get("tab", "").strip().lower()
        return HTMLResponse(_build_system_main_tabs_html(_service_info_payload(), initial_tab=selected_tab))
    return _service_info_payload()


@app.get("/api/public/adoption-plan")
def get_public_adoption_plan() -> dict[str, Any]:
    return _adoption_plan_payload()


@app.get("/api/public/adoption-plan/campaign")
def get_public_adoption_campaign() -> dict[str, Any]:
    plan = _adoption_plan_payload()
    return {
        "title": plan.get("title"),
        "public": plan.get("public", True),
        "campaign_kit": plan.get("campaign_kit", {}),
    }


@app.get("/api/public/adoption-plan/w02")
def get_public_adoption_w02() -> dict[str, Any]:
    return _adoption_w02_payload()


@app.get("/api/public/adoption-plan/w03")
def get_public_adoption_w03() -> dict[str, Any]:
    return _adoption_w03_payload()


@app.get("/api/public/adoption-plan/w04")
def get_public_adoption_w04() -> dict[str, Any]:
    return _adoption_w04_payload()


@app.get("/api/public/adoption-plan/w05")
def get_public_adoption_w05() -> dict[str, Any]:
    return _adoption_w05_payload()


@app.get("/api/public/adoption-plan/w06")
def get_public_adoption_w06() -> dict[str, Any]:
    return _adoption_w06_payload()


@app.get("/api/public/adoption-plan/w07")
def get_public_adoption_w07() -> dict[str, Any]:
    return _adoption_w07_payload()


@app.get("/api/public/adoption-plan/w08")
def get_public_adoption_w08() -> dict[str, Any]:
    return _adoption_w08_payload()


@app.get("/api/public/adoption-plan/w09")
def get_public_adoption_w09() -> dict[str, Any]:
    return _adoption_w09_payload()


@app.get("/api/public/adoption-plan/w10")
def get_public_adoption_w10() -> dict[str, Any]:
    return _adoption_w10_payload()


@app.get("/api/public/adoption-plan/w11")
def get_public_adoption_w11() -> dict[str, Any]:
    return _adoption_w11_payload()


@app.get("/api/public/adoption-plan/w12")
def get_public_adoption_w12() -> dict[str, Any]:
    return _adoption_w12_payload()


@app.get("/api/public/adoption-plan/w13")
def get_public_adoption_w13() -> dict[str, Any]:
    return _adoption_w13_payload()


@app.get("/api/public/adoption-plan/w14")
def get_public_adoption_w14() -> dict[str, Any]:
    return _adoption_w14_payload()



@app.get("/api/public/adoption-plan/w15")
def get_public_adoption_w15() -> dict[str, Any]:
    return _adoption_w15_payload()




@app.get("/api/public/modules", response_model=None)
def get_public_modules(request: Request) -> Any:
    payload = _facility_modules_payload()
    accept = request.headers.get("accept", "").lower()
    if "text/html" in accept:
        return HTMLResponse(_build_public_modules_html(payload))
    return payload


@app.get("/api/public/adoption-plan/schedule.csv")
def get_public_adoption_plan_schedule_csv() -> Response:
    plan = _adoption_plan_payload()
    csv_text = _build_adoption_plan_schedule_csv(plan)
    file_name = f"ka-facility-os-adoption-plan-{ADOPTION_PLAN_START.isoformat()}-{ADOPTION_PLAN_END.isoformat()}.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/schedule.ics")
def get_public_adoption_plan_schedule_ics() -> Response:
    plan = _adoption_plan_payload()
    ics_text = _build_adoption_plan_schedule_ics(plan)
    file_name = f"ka-facility-os-adoption-plan-{ADOPTION_PLAN_START.isoformat()}-{ADOPTION_PLAN_END.isoformat()}.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w02/checklist.csv")
def get_public_adoption_w02_checklist_csv() -> Response:
    payload = _adoption_w02_payload()
    csv_text = _build_adoption_w02_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w02-sop-sandbox-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w02/schedule.ics")
def get_public_adoption_w02_schedule_ics() -> Response:
    payload = _adoption_w02_payload()
    ics_text = _build_adoption_w02_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w02-sop-sandbox.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w03/checklist.csv")
def get_public_adoption_w03_checklist_csv() -> Response:
    payload = _adoption_w03_payload()
    csv_text = _build_adoption_w03_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w03-go-live-onboarding-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w03/schedule.ics")
def get_public_adoption_w03_schedule_ics() -> Response:
    payload = _adoption_w03_payload()
    ics_text = _build_adoption_w03_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w03-go-live-onboarding.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w04/checklist.csv")
def get_public_adoption_w04_checklist_csv() -> Response:
    payload = _adoption_w04_payload()
    csv_text = _build_adoption_w04_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w04-first-success-acceleration-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w04/schedule.ics")
def get_public_adoption_w04_schedule_ics() -> Response:
    payload = _adoption_w04_payload()
    ics_text = _build_adoption_w04_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w04-first-success-acceleration.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w04/common-mistakes")
def get_public_adoption_w04_common_mistakes(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
) -> dict[str, Any]:
    return _build_w04_common_mistakes_payload(site=site, days=days, allowed_sites=None)


@app.get("/web/adoption/w04/common-mistakes", response_model=None)
def get_public_adoption_w04_common_mistakes_html(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
) -> HTMLResponse:
    payload = _build_w04_common_mistakes_payload(site=site, days=days, allowed_sites=None)
    return HTMLResponse(_build_w04_common_mistakes_html(payload))


@app.get("/api/public/adoption-plan/w05/missions.csv")
def get_public_adoption_w05_missions_csv() -> Response:
    payload = _adoption_w05_payload()
    csv_text = _build_adoption_w05_missions_csv(payload)
    file_name = "ka-facility-os-adoption-w05-usage-consistency-missions.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w05/schedule.ics")
def get_public_adoption_w05_schedule_ics() -> Response:
    payload = _adoption_w05_payload()
    ics_text = _build_adoption_w05_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w05-usage-consistency.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w05/help-docs")
def get_public_adoption_w05_help_docs() -> dict[str, Any]:
    payload = _adoption_w05_payload()
    return {
        "title": "W05 Help Docs v2",
        "public": True,
        "timeline": payload.get("timeline", {}),
        "items": payload.get("help_docs", []),
    }


@app.get("/api/public/adoption-plan/w06/checklist.csv")
def get_public_adoption_w06_checklist_csv() -> Response:
    payload = _adoption_w06_payload()
    csv_text = _build_adoption_w06_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w06-operational-rhythm-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w06/schedule.ics")
def get_public_adoption_w06_schedule_ics() -> Response:
    payload = _adoption_w06_payload()
    ics_text = _build_adoption_w06_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w06-operational-rhythm.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w06/rbac-audit-template")
def get_public_adoption_w06_rbac_audit_template() -> dict[str, Any]:
    payload = _adoption_w06_payload()
    return {
        "title": "W06 RBAC Audit Template",
        "public": True,
        "timeline": payload.get("timeline", {}),
        "items": payload.get("rbac_audit_checklist", []),
    }


@app.get("/api/public/adoption-plan/w07/checklist.csv")
def get_public_adoption_w07_checklist_csv() -> Response:
    payload = _adoption_w07_payload()
    csv_text = _build_adoption_w07_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w07-sla-quality-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w07/schedule.ics")
def get_public_adoption_w07_schedule_ics() -> Response:
    payload = _adoption_w07_payload()
    ics_text = _build_adoption_w07_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w07-sla-quality.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w07/coaching-playbook")
def get_public_adoption_w07_coaching_playbook() -> dict[str, Any]:
    payload = _adoption_w07_payload()
    return {
        "title": "W07 Coaching Playbook",
        "public": True,
        "timeline": payload.get("timeline", {}),
        "items": payload.get("coaching_plays", []),
    }


@app.get("/api/public/adoption-plan/w08/checklist.csv")
def get_public_adoption_w08_checklist_csv() -> Response:
    payload = _adoption_w08_payload()
    csv_text = _build_adoption_w08_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w08-report-discipline-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w08/schedule.ics")
def get_public_adoption_w08_schedule_ics() -> Response:
    payload = _adoption_w08_payload()
    ics_text = _build_adoption_w08_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w08-report-discipline.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w09/checklist.csv")
def get_public_adoption_w09_checklist_csv() -> Response:
    payload = _adoption_w09_payload()
    csv_text = _build_adoption_w09_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w09-kpi-operation-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w09/schedule.ics")
def get_public_adoption_w09_schedule_ics() -> Response:
    payload = _adoption_w09_payload()
    ics_text = _build_adoption_w09_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w09-kpi-operation.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w10/checklist.csv")
def get_public_adoption_w10_checklist_csv() -> Response:
    payload = _adoption_w10_payload()
    csv_text = _build_adoption_w10_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w10-self-serve-support-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w10/schedule.ics")
def get_public_adoption_w10_schedule_ics() -> Response:
    payload = _adoption_w10_payload()
    ics_text = _build_adoption_w10_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w10-self-serve-support.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w11/checklist.csv")
def get_public_adoption_w11_checklist_csv() -> Response:
    payload = _adoption_w11_payload()
    csv_text = _build_adoption_w11_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w11-scale-readiness-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w11/schedule.ics")
def get_public_adoption_w11_schedule_ics() -> Response:
    payload = _adoption_w11_payload()
    ics_text = _build_adoption_w11_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w11-scale-readiness.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w12/checklist.csv")
def get_public_adoption_w12_checklist_csv() -> Response:
    payload = _adoption_w12_payload()
    csv_text = _build_adoption_w12_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w12-closure-handoff-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w12/schedule.ics")
def get_public_adoption_w12_schedule_ics() -> Response:
    payload = _adoption_w12_payload()
    ics_text = _build_adoption_w12_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w12-closure-handoff.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w13/checklist.csv")
def get_public_adoption_w13_checklist_csv() -> Response:
    payload = _adoption_w13_payload()
    csv_text = _build_adoption_w13_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w13-continuous-improvement-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w13/schedule.ics")
def get_public_adoption_w13_schedule_ics() -> Response:
    payload = _adoption_w13_payload()
    ics_text = _build_adoption_w13_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w13-continuous-improvement.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w14/checklist.csv")
def get_public_adoption_w14_checklist_csv() -> Response:
    payload = _adoption_w14_payload()
    csv_text = _build_adoption_w14_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w14-stability-sprint-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w14/schedule.ics")
def get_public_adoption_w14_schedule_ics() -> Response:
    payload = _adoption_w14_payload()
    ics_text = _build_adoption_w14_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w14-stability-sprint.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )



@app.get("/api/public/adoption-plan/w15/checklist.csv")
def get_public_adoption_w15_checklist_csv() -> Response:
    payload = _adoption_w15_payload()
    csv_text = _build_adoption_w15_checklist_csv(payload)
    file_name = "ka-facility-os-adoption-w15-operations-efficiency-checklist.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/adoption-plan/w15/schedule.ics")
def get_public_adoption_w15_schedule_ics() -> Response:
    payload = _adoption_w15_payload()
    ics_text = _build_adoption_w15_schedule_ics(payload)
    file_name = "ka-facility-os-adoption-w15-operations-efficiency.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )




@app.get("/api/public/adoption-plan/w08/reporting-sop")
def get_public_adoption_w08_reporting_sop() -> dict[str, Any]:
    payload = _adoption_w08_payload()
    return {
        "title": "W08 Reporting SOP",
        "public": True,
        "count": len(payload.get("reporting_sop", [])),
        "items": payload.get("reporting_sop", []),
    }


@app.get("/api/public/adoption-plan/w02/sample-files")
def get_public_adoption_w02_sample_files() -> dict[str, Any]:
    return _w02_sample_files_payload()


@app.get("/api/public/adoption-plan/w02/sample-files/{sample_id}", response_model=None)
def download_public_adoption_w02_sample_file(sample_id: str) -> Response:
    artifact = _find_w02_sample_file(sample_id)
    if artifact is None:
        raise HTTPException(status_code=404, detail="W02 sample file not found")

    file_name = _safe_download_filename(
        str(artifact.get("file_name") or f"{sample_id}.txt"),
        fallback="w02-sample.txt",
        max_length=120,
    )
    content_type = str(artifact.get("content_type") or "text/plain").strip().lower() or "text/plain"
    if content_type not in EVIDENCE_ALLOWED_CONTENT_TYPES:
        content_type = "text/plain"
    content_text = str(artifact.get("content") or "")
    return Response(
        content=content_text.encode("utf-8"),
        media_type=f"{content_type}; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/post-mvp")
def get_public_post_mvp_plan() -> dict[str, Any]:
    return _post_mvp_payload()


@app.get("/api/public/post-mvp/backlog.csv")
def get_public_post_mvp_backlog_csv() -> Response:
    plan = _post_mvp_payload()
    csv_text = _build_post_mvp_backlog_csv(plan)
    file_name = f"ka-facility-os-post-mvp-backlog-{POST_MVP_PLAN_START.isoformat()}-{POST_MVP_PLAN_END.isoformat()}.csv"
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/post-mvp/releases.ics")
def get_public_post_mvp_releases_ics() -> Response:
    plan = _post_mvp_payload()
    ics_text = _build_post_mvp_release_ics(plan)
    file_name = f"ka-facility-os-post-mvp-releases-{POST_MVP_PLAN_START.isoformat()}-{POST_MVP_PLAN_END.isoformat()}.ics"
    return Response(
        content=ics_text,
        media_type="text/calendar; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/public/post-mvp/kpi-dashboard")
def get_public_post_mvp_kpi_dashboard() -> dict[str, Any]:
    plan = _post_mvp_payload()
    return {
        "title": plan.get("title"),
        "public": plan.get("public", True),
        "timeline": plan.get("timeline", {}),
        "kpi_dashboard_spec": plan.get("kpi_dashboard_spec", []),
    }


@app.get("/api/public/post-mvp/risks")
def get_public_post_mvp_risks() -> dict[str, Any]:
    plan = _post_mvp_payload()
    return {
        "title": plan.get("title"),
        "public": plan.get("public", True),
        "timeline": plan.get("timeline", {}),
        "risk_register": plan.get("risk_register", []),
    }


@app.post("/api/adoption/w02/tracker/bootstrap", response_model=W02TrackerBootstrapResponse)
def bootstrap_w02_tracker_items(
    payload: W02TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:write")),
) -> W02TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w02_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w02_tracker_items.c.item_type,
                adoption_w02_tracker_items.c.item_key,
            ).where(adoption_w02_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w02_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W02_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w02_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w02_tracker_items)
            .where(adoption_w02_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w02_tracker_items.c.item_type.asc(),
                adoption_w02_tracker_items.c.item_key.asc(),
                adoption_w02_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w02_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w02_tracker_bootstrap",
        resource_type="adoption_w02_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W02TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w02/tracker/items", response_model=list[W02TrackerItemRead])
def list_w02_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> list[W02TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W02_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W02 tracker status")

    stmt = select(adoption_w02_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w02_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w02_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w02_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w02_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w02_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w02_tracker_items.c.updated_at.desc(),
        adoption_w02_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w02_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w02/tracker/overview", response_model=W02TrackerOverviewRead)
def get_w02_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> W02TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w02_tracker_items).where(adoption_w02_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w02_tracker_item_model(row) for row in rows]
    return _compute_w02_tracker_overview(site, models)


@app.get("/api/adoption/w02/tracker/readiness", response_model=W02TrackerReadinessRead)
def get_w02_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> W02TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w02_tracker_items_for_site(site)
    return _compute_w02_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w02/tracker/completion", response_model=W02TrackerCompletionRead)
def get_w02_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> W02TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w02_tracker_items_for_site(site)
    readiness = _compute_w02_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w02_site_runs).where(adoption_w02_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w02_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w02/tracker/complete", response_model=W02TrackerCompletionRead)
def complete_w02_tracker(
    payload: W02TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:write")),
) -> W02TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w02_tracker_items_for_site(payload.site)
    readiness = _compute_w02_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W02 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W02_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W02_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w02_site_runs).where(adoption_w02_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w02_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w02_site_runs)
                .where(adoption_w02_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w02_site_runs).where(adoption_w02_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w02_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w02_tracker_complete",
        resource_type="adoption_w02_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w02/tracker/items/{tracker_item_id}", response_model=W02TrackerItemRead)
def update_w02_tracker_item(
    tracker_item_id: int,
    payload: W02TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:write")),
) -> W02TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w02_tracker_items).where(adoption_w02_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W02 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W02_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W02_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W02_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W02_TRACKER_STATUS_DONE:
            next_status = W02_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W02_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W02 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w02_tracker_items)
            .where(adoption_w02_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w02_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w02_tracker_items).where(adoption_w02_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W02 tracker item")
    model = _row_to_w02_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w02_tracker_item_update",
        resource_type="adoption_w02_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w02/tracker/items/{tracker_item_id}/evidence", response_model=W02EvidenceRead, status_code=201)
async def upload_w02_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:write")),
) -> W02EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(
            status_code=415,
            detail="Unsupported evidence content type",
        )
    file_bytes = await file.read(W02_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W02_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W02_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w02_tracker_items).where(adoption_w02_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W02 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w02_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w02_tracker_items)
            .where(adoption_w02_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        evidence_row = conn.execute(
            select(adoption_w02_evidence_files).where(adoption_w02_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w02_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w02_tracker_evidence_upload",
        resource_type="adoption_w02_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w02/tracker/items/{tracker_item_id}/evidence", response_model=list[W02EvidenceRead])
def list_w02_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> list[W02EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w02_tracker_items).where(adoption_w02_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W02 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w02_evidence_files)
            .where(adoption_w02_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w02_evidence_files.c.uploaded_at.desc(), adoption_w02_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w02_evidence_model(row) for row in rows]


@app.get("/api/adoption/w02/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w02_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w02:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w02_evidence_files).where(adoption_w02_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W02 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w02_tracker_evidence_download",
        resource_type="adoption_w02_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w03/tracker/bootstrap", response_model=W03TrackerBootstrapResponse)
def bootstrap_w03_tracker_items(
    payload: W03TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:write")),
) -> W03TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w03_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w03_tracker_items.c.item_type,
                adoption_w03_tracker_items.c.item_key,
            ).where(adoption_w03_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w03_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W03_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w03_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w03_tracker_items)
            .where(adoption_w03_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w03_tracker_items.c.item_type.asc(),
                adoption_w03_tracker_items.c.item_key.asc(),
                adoption_w03_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w03_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w03_tracker_bootstrap",
        resource_type="adoption_w03_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W03TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w03/tracker/items", response_model=list[W03TrackerItemRead])
def list_w03_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> list[W03TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W03_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W03 tracker status")

    stmt = select(adoption_w03_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w03_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w03_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w03_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w03_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w03_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w03_tracker_items.c.updated_at.desc(),
        adoption_w03_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w03_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w03/tracker/overview", response_model=W03TrackerOverviewRead)
def get_w03_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> W03TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w03_tracker_items).where(adoption_w03_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w03_tracker_item_model(row) for row in rows]
    return _compute_w03_tracker_overview(site, models)


@app.get("/api/adoption/w03/tracker/readiness", response_model=W03TrackerReadinessRead)
def get_w03_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> W03TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w03_tracker_items_for_site(site)
    return _compute_w03_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w03/tracker/completion", response_model=W03TrackerCompletionRead)
def get_w03_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> W03TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w03_tracker_items_for_site(site)
    readiness = _compute_w03_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w03_site_runs).where(adoption_w03_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w03_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w03/tracker/complete", response_model=W03TrackerCompletionRead)
def complete_w03_tracker(
    payload: W03TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:write")),
) -> W03TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w03_tracker_items_for_site(payload.site)
    readiness = _compute_w03_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W03 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W03_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W03_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w03_site_runs).where(adoption_w03_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w03_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w03_site_runs)
                .where(adoption_w03_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w03_site_runs).where(adoption_w03_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w03_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w03_tracker_complete",
        resource_type="adoption_w03_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w03/tracker/items/{tracker_item_id}", response_model=W03TrackerItemRead)
def update_w03_tracker_item(
    tracker_item_id: int,
    payload: W03TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:write")),
) -> W03TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w03_tracker_items).where(adoption_w03_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W03 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W03_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W03_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W03_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W03_TRACKER_STATUS_DONE:
            next_status = W03_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W03_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W03 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w03_tracker_items)
            .where(adoption_w03_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w03_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w03_tracker_items).where(adoption_w03_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W03 tracker item")
    model = _row_to_w03_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w03_tracker_item_update",
        resource_type="adoption_w03_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w03/tracker/items/{tracker_item_id}/evidence", response_model=W03EvidenceRead, status_code=201)
async def upload_w03_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:write")),
) -> W03EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(
            status_code=415,
            detail="Unsupported evidence content type",
        )
    file_bytes = await file.read(W03_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W03_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W03_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w03_tracker_items).where(adoption_w03_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W03 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w03_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w03_tracker_items)
            .where(adoption_w03_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        evidence_row = conn.execute(
            select(adoption_w03_evidence_files).where(adoption_w03_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w03_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w03_tracker_evidence_upload",
        resource_type="adoption_w03_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w03/tracker/items/{tracker_item_id}/evidence", response_model=list[W03EvidenceRead])
def list_w03_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> list[W03EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w03_tracker_items).where(adoption_w03_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W03 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w03_evidence_files)
            .where(adoption_w03_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w03_evidence_files.c.uploaded_at.desc(), adoption_w03_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w03_evidence_model(row) for row in rows]


@app.get("/api/adoption/w03/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w03_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w03:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w03_evidence_files).where(adoption_w03_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W03 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w03_tracker_evidence_download",
        resource_type="adoption_w03_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w04/tracker/bootstrap", response_model=W04TrackerBootstrapResponse)
def bootstrap_w04_tracker_items(
    payload: W04TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:write")),
) -> W04TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w04_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w04_tracker_items.c.item_type,
                adoption_w04_tracker_items.c.item_key,
            ).where(adoption_w04_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w04_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W04_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w04_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w04_tracker_items)
            .where(adoption_w04_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w04_tracker_items.c.item_type.asc(),
                adoption_w04_tracker_items.c.item_key.asc(),
                adoption_w04_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w04_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w04_tracker_bootstrap",
        resource_type="adoption_w04_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W04TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w04/tracker/items", response_model=list[W04TrackerItemRead])
def list_w04_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> list[W04TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W04_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W04 tracker status")

    stmt = select(adoption_w04_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w04_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w04_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w04_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w04_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w04_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w04_tracker_items.c.updated_at.desc(),
        adoption_w04_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w04_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w04/tracker/overview", response_model=W04TrackerOverviewRead)
def get_w04_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> W04TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w04_tracker_items).where(adoption_w04_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w04_tracker_item_model(row) for row in rows]
    return _compute_w04_tracker_overview(site, models)


@app.get("/api/adoption/w04/tracker/readiness", response_model=W04TrackerReadinessRead)
def get_w04_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> W04TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w04_tracker_items_for_site(site)
    return _compute_w04_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w04/tracker/completion", response_model=W04TrackerCompletionRead)
def get_w04_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> W04TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w04_tracker_items_for_site(site)
    readiness = _compute_w04_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w04_site_runs).where(adoption_w04_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w04_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w04/tracker/complete", response_model=W04TrackerCompletionRead)
def complete_w04_tracker(
    payload: W04TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:write")),
) -> W04TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w04_tracker_items_for_site(payload.site)
    readiness = _compute_w04_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W04 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W04_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W04_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w04_site_runs).where(adoption_w04_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w04_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w04_site_runs)
                .where(adoption_w04_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w04_site_runs).where(adoption_w04_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w04_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w04_tracker_complete",
        resource_type="adoption_w04_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w04/tracker/items/{tracker_item_id}", response_model=W04TrackerItemRead)
def update_w04_tracker_item(
    tracker_item_id: int,
    payload: W04TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:write")),
) -> W04TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w04_tracker_items).where(adoption_w04_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W04 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W04_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W04_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W04_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W04_TRACKER_STATUS_DONE:
            next_status = W04_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W04_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W04 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w04_tracker_items)
            .where(adoption_w04_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w04_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w04_tracker_items).where(adoption_w04_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W04 tracker item")
    model = _row_to_w04_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w04_tracker_item_update",
        resource_type="adoption_w04_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w04/tracker/items/{tracker_item_id}/evidence", response_model=W04EvidenceRead, status_code=201)
async def upload_w04_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:write")),
) -> W04EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(
            status_code=415,
            detail="Unsupported evidence content type",
        )
    file_bytes = await file.read(W04_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W04_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W04_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w04_tracker_items).where(adoption_w04_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W04 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w04_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w04_tracker_items)
            .where(adoption_w04_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        evidence_row = conn.execute(
            select(adoption_w04_evidence_files).where(adoption_w04_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w04_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w04_tracker_evidence_upload",
        resource_type="adoption_w04_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w04/tracker/items/{tracker_item_id}/evidence", response_model=list[W04EvidenceRead])
def list_w04_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> list[W04EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w04_tracker_items).where(adoption_w04_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W04 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w04_evidence_files)
            .where(adoption_w04_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w04_evidence_files.c.uploaded_at.desc(), adoption_w04_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w04_evidence_model(row) for row in rows]


@app.get("/api/adoption/w04/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w04_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w04_evidence_files).where(adoption_w04_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W04 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w04_tracker_evidence_download",
        resource_type="adoption_w04_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w07/tracker/bootstrap", response_model=W07TrackerBootstrapResponse)
def bootstrap_w07_tracker_items(
    payload: W07TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:write")),
) -> W07TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w07_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w07_tracker_items.c.item_type,
                adoption_w07_tracker_items.c.item_key,
            ).where(adoption_w07_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w07_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W07_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w07_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w07_tracker_items)
            .where(adoption_w07_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w07_tracker_items.c.item_type.asc(),
                adoption_w07_tracker_items.c.item_key.asc(),
                adoption_w07_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w07_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w07_tracker_bootstrap",
        resource_type="adoption_w07_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W07TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w07/tracker/items", response_model=list[W07TrackerItemRead])
def list_w07_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> list[W07TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W07_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W07 tracker status")

    stmt = select(adoption_w07_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w07_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w07_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w07_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w07_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w07_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w07_tracker_items.c.updated_at.desc(),
        adoption_w07_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w07_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w07/tracker/overview", response_model=W07TrackerOverviewRead)
def get_w07_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> W07TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w07_tracker_items).where(adoption_w07_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w07_tracker_item_model(row) for row in rows]
    return _compute_w07_tracker_overview(site, models)


@app.get("/api/adoption/w07/tracker/readiness", response_model=W07TrackerReadinessRead)
def get_w07_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> W07TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w07_tracker_items_for_site(site)
    return _compute_w07_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w07/tracker/completion", response_model=W07TrackerCompletionRead)
def get_w07_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> W07TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w07_tracker_items_for_site(site)
    readiness = _compute_w07_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w07_site_runs).where(adoption_w07_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w07_completion_model(site=site, readiness=readiness, row=row)


@app.get("/api/adoption/w07/tracker/completion-package", response_model=None)
def download_w07_tracker_completion_package(
    site: Annotated[str, Query(min_length=1)],
    include_evidence: Annotated[bool, Query()] = True,
    include_weekly: Annotated[bool, Query()] = True,
    weekly_limit: Annotated[int, Query(ge=1, le=104)] = 26,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> Response:
    _require_site_access(principal, site)
    checked_at = datetime.now(timezone.utc)
    rows = _load_w07_tracker_items_for_site(site)
    readiness = _compute_w07_tracker_readiness(site=site, rows=rows, checked_at=checked_at)
    with get_conn() as conn:
        completion_row = conn.execute(
            select(adoption_w07_site_runs).where(adoption_w07_site_runs.c.site == site).limit(1)
        ).mappings().first()
    completion = _row_to_w07_completion_model(site=site, readiness=readiness, row=completion_row)
    package_bytes, manifest = _build_w07_completion_package_zip(
        site=site,
        completion=completion,
        rows=rows,
        include_evidence=include_evidence,
        include_weekly=include_weekly,
        weekly_limit=weekly_limit,
        principal=principal,
    )
    timestamp = checked_at.strftime("%Y%m%dT%H%M%SZ")
    file_name = _safe_download_filename(
        f"ka-facility-os-w07-completion-package-{site}-{timestamp}.zip",
        fallback=f"ka-facility-os-w07-completion-package-{timestamp}.zip",
        max_length=140,
    )
    _write_audit_log(
        principal=principal,
        action="w07_completion_package_download",
        resource_type="adoption_w07_package",
        resource_id=site,
        detail={
            "site": site,
            "include_evidence": include_evidence,
            "include_weekly": include_weekly,
            "weekly_limit": weekly_limit,
            "completion_status": completion.status,
            "readiness_ready": completion.readiness.ready,
            "sha256": manifest.get("sha256"),
            "bytes": manifest.get("bytes"),
        },
    )
    return Response(
        content=package_bytes,
        media_type="application/zip",
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Archive-SHA256": str(manifest.get("sha256") or ""),
            "X-Package-Site": site,
        },
    )


@app.post("/api/adoption/w07/tracker/complete", response_model=W07TrackerCompletionRead)
def complete_w07_tracker(
    payload: W07TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:write")),
) -> W07TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w07_tracker_items_for_site(payload.site)
    readiness = _compute_w07_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W07 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W07_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W07_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w07_site_runs).where(adoption_w07_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w07_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w07_site_runs)
                .where(adoption_w07_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w07_site_runs).where(adoption_w07_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w07_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w07_tracker_complete",
        resource_type="adoption_w07_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w07/tracker/items/{tracker_item_id}", response_model=W07TrackerItemRead)
def update_w07_tracker_item(
    tracker_item_id: int,
    payload: W07TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:write")),
) -> W07TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w07_tracker_items).where(adoption_w07_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W07 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W07_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W07_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W07_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W07_TRACKER_STATUS_DONE:
            next_status = W07_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W07_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W07 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w07_tracker_items)
            .where(adoption_w07_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w07_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w07_tracker_items).where(adoption_w07_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W07 tracker item")
    model = _row_to_w07_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w07_tracker_item_update",
        resource_type="adoption_w07_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w07/tracker/items/{tracker_item_id}/evidence", response_model=W07EvidenceRead, status_code=201)
async def upload_w07_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:write")),
) -> W07EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(
            status_code=415,
            detail="Unsupported evidence content type",
        )
    file_bytes = await file.read(W07_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W07_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W07_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w07_tracker_items).where(adoption_w07_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W07 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w07_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w07_tracker_items)
            .where(adoption_w07_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        evidence_row = conn.execute(
            select(adoption_w07_evidence_files).where(adoption_w07_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w07_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w07_tracker_evidence_upload",
        resource_type="adoption_w07_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w07/tracker/items/{tracker_item_id}/evidence", response_model=list[W07EvidenceRead])
def list_w07_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> list[W07EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w07_tracker_items).where(adoption_w07_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W07 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w07_evidence_files)
            .where(adoption_w07_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w07_evidence_files.c.uploaded_at.desc(), adoption_w07_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w07_evidence_model(row) for row in rows]


@app.get("/api/adoption/w07/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w07_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w07_evidence_files).where(adoption_w07_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W07 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w07_tracker_evidence_download",
        resource_type="adoption_w07_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )



@app.post("/api/adoption/w09/tracker/bootstrap", response_model=W09TrackerBootstrapResponse)
def bootstrap_w09_tracker_items(
    payload: W09TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:write")),
) -> W09TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w09_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w09_tracker_items.c.item_type,
                adoption_w09_tracker_items.c.item_key,
            ).where(adoption_w09_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w09_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W09_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w09_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w09_tracker_items)
            .where(adoption_w09_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w09_tracker_items.c.item_type.asc(),
                adoption_w09_tracker_items.c.item_key.asc(),
                adoption_w09_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w09_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w09_tracker_bootstrap",
        resource_type="adoption_w09_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W09TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w09/tracker/items", response_model=list[W09TrackerItemRead])
def list_w09_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> list[W09TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W09_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W09 tracker status")

    stmt = select(adoption_w09_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w09_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w09_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w09_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w09_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w09_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w09_tracker_items.c.updated_at.desc(),
        adoption_w09_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w09_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w09/tracker/overview", response_model=W09TrackerOverviewRead)
def get_w09_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> W09TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w09_tracker_items).where(adoption_w09_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w09_tracker_item_model(row) for row in rows]
    return _compute_w09_tracker_overview(site, models)


@app.get("/api/adoption/w09/tracker/readiness", response_model=W09TrackerReadinessRead)
def get_w09_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> W09TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w09_tracker_items_for_site(site)
    return _compute_w09_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w09/tracker/completion", response_model=W09TrackerCompletionRead)
def get_w09_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> W09TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w09_tracker_items_for_site(site)
    readiness = _compute_w09_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w09_site_runs).where(adoption_w09_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w09_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w09/tracker/complete", response_model=W09TrackerCompletionRead)
def complete_w09_tracker(
    payload: W09TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:write")),
) -> W09TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w09_tracker_items_for_site(payload.site)
    readiness = _compute_w09_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W09 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W09_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W09_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w09_site_runs).where(adoption_w09_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w09_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w09_site_runs)
                .where(adoption_w09_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w09_site_runs).where(adoption_w09_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w09_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w09_tracker_complete",
        resource_type="adoption_w09_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w09/tracker/items/{tracker_item_id}", response_model=W09TrackerItemRead)
def update_w09_tracker_item(
    tracker_item_id: int,
    payload: W09TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:write")),
) -> W09TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w09_tracker_items).where(adoption_w09_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W09 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W09_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W09_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W09_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W09_TRACKER_STATUS_DONE:
            next_status = W09_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W09_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W09 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w09_tracker_items)
            .where(adoption_w09_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w09_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w09_tracker_items).where(adoption_w09_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W09 tracker item")
    model = _row_to_w09_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w09_tracker_item_update",
        resource_type="adoption_w09_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w09/tracker/items/{tracker_item_id}/evidence", response_model=W09EvidenceRead, status_code=201)
async def upload_w09_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:write")),
) -> W09EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W09_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W09_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W09_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w09_tracker_items).where(adoption_w09_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W09 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w09_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w09_tracker_items)
            .where(adoption_w09_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w09_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w09_evidence_files).where(adoption_w09_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w09_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w09_tracker_evidence_upload",
        resource_type="adoption_w09_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w09/tracker/items/{tracker_item_id}/evidence", response_model=list[W09EvidenceRead])
def list_w09_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> list[W09EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w09_tracker_items).where(adoption_w09_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W09 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w09_evidence_files)
            .where(adoption_w09_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w09_evidence_files.c.uploaded_at.desc(), adoption_w09_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w09_evidence_model(row) for row in rows]


@app.get("/api/adoption/w09/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w09_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w09_evidence_files).where(adoption_w09_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W09 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w09_tracker_evidence_download",
        resource_type="adoption_w09_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )




@app.post("/api/adoption/w10/tracker/bootstrap", response_model=W10TrackerBootstrapResponse)
def bootstrap_w10_tracker_items(
    payload: W10TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:write")),
) -> W10TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w10_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w10_tracker_items.c.item_type,
                adoption_w10_tracker_items.c.item_key,
            ).where(adoption_w10_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w10_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W10_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w10_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w10_tracker_items)
            .where(adoption_w10_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w10_tracker_items.c.item_type.asc(),
                adoption_w10_tracker_items.c.item_key.asc(),
                adoption_w10_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w10_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w10_tracker_bootstrap",
        resource_type="adoption_w10_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W10TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w10/tracker/items", response_model=list[W10TrackerItemRead])
def list_w10_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> list[W10TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W10_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W10 tracker status")

    stmt = select(adoption_w10_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w10_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w10_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w10_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w10_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w10_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w10_tracker_items.c.updated_at.desc(),
        adoption_w10_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w10_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w10/tracker/overview", response_model=W10TrackerOverviewRead)
def get_w10_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> W10TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w10_tracker_items).where(adoption_w10_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w10_tracker_item_model(row) for row in rows]
    return _compute_w10_tracker_overview(site, models)


@app.get("/api/adoption/w10/tracker/readiness", response_model=W10TrackerReadinessRead)
def get_w10_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> W10TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w10_tracker_items_for_site(site)
    return _compute_w10_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w10/tracker/completion", response_model=W10TrackerCompletionRead)
def get_w10_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> W10TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w10_tracker_items_for_site(site)
    readiness = _compute_w10_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w10_site_runs).where(adoption_w10_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w10_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w10/tracker/complete", response_model=W10TrackerCompletionRead)
def complete_w10_tracker(
    payload: W10TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:write")),
) -> W10TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w10_tracker_items_for_site(payload.site)
    readiness = _compute_w10_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W10 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W10_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W10_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w10_site_runs).where(adoption_w10_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w10_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w10_site_runs)
                .where(adoption_w10_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w10_site_runs).where(adoption_w10_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w10_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w10_tracker_complete",
        resource_type="adoption_w10_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w10/tracker/items/{tracker_item_id}", response_model=W10TrackerItemRead)
def update_w10_tracker_item(
    tracker_item_id: int,
    payload: W10TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:write")),
) -> W10TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w10_tracker_items).where(adoption_w10_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W10 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W10_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W10_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W10_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W10_TRACKER_STATUS_DONE:
            next_status = W10_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W10_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W10 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w10_tracker_items)
            .where(adoption_w10_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w10_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w10_tracker_items).where(adoption_w10_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W10 tracker item")
    model = _row_to_w10_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w10_tracker_item_update",
        resource_type="adoption_w10_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w10/tracker/items/{tracker_item_id}/evidence", response_model=W10EvidenceRead, status_code=201)
async def upload_w10_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:write")),
) -> W10EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W10_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W10_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W10_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w10_tracker_items).where(adoption_w10_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W10 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w10_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        next_count = int(tracker_row.get("evidence_count") or 0) + 1
        conn.execute(
            update(adoption_w10_tracker_items)
            .where(adoption_w10_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=next_count,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w10_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w10_evidence_files).where(adoption_w10_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w10_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w10_tracker_evidence_upload",
        resource_type="adoption_w10_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w10/tracker/items/{tracker_item_id}/evidence", response_model=list[W10EvidenceRead])
def list_w10_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> list[W10EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w10_tracker_items).where(adoption_w10_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W10 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w10_evidence_files)
            .where(adoption_w10_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w10_evidence_files.c.uploaded_at.desc(), adoption_w10_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w10_evidence_model(row) for row in rows]


@app.get("/api/adoption/w10/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w10_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w10_evidence_files).where(adoption_w10_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W10 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w10_tracker_evidence_download",
        resource_type="adoption_w10_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w11/tracker/bootstrap", response_model=W11TrackerBootstrapResponse)
def bootstrap_w11_tracker_items(
    payload: W11TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:write")),
) -> W11TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w11_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w11_tracker_items.c.item_type,
                adoption_w11_tracker_items.c.item_key,
            ).where(adoption_w11_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w11_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W11_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w11_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w11_tracker_items)
            .where(adoption_w11_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w11_tracker_items.c.item_type.asc(),
                adoption_w11_tracker_items.c.item_key.asc(),
                adoption_w11_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w11_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w11_tracker_bootstrap",
        resource_type="adoption_w11_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W11TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w11/tracker/items", response_model=list[W11TrackerItemRead])
def list_w11_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> list[W11TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W11_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W11 tracker status")

    stmt = select(adoption_w11_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w11_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w11_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w11_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w11_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w11_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w11_tracker_items.c.updated_at.desc(),
        adoption_w11_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w11_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w11/tracker/overview", response_model=W11TrackerOverviewRead)
def get_w11_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> W11TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w11_tracker_items).where(adoption_w11_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w11_tracker_item_model(row) for row in rows]
    return _compute_w11_tracker_overview(site, models)


@app.get("/api/adoption/w11/tracker/readiness", response_model=W11TrackerReadinessRead)
def get_w11_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> W11TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w11_tracker_items_for_site(site)
    return _compute_w11_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w11/tracker/completion", response_model=W11TrackerCompletionRead)
def get_w11_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> W11TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w11_tracker_items_for_site(site)
    readiness = _compute_w11_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w11_site_runs).where(adoption_w11_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w11_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w11/tracker/complete", response_model=W11TrackerCompletionRead)
def complete_w11_tracker(
    payload: W11TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:write")),
) -> W11TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w11_tracker_items_for_site(payload.site)
    readiness = _compute_w11_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W11 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W11_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W11_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w11_site_runs).where(adoption_w11_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w11_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w11_site_runs)
                .where(adoption_w11_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w11_site_runs).where(adoption_w11_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w11_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w11_tracker_complete",
        resource_type="adoption_w11_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w11/tracker/items/{tracker_item_id}", response_model=W11TrackerItemRead)
def update_w11_tracker_item(
    tracker_item_id: int,
    payload: W11TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:write")),
) -> W11TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w11_tracker_items).where(adoption_w11_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W11 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W11_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W11_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W11_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W11_TRACKER_STATUS_DONE:
            next_status = W11_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W11_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W11 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w11_tracker_items)
            .where(adoption_w11_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w11_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w11_tracker_items).where(adoption_w11_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W11 tracker item")
    model = _row_to_w11_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w11_tracker_item_update",
        resource_type="adoption_w11_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w11/tracker/items/{tracker_item_id}/evidence", response_model=W11EvidenceRead, status_code=201)
async def upload_w11_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:write")),
) -> W11EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W11_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W11_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W11_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w11_tracker_items).where(adoption_w11_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W11 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w11_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        conn.execute(
            update(adoption_w11_tracker_items)
            .where(adoption_w11_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=adoption_w11_tracker_items.c.evidence_count + 1,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w11_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w11_evidence_files).where(adoption_w11_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w11_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w11_tracker_evidence_upload",
        resource_type="adoption_w11_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w11/tracker/items/{tracker_item_id}/evidence", response_model=list[W11EvidenceRead])
def list_w11_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> list[W11EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w11_tracker_items).where(adoption_w11_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W11 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w11_evidence_files)
            .where(adoption_w11_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w11_evidence_files.c.uploaded_at.desc(), adoption_w11_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w11_evidence_model(row) for row in rows]


@app.get("/api/adoption/w11/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w11_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w11_evidence_files).where(adoption_w11_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W11 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w11_tracker_evidence_download",
        resource_type="adoption_w11_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w12/tracker/bootstrap", response_model=W12TrackerBootstrapResponse)
def bootstrap_w12_tracker_items(
    payload: W12TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:write")),
) -> W12TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w12_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w12_tracker_items.c.item_type,
                adoption_w12_tracker_items.c.item_key,
            ).where(adoption_w12_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w12_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W12_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w12_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w12_tracker_items)
            .where(adoption_w12_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w12_tracker_items.c.item_type.asc(),
                adoption_w12_tracker_items.c.item_key.asc(),
                adoption_w12_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w12_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w12_tracker_bootstrap",
        resource_type="adoption_w12_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W12TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w12/tracker/items", response_model=list[W12TrackerItemRead])
def list_w12_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> list[W12TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W12_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W12 tracker status")

    stmt = select(adoption_w12_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w12_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w12_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w12_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w12_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w12_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w12_tracker_items.c.updated_at.desc(),
        adoption_w12_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w12_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w12/tracker/overview", response_model=W12TrackerOverviewRead)
def get_w12_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> W12TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w12_tracker_items).where(adoption_w12_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w12_tracker_item_model(row) for row in rows]
    return _compute_w12_tracker_overview(site, models)


@app.get("/api/adoption/w12/tracker/readiness", response_model=W12TrackerReadinessRead)
def get_w12_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> W12TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w12_tracker_items_for_site(site)
    return _compute_w12_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w12/tracker/completion", response_model=W12TrackerCompletionRead)
def get_w12_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> W12TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w12_tracker_items_for_site(site)
    readiness = _compute_w12_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w12_site_runs).where(adoption_w12_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w12_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w12/tracker/complete", response_model=W12TrackerCompletionRead)
def complete_w12_tracker(
    payload: W12TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:write")),
) -> W12TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w12_tracker_items_for_site(payload.site)
    readiness = _compute_w12_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W12 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W12_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W12_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w12_site_runs).where(adoption_w12_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w12_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w12_site_runs)
                .where(adoption_w12_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w12_site_runs).where(adoption_w12_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w12_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w12_tracker_complete",
        resource_type="adoption_w12_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w12/tracker/items/{tracker_item_id}", response_model=W12TrackerItemRead)
def update_w12_tracker_item(
    tracker_item_id: int,
    payload: W12TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:write")),
) -> W12TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w12_tracker_items).where(adoption_w12_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W12 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W12_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W12_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W12_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W12_TRACKER_STATUS_DONE:
            next_status = W12_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W12_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W12 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w12_tracker_items)
            .where(adoption_w12_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w12_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w12_tracker_items).where(adoption_w12_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W12 tracker item")
    model = _row_to_w12_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w12_tracker_item_update",
        resource_type="adoption_w12_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w12/tracker/items/{tracker_item_id}/evidence", response_model=W12EvidenceRead, status_code=201)
async def upload_w12_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:write")),
) -> W12EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W12_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W12_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W12_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w12_tracker_items).where(adoption_w12_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W12 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w12_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        conn.execute(
            update(adoption_w12_tracker_items)
            .where(adoption_w12_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=adoption_w12_tracker_items.c.evidence_count + 1,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w12_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w12_evidence_files).where(adoption_w12_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w12_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w12_tracker_evidence_upload",
        resource_type="adoption_w12_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w12/tracker/items/{tracker_item_id}/evidence", response_model=list[W12EvidenceRead])
def list_w12_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> list[W12EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w12_tracker_items).where(adoption_w12_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W12 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w12_evidence_files)
            .where(adoption_w12_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w12_evidence_files.c.uploaded_at.desc(), adoption_w12_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w12_evidence_model(row) for row in rows]


@app.get("/api/adoption/w12/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w12_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w12_evidence_files).where(adoption_w12_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W12 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w12_tracker_evidence_download",
        resource_type="adoption_w12_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w13/tracker/bootstrap", response_model=W13TrackerBootstrapResponse)
def bootstrap_w13_tracker_items(
    payload: W13TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:write")),
) -> W13TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w13_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w13_tracker_items.c.item_type,
                adoption_w13_tracker_items.c.item_key,
            ).where(adoption_w13_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w13_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W13_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w13_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w13_tracker_items)
            .where(adoption_w13_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w13_tracker_items.c.item_type.asc(),
                adoption_w13_tracker_items.c.item_key.asc(),
                adoption_w13_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w13_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w13_tracker_bootstrap",
        resource_type="adoption_w13_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W13TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w13/tracker/items", response_model=list[W13TrackerItemRead])
def list_w13_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> list[W13TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W13_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W13 tracker status")

    stmt = select(adoption_w13_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w13_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w13_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w13_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w13_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w13_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w13_tracker_items.c.updated_at.desc(),
        adoption_w13_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w13_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w13/tracker/overview", response_model=W13TrackerOverviewRead)
def get_w13_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> W13TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w13_tracker_items).where(adoption_w13_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w13_tracker_item_model(row) for row in rows]
    return _compute_w13_tracker_overview(site, models)


@app.get("/api/adoption/w13/tracker/readiness", response_model=W13TrackerReadinessRead)
def get_w13_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> W13TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w13_tracker_items_for_site(site)
    return _compute_w13_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w13/tracker/completion", response_model=W13TrackerCompletionRead)
def get_w13_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> W13TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w13_tracker_items_for_site(site)
    readiness = _compute_w13_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w13_site_runs).where(adoption_w13_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w13_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w13/tracker/complete", response_model=W13TrackerCompletionRead)
def complete_w13_tracker(
    payload: W13TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:write")),
) -> W13TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w13_tracker_items_for_site(payload.site)
    readiness = _compute_w13_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W13 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W13_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W13_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w13_site_runs).where(adoption_w13_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w13_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w13_site_runs)
                .where(adoption_w13_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w13_site_runs).where(adoption_w13_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w13_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w13_tracker_complete",
        resource_type="adoption_w13_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w13/tracker/items/{tracker_item_id}", response_model=W13TrackerItemRead)
def update_w13_tracker_item(
    tracker_item_id: int,
    payload: W13TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:write")),
) -> W13TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w13_tracker_items).where(adoption_w13_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W13 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W13_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W13_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W13_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W13_TRACKER_STATUS_DONE:
            next_status = W13_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W13_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W13 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w13_tracker_items)
            .where(adoption_w13_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w13_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w13_tracker_items).where(adoption_w13_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W13 tracker item")
    model = _row_to_w13_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w13_tracker_item_update",
        resource_type="adoption_w13_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w13/tracker/items/{tracker_item_id}/evidence", response_model=W13EvidenceRead, status_code=201)
async def upload_w13_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:write")),
) -> W13EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W13_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W13_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W13_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w13_tracker_items).where(adoption_w13_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W13 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w13_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        conn.execute(
            update(adoption_w13_tracker_items)
            .where(adoption_w13_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=adoption_w13_tracker_items.c.evidence_count + 1,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w13_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w13_evidence_files).where(adoption_w13_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w13_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w13_tracker_evidence_upload",
        resource_type="adoption_w13_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w13/tracker/items/{tracker_item_id}/evidence", response_model=list[W13EvidenceRead])
def list_w13_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> list[W13EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w13_tracker_items).where(adoption_w13_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W13 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w13_evidence_files)
            .where(adoption_w13_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w13_evidence_files.c.uploaded_at.desc(), adoption_w13_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w13_evidence_model(row) for row in rows]


@app.get("/api/adoption/w13/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w13_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w13_evidence_files).where(adoption_w13_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W13 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w13_tracker_evidence_download",
        resource_type="adoption_w13_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )

@app.post("/api/adoption/w14/tracker/bootstrap", response_model=W14TrackerBootstrapResponse)
def bootstrap_w14_tracker_items(
    payload: W14TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:write")),
) -> W14TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w14_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w14_tracker_items.c.item_type,
                adoption_w14_tracker_items.c.item_key,
            ).where(adoption_w14_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w14_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W14_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w14_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w14_tracker_items)
            .where(adoption_w14_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w14_tracker_items.c.item_type.asc(),
                adoption_w14_tracker_items.c.item_key.asc(),
                adoption_w14_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w14_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w14_tracker_bootstrap",
        resource_type="adoption_w14_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W14TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w14/tracker/items", response_model=list[W14TrackerItemRead])
def list_w14_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> list[W14TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W14_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W14 tracker status")

    stmt = select(adoption_w14_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w14_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w14_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w14_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w14_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w14_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w14_tracker_items.c.updated_at.desc(),
        adoption_w14_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w14_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w14/tracker/overview", response_model=W14TrackerOverviewRead)
def get_w14_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> W14TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w14_tracker_items).where(adoption_w14_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w14_tracker_item_model(row) for row in rows]
    return _compute_w14_tracker_overview(site, models)


@app.get("/api/adoption/w14/tracker/readiness", response_model=W14TrackerReadinessRead)
def get_w14_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> W14TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w14_tracker_items_for_site(site)
    return _compute_w14_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w14/tracker/completion", response_model=W14TrackerCompletionRead)
def get_w14_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> W14TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w14_tracker_items_for_site(site)
    readiness = _compute_w14_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w14_site_runs).where(adoption_w14_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w14_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w14/tracker/complete", response_model=W14TrackerCompletionRead)
def complete_w14_tracker(
    payload: W14TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:write")),
) -> W14TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w14_tracker_items_for_site(payload.site)
    readiness = _compute_w14_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W14 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W14_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W14_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w14_site_runs).where(adoption_w14_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w14_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w14_site_runs)
                .where(adoption_w14_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w14_site_runs).where(adoption_w14_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w14_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w14_tracker_complete",
        resource_type="adoption_w14_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w14/tracker/items/{tracker_item_id}", response_model=W14TrackerItemRead)
def update_w14_tracker_item(
    tracker_item_id: int,
    payload: W14TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:write")),
) -> W14TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w14_tracker_items).where(adoption_w14_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W14 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W14_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W14_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W14_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W14_TRACKER_STATUS_DONE:
            next_status = W14_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W14_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W14 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w14_tracker_items)
            .where(adoption_w14_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w14_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w14_tracker_items).where(adoption_w14_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W14 tracker item")
    model = _row_to_w14_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w14_tracker_item_update",
        resource_type="adoption_w14_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w14/tracker/items/{tracker_item_id}/evidence", response_model=W14EvidenceRead, status_code=201)
async def upload_w14_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:write")),
) -> W14EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W14_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W14_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W14_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w14_tracker_items).where(adoption_w14_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W14 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w14_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        conn.execute(
            update(adoption_w14_tracker_items)
            .where(adoption_w14_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=adoption_w14_tracker_items.c.evidence_count + 1,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w14_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w14_evidence_files).where(adoption_w14_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w14_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w14_tracker_evidence_upload",
        resource_type="adoption_w14_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w14/tracker/items/{tracker_item_id}/evidence", response_model=list[W14EvidenceRead])
def list_w14_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> list[W14EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w14_tracker_items).where(adoption_w14_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W14 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w14_evidence_files)
            .where(adoption_w14_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w14_evidence_files.c.uploaded_at.desc(), adoption_w14_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w14_evidence_model(row) for row in rows]


@app.get("/api/adoption/w14/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w14_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w14_evidence_files).where(adoption_w14_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W14 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w14_tracker_evidence_download",
        resource_type="adoption_w14_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )


@app.post("/api/adoption/w15/tracker/bootstrap", response_model=W15TrackerBootstrapResponse)
def bootstrap_w15_tracker_items(
    payload: W15TrackerBootstrapRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:write")),
) -> W15TrackerBootstrapResponse:
    _require_site_access(principal, payload.site)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    catalog = _adoption_w15_catalog_items(payload.site)
    created_count = 0

    with get_conn() as conn:
        existing_rows = conn.execute(
            select(
                adoption_w15_tracker_items.c.item_type,
                adoption_w15_tracker_items.c.item_key,
            ).where(adoption_w15_tracker_items.c.site == payload.site)
        ).mappings().all()
        existing_keys = {(str(row["item_type"]), str(row["item_key"])) for row in existing_rows}

        for entry in catalog:
            key = (str(entry["item_type"]), str(entry["item_key"]))
            if key in existing_keys:
                continue
            conn.execute(
                insert(adoption_w15_tracker_items).values(
                    site=payload.site,
                    item_type=str(entry["item_type"]),
                    item_key=str(entry["item_key"]),
                    item_name=str(entry["item_name"]),
                    assignee=None,
                    status=W15_TRACKER_STATUS_PENDING,
                    completion_checked=False,
                    completion_note="",
                    due_at=entry.get("due_at"),
                    completed_at=None,
                    evidence_count=0,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
            existing_keys.add(key)
            created_count += 1

        if created_count > 0:
            _reset_w15_completion_if_closed(
                conn=conn,
                site=payload.site,
                actor_username=actor_username,
                checked_at=now,
                reason="bootstrap_added_items",
            )

        rows = conn.execute(
            select(adoption_w15_tracker_items)
            .where(adoption_w15_tracker_items.c.site == payload.site)
            .order_by(
                adoption_w15_tracker_items.c.item_type.asc(),
                adoption_w15_tracker_items.c.item_key.asc(),
                adoption_w15_tracker_items.c.id.asc(),
            )
        ).mappings().all()

    items = [_row_to_w15_tracker_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="w15_tracker_bootstrap",
        resource_type="adoption_w15_tracker",
        resource_id=payload.site,
        detail={"site": payload.site, "created_count": created_count, "total_count": len(items)},
    )
    return W15TrackerBootstrapResponse(
        site=payload.site,
        created_count=created_count,
        total_count=len(items),
        items=items,
    )


@app.get("/api/adoption/w15/tracker/items", response_model=list[W15TrackerItemRead])
def list_w15_tracker_items(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    item_type: Annotated[str | None, Query()] = None,
    assignee: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> list[W15TrackerItemRead]:
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in W15_TRACKER_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid W15 tracker status")

    stmt = select(adoption_w15_tracker_items)
    if site is not None:
        stmt = stmt.where(adoption_w15_tracker_items.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(adoption_w15_tracker_items.c.site.in_(allowed_sites))

    if normalized_status is not None:
        stmt = stmt.where(adoption_w15_tracker_items.c.status == normalized_status)
    if item_type is not None:
        stmt = stmt.where(adoption_w15_tracker_items.c.item_type == item_type.strip())
    if assignee is not None:
        stmt = stmt.where(adoption_w15_tracker_items.c.assignee == assignee.strip())

    stmt = stmt.order_by(
        adoption_w15_tracker_items.c.updated_at.desc(),
        adoption_w15_tracker_items.c.id.desc(),
    ).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_w15_tracker_item_model(row) for row in rows]


@app.get("/api/adoption/w15/tracker/overview", response_model=W15TrackerOverviewRead)
def get_w15_tracker_overview(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> W15TrackerOverviewRead:
    _require_site_access(principal, site)
    with get_conn() as conn:
        rows = conn.execute(
            select(adoption_w15_tracker_items).where(adoption_w15_tracker_items.c.site == site)
        ).mappings().all()
    models = [_row_to_w15_tracker_item_model(row) for row in rows]
    return _compute_w15_tracker_overview(site, models)


@app.get("/api/adoption/w15/tracker/readiness", response_model=W15TrackerReadinessRead)
def get_w15_tracker_readiness(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> W15TrackerReadinessRead:
    _require_site_access(principal, site)
    models = _load_w15_tracker_items_for_site(site)
    return _compute_w15_tracker_readiness(site=site, rows=models)


@app.get("/api/adoption/w15/tracker/completion", response_model=W15TrackerCompletionRead)
def get_w15_tracker_completion(
    site: Annotated[str, Query(min_length=1)],
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> W15TrackerCompletionRead:
    _require_site_access(principal, site)
    now = datetime.now(timezone.utc)
    models = _load_w15_tracker_items_for_site(site)
    readiness = _compute_w15_tracker_readiness(site=site, rows=models, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w15_site_runs).where(adoption_w15_site_runs.c.site == site).limit(1)
        ).mappings().first()
    return _row_to_w15_completion_model(site=site, readiness=readiness, row=row)


@app.post("/api/adoption/w15/tracker/complete", response_model=W15TrackerCompletionRead)
def complete_w15_tracker(
    payload: W15TrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:write")),
) -> W15TrackerCompletionRead:
    _require_site_access(principal, payload.site)
    if payload.force and not _has_permission(principal, "admins:manage"):
        raise HTTPException(status_code=403, detail="force completion requires admins:manage")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    models = _load_w15_tracker_items_for_site(payload.site)
    readiness = _compute_w15_tracker_readiness(site=payload.site, rows=models, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "W15 completion gate failed",
                "site": payload.site,
                "ready": readiness.ready,
                "blockers": readiness.blockers,
                "readiness": readiness.model_dump(mode="json"),
            },
        )

    completion_note = (payload.completion_note or "").strip()
    next_status = (
        W15_SITE_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
        if payload.force and not readiness.ready
        else W15_SITE_COMPLETION_STATUS_COMPLETED
    )
    with get_conn() as conn:
        existing = conn.execute(
            select(adoption_w15_site_runs).where(adoption_w15_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(adoption_w15_site_runs).values(
                    site=payload.site,
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(adoption_w15_site_runs)
                .where(adoption_w15_site_runs.c.site == payload.site)
                .values(
                    status=next_status,
                    completion_note=completion_note,
                    force_used=bool(payload.force and not readiness.ready),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=readiness.checked_at,
                    readiness_json=_to_json_text(readiness.model_dump(mode="json")),
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(adoption_w15_site_runs).where(adoption_w15_site_runs.c.site == payload.site).limit(1)
        ).mappings().first()

    model = _row_to_w15_completion_model(site=payload.site, readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="w15_tracker_complete",
        resource_type="adoption_w15_tracker_site",
        resource_id=payload.site,
        detail={
            "site": payload.site,
            "status": model.status,
            "ready": readiness.ready,
            "force_used": model.force_used,
            "blockers": readiness.blockers,
            "completion_rate_percent": readiness.completion_rate_percent,
            "missing_required_evidence_count": readiness.missing_required_evidence_count,
        },
    )
    return model


@app.patch("/api/adoption/w15/tracker/items/{tracker_item_id}", response_model=W15TrackerItemRead)
def update_w15_tracker_item(
    tracker_item_id: int,
    payload: W15TrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:write")),
) -> W15TrackerItemRead:
    has_update = (
        payload.assignee is not None
        or payload.status is not None
        or payload.completion_checked is not None
        or payload.completion_note is not None
    )
    if not has_update:
        raise HTTPException(status_code=400, detail="No update fields provided")

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w15_tracker_items).where(adoption_w15_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="W15 tracker item not found")
        _require_site_access(principal, str(row["site"]))

        next_assignee = row.get("assignee")
        if payload.assignee is not None:
            normalized_assignee = payload.assignee.strip()
            next_assignee = normalized_assignee or None

        next_status = str(row["status"])
        if payload.status is not None:
            next_status = str(payload.status)

        next_checked = bool(row.get("completion_checked", False))
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)

        if next_status == W15_TRACKER_STATUS_DONE:
            next_checked = True
        elif payload.status is not None and payload.status != W15_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False
        if payload.completion_checked is True:
            next_status = W15_TRACKER_STATUS_DONE
        elif payload.completion_checked is False and next_status == W15_TRACKER_STATUS_DONE:
            next_status = W15_TRACKER_STATUS_IN_PROGRESS

        if next_status not in W15_TRACKER_STATUS_SET:
            raise HTTPException(status_code=400, detail="Invalid W15 tracker status")

        next_note = str(row.get("completion_note") or "")
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        existing_completed_at = _as_optional_datetime(row.get("completed_at"))
        next_completed_at = existing_completed_at
        if next_checked:
            if existing_completed_at is None:
                next_completed_at = now
        else:
            next_completed_at = None

        conn.execute(
            update(adoption_w15_tracker_items)
            .where(adoption_w15_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w15_completion_if_closed(
            conn=conn,
            site=str(row["site"]),
            actor_username=actor_username,
            checked_at=now,
            reason="tracker_item_updated",
        )
        updated = conn.execute(
            select(adoption_w15_tracker_items).where(adoption_w15_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update W15 tracker item")
    model = _row_to_w15_tracker_item_model(updated)
    _write_audit_log(
        principal=principal,
        action="w15_tracker_item_update",
        resource_type="adoption_w15_tracker_item",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
        },
    )
    return model


@app.post("/api/adoption/w15/tracker/items/{tracker_item_id}/evidence", response_model=W15EvidenceRead, status_code=201)
async def upload_w15_tracker_evidence(
    tracker_item_id: int,
    file: UploadFile = File(...),
    note: str = Form(default=""),
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:write")),
) -> W15EvidenceRead:
    file_name = _safe_download_filename(file.filename or "", fallback="evidence.bin", max_length=120)
    content_type = (file.content_type or "application/octet-stream").strip() or "application/octet-stream"
    content_type = content_type[:120].lower()
    if not _is_allowed_evidence_content_type(content_type):
        raise HTTPException(status_code=415, detail="Unsupported evidence content type")
    file_bytes = await file.read(W15_EVIDENCE_MAX_BYTES + 1)
    await file.close()
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Empty evidence file is not allowed")
    if len(file_bytes) > W15_EVIDENCE_MAX_BYTES:
        raise HTTPException(status_code=413, detail=f"Evidence file too large (max {W15_EVIDENCE_MAX_BYTES} bytes)")
    sha256_digest = hashlib.sha256(file_bytes).hexdigest()
    scan_status, scan_engine, scan_reason = _scan_evidence_bytes(
        file_bytes=file_bytes,
        content_type=content_type,
    )
    if scan_status == "infected" or (scan_status == "suspicious" and EVIDENCE_SCAN_BLOCK_SUSPICIOUS):
        raise HTTPException(status_code=422, detail=f"Evidence scan blocked upload: {scan_reason or scan_status}")
    storage_backend, storage_key, stored_bytes = _write_evidence_blob(
        file_name=file_name,
        file_bytes=file_bytes,
        sha256_digest=sha256_digest,
    )

    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w15_tracker_items).where(adoption_w15_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W15 tracker item not found")
        site = str(tracker_row["site"])
        _require_site_access(principal, site)

        result = conn.execute(
            insert(adoption_w15_evidence_files).values(
                tracker_item_id=tracker_item_id,
                site=site,
                file_name=file_name,
                content_type=content_type,
                file_size=len(file_bytes),
                file_bytes=stored_bytes,
                storage_backend=storage_backend,
                storage_key=storage_key,
                sha256=sha256_digest,
                malware_scan_status=scan_status,
                malware_scan_engine=scan_engine,
                malware_scanned_at=now,
                note=note.strip(),
                uploaded_by=actor_username,
                uploaded_at=now,
            )
        )
        evidence_id = int(result.inserted_primary_key[0])
        conn.execute(
            update(adoption_w15_tracker_items)
            .where(adoption_w15_tracker_items.c.id == tracker_item_id)
            .values(
                evidence_count=adoption_w15_tracker_items.c.evidence_count + 1,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        _reset_w15_completion_if_closed(
            conn=conn,
            site=site,
            actor_username=actor_username,
            checked_at=now,
            reason="evidence_uploaded",
        )
        evidence_row = conn.execute(
            select(adoption_w15_evidence_files).where(adoption_w15_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()

    if evidence_row is None:
        raise HTTPException(status_code=500, detail="Failed to save evidence file")
    model = _row_to_w15_evidence_model(evidence_row)
    _write_audit_log(
        principal=principal,
        action="w15_tracker_evidence_upload",
        resource_type="adoption_w15_evidence",
        resource_id=str(model.id),
        detail={
            "tracker_item_id": model.tracker_item_id,
            "site": model.site,
            "file_name": model.file_name,
            "file_size": model.file_size,
            "storage_backend": model.storage_backend,
            "sha256": model.sha256,
            "malware_scan_status": model.malware_scan_status,
            "scan_reason": scan_reason,
        },
    )
    return model


@app.get("/api/adoption/w15/tracker/items/{tracker_item_id}/evidence", response_model=list[W15EvidenceRead])
def list_w15_tracker_evidence(
    tracker_item_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> list[W15EvidenceRead]:
    with get_conn() as conn:
        tracker_row = conn.execute(
            select(adoption_w15_tracker_items).where(adoption_w15_tracker_items.c.id == tracker_item_id).limit(1)
        ).mappings().first()
        if tracker_row is None:
            raise HTTPException(status_code=404, detail="W15 tracker item not found")
        _require_site_access(principal, str(tracker_row["site"]))

        rows = conn.execute(
            select(adoption_w15_evidence_files)
            .where(adoption_w15_evidence_files.c.tracker_item_id == tracker_item_id)
            .order_by(adoption_w15_evidence_files.c.uploaded_at.desc(), adoption_w15_evidence_files.c.id.desc())
        ).mappings().all()
    return [_row_to_w15_evidence_model(row) for row in rows]


@app.get("/api/adoption/w15/tracker/evidence/{evidence_id}/download", response_model=None)
def download_w15_tracker_evidence(
    evidence_id: int,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(adoption_w15_evidence_files).where(adoption_w15_evidence_files.c.id == evidence_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="W15 evidence not found")

    site = str(row["site"])
    _require_site_access(principal, site)
    content_type = str(row.get("content_type") or "application/octet-stream")
    file_name = _safe_download_filename(str(row.get("file_name") or ""), fallback="evidence.bin", max_length=120)
    data = _read_evidence_blob(row=row)
    if data is None:
        raise HTTPException(status_code=410, detail="Evidence file is unavailable")
    sha256_digest = hashlib.sha256(data).hexdigest()
    stored_sha = str(row.get("sha256") or "").strip().lower()
    if stored_sha and stored_sha != sha256_digest:
        raise HTTPException(status_code=409, detail="Evidence integrity check failed")
    storage_backend = _normalize_evidence_storage_backend(str(row.get("storage_backend") or "db"))

    _write_audit_log(
        principal=principal,
        action="w15_tracker_evidence_download",
        resource_type="adoption_w15_evidence",
        resource_id=str(evidence_id),
        detail={"site": site, "file_name": file_name, "sha256": sha256_digest, "storage_backend": storage_backend},
    )
    return Response(
        content=data,
        media_type=content_type,
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Download-Options": "noopen",
            "X-Evidence-SHA256": sha256_digest,
        },
    )



@app.get("/health")
def health() -> dict[str, str]:
    return {"status": "ok"}


@app.get("/meta")
def meta() -> dict[str, str]:
    db_backend = "postgresql" if DATABASE_URL.startswith("postgresql+") else "sqlite"
    return {"env": getenv("ENV", "local"), "db": db_backend}


@app.get("/api/auth/me", response_model=AuthMeRead)
def auth_me(
    principal: dict[str, Any] = Depends(get_current_admin),
) -> AuthMeRead:
    return AuthMeRead(
        user_id=principal.get("user_id"),
        token_id=principal.get("token_id"),
        token_label=principal.get("token_label"),
        token_expires_at=principal.get("token_expires_at"),
        token_rotate_due_at=principal.get("token_rotate_due_at"),
        token_idle_due_at=principal.get("token_idle_due_at"),
        token_must_rotate=bool(principal.get("token_must_rotate", False)),
        username=principal["username"],
        display_name=principal["display_name"],
        role=principal["role"],
        permissions=list(principal.get("permissions", [])),
        site_scope=list(_principal_site_scope(principal)),
        is_legacy=bool(principal.get("is_legacy", False)),
    )


@app.get("/api/admin/users", response_model=list[AdminUserRead])
def list_admin_users(
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[AdminUserRead]:
    with get_conn() as conn:
        rows = conn.execute(
            select(admin_users).order_by(admin_users.c.created_at.desc(), admin_users.c.id.desc())
        ).mappings().all()
    return [_row_to_admin_user_model(row) for row in rows]


@app.post("/api/admin/users", response_model=AdminUserRead, status_code=201)
def create_admin_user(
    payload: AdminUserCreate,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AdminUserRead:
    now = datetime.now(timezone.utc)
    permissions_text = _permission_list_to_text(payload.permissions)
    site_scope_text = _site_scope_list_to_text(payload.site_scope)
    display_name = payload.display_name.strip() or payload.username

    with get_conn() as conn:
        existing = conn.execute(
            select(admin_users.c.id).where(admin_users.c.username == payload.username)
        ).first()
        if existing is not None:
            raise HTTPException(status_code=409, detail="username already exists")

        result = conn.execute(
            insert(admin_users).values(
                username=payload.username,
                display_name=display_name,
                role=payload.role,
                permissions=permissions_text,
                site_scope=site_scope_text,
                is_active=payload.is_active,
                created_at=now,
                updated_at=now,
            )
        )
        user_id = result.inserted_primary_key[0]
        row = conn.execute(select(admin_users).where(admin_users.c.id == user_id)).mappings().first()

    if row is None:
        raise HTTPException(status_code=500, detail="Failed to load created admin user")
    model = _row_to_admin_user_model(row)
    _write_audit_log(
        principal=principal,
        action="admin_user_create",
        resource_type="admin_user",
        resource_id=str(model.id),
        detail={
            "username": model.username,
            "role": model.role,
            "site_scope": model.site_scope,
            "is_active": model.is_active,
        },
    )
    return model


@app.patch("/api/admin/users/{user_id}/active", response_model=AdminUserRead)
def set_admin_user_active(
    user_id: int,
    payload: AdminUserActiveUpdate,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AdminUserRead:
    now = datetime.now(timezone.utc)
    actor_user_id = principal.get("user_id")
    if actor_user_id is not None and int(actor_user_id) == user_id and payload.is_active is False:
        raise HTTPException(status_code=409, detail="Cannot deactivate current admin user")

    with get_conn() as conn:
        row = conn.execute(select(admin_users).where(admin_users.c.id == user_id)).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Admin user not found")

        conn.execute(
            update(admin_users)
            .where(admin_users.c.id == user_id)
            .values(is_active=payload.is_active, updated_at=now)
        )

        if payload.is_active is False:
            conn.execute(
                update(admin_tokens)
                .where(admin_tokens.c.user_id == user_id)
                .values(is_active=False)
            )

        updated = conn.execute(select(admin_users).where(admin_users.c.id == user_id)).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update admin user")
    model = _row_to_admin_user_model(updated)
    _write_audit_log(
        principal=principal,
        action="admin_user_set_active",
        resource_type="admin_user",
        resource_id=str(model.id),
        detail={"username": model.username, "is_active": model.is_active},
    )
    return model


def _enforce_active_token_quota(
    *,
    conn: Any,
    user_id: int,
    now: datetime,
    keep_token_ids: set[int] | None = None,
) -> list[int]:
    keep_ids = keep_token_ids or set()
    rows = conn.execute(
        select(admin_tokens.c.id, admin_tokens.c.created_at)
        .where(admin_tokens.c.user_id == user_id)
        .where(admin_tokens.c.is_active.is_(True))
        .order_by(admin_tokens.c.created_at.asc(), admin_tokens.c.id.asc())
    ).all()
    active_ids = [int(row[0]) for row in rows if int(row[0]) not in keep_ids]
    overflow = len(active_ids) - ADMIN_TOKEN_MAX_ACTIVE_PER_USER
    if overflow <= 0:
        return []
    revoke_ids = active_ids[:overflow]
    conn.execute(
        update(admin_tokens)
        .where(admin_tokens.c.id.in_(revoke_ids))
        .values(is_active=False, last_used_at=now)
    )
    return revoke_ids


@app.post("/api/admin/users/{user_id}/tokens", response_model=AdminTokenIssueResponse, status_code=201)
def issue_admin_token(
    user_id: int,
    payload: AdminTokenIssueRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AdminTokenIssueResponse:
    now = datetime.now(timezone.utc)
    token_plain = f"kaos_{secrets.token_urlsafe(24)}"
    token_hash = _hash_token(token_plain)
    expires_at = _as_optional_datetime(payload.expires_at)
    max_allowed_expires_at = now + timedelta(days=ADMIN_TOKEN_MAX_TTL_DAYS)
    if expires_at is None and ADMIN_TOKEN_REQUIRE_EXPIRY:
        expires_at = max_allowed_expires_at
    if expires_at is not None and expires_at <= now:
        raise HTTPException(status_code=400, detail="Token expiry must be in the future")
    if expires_at is not None and expires_at > max_allowed_expires_at:
        raise HTTPException(
            status_code=400,
            detail=f"Token expiry exceeds max TTL ({ADMIN_TOKEN_MAX_TTL_DAYS} days)",
        )
    token_scope_text: str | None = None
    effective_scope: list[str] = [SITE_SCOPE_ALL]
    revoked_ids: list[int] = []

    with get_conn() as conn:
        user_row = conn.execute(select(admin_users).where(admin_users.c.id == user_id)).mappings().first()
        if user_row is None:
            raise HTTPException(status_code=404, detail="Admin user not found")
        if not user_row["is_active"]:
            raise HTTPException(status_code=409, detail="Inactive user cannot receive token")

        user_scope = _site_scope_text_to_list(user_row.get("site_scope"), default_all=True)
        token_scope = None
        if payload.site_scope is not None:
            token_scope = _site_scope_text_to_list(payload.site_scope, default_all=True)
            token_scope_text = _site_scope_list_to_text(token_scope)
        effective_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
        if not effective_scope:
            raise HTTPException(status_code=409, detail="Token site scope does not overlap user site scope")

        result = conn.execute(
            insert(admin_tokens).values(
                user_id=user_id,
                label=payload.label,
                token_hash=token_hash,
                is_active=True,
                site_scope=token_scope_text,
                expires_at=expires_at,
                last_used_at=None,
                created_at=now,
            )
        )
        token_id = int(result.inserted_primary_key[0])
        revoked_ids = _enforce_active_token_quota(
            conn=conn,
            user_id=user_id,
            now=now,
            keep_token_ids={token_id},
        )

    response = AdminTokenIssueResponse(
        token_id=token_id,
        user_id=user_id,
        label=payload.label,
        token=token_plain,
        site_scope=effective_scope,
        expires_at=expires_at,
        created_at=now,
    )
    _write_audit_log(
        principal=principal,
        action="admin_token_issue",
        resource_type="admin_token",
        resource_id=str(token_id),
        detail={
            "user_id": user_id,
            "label": payload.label,
            "site_scope": effective_scope,
            "expires_at": expires_at,
        },
    )
    if revoked_ids:
        _write_audit_log(
            principal=principal,
            action="admin_token_auto_revoke_quota",
            resource_type="admin_token",
            resource_id=",".join(str(tid) for tid in revoked_ids),
            detail={
                "user_id": user_id,
                "max_active_per_user": ADMIN_TOKEN_MAX_ACTIVE_PER_USER,
                "revoked_token_ids": revoked_ids,
            },
    )
    return response


@app.post("/api/admin/tokens/{token_id}/rotate", response_model=AdminTokenIssueResponse)
def rotate_admin_token(
    token_id: int,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AdminTokenIssueResponse:
    now = datetime.now(timezone.utc)
    token_plain = f"kaos_{secrets.token_urlsafe(24)}"
    token_hash = _hash_token(token_plain)
    max_allowed_expires_at = now + timedelta(days=ADMIN_TOKEN_MAX_TTL_DAYS)
    revoked_ids: list[int] = []

    with get_conn() as conn:
        row = conn.execute(
            select(
                admin_tokens.c.id.label("token_id"),
                admin_tokens.c.user_id.label("user_id"),
                admin_tokens.c.label.label("label"),
                admin_tokens.c.is_active.label("is_active"),
                admin_tokens.c.site_scope.label("token_site_scope"),
                admin_tokens.c.expires_at.label("expires_at"),
                admin_users.c.site_scope.label("user_site_scope"),
                admin_users.c.is_active.label("user_is_active"),
            )
            .where(admin_tokens.c.id == token_id)
            .where(admin_users.c.id == admin_tokens.c.user_id)
            .limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Admin token not found")
        if not bool(row.get("is_active")):
            raise HTTPException(status_code=409, detail="Admin token already inactive")
        if not bool(row.get("user_is_active")):
            raise HTTPException(status_code=409, detail="Inactive user cannot rotate token")

        user_id = int(row["user_id"])
        token_scope_raw = row.get("token_site_scope")
        token_scope = None
        if token_scope_raw is not None:
            token_scope = _site_scope_text_to_list(token_scope_raw, default_all=True)
        user_scope = _site_scope_text_to_list(row.get("user_site_scope"), default_all=True)
        effective_scope = _resolve_effective_site_scope(user_scope=user_scope, token_scope=token_scope)
        if not effective_scope:
            raise HTTPException(status_code=409, detail="Token site scope does not overlap user site scope")

        old_expires_at = _as_optional_datetime(row.get("expires_at"))
        if old_expires_at is not None:
            expires_at = min(old_expires_at, max_allowed_expires_at)
            if expires_at <= now:
                expires_at = max_allowed_expires_at
        elif ADMIN_TOKEN_REQUIRE_EXPIRY:
            expires_at = max_allowed_expires_at
        else:
            expires_at = None

        conn.execute(
            update(admin_tokens)
            .where(admin_tokens.c.id == token_id)
            .values(is_active=False, last_used_at=now)
        )
        inserted = conn.execute(
            insert(admin_tokens).values(
                user_id=user_id,
                label=str(row.get("label") or "rotated"),
                token_hash=token_hash,
                is_active=True,
                site_scope=row.get("token_site_scope"),
                expires_at=expires_at,
                last_used_at=None,
                created_at=now,
            )
        )
        new_token_id = int(inserted.inserted_primary_key[0])
        revoked_ids = _enforce_active_token_quota(
            conn=conn,
            user_id=user_id,
            now=now,
            keep_token_ids={new_token_id},
        )

    response = AdminTokenIssueResponse(
        token_id=new_token_id,
        user_id=user_id,
        label=str(row.get("label") or "rotated"),
        token=token_plain,
        site_scope=effective_scope,
        expires_at=expires_at,
        created_at=now,
    )
    _write_audit_log(
        principal=principal,
        action="admin_token_rotate",
        resource_type="admin_token",
        resource_id=str(token_id),
        detail={
            "old_token_id": token_id,
            "new_token_id": new_token_id,
            "user_id": user_id,
            "label": response.label,
            "site_scope": effective_scope,
            "expires_at": expires_at,
        },
    )
    if revoked_ids:
        _write_audit_log(
            principal=principal,
            action="admin_token_auto_revoke_quota",
            resource_type="admin_token",
            resource_id=",".join(str(tid) for tid in revoked_ids),
            detail={
                "user_id": user_id,
                "max_active_per_user": ADMIN_TOKEN_MAX_ACTIVE_PER_USER,
                "revoked_token_ids": revoked_ids,
            },
        )
    return response


@app.get("/api/admin/tokens", response_model=list[AdminTokenRead])
def list_admin_tokens(
    user_id: Annotated[int | None, Query()] = None,
    active_only: Annotated[bool, Query()] = False,
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[AdminTokenRead]:
    stmt = (
        select(
            admin_tokens.c.id.label("token_id"),
            admin_tokens.c.user_id.label("user_id"),
            admin_users.c.username.label("username"),
            admin_tokens.c.label.label("label"),
            admin_tokens.c.is_active.label("is_active"),
            admin_tokens.c.site_scope.label("token_site_scope"),
            admin_users.c.site_scope.label("user_site_scope"),
            admin_tokens.c.expires_at.label("expires_at"),
            admin_tokens.c.last_used_at.label("last_used_at"),
            admin_tokens.c.created_at.label("created_at"),
        )
        .where(admin_users.c.id == admin_tokens.c.user_id)
        .order_by(admin_tokens.c.created_at.desc(), admin_tokens.c.id.desc())
    )
    if user_id is not None:
        stmt = stmt.where(admin_tokens.c.user_id == user_id)
    if active_only:
        stmt = stmt.where(admin_tokens.c.is_active.is_(True))

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_admin_token_model(row) for row in rows]


@app.get("/api/admin/token-policy")
def get_admin_token_policy(
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    return {
        "require_expiry": ADMIN_TOKEN_REQUIRE_EXPIRY,
        "max_ttl_days": ADMIN_TOKEN_MAX_TTL_DAYS,
        "rotate_after_days": ADMIN_TOKEN_ROTATE_AFTER_DAYS,
        "rotate_warning_days": ADMIN_TOKEN_ROTATE_WARNING_DAYS,
        "max_idle_days": ADMIN_TOKEN_MAX_IDLE_DAYS,
        "max_active_per_user": ADMIN_TOKEN_MAX_ACTIVE_PER_USER,
    }


@app.get("/api/admin/audit-logs", response_model=list[AdminAuditLogRead])
def list_admin_audit_logs(
    action: Annotated[str | None, Query()] = None,
    actor_username: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=200)] = 50,
    offset: Annotated[int, Query(ge=0)] = 0,
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[AdminAuditLogRead]:
    stmt = select(admin_audit_logs).order_by(
        admin_audit_logs.c.created_at.desc(), admin_audit_logs.c.id.desc()
    )
    if action is not None:
        stmt = stmt.where(admin_audit_logs.c.action == action)
    if actor_username is not None:
        stmt = stmt.where(admin_audit_logs.c.actor_username == actor_username)
    stmt = stmt.limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_admin_audit_log_model(row) for row in rows]


def _build_audit_archive_csv(entries: list[dict[str, Any]]) -> str:
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(
        [
            "id",
            "created_at",
            "actor_username",
            "action",
            "resource_type",
            "resource_id",
            "status",
            "prev_hash",
            "entry_hash",
        ]
    )
    for item in entries:
        writer.writerow(
            [
                item.get("id"),
                item.get("created_at"),
                item.get("actor_username"),
                item.get("action"),
                item.get("resource_type"),
                item.get("resource_id"),
                item.get("status"),
                item.get("prev_hash"),
                item.get("entry_hash"),
            ]
        )
    return output.getvalue()


@app.get("/api/admin/audit-integrity")
def get_admin_audit_integrity(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    max_entries: Annotated[int, Query(ge=1, le=50000)] = 10000,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    archive = build_monthly_audit_archive(
        month=month,
        max_entries=max_entries,
        include_entries=False,
    )
    _write_audit_log(
        principal=principal,
        action="admin_audit_integrity_check",
        resource_type="admin_audit_log",
        resource_id=archive["month"],
        detail={
            "month": archive["month"],
            "entry_count": archive["entry_count"],
            "chain_ok": archive["chain"]["chain_ok"],
            "issue_count": archive["chain"]["issue_count"],
        },
    )
    return {
        "month": archive["month"],
        "generated_at": archive["generated_at"],
        "entry_count": archive["entry_count"],
        "chain": archive["chain"],
        "archive_sha256": archive["archive_sha256"],
        "signature": archive["signature"],
        "signature_algorithm": archive["signature_algorithm"],
    }


@app.post("/api/admin/audit-chain/rebaseline")
def post_admin_audit_chain_rebaseline(
    from_month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    max_rows: Annotated[int, Query(ge=1, le=200000)] = 50000,
    dry_run: Annotated[bool, Query()] = False,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = rebaseline_admin_audit_chain(
        from_month=from_month,
        max_rows=max_rows,
        dry_run=dry_run,
    )
    _write_audit_log(
        principal=principal,
        action="admin_audit_chain_rebaseline",
        resource_type="admin_audit_log",
        resource_id=result["from_month"] or "all",
        detail={
            "from_month": result["from_month"],
            "max_rows": result["max_rows"],
            "dry_run": result["dry_run"],
            "anchor_id": result["anchor_id"],
            "scanned_count": result["scanned_count"],
            "updated_count": result["updated_count"],
            "first_updated_id": result["first_updated_id"],
            "last_updated_id": result["last_updated_id"],
        },
    )
    return result


@app.get("/api/admin/audit-archive/monthly")
def get_admin_monthly_audit_archive(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    max_entries: Annotated[int, Query(ge=1, le=50000)] = 10000,
    include_entries: Annotated[bool, Query()] = True,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    archive = build_monthly_audit_archive(
        month=month,
        max_entries=max_entries,
        include_entries=include_entries,
    )
    _write_audit_log(
        principal=principal,
        action="admin_audit_archive_export_json",
        resource_type="admin_audit_log",
        resource_id=archive["month"],
        detail={
            "month": archive["month"],
            "entry_count": archive["entry_count"],
            "include_entries": include_entries,
            "chain_ok": archive["chain"]["chain_ok"],
        },
    )
    return archive


@app.get("/api/admin/audit-archive/monthly/csv")
def get_admin_monthly_audit_archive_csv(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    max_entries: Annotated[int, Query(ge=1, le=50000)] = 10000,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    archive = build_monthly_audit_archive(
        month=month,
        max_entries=max_entries,
        include_entries=True,
    )
    csv_text = _build_audit_archive_csv(archive["entries"])
    file_name = f"audit-archive-{archive['month']}.csv"
    _write_audit_log(
        principal=principal,
        action="admin_audit_archive_export_csv",
        resource_type="admin_audit_log",
        resource_id=archive["month"],
        detail={
            "month": archive["month"],
            "entry_count": archive["entry_count"],
            "chain_ok": archive["chain"]["chain_ok"],
        },
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={
            "Content-Disposition": f'attachment; filename="{file_name}"',
            "X-Audit-Archive-Signature": archive["signature"] or "",
            "X-Audit-Archive-SHA256": archive["archive_sha256"],
        },
    )


@app.get("/api/ops/job-runs", response_model=list[JobRunRead])
def list_job_runs(
    job_name: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=200)] = 50,
    offset: Annotated[int, Query(ge=0)] = 0,
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[JobRunRead]:
    stmt = select(job_runs).order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
    if job_name is not None:
        stmt = stmt.where(job_runs.c.job_name == job_name)
    stmt = stmt.limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_job_run_model(row) for row in rows]


@app.get("/api/ops/performance/api-latency")
def get_ops_api_latency_snapshot(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_api_latency_snapshot()
    _write_audit_log(
        principal=principal,
        action="ops_api_latency_view",
        resource_type="ops_performance",
        resource_id="api_latency",
        detail={
            "status": snapshot.get("status"),
            "target_count": snapshot.get("target_count"),
            "critical_count": snapshot.get("critical_count"),
            "warning_count": snapshot.get("warning_count"),
            "insufficient_samples_count": snapshot.get("insufficient_samples_count"),
        },
    )
    return snapshot


@app.get("/api/ops/integrity/evidence-archive")
def get_ops_evidence_archive_integrity(
    sample_per_table: Annotated[int | None, Query(ge=1, le=200)] = None,
    max_issues: Annotated[int | None, Query(ge=1, le=500)] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_evidence_archive_integrity_batch(
        sample_per_table=sample_per_table,
        max_issues=max_issues,
    )
    _write_audit_log(
        principal=principal,
        action="ops_evidence_archive_integrity_view",
        resource_type="ops_integrity",
        resource_id="evidence_archive",
        detail={
            "status": snapshot.get("status"),
            "checked_count": snapshot.get("checked_count"),
            "digest_mismatch_count": snapshot.get("digest_mismatch_count"),
            "issue_count": snapshot.get("issue_count"),
            "sample_per_table": snapshot.get("sample_per_table"),
        },
    )
    return snapshot


@app.get("/api/ops/deploy/checklist")
def get_ops_deploy_checklist(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    payload = _build_deploy_checklist_payload()
    _write_audit_log(
        principal=principal,
        action="ops_deploy_checklist_view",
        resource_type="ops_deploy",
        resource_id=payload["version"],
        detail={
            "checklist_version": payload["version"],
            "step_count": len(payload.get("steps", [])),
        },
    )
    return payload


@app.post("/api/ops/deploy/smoke/record")
def post_ops_deploy_smoke_record(
    payload: dict[str, Any],
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    now = datetime.now(timezone.utc)
    started_at = _as_optional_datetime(payload.get("started_at")) or now
    finished_at = _as_optional_datetime(payload.get("finished_at")) or now
    if finished_at < started_at:
        finished_at = started_at

    raw_status = str(payload.get("status") or "success").strip().lower()
    if raw_status in {"ok", "success", "healthy"}:
        status = "success"
    elif raw_status in {"warning", "warn", "degraded"}:
        status = "warning"
    elif raw_status in {"critical", "failed", "error"}:
        status = "critical"
    else:
        status = "warning"

    checks_raw = payload.get("checks")
    checks: list[dict[str, Any]] = []
    if isinstance(checks_raw, list):
        for item in checks_raw[:50]:
            if not isinstance(item, dict):
                continue
            checks.append(
                {
                    "id": str(item.get("id") or ""),
                    "status": str(item.get("status") or ""),
                    "message": str(item.get("message") or ""),
                }
            )

    checklist_payload = _build_deploy_checklist_payload()
    checklist_policy = checklist_payload.get("policy") if isinstance(checklist_payload.get("policy"), dict) else {}
    expected_rollback_reference = str(
        checklist_policy.get("rollback_guide_path") or "docs/W15_MIGRATION_ROLLBACK.md"
    ).replace("\\", "/")
    expected_rollback_exists = bool(checklist_policy.get("rollback_guide_exists", False))
    expected_rollback_sha256 = str(checklist_policy.get("rollback_guide_sha256") or "").strip().lower()
    provided_rollback_reference = str(
        payload.get("rollback_reference") or expected_rollback_reference
    ).replace("\\", "/")
    provided_rollback_sha256 = str(payload.get("rollback_reference_sha256") or "").strip().lower()
    rollback_reference_match = provided_rollback_reference == expected_rollback_reference
    rollback_sha_provided = provided_rollback_sha256 != ""
    rollback_sha_match = (not rollback_sha_provided) or (provided_rollback_sha256 == expected_rollback_sha256)

    runbook_gate_passed = bool(payload.get("runbook_gate_passed", False))
    rollback_ready = bool(payload.get("rollback_ready", False))
    if status == "success" and DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE and not runbook_gate_passed:
        status = "warning"
    if status == "success" and not rollback_ready:
        status = "warning"
    if status == "success" and not expected_rollback_exists:
        status = "critical"
    if status == "success" and not rollback_reference_match:
        status = "warning"
    if status == "success" and rollback_sha_provided and not rollback_sha_match:
        status = "warning"

    rollback_binding_status = "ok"
    rollback_binding_message = "Rollback guide binding is valid."
    if not expected_rollback_exists:
        rollback_binding_status = "critical"
        rollback_binding_message = "Rollback guide file is missing from repository."
    elif not rollback_reference_match:
        rollback_binding_status = "warning"
        rollback_binding_message = "Rollback guide reference does not match checklist policy."
    elif rollback_sha_provided and not rollback_sha_match:
        rollback_binding_status = "warning"
        rollback_binding_message = "Rollback guide checksum does not match checklist policy."
    elif not rollback_sha_provided:
        rollback_binding_status = "warning"
        rollback_binding_message = "Rollback guide checksum was not provided by smoke client."

    checks.append(
        {
            "id": "rollback_guide_binding",
            "status": rollback_binding_status,
            "message": rollback_binding_message,
        }
    )

    detail = {
        "deploy_id": str(payload.get("deploy_id") or ""),
        "environment": str(payload.get("environment") or ENV_NAME),
        "base_url": str(payload.get("base_url") or ""),
        "checklist_version": str(payload.get("checklist_version") or DEPLOY_CHECKLIST_VERSION),
        "rollback_reference": provided_rollback_reference,
        "rollback_reference_expected": expected_rollback_reference,
        "rollback_reference_match": rollback_reference_match,
        "rollback_reference_exists": expected_rollback_exists,
        "rollback_reference_sha256": provided_rollback_sha256 or None,
        "rollback_reference_expected_sha256": expected_rollback_sha256 or None,
        "rollback_reference_sha256_match": rollback_sha_match if rollback_sha_provided else None,
        "rollback_ready": rollback_ready,
        "runbook_gate_passed": runbook_gate_passed,
        "notes": str(payload.get("notes") or ""),
        "checks": checks,
    }
    run_id = _write_job_run(
        job_name="deploy_smoke",
        trigger="api",
        status=status,
        started_at=started_at,
        finished_at=finished_at,
        detail=detail,
    )

    _write_audit_log(
        principal=principal,
        action="ops_deploy_smoke_record",
        resource_type="ops_deploy",
        resource_id=str(run_id or "pending"),
        status="success" if status == "success" else "warning",
        detail={
            "run_id": run_id,
            "status": status,
            "deploy_id": detail["deploy_id"],
            "rollback_ready": rollback_ready,
            "runbook_gate_passed": runbook_gate_passed,
            "check_count": len(checks),
            "checklist_version": detail["checklist_version"],
        },
    )
    return {
        "run_id": run_id,
        "job_name": "deploy_smoke",
        "status": status,
        "started_at": started_at.isoformat(),
        "finished_at": finished_at.isoformat(),
        "detail": detail,
    }


@app.get("/api/ops/dashboard/summary", response_model=DashboardSummaryRead)
def get_dashboard_summary(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
    recent_job_limit: Annotated[int, Query(alias="job_limit", ge=1, le=50)] = 10,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> DashboardSummaryRead:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    return build_dashboard_summary(
        site=site,
        days=days,
        recent_job_limit=recent_job_limit,
        allowed_sites=allowed_sites,
    )


def _build_ops_runbook_checks_snapshot(
    *,
    now: datetime | None = None,
    horizon_minutes: int = 90,
) -> dict[str, Any]:
    generated_at = now or datetime.now(timezone.utc)
    horizon = generated_at - timedelta(minutes=max(1, horizon_minutes))
    with get_conn() as conn:
        sla_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == "sla_escalation")
            .where(job_runs.c.finished_at >= horizon)
            .limit(1)
        ).first()
        alert_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == "alert_retry")
            .where(job_runs.c.finished_at >= horizon)
            .limit(1)
        ).first()
        retention_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == "alert_retention")
            .where(job_runs.c.finished_at >= (generated_at - timedelta(hours=36)))
            .limit(1)
        ).first()
        guard_recover_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == "alert_guard_recover")
            .where(job_runs.c.finished_at >= (generated_at - timedelta(hours=3)))
            .limit(1)
        ).first()
        mttr_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == "alert_mttr_slo_check")
            .where(job_runs.c.finished_at >= (generated_at - timedelta(hours=6)))
            .limit(1)
        ).first()
        w07_weekly_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == W07_WEEKLY_JOB_NAME)
            .where(job_runs.c.finished_at >= (generated_at - timedelta(days=8)))
            .limit(1)
        ).first()
        quality_weekly_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == OPS_QUALITY_WEEKLY_JOB_NAME)
            .where(job_runs.c.finished_at >= (generated_at - timedelta(days=8)))
            .limit(1)
        ).first()
        dr_rehearsal_recent = conn.execute(
            select(job_runs.c.id)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .where(job_runs.c.finished_at >= (generated_at - timedelta(days=35)))
            .limit(1)
        ).first()
        mttr_latest = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.detail_json)
            .where(job_runs.c.job_name == "alert_mttr_slo_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        w07_latest = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.detail_json)
            .where(job_runs.c.job_name == W07_WEEKLY_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        dr_latest = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.status, job_runs.c.detail_json)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        expiring_soon_cutoff = generated_at + timedelta(days=3)
        expiring_count = conn.execute(
            select(admin_tokens.c.id)
            .where(admin_tokens.c.is_active.is_(True))
            .where(admin_tokens.c.expires_at.is_not(None))
            .where(admin_tokens.c.expires_at <= expiring_soon_cutoff)
        ).all()
        deploy_smoke_latest = conn.execute(
            select(job_runs.c.finished_at, job_runs.c.status, job_runs.c.detail_json)
            .where(job_runs.c.job_name == "deploy_smoke")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()

    rate_limit_snapshot = _rate_limit_backend_snapshot()
    signing_snapshot = _audit_signing_snapshot()
    latency_snapshot = _build_api_latency_snapshot()
    integrity_batch = _build_evidence_archive_integrity_batch()
    guard_snapshot = _build_alert_channel_guard_snapshot(now=generated_at, lookback_days=30, max_targets=200)
    guard_summary = guard_snapshot.get("summary", {})
    mttr_policy, _, _ = _ensure_mttr_slo_policy()
    mttr_latest_detail: dict[str, Any] = {}
    mttr_latest_finished_at: datetime | None = None
    if mttr_latest is not None:
        raw = str(mttr_latest.get("detail_json") or "{}")
        try:
            loaded = json.loads(raw)
        except json.JSONDecodeError:
            loaded = {}
        if isinstance(loaded, dict):
            mttr_latest_detail = loaded
        mttr_latest_finished_at = _as_optional_datetime(mttr_latest.get("finished_at"))
    mttr_policy_from_latest = mttr_latest_detail.get("policy", {})
    if isinstance(mttr_policy_from_latest, dict):
        mttr_policy = _normalize_mttr_slo_policy(mttr_policy_from_latest)
    mttr_window = mttr_latest_detail.get("window", {})
    if not isinstance(mttr_window, dict):
        mttr_window = {}
    mttr_breach = bool(mttr_latest_detail.get("breach", False))
    w07_latest_detail: dict[str, Any] = {}
    w07_latest_finished_at: datetime | None = None
    if w07_latest is not None:
        w07_latest_detail = _parse_job_detail_json(w07_latest.get("detail_json"))
        w07_latest_finished_at = _as_optional_datetime(w07_latest.get("finished_at"))
    w07_latest_degraded = bool((w07_latest_detail.get("degradation") or {}).get("degraded", False))
    w07_alert_targets = _configured_alert_targets()
    w07_webhook_ready = len(w07_alert_targets) > 0
    preflight_snapshot = _get_startup_preflight_snapshot(refresh=False)
    weekly_streak_snapshot = _build_ops_quality_weekly_streak_snapshot()
    rollback_guide_exists = Path("docs/W15_MIGRATION_ROLLBACK.md").exists()
    alert_noise_policy_doc_exists = Path("docs/W17_ALERT_NOISE_POLICY.md").exists()

    quarantined_count = int(guard_summary.get("quarantined_count") or 0)
    guard_warning_count = int(guard_summary.get("warning_count") or 0)
    current_month_archive = build_monthly_audit_archive(month=None, include_entries=False, max_entries=10000)
    deploy_recent_hours = max(1, DEPLOY_SMOKE_RECENT_HOURS)
    deploy_smoke_finished_at: datetime | None = None
    deploy_smoke_status = "missing"
    deploy_smoke_detail: dict[str, Any] = {}
    if deploy_smoke_latest is not None:
        deploy_smoke_finished_at = _as_optional_datetime(deploy_smoke_latest.get("finished_at"))
        deploy_smoke_status = str(deploy_smoke_latest.get("status") or "unknown")
        deploy_smoke_detail = _parse_job_detail_json(deploy_smoke_latest.get("detail_json"))
    deploy_smoke_recent_cutoff = generated_at - timedelta(hours=deploy_recent_hours)
    deploy_smoke_is_recent = (
        deploy_smoke_finished_at is not None and deploy_smoke_finished_at >= deploy_smoke_recent_cutoff
    )
    deploy_smoke_rollback_ready = bool(deploy_smoke_detail.get("rollback_ready", False))
    deploy_smoke_runbook_gate_passed = bool(deploy_smoke_detail.get("runbook_gate_passed", False))
    deploy_smoke_checklist_version = str(deploy_smoke_detail.get("checklist_version") or "")
    deploy_smoke_status_value = "ok"
    if deploy_smoke_finished_at is None:
        deploy_smoke_status_value = "warning"
        deploy_smoke_message = "No deploy smoke record found."
    elif not deploy_smoke_is_recent:
        deploy_smoke_status_value = "warning"
        deploy_smoke_message = f"Latest deploy smoke is older than {deploy_recent_hours} hours."
    elif deploy_smoke_status in {"critical", "failed", "error"}:
        deploy_smoke_status_value = "critical"
        deploy_smoke_message = "Latest deploy smoke run reported critical/failure status."
    elif DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE and not deploy_smoke_runbook_gate_passed:
        deploy_smoke_status_value = "warning"
        deploy_smoke_message = "Deploy smoke recorded without passing runbook gate."
    elif not deploy_smoke_rollback_ready:
        deploy_smoke_status_value = "warning"
        deploy_smoke_message = "Deploy smoke recorded without rollback-ready confirmation."
    else:
        deploy_smoke_message = "Deploy smoke checklist and rollback readiness are healthy."
    dr_latest_finished_at: datetime | None = None
    dr_latest_status = "missing"
    dr_latest_restore_valid = False
    if dr_latest is not None:
        dr_latest_finished_at = _as_optional_datetime(dr_latest.get("finished_at"))
        dr_latest_status = str(dr_latest.get("status") or "unknown")
        dr_detail = _parse_job_detail_json(dr_latest.get("detail_json"))
        dr_latest_restore_valid = bool(dr_detail.get("restore_valid", False))

    checks = [
        {
            "id": "sla_cron_recent",
            "status": "ok" if sla_recent is not None else "warning",
            "message": "SLA escalation job observed within last 90 minutes."
            if sla_recent is not None
            else "No recent SLA escalation job run in last 90 minutes.",
        },
        {
            "id": "alert_retry_recent",
            "status": "ok" if alert_recent is not None else "warning",
            "message": "Alert retry job observed within last 90 minutes."
            if alert_recent is not None
            else "No recent alert retry job run in last 90 minutes.",
        },
        {
            "id": "startup_preflight",
            "status": (
                "critical"
                if preflight_snapshot.get("has_error")
                else ("warning" if int(preflight_snapshot.get("warning_count") or 0) > 0 else "ok")
            ),
            "message": (
                "Startup preflight has blocking errors."
                if preflight_snapshot.get("has_error")
                else (
                    "Startup preflight has warnings."
                    if int(preflight_snapshot.get("warning_count") or 0) > 0
                    else "Startup preflight is healthy."
                )
            ),
            "error_count": int(preflight_snapshot.get("error_count") or 0),
            "warning_count": int(preflight_snapshot.get("warning_count") or 0),
            "generated_at": preflight_snapshot.get("generated_at"),
        },
        {
            "id": "ops_quality_weekly_report_streak",
            "status": "ok" if bool(weekly_streak_snapshot.get("target_met", False)) else "warning",
            "message": (
                "Ops quality weekly report streak target met."
                if bool(weekly_streak_snapshot.get("target_met", False))
                else "Ops quality weekly report streak target not met."
            ),
            "current_streak_weeks": int(weekly_streak_snapshot.get("current_streak_weeks") or 0),
            "target_weeks": int(weekly_streak_snapshot.get("target_weeks") or 0),
        },
        {
            "id": "ops_daily_check_archive",
            "status": "ok" if OPS_DAILY_CHECK_ARCHIVE_ENABLED else "warning",
            "message": (
                "Ops daily check summary archive is enabled."
                if OPS_DAILY_CHECK_ARCHIVE_ENABLED
                else "Ops daily check summary archive is disabled."
            ),
            "archive_enabled": OPS_DAILY_CHECK_ARCHIVE_ENABLED,
            "archive_path": OPS_DAILY_CHECK_ARCHIVE_PATH,
            "retention_days": max(1, OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS),
        },
        {
            "id": "api_latency_p95",
            "status": latency_snapshot["status"],
            "message": latency_snapshot["message"],
            "target_count": latency_snapshot["target_count"],
            "warning_threshold_ms": latency_snapshot["warning_threshold_ms"],
            "critical_threshold_ms": latency_snapshot["critical_threshold_ms"],
            "min_samples": latency_snapshot["min_samples"],
            "insufficient_samples_count": latency_snapshot["insufficient_samples_count"],
            "critical_count": latency_snapshot["critical_count"],
            "warning_count": latency_snapshot["warning_count"],
            "endpoints": latency_snapshot["endpoints"],
        },
        {
            "id": "api_burn_rate",
            "status": str((latency_snapshot.get("burn_rate") or {}).get("status") or "warning"),
            "message": str((latency_snapshot.get("burn_rate") or {}).get("message") or "Burn-rate status unavailable."),
            "short_window_minutes": int((latency_snapshot.get("burn_rate") or {}).get("short_window_minutes") or 0),
            "long_window_minutes": int((latency_snapshot.get("burn_rate") or {}).get("long_window_minutes") or 0),
            "warning_threshold": float((latency_snapshot.get("burn_rate") or {}).get("warning_threshold") or 0.0),
            "critical_threshold": float((latency_snapshot.get("burn_rate") or {}).get("critical_threshold") or 0.0),
            "min_samples": int((latency_snapshot.get("burn_rate") or {}).get("min_samples") or 0),
            "error_budget_percent": float((latency_snapshot.get("burn_rate") or {}).get("error_budget_percent") or 0.0),
            "latency_budget_percent": float((latency_snapshot.get("burn_rate") or {}).get("latency_budget_percent") or 0.0),
            "critical_count": int((latency_snapshot.get("burn_rate") or {}).get("critical_count") or 0),
            "warning_count": int((latency_snapshot.get("burn_rate") or {}).get("warning_count") or 0),
            "warming_up_count": int((latency_snapshot.get("burn_rate") or {}).get("warming_up_count") or 0),
        },
        {
            "id": "audit_chain_integrity",
            "status": "ok" if current_month_archive["chain"]["chain_ok"] else "critical",
            "message": "Audit chain verified."
            if current_month_archive["chain"]["chain_ok"]
            else "Audit chain mismatch detected.",
            "issue_count": current_month_archive["chain"]["issue_count"],
        },
        {
            "id": "evidence_archive_integrity_batch",
            "status": integrity_batch["status"],
            "message": integrity_batch["message"],
            "sample_per_table": integrity_batch["sample_per_table"],
            "checked_count": integrity_batch["checked_count"],
            "missing_blob_count": integrity_batch["missing_blob_count"],
            "missing_hash_count": integrity_batch["missing_hash_count"],
            "digest_mismatch_count": integrity_batch["digest_mismatch_count"],
            "read_error_count": integrity_batch["read_error_count"],
            "archive": integrity_batch["archive"],
            "issue_count": integrity_batch["issue_count"],
        },
        {
            "id": "deploy_smoke_checklist",
            "status": deploy_smoke_status_value,
            "message": deploy_smoke_message,
            "recent_window_hours": deploy_recent_hours,
            "latest_run_at": deploy_smoke_finished_at.isoformat() if deploy_smoke_finished_at is not None else None,
            "latest_run_status": deploy_smoke_status,
            "rollback_ready": deploy_smoke_rollback_ready,
            "runbook_gate_passed": deploy_smoke_runbook_gate_passed,
            "checklist_version": deploy_smoke_checklist_version,
            "require_runbook_gate": DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE,
        },
        {
            "id": "migration_rollback_guide",
            "status": "ok" if rollback_guide_exists else "critical",
            "message": (
                "Migration rollback guide is available."
                if rollback_guide_exists
                else "Migration rollback guide file is missing."
            ),
            "path": "docs/W15_MIGRATION_ROLLBACK.md",
        },
        {
            "id": "token_expiry_pressure",
            "status": "ok" if len(expiring_count) == 0 else "warning",
            "message": "No active admin tokens expiring within 3 days."
            if len(expiring_count) == 0
            else f"{len(expiring_count)} active admin token(s) expire within 3 days.",
        },
        {
            "id": "rate_limit_backend",
            "status": rate_limit_snapshot["status"],
            "message": rate_limit_snapshot["message"],
            "configured_store": rate_limit_snapshot["configured_store"],
            "active_backend": rate_limit_snapshot["active_backend"],
            "redis_ping_ok": rate_limit_snapshot["redis_ping_ok"],
        },
        {
            "id": "audit_archive_signing",
            "status": signing_snapshot["status"],
            "message": signing_snapshot["message"],
            "algorithm": signing_snapshot["algorithm"],
            "enabled": signing_snapshot["enabled"],
        },
        {
            "id": "alert_channel_guard",
            "status": str(guard_summary.get("status") or "ok"),
            "message": (
                f"{quarantined_count} alert channel(s) are quarantined."
                if quarantined_count > 0
                else (
                    f"{guard_warning_count} alert channel(s) show warning state."
                    if guard_warning_count > 0
                    else "All alert channels are healthy."
                )
            ),
            "quarantined_count": quarantined_count,
            "warning_count": guard_warning_count,
            "target_count": int(guard_summary.get("target_count") or 0),
        },
        {
            "id": "alert_retention_recent",
            "status": "ok" if retention_recent is not None else "warning",
            "message": "Alert retention job observed within last 36 hours."
            if retention_recent is not None
            else "No recent alert retention job run in last 36 hours.",
        },
        {
            "id": "alert_guard_recovery_recent",
            "status": (
                "ok"
                if quarantined_count == 0 or guard_recover_recent is not None
                else "warning"
            ),
            "message": (
                "Guard recovery job observed within last 3 hours."
                if quarantined_count > 0 and guard_recover_recent is not None
                else (
                    "No quarantined channels currently."
                    if quarantined_count == 0
                    else "Quarantined channels exist but no guard recovery job in last 3 hours."
                )
            ),
        },
        {
            "id": "alert_mttr_slo_recent",
            "status": "ok" if mttr_recent is not None else "warning",
            "message": "MTTR SLO check observed within last 6 hours."
            if mttr_recent is not None
            else "No recent MTTR SLO check run in last 6 hours.",
        },
        {
            "id": "alert_noise_policy_documented",
            "status": "ok" if alert_noise_policy_doc_exists else "warning",
            "message": (
                "Alert noise policy document is available."
                if alert_noise_policy_doc_exists
                else "Alert noise policy document is missing."
            ),
            "path": "docs/W17_ALERT_NOISE_POLICY.md",
        },
        {
            "id": "alert_mttr_slo_breach",
            "status": (
                "ok"
                if not bool(mttr_policy.get("enabled", True))
                else ("warning" if mttr_breach else "ok")
            ),
            "message": (
                "MTTR SLO policy disabled."
                if not bool(mttr_policy.get("enabled", True))
                else (
                    "MTTR SLO breach detected in latest check."
                    if mttr_breach
                    else "MTTR SLO within threshold in latest check."
                )
            ),
            "latest_checked_at": mttr_latest_finished_at.isoformat() if mttr_latest_finished_at is not None else None,
            "threshold_minutes": int(mttr_policy.get("threshold_minutes") or 0),
            "window_days": int(mttr_policy.get("window_days") or 0),
            "min_incidents": int(mttr_policy.get("min_incidents") or 0),
            "window_incident_count": int(mttr_window.get("incident_count") or 0),
            "window_mttr_minutes": mttr_window.get("mttr_minutes"),
        },
        {
            "id": "w07_weekly_quality_recent",
            "status": "ok" if w07_weekly_recent is not None else "warning",
            "message": (
                "W07 weekly SLA quality automation observed within last 8 days."
                if w07_weekly_recent is not None
                else "No recent W07 weekly SLA quality automation run within last 8 days."
            ),
            "latest_checked_at": w07_latest_finished_at.isoformat() if w07_latest_finished_at is not None else None,
            "latest_degraded": w07_latest_degraded,
        },
        {
            "id": "dr_rehearsal_recent",
            "status": (
                "ok"
                if (not DR_REHEARSAL_ENABLED) or dr_rehearsal_recent is not None
                else "warning"
            ),
            "message": (
                "DR rehearsal run observed within last 35 days."
                if dr_rehearsal_recent is not None
                else (
                    "DR rehearsal is disabled by policy."
                    if not DR_REHEARSAL_ENABLED
                    else "No recent DR rehearsal run in last 35 days."
                )
            ),
            "enabled": DR_REHEARSAL_ENABLED,
            "latest_run_at": dr_latest_finished_at.isoformat() if dr_latest_finished_at is not None else None,
            "latest_status": dr_latest_status,
            "latest_restore_valid": dr_latest_restore_valid,
        },
        {
            "id": "ops_quality_weekly_report_recent",
            "status": "ok" if quality_weekly_recent is not None else "warning",
            "message": (
                "Ops quality weekly report job observed within last 8 days."
                if quality_weekly_recent is not None
                else "No recent ops quality weekly report job run in last 8 days."
            ),
        },
        {
            "id": "w07_quality_alert_channel",
            "status": (
                "ok"
                if (not W07_QUALITY_ALERT_ENABLED) or w07_webhook_ready
                else "warning"
            ),
            "message": (
                "W07 quality alert channel configured."
                if w07_webhook_ready
                else (
                    "W07 quality alert is enabled but no webhook channel is configured."
                    if W07_QUALITY_ALERT_ENABLED
                    else "W07 quality alert is disabled."
                )
            ),
            "alert_enabled": W07_QUALITY_ALERT_ENABLED,
            "webhook_target_count": len(w07_alert_targets),
        },
    ]
    overall = "ok"
    if any(check["status"] == "critical" for check in checks):
        overall = "critical"
    elif any(check["status"] == "warning" for check in checks):
        overall = "warning"
    return {
        "generated_at": generated_at.isoformat(),
        "overall_status": overall,
        "checks": checks,
    }


def _build_ops_security_posture_snapshot(*, now: datetime | None = None) -> dict[str, Any]:
    generated_at = now or datetime.now(timezone.utc)
    rate_limit_snapshot = _rate_limit_backend_snapshot()
    signing_snapshot = _audit_signing_snapshot()
    latency_snapshot = _build_api_latency_snapshot()
    alert_targets = _configured_alert_targets()
    mttr_policy, mttr_policy_updated_at, _ = _ensure_mttr_slo_policy()
    with get_conn() as conn:
        w07_latest = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == W07_WEEKLY_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
        deploy_smoke_latest = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "deploy_smoke")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    w07_latest_model = _row_to_job_run_model(w07_latest) if w07_latest is not None else None
    deploy_smoke_latest_model = _row_to_job_run_model(deploy_smoke_latest) if deploy_smoke_latest is not None else None
    deploy_smoke_latest_detail = (
        deploy_smoke_latest_model.detail
        if deploy_smoke_latest_model is not None and isinstance(deploy_smoke_latest_model.detail, dict)
        else {}
    )
    w07_latest_detail = (
        w07_latest_model.detail
        if w07_latest_model is not None and isinstance(w07_latest_model.detail, dict)
        else {}
    )
    w07_latest_degraded = bool((w07_latest_detail.get("degradation") or {}).get("degraded", False))
    preflight = _get_startup_preflight_snapshot(refresh=False)
    weekly_streak = _build_ops_quality_weekly_streak_snapshot()
    dr_latest_payload = _latest_dr_rehearsal_payload()
    return {
        "generated_at": generated_at.isoformat(),
        "env": ENV_NAME,
        "rate_limit": rate_limit_snapshot,
        "audit_archive_signing": signing_snapshot,
        "api_latency": latency_snapshot,
        "deploy_smoke_policy": {
            "checklist_version": DEPLOY_CHECKLIST_VERSION,
            "recent_hours": max(1, DEPLOY_SMOKE_RECENT_HOURS),
            "require_runbook_gate": DEPLOY_SMOKE_REQUIRE_RUNBOOK_GATE,
            "latest_run_at": (
                deploy_smoke_latest_model.finished_at.isoformat()
                if deploy_smoke_latest_model is not None
                else None
            ),
            "latest_status": (
                deploy_smoke_latest_model.status
                if deploy_smoke_latest_model is not None
                else None
            ),
            "latest_runbook_gate_passed": bool(deploy_smoke_latest_detail.get("runbook_gate_passed", False)),
            "latest_rollback_ready": bool(deploy_smoke_latest_detail.get("rollback_ready", False)),
        },
        "evidence_archive_integrity_policy": {
            "sample_per_table": max(1, EVIDENCE_INTEGRITY_SAMPLE_PER_TABLE),
            "max_issues": max(1, EVIDENCE_INTEGRITY_MAX_ISSUES),
            "modules": [name for name, _ in EVIDENCE_INTEGRITY_TABLES],
        },
        "preflight": {
            "overall_status": preflight.get("overall_status"),
            "has_error": bool(preflight.get("has_error", False)),
            "error_count": int(preflight.get("error_count") or 0),
            "warning_count": int(preflight.get("warning_count") or 0),
            "fail_on_error": PREFLIGHT_FAIL_ON_ERROR,
        },
        "ops_quality_reports": {
            "archive_enabled": OPS_QUALITY_REPORT_ARCHIVE_ENABLED,
            "archive_path": OPS_QUALITY_REPORT_ARCHIVE_PATH,
            "archive_retention_days": max(1, OPS_QUALITY_REPORT_ARCHIVE_RETENTION_DAYS),
            "weekly_streak_target": max(1, OPS_QUALITY_WEEKLY_STREAK_TARGET),
            "weekly_streak_current": int(weekly_streak.get("current_streak_weeks") or 0),
            "weekly_streak_met": bool(weekly_streak.get("target_met", False)),
        },
        "dr_rehearsal": {
            "enabled": DR_REHEARSAL_ENABLED,
            "backup_path": DR_REHEARSAL_BACKUP_PATH,
            "retention_days": max(1, DR_REHEARSAL_RETENTION_DAYS),
            "latest_run_at": dr_latest_payload.get("finished_at") if isinstance(dr_latest_payload, dict) else None,
            "latest_status": dr_latest_payload.get("status") if isinstance(dr_latest_payload, dict) else None,
            "latest_restore_valid": (
                bool(dr_latest_payload.get("restore_valid", False)) if isinstance(dr_latest_payload, dict) else False
            ),
        },
        "alerting": {
            "webhook_target_count": len(alert_targets),
            "ops_daily_check_alert_level": _normalize_ops_daily_check_alert_level(OPS_DAILY_CHECK_ALERT_LEVEL),
            "ops_daily_check_archive_enabled": OPS_DAILY_CHECK_ARCHIVE_ENABLED,
            "ops_daily_check_archive_path": OPS_DAILY_CHECK_ARCHIVE_PATH,
            "ops_daily_check_archive_retention_days": max(1, OPS_DAILY_CHECK_ARCHIVE_RETENTION_DAYS),
            "channel_guard_enabled": ALERT_CHANNEL_GUARD_ENABLED,
            "channel_guard_fail_threshold": max(1, ALERT_CHANNEL_GUARD_FAIL_THRESHOLD),
            "channel_guard_cooldown_minutes": max(1, ALERT_CHANNEL_GUARD_COOLDOWN_MINUTES),
            "guard_recover_max_targets": max(1, ALERT_GUARD_RECOVER_MAX_TARGETS),
            "retention_days": max(1, ALERT_RETENTION_DAYS),
            "retention_max_delete": max(1, ALERT_RETENTION_MAX_DELETE),
            "retention_archive_enabled": ALERT_RETENTION_ARCHIVE_ENABLED,
            "mttr_slo_enabled": bool(mttr_policy.get("enabled", True)),
            "mttr_slo_window_days": int(mttr_policy.get("window_days") or 0),
            "mttr_slo_threshold_minutes": int(mttr_policy.get("threshold_minutes") or 0),
            "mttr_slo_min_incidents": int(mttr_policy.get("min_incidents") or 0),
            "mttr_slo_auto_recover_enabled": bool(mttr_policy.get("auto_recover_enabled", True)),
            "mttr_slo_recover_state": str(mttr_policy.get("recover_state") or "quarantined"),
            "mttr_slo_recover_max_targets": int(mttr_policy.get("recover_max_targets") or 0),
            "mttr_slo_notify_enabled": bool(mttr_policy.get("notify_enabled", True)),
            "mttr_slo_notify_event_type": str(mttr_policy.get("notify_event_type") or "mttr_slo_breach"),
            "mttr_slo_notify_cooldown_minutes": int(mttr_policy.get("notify_cooldown_minutes") or 0),
            "mttr_slo_top_channels": int(mttr_policy.get("top_channels") or 0),
            "mttr_slo_policy_updated_at": mttr_policy_updated_at.isoformat(),
            "w07_quality_alert_enabled": W07_QUALITY_ALERT_ENABLED,
            "w07_quality_alert_cooldown_minutes": max(0, W07_QUALITY_ALERT_COOLDOWN_MINUTES),
            "w07_quality_escalation_threshold_percent": round(max(0.0, W07_QUALITY_ALERT_ESCALATION_RATE_THRESHOLD), 2),
            "w07_quality_alert_success_threshold_percent": round(
                max(0.0, min(100.0, W07_QUALITY_ALERT_SUCCESS_RATE_THRESHOLD)),
                2,
            ),
            "w07_quality_webhook_target_count": len(alert_targets),
            "w07_quality_weekly_latest_run_at": (
                w07_latest_model.finished_at.isoformat()
                if w07_latest_model is not None
                else None
            ),
            "w07_quality_weekly_latest_status": (
                w07_latest_model.status
                if w07_latest_model is not None
                else None
            ),
            "w07_quality_weekly_latest_degraded": w07_latest_degraded,
            "w07_quality_archive_enabled": W07_WEEKLY_ARCHIVE_ENABLED,
            "w07_quality_archive_path": W07_WEEKLY_ARCHIVE_PATH,
        },
        "evidence_storage_backend": _normalize_evidence_storage_backend(EVIDENCE_STORAGE_BACKEND),
        "token_policy": {
            "require_expiry": ADMIN_TOKEN_REQUIRE_EXPIRY,
            "max_ttl_days": ADMIN_TOKEN_MAX_TTL_DAYS,
            "rotate_after_days": ADMIN_TOKEN_ROTATE_AFTER_DAYS,
            "rotate_warning_days": ADMIN_TOKEN_ROTATE_WARNING_DAYS,
            "max_idle_days": ADMIN_TOKEN_MAX_IDLE_DAYS,
            "max_active_per_user": ADMIN_TOKEN_MAX_ACTIVE_PER_USER,
        },
    }


@app.get("/api/ops/runbook/checks")
def get_ops_runbook_checks(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_ops_runbook_checks_snapshot()
    checks = snapshot["checks"]
    overall = str(snapshot["overall_status"])
    rate_limit_check = next((item for item in checks if item["id"] == "rate_limit_backend"), {})
    signing_check = next((item for item in checks if item["id"] == "audit_archive_signing"), {})

    _write_audit_log(
        principal=principal,
        action="ops_runbook_checks_view",
        resource_type="ops_runbook",
        resource_id="checks",
        detail={
            "overall_status": overall,
            "checks": [{"id": item["id"], "status": item["status"]} for item in checks],
            "rate_limit": {
                "configured_store": rate_limit_check.get("configured_store"),
                "active_backend": rate_limit_check.get("active_backend"),
                "redis_ping_ok": rate_limit_check.get("redis_ping_ok"),
            },
            "audit_signing": {
                "enabled": signing_check.get("enabled"),
                "algorithm": signing_check.get("algorithm"),
            },
        },
    )
    return snapshot


@app.post("/api/ops/runbook/checks/run")
def run_ops_runbook_checks(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_ops_daily_check_job(trigger="api")
    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_run",
        resource_type="ops_runbook",
        resource_id=str(result.get("run_id") or "pending"),
        detail={
            "run_id": result.get("run_id"),
            "status": result.get("status"),
            "overall_status": result.get("overall_status"),
            "check_count": result.get("check_count"),
            "warning_count": result.get("warning_count"),
            "critical_count": result.get("critical_count"),
            "alert_attempted": result.get("alert_attempted"),
            "alert_dispatched": result.get("alert_dispatched"),
            "alert_error": result.get("alert_error"),
            "mttr_slo_check": result.get("mttr_slo_check"),
        },
    )
    return result


@app.get("/api/ops/runbook/checks/latest")
def get_ops_runbook_checks_latest(
    include_checks: Annotated[bool, Query()] = True,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "ops_daily_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No ops_daily_check run found")
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    checks = detail.get("checks", [])
    if not isinstance(checks, list):
        checks = []
    try:
        check_count = int(detail.get("check_count", len(checks)))
    except (TypeError, ValueError):
        check_count = len(checks)
    try:
        warning_count = int(detail.get("warning_count", sum(1 for item in checks if item.get("status") == "warning")))
    except (TypeError, ValueError):
        warning_count = sum(1 for item in checks if item.get("status") == "warning")
    try:
        critical_count = int(detail.get("critical_count", sum(1 for item in checks if item.get("status") == "critical")))
    except (TypeError, ValueError):
        critical_count = sum(1 for item in checks if item.get("status") == "critical")
    summary = detail.get("summary") if isinstance(detail.get("summary"), dict) else None
    if summary is None:
        summary = _build_ops_daily_check_summary_from_job_run(model, detail)
    archive = detail.get("archive") if isinstance(detail.get("archive"), dict) else {}

    response: dict[str, Any] = {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        "overall_status": str(detail.get("overall_status") or model.status),
        "check_count": check_count,
        "warning_count": warning_count,
        "critical_count": critical_count,
        "alert_level": detail.get("alert_level"),
        "alert_attempted": bool(detail.get("alert_attempted", False)),
        "alert_dispatched": bool(detail.get("alert_dispatched", False)),
        "alert_error": detail.get("alert_error"),
        "alert_channels": detail.get("alert_channels", []),
        "security_posture": detail.get("security_posture", {}),
        "mttr_slo_check": detail.get("mttr_slo_check", {}),
        "summary": summary,
        "archive": archive,
    }
    if include_checks:
        response["checks"] = checks

    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_latest_view",
        resource_type="ops_runbook",
        resource_id=str(model.id),
        detail={
            "run_id": model.id,
            "status": model.status,
            "include_checks": include_checks,
        },
    )
    return response


@app.get("/api/ops/runbook/checks/latest/summary.json")
def get_ops_runbook_checks_latest_summary_json(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "ops_daily_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No ops_daily_check run found")
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    summary = detail.get("summary") if isinstance(detail.get("summary"), dict) else None
    if summary is None:
        summary = _build_ops_daily_check_summary_from_job_run(model, detail)
    archive = detail.get("archive") if isinstance(detail.get("archive"), dict) else {}
    payload = {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "job_name": "ops_daily_check",
        "summary": summary,
        "archive": archive,
    }
    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_summary_json_view",
        resource_type="ops_runbook",
        resource_id=str(model.id),
        detail={
            "run_id": model.id,
            "status": model.status,
        },
    )
    return payload


@app.get("/api/ops/runbook/checks/latest/summary.csv")
def get_ops_runbook_checks_latest_summary_csv(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "ops_daily_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No ops_daily_check run found")
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    summary = detail.get("summary") if isinstance(detail.get("summary"), dict) else None
    if summary is None:
        summary = _build_ops_daily_check_summary_from_job_run(model, detail)
    csv_text = _build_ops_daily_check_summary_csv(summary)
    stamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    file_name = f"ops-daily-check-summary-{stamp}.csv"
    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_summary_csv_export",
        resource_type="ops_runbook",
        resource_id=file_name,
        detail={
            "run_id": model.id,
            "status": model.status,
        },
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/ops/runbook/checks/archive.json")
def get_ops_runbook_checks_archive_json(
    limit: Annotated[int, Query(ge=1, le=365)] = 30,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    rows = _build_ops_daily_check_archive_rows(limit=limit)
    payload = {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "job_name": "ops_daily_check",
        "limit": limit,
        "count": len(rows),
        "rows": rows,
    }
    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_archive_json_view",
        resource_type="ops_runbook",
        resource_id="archive",
        detail={
            "limit": limit,
            "count": len(rows),
        },
    )
    return payload


@app.get("/api/ops/runbook/checks/archive.csv")
def get_ops_runbook_checks_archive_csv(
    limit: Annotated[int, Query(ge=1, le=365)] = 90,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    rows = _build_ops_daily_check_archive_rows(limit=limit)
    csv_text = _build_ops_daily_check_archive_csv(rows)
    stamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    file_name = f"ops-daily-check-archive-{stamp}.csv"
    _write_audit_log(
        principal=principal,
        action="ops_runbook_daily_check_archive_csv_export",
        resource_type="ops_runbook",
        resource_id=file_name,
        detail={
            "limit": limit,
            "count": len(rows),
        },
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/ops/security/posture")
def get_ops_security_posture(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_ops_security_posture_snapshot()
    rate_limit_snapshot = snapshot["rate_limit"]
    signing_snapshot = snapshot["audit_archive_signing"]
    _write_audit_log(
        principal=principal,
        action="ops_security_posture_view",
        resource_type="ops_security",
        resource_id="posture",
        detail={
            "rate_limit_store": rate_limit_snapshot["configured_store"],
            "rate_limit_backend": rate_limit_snapshot["active_backend"],
            "rate_limit_status": rate_limit_snapshot["status"],
            "audit_signing_enabled": signing_snapshot["enabled"],
            "audit_signing_status": signing_snapshot["status"],
            "api_latency_status": snapshot.get("api_latency", {}).get("status"),
            "api_latency_warning_threshold_ms": snapshot.get("api_latency", {}).get("warning_threshold_ms"),
            "api_burn_rate_status": snapshot.get("api_latency", {}).get("burn_rate", {}).get("status"),
            "api_burn_rate_warning_threshold": snapshot.get("api_latency", {}).get("burn_rate", {}).get(
                "warning_threshold"
            ),
            "deploy_smoke_latest_status": snapshot.get("deploy_smoke_policy", {}).get("latest_status"),
            "deploy_smoke_latest_run_at": snapshot.get("deploy_smoke_policy", {}).get("latest_run_at"),
            "preflight_status": snapshot.get("preflight", {}).get("overall_status"),
            "preflight_error_count": snapshot.get("preflight", {}).get("error_count"),
            "dr_rehearsal_enabled": snapshot.get("dr_rehearsal", {}).get("enabled"),
            "dr_rehearsal_latest_status": snapshot.get("dr_rehearsal", {}).get("latest_status"),
            "ops_quality_weekly_streak_met": snapshot.get("ops_quality_reports", {}).get("weekly_streak_met"),
            "evidence_storage_backend": snapshot["evidence_storage_backend"],
            "ops_daily_check_alert_level": snapshot.get("alerting", {}).get("ops_daily_check_alert_level"),
            "alert_webhook_target_count": snapshot.get("alerting", {}).get("webhook_target_count"),
            "alert_channel_guard_enabled": snapshot.get("alerting", {}).get("channel_guard_enabled"),
            "alert_channel_guard_fail_threshold": snapshot.get("alerting", {}).get("channel_guard_fail_threshold"),
            "alert_retention_days": snapshot.get("alerting", {}).get("retention_days"),
            "alert_mttr_slo_enabled": snapshot.get("alerting", {}).get("mttr_slo_enabled"),
            "alert_mttr_slo_window_days": snapshot.get("alerting", {}).get("mttr_slo_window_days"),
            "alert_mttr_slo_threshold_minutes": snapshot.get("alerting", {}).get("mttr_slo_threshold_minutes"),
            "ops_daily_check_archive_enabled": snapshot.get("alerting", {}).get("ops_daily_check_archive_enabled"),
            "ops_daily_check_archive_path": snapshot.get("alerting", {}).get("ops_daily_check_archive_path"),
            "ops_daily_check_archive_retention_days": snapshot.get("alerting", {}).get(
                "ops_daily_check_archive_retention_days"
            ),
        },
    )
    return snapshot


@ops_router.get("/preflight")
def get_ops_preflight(
    refresh: Annotated[bool, Query()] = False,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _get_startup_preflight_snapshot(refresh=refresh)
    _write_audit_log(
        principal=principal,
        action="ops_preflight_view",
        resource_type="ops_preflight",
        resource_id="startup",
        detail={
            "refresh": refresh,
            "overall_status": snapshot.get("overall_status"),
            "error_count": snapshot.get("error_count"),
            "warning_count": snapshot.get("warning_count"),
        },
    )
    return snapshot


@ops_router.get("/alerts/noise-policy")
def get_ops_alert_noise_policy(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    payload = _build_alert_noise_policy_snapshot()
    _write_audit_log(
        principal=principal,
        action="ops_alert_noise_policy_view",
        resource_type="ops_alerting",
        resource_id="noise_policy",
        detail={
            "review_window_days": payload.get("review_window_days"),
            "false_positive_threshold_percent": payload.get("false_positive_threshold_percent"),
            "false_negative_threshold_percent": payload.get("false_negative_threshold_percent"),
        },
    )
    return payload


@ops_router.get("/admin/security-dashboard")
def get_ops_admin_security_dashboard(
    days: Annotated[int, Query(ge=1, le=180)] = 30,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_admin_security_dashboard_snapshot(days=days)
    _write_audit_log(
        principal=principal,
        action="ops_admin_security_dashboard_view",
        resource_type="ops_admin_security",
        resource_id="dashboard",
        detail={
            "window_days": snapshot.get("window_days"),
            "overall_status": snapshot.get("overall_status"),
            "anomaly_count": len(snapshot.get("anomalies", [])),
        },
    )
    return snapshot


@ops_router.get("/reports/quality/weekly")
def get_ops_quality_report_weekly(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    end = datetime.now(timezone.utc)
    start = end - timedelta(days=7)
    payload = _build_ops_quality_report_payload(
        window="weekly",
        start=start,
        end=end,
        label=f"week-{start.date().isoformat()}-{end.date().isoformat()}",
    )
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_weekly_view",
        resource_type="ops_quality_report",
        resource_id="weekly",
        detail={
            "window_start": payload.get("period", {}).get("start"),
            "window_end": payload.get("period", {}).get("end"),
            "critical_findings_total": payload.get("summary", {}).get("critical_findings_total"),
        },
    )
    return payload


@ops_router.get("/reports/quality/weekly/csv")
def get_ops_quality_report_weekly_csv(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    end = datetime.now(timezone.utc)
    start = end - timedelta(days=7)
    payload = _build_ops_quality_report_payload(
        window="weekly",
        start=start,
        end=end,
        label=f"week-{start.date().isoformat()}-{end.date().isoformat()}",
    )
    csv_text = _build_ops_quality_report_csv(payload)
    stamp = end.strftime("%Y%m%dT%H%M%SZ")
    file_name = f"ops-quality-weekly-{stamp}.csv"
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_weekly_csv_export",
        resource_type="ops_quality_report",
        resource_id=file_name,
        detail={"window": "weekly"},
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@ops_router.get("/reports/quality/monthly")
def get_ops_quality_report_monthly(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    start, end, normalized_month = _month_window(month)
    payload = _build_ops_quality_report_payload(
        window="monthly",
        start=start,
        end=end,
        label=normalized_month,
    )
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_monthly_view",
        resource_type="ops_quality_report",
        resource_id=normalized_month,
        detail={"month": normalized_month},
    )
    return payload


@ops_router.get("/reports/quality/monthly/csv")
def get_ops_quality_report_monthly_csv(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    start, end, normalized_month = _month_window(month)
    payload = _build_ops_quality_report_payload(
        window="monthly",
        start=start,
        end=end,
        label=normalized_month,
    )
    csv_text = _build_ops_quality_report_csv(payload)
    file_name = f"ops-quality-monthly-{normalized_month}.csv"
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_monthly_csv_export",
        resource_type="ops_quality_report",
        resource_id=file_name,
        detail={"month": normalized_month},
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@ops_router.post("/reports/quality/run")
def run_ops_quality_report(
    window: Annotated[str, Query(pattern="^(weekly|monthly)$")] = "weekly",
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_ops_quality_report_job(window=window, month=month, trigger="api")
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_run",
        resource_type="ops_quality_report",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "success"),
        detail={
            "window": result.get("window"),
            "label": result.get("label"),
            "archive_file": (result.get("archive") or {}).get("json_file"),
            "streak": result.get("streak"),
        },
    )
    return result


@ops_router.get("/reports/quality/weekly/streak")
def get_ops_quality_report_weekly_streak(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_ops_quality_weekly_streak_snapshot()
    _write_audit_log(
        principal=principal,
        action="ops_quality_report_weekly_streak_view",
        resource_type="ops_quality_report",
        resource_id="weekly_streak",
        detail=snapshot,
    )
    return snapshot


@ops_router.post("/dr/rehearsal/run")
def run_ops_dr_rehearsal(
    simulate_restore: Annotated[bool, Query()] = True,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_dr_rehearsal_job(trigger="api", simulate_restore=simulate_restore)
    _write_audit_log(
        principal=principal,
        action="ops_dr_rehearsal_run",
        resource_type="ops_dr",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "success"),
        detail={
            "simulate_restore": simulate_restore,
            "backup_file": result.get("backup_file"),
            "restore_valid": result.get("restore_valid"),
            "notes": result.get("notes"),
        },
    )
    return result


@ops_router.get("/dr/rehearsal/latest")
def get_ops_dr_rehearsal_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    payload = _latest_dr_rehearsal_payload()
    if payload is None:
        raise HTTPException(status_code=404, detail="No dr_rehearsal run found")
    _write_audit_log(
        principal=principal,
        action="ops_dr_rehearsal_latest_view",
        resource_type="ops_dr",
        resource_id=str(payload.get("run_id") or "unknown"),
        detail={"status": payload.get("status")},
    )
    return payload


@ops_router.get("/dr/rehearsal/history")
def get_ops_dr_rehearsal_history(
    limit: Annotated[int, Query(ge=1, le=100)] = 20,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == DR_REHEARSAL_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(limit)
        ).mappings().all()
    items = []
    for row in rows:
        model = _row_to_job_run_model(row)
        detail = model.detail if isinstance(model.detail, dict) else {}
        items.append(
            {
                "run_id": model.id,
                "status": model.status,
                "trigger": model.trigger,
                "finished_at": model.finished_at.isoformat(),
                "backup_file": detail.get("backup_file"),
                "restore_valid": bool(detail.get("restore_valid", False)),
                "pruned_files": int(detail.get("pruned_files") or 0),
            }
        )
    _write_audit_log(
        principal=principal,
        action="ops_dr_rehearsal_history_view",
        resource_type="ops_dr",
        resource_id="history",
        detail={"limit": limit, "count": len(items)},
    )
    return {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "count": len(items),
        "items": items,
    }


@ops_router.get("/governance/gate")
def get_ops_governance_gate(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_ops_governance_gate_snapshot()
    summary = snapshot.get("summary", {}) if isinstance(snapshot.get("summary"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_view",
        resource_type="ops_governance_gate",
        resource_id="snapshot",
        status="success" if str(snapshot.get("decision") or "no_go") == "go" else "warning",
        detail={
            "decision": snapshot.get("decision"),
            "failure_count": int(summary.get("failure_count") or 0),
            "warning_count": int(summary.get("warning_count") or 0),
        },
    )
    return snapshot


@ops_router.post("/governance/gate/run")
def run_ops_governance_gate(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_ops_governance_gate_job(trigger="api")
    summary = result.get("summary", {}) if isinstance(result.get("summary"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_run",
        resource_type="ops_governance_gate",
        resource_id=str(result.get("run_id") or "pending"),
        status="success" if str(result.get("decision") or "no_go") == "go" else "warning",
        detail={
            "decision": result.get("decision"),
            "status": result.get("status"),
            "failure_count": int(summary.get("failure_count") or 0),
            "warning_count": int(summary.get("warning_count") or 0),
        },
    )
    return result


@ops_router.get("/governance/gate/latest")
def get_ops_governance_gate_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    payload = _latest_ops_governance_gate_payload()
    if payload is None:
        raise HTTPException(status_code=404, detail="No ops_governance_gate run found")
    summary = payload.get("summary", {}) if isinstance(payload.get("summary"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_latest_view",
        resource_type="ops_governance_gate",
        resource_id=str(payload.get("run_id") or "unknown"),
        detail={
            "decision": payload.get("decision"),
            "status": payload.get("status"),
            "failure_count": int(summary.get("failure_count") or 0),
            "warning_count": int(summary.get("warning_count") or 0),
        },
    )
    return payload


@ops_router.get("/governance/gate/history")
def get_ops_governance_gate_history(
    limit: Annotated[int, Query(ge=1, le=100)] = 20,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        rows = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == OPS_GOVERNANCE_GATE_JOB_NAME)
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(limit)
        ).mappings().all()
    items: list[dict[str, Any]] = []
    for row in rows:
        model = _row_to_job_run_model(row)
        detail = model.detail if isinstance(model.detail, dict) else {}
        summary = detail.get("summary", {}) if isinstance(detail.get("summary"), dict) else {}
        items.append(
            {
                "run_id": model.id,
                "status": model.status,
                "decision": detail.get("decision"),
                "failure_count": int(summary.get("failure_count") or 0),
                "warning_count": int(summary.get("warning_count") or 0),
                "finished_at": model.finished_at.isoformat(),
            }
        )
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_history_view",
        resource_type="ops_governance_gate",
        resource_id="history",
        detail={"limit": limit, "count": len(items)},
    )
    return {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "count": len(items),
        "items": items,
    }


@ops_router.get("/governance/gate/remediation")
def get_ops_governance_gate_remediation(
    include_warnings: Annotated[bool, Query()] = True,
    max_items: Annotated[int, Query(ge=1, le=200)] = OPS_GOVERNANCE_REMEDIATION_DEFAULT_MAX_ITEMS,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_ops_governance_gate_snapshot()
    plan = _build_ops_governance_remediation_plan(
        snapshot=snapshot,
        include_warnings=include_warnings,
        max_items=max_items,
    )
    summary = plan.get("summary", {}) if isinstance(plan.get("summary"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_remediation_view",
        resource_type="ops_governance_gate",
        resource_id="remediation",
        status="success" if str(plan.get("decision") or "no_go") == "go" else "warning",
        detail={
            "decision": plan.get("decision"),
            "include_warnings": include_warnings,
            "item_count": int(summary.get("item_count") or 0),
            "fail_count": int(summary.get("fail_count") or 0),
            "warning_count": int(summary.get("warning_count") or 0),
        },
    )
    return plan


@ops_router.get("/governance/gate/remediation/csv")
def get_ops_governance_gate_remediation_csv(
    include_warnings: Annotated[bool, Query()] = True,
    max_items: Annotated[int, Query(ge=1, le=200)] = OPS_GOVERNANCE_REMEDIATION_DEFAULT_MAX_ITEMS,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    snapshot = _build_ops_governance_gate_snapshot()
    plan = _build_ops_governance_remediation_plan(
        snapshot=snapshot,
        include_warnings=include_warnings,
        max_items=max_items,
    )
    csv_text = _build_ops_governance_remediation_csv(plan)
    stamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    file_name = f"ops-governance-remediation-{stamp}.csv"
    summary = plan.get("summary", {}) if isinstance(plan.get("summary"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_gate_remediation_csv_export",
        resource_type="ops_governance_gate",
        resource_id=file_name,
        status="success" if str(plan.get("decision") or "no_go") == "go" else "warning",
        detail={
            "decision": plan.get("decision"),
            "include_warnings": include_warnings,
            "item_count": int(summary.get("item_count") or 0),
            "fail_count": int(summary.get("fail_count") or 0),
            "warning_count": int(summary.get("warning_count") or 0),
        },
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@ops_router.post(
    "/governance/gate/remediation/tracker/sync",
    response_model=W21RemediationTrackerSyncResponse,
)
def sync_ops_governance_gate_remediation_tracker(
    payload: W21RemediationTrackerSyncRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerSyncResponse:
    result = _sync_w21_remediation_tracker(
        actor_username=str(principal.get("username") or "system"),
        include_warnings=bool(payload.include_warnings),
        max_items=int(payload.max_items),
    )
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_sync",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        detail={
            "include_warnings": bool(payload.include_warnings),
            "max_items": int(payload.max_items),
            "active_count": int(result.active_count),
            "created_count": int(result.created_count),
            "reopened_count": int(result.reopened_count),
            "resolved_count": int(result.resolved_count),
        },
    )
    return result


@ops_router.get(
    "/governance/gate/remediation/tracker/items",
    response_model=list[W21RemediationTrackerItemRead],
)
def list_ops_governance_gate_remediation_tracker_items(
    include_inactive: Annotated[bool, Query()] = False,
    status: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 200,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[W21RemediationTrackerItemRead]:
    normalized_status: str | None = None
    if status is not None:
        normalized_status = status.strip().lower()
        if normalized_status not in W21_TRACKER_STATUS_SET:
            raise HTTPException(status_code=422, detail="Invalid tracker status")

    stmt = select(ops_governance_remediation_tracker_items)
    if not include_inactive:
        stmt = stmt.where(ops_governance_remediation_tracker_items.c.is_active.is_(True))
    if normalized_status is not None:
        stmt = stmt.where(ops_governance_remediation_tracker_items.c.status == normalized_status)
    stmt = stmt.order_by(
        ops_governance_remediation_tracker_items.c.is_active.desc(),
        ops_governance_remediation_tracker_items.c.priority.asc(),
        ops_governance_remediation_tracker_items.c.due_at.asc(),
        ops_governance_remediation_tracker_items.c.id.asc(),
    ).limit(limit)
    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    models = [_row_to_w21_remediation_item_model(row) for row in rows]
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_items_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        detail={
            "include_inactive": include_inactive,
            "status": normalized_status,
            "limit": limit,
            "count": len(models),
        },
    )
    return models


@ops_router.patch(
    "/governance/gate/remediation/tracker/items/{tracker_item_id}",
    response_model=W21RemediationTrackerItemRead,
)
def update_ops_governance_gate_remediation_tracker_item(
    tracker_item_id: int,
    payload: W21RemediationTrackerItemUpdate,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerItemRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "system")
    with get_conn() as conn:
        existing = conn.execute(
            select(ops_governance_remediation_tracker_items)
            .where(ops_governance_remediation_tracker_items.c.id == tracker_item_id)
            .limit(1)
        ).mappings().first()
        if existing is None:
            raise HTTPException(status_code=404, detail="Remediation tracker item not found")

        next_assignee = existing.get("assignee")
        next_status = _normalize_w21_tracker_status(existing.get("status"))
        next_checked = bool(existing.get("completion_checked", False))
        next_note = str(existing.get("completion_note") or "")
        next_completed_at = _as_optional_datetime(existing.get("completed_at"))

        if payload.assignee is not None:
            assignee_text = payload.assignee.strip()
            next_assignee = assignee_text or None
        if payload.status is not None:
            next_status = _normalize_w21_tracker_status(payload.status)
        if payload.completion_checked is not None:
            next_checked = bool(payload.completion_checked)
        if payload.completion_note is not None:
            next_note = payload.completion_note.strip()

        if next_status == W21_TRACKER_STATUS_DONE:
            next_completed_at = now
            if payload.completion_checked is None and payload.status is not None:
                next_checked = True
        elif payload.status is not None and payload.status != W21_TRACKER_STATUS_DONE and payload.completion_checked is None:
            next_checked = False

        if next_checked and next_status != W21_TRACKER_STATUS_DONE:
            next_status = W21_TRACKER_STATUS_DONE
            next_completed_at = now
        elif (not next_checked) and next_status == W21_TRACKER_STATUS_DONE:
            next_status = W21_TRACKER_STATUS_IN_PROGRESS
            next_completed_at = None
        elif next_status != W21_TRACKER_STATUS_DONE:
            next_completed_at = None

        conn.execute(
            update(ops_governance_remediation_tracker_items)
            .where(ops_governance_remediation_tracker_items.c.id == tracker_item_id)
            .values(
                assignee=next_assignee,
                status=next_status,
                completion_checked=next_checked,
                completion_note=next_note,
                completed_at=next_completed_at,
                updated_by=actor_username,
                updated_at=now,
            )
        )

        _reset_w21_completion_if_closed(
            conn=conn,
            actor_username=actor_username,
            checked_at=now,
            reason=f"tracker item {tracker_item_id} updated",
        )

        updated_row = conn.execute(
            select(ops_governance_remediation_tracker_items)
            .where(ops_governance_remediation_tracker_items.c.id == tracker_item_id)
            .limit(1)
        ).mappings().first()
        if updated_row is None:
            raise HTTPException(status_code=404, detail="Remediation tracker item not found")

    model = _row_to_w21_remediation_item_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_item_update",
        resource_type="ops_governance_remediation_tracker_item",
        resource_id=str(tracker_item_id),
        detail={
            "status": model.status,
            "assignee": model.assignee,
            "completion_checked": model.completion_checked,
            "is_active": model.is_active,
        },
    )
    return model


@ops_router.get(
    "/governance/gate/remediation/tracker/overview",
    response_model=W21RemediationTrackerOverviewRead,
)
def get_ops_governance_gate_remediation_tracker_overview(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerOverviewRead:
    now = datetime.now(timezone.utc)
    all_rows = _load_w21_remediation_items(include_inactive=True)
    active_rows = [row for row in all_rows if row.is_active]
    overview = _compute_w21_remediation_overview(
        active_rows=active_rows,
        active_count=len(active_rows),
        closed_count=max(0, len(all_rows) - len(active_rows)),
        checked_at=now,
    )
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_overview_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        detail={
            "active_count": overview.active_count,
            "closed_count": overview.closed_count,
            "completion_rate_percent": overview.completion_rate_percent,
        },
    )
    return overview


@ops_router.get(
    "/governance/gate/remediation/tracker/readiness",
    response_model=W21RemediationTrackerReadinessRead,
)
def get_ops_governance_gate_remediation_tracker_readiness(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerReadinessRead:
    active_rows = _load_w21_remediation_items(include_inactive=False)
    readiness = _compute_w21_remediation_readiness(active_rows=active_rows)
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_readiness_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        status="success" if readiness.ready else "warning",
        detail={
            "ready": readiness.ready,
            "total_items": readiness.total_items,
            "readiness_score_percent": readiness.readiness_score_percent,
        },
    )
    return readiness


@ops_router.get(
    "/governance/gate/remediation/tracker/completion",
    response_model=W21RemediationTrackerCompletionRead,
)
def get_ops_governance_gate_remediation_tracker_completion(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerCompletionRead:
    now = datetime.now(timezone.utc)
    active_rows = _load_w21_remediation_items(include_inactive=False)
    readiness = _compute_w21_remediation_readiness(active_rows=active_rows, checked_at=now)
    with get_conn() as conn:
        row = conn.execute(
            select(ops_governance_remediation_tracker_runs)
            .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
            .limit(1)
        ).mappings().first()
    result = _row_to_w21_completion_model(readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_completion_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        detail={
            "status": result.status,
            "ready": readiness.ready,
            "readiness_score_percent": readiness.readiness_score_percent,
        },
    )
    return result


@ops_router.post(
    "/governance/gate/remediation/tracker/complete",
    response_model=W21RemediationTrackerCompletionRead,
)
def complete_ops_governance_gate_remediation_tracker(
    payload: W21RemediationTrackerCompletionRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> W21RemediationTrackerCompletionRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "system")
    active_rows = _load_w21_remediation_items(include_inactive=False)
    readiness = _compute_w21_remediation_readiness(active_rows=active_rows, checked_at=now)
    if not readiness.ready and not payload.force:
        raise HTTPException(
            status_code=409,
            detail={
                "message": "Remediation tracker is not ready for completion.",
                "blockers": readiness.blockers,
                "readiness_score_percent": readiness.readiness_score_percent,
            },
        )

    status = W21_COMPLETION_STATUS_COMPLETED if readiness.ready else W21_COMPLETION_STATUS_COMPLETED_WITH_EXCEPTIONS
    completion_note = (payload.completion_note or "").strip()
    readiness_json = _to_json_text(
        {
            "ready": readiness.ready,
            "readiness_score_percent": readiness.readiness_score_percent,
            "blockers": readiness.blockers,
            "checked_at": now.isoformat(),
        }
    )

    with get_conn() as conn:
        existing = conn.execute(
            select(ops_governance_remediation_tracker_runs)
            .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
            .limit(1)
        ).mappings().first()
        if existing is None:
            conn.execute(
                insert(ops_governance_remediation_tracker_runs).values(
                    scope=W21_TRACKER_SCOPE_GLOBAL,
                    status=status,
                    completion_note=completion_note,
                    force_used=bool(payload.force),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=now,
                    readiness_json=readiness_json,
                    created_by=actor_username,
                    updated_by=actor_username,
                    created_at=now,
                    updated_at=now,
                )
            )
        else:
            conn.execute(
                update(ops_governance_remediation_tracker_runs)
                .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
                .values(
                    status=status,
                    completion_note=completion_note,
                    force_used=bool(payload.force),
                    completed_by=actor_username,
                    completed_at=now,
                    last_checked_at=now,
                    readiness_json=readiness_json,
                    updated_by=actor_username,
                    updated_at=now,
                )
            )
        row = conn.execute(
            select(ops_governance_remediation_tracker_runs)
            .where(ops_governance_remediation_tracker_runs.c.scope == W21_TRACKER_SCOPE_GLOBAL)
            .limit(1)
        ).mappings().first()
    result = _row_to_w21_completion_model(readiness=readiness, row=row)
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_complete",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        status="success" if readiness.ready else "warning",
        detail={
            "status": result.status,
            "force": bool(payload.force),
            "ready": readiness.ready,
            "readiness_score_percent": readiness.readiness_score_percent,
            "blockers": readiness.blockers,
        },
    )
    return result


@ops_router.get("/governance/gate/remediation/tracker/sla")
def get_ops_governance_gate_remediation_tracker_sla(
    due_soon_hours: Annotated[int, Query(ge=0, le=168)] = 24,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_w22_remediation_sla_snapshot(due_soon_hours=due_soon_hours)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_sla_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=W21_TRACKER_SCOPE_GLOBAL,
        status="success",
        detail={
            "due_soon_hours": int(snapshot.get("due_soon_hours") or due_soon_hours),
            "open_items": int(metrics.get("open_items") or 0),
            "overdue_count": int(metrics.get("overdue_count") or 0),
            "critical_open_count": int(metrics.get("critical_open_count") or 0),
        },
    )
    return snapshot


@ops_router.post("/governance/gate/remediation/tracker/escalate/run")
def run_ops_governance_gate_remediation_tracker_escalation(
    dry_run: Annotated[bool, Query()] = False,
    include_due_soon_hours: Annotated[int, Query(ge=0, le=168)] = GOVERNANCE_REMEDIATION_ESCALATION_DUE_SOON_HOURS,
    notify: Annotated[bool | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_ops_governance_remediation_escalation_job(
        trigger="api",
        dry_run=dry_run,
        include_due_soon_hours=include_due_soon_hours,
        notify_enabled=notify,
    )
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_escalation_run",
        resource_type="ops_governance_remediation_tracker",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "warning"),
        detail={
            "dry_run": bool(result.get("dry_run", dry_run)),
            "due_soon_hours": int(result.get("due_soon_hours") or include_due_soon_hours),
            "candidate_count": int(result.get("candidate_count") or 0),
            "critical_count": int(result.get("critical_count") or 0),
            "notify_attempted": bool(result.get("notify_attempted", False)),
            "notify_dispatched": bool(result.get("notify_dispatched", False)),
            "notify_error": result.get("notify_error"),
        },
    )
    return result


@ops_router.get("/governance/gate/remediation/tracker/escalate/latest")
def get_ops_governance_gate_remediation_tracker_escalation_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    payload = _latest_ops_governance_remediation_escalation_payload()
    if payload is None:
        raise HTTPException(status_code=404, detail="No ops_governance_remediation_escalation run found")
    _write_audit_log(
        principal=principal,
        action="ops_governance_remediation_tracker_escalation_latest_view",
        resource_type="ops_governance_remediation_tracker",
        resource_id=str(payload.get("run_id") or "unknown"),
        status=str(payload.get("status") or "warning"),
        detail={
            "candidate_count": int(payload.get("candidate_count") or 0),
            "critical_count": int(payload.get("critical_count") or 0),
            "notify_attempted": bool(payload.get("notify_attempted", False)),
            "notify_dispatched": bool(payload.get("notify_dispatched", False)),
        },
    )
    return payload


@app.get("/api/ops/dashboard/trends", response_model=DashboardTrendsRead)
def get_dashboard_trends(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> DashboardTrendsRead:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    return build_dashboard_trends(site=site, days=days, allowed_sites=allowed_sites)


@app.get("/api/ops/adoption/w05/consistency")
def get_ops_adoption_w05_consistency(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=90)] = 28,
    principal: dict[str, Any] = Depends(require_permission("adoption_w05:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w05_usage_consistency_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    _write_audit_log(
        principal=principal,
        action="w05_usage_consistency_view",
        resource_type="adoption_w05_consistency",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "two_week_retention_percent": snapshot.get("metrics", {}).get("two_week_retention_percent"),
            "overdue_ratio_percent": snapshot.get("metrics", {}).get("overdue_ratio_percent"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w06/rhythm")
def get_ops_adoption_w06_rhythm(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=7, le=90)] = 14,
    principal: dict[str, Any] = Depends(require_permission("adoption_w06:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w06_operational_rhythm_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    _write_audit_log(
        principal=principal,
        action="w06_operational_rhythm_view",
        resource_type="adoption_w06_rhythm",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "weekly_active_rate_percent": snapshot.get("metrics", {}).get("weekly_active_rate_percent"),
            "cadence_adherence_percent": snapshot.get("metrics", {}).get("cadence_adherence_percent"),
            "users_without_active_token": snapshot.get("metrics", {}).get("users_without_active_token"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w07/sla-quality")
def get_ops_adoption_w07_sla_quality(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=7, le=90)] = 14,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w07_sla_quality_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    _write_audit_log(
        principal=principal,
        action="w07_sla_quality_view",
        resource_type="adoption_w07_sla_quality",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "median_ack_minutes": snapshot.get("metrics", {}).get("median_ack_minutes"),
            "response_time_improvement_percent": snapshot.get("metrics", {}).get("response_time_improvement_percent"),
            "escalation_rate_percent": snapshot.get("metrics", {}).get("escalation_rate_percent"),
            "alert_success_rate_percent": snapshot.get("metrics", {}).get("alert_success_rate_percent"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w08/report-discipline")
def get_ops_adoption_w08_report_discipline(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w08:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w08_report_discipline_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w08_report_discipline_view",
        resource_type="adoption_w08_report_discipline",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "discipline_score": metrics.get("discipline_score"),
            "report_export_coverage_percent": metrics.get("report_export_coverage_percent"),
            "data_quality_issue_rate_percent": metrics.get("data_quality_issue_rate_percent"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w08/site-benchmark")
def get_ops_adoption_w08_site_benchmark(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    limit: Annotated[int, Query(ge=1, le=30)] = 10,
    principal: dict[str, Any] = Depends(require_permission("adoption_w08:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w08_report_discipline_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    items = snapshot.get("site_benchmark", []) if isinstance(snapshot.get("site_benchmark"), list) else []
    filtered: list[dict[str, Any]] = []
    for row in items:
        row_site = _normalize_site_name(str(row.get("site") or ""))
        if site is not None and row_site != site:
            continue
        filtered.append(row)
    limited = filtered[: max(1, min(limit, 30))]
    _write_audit_log(
        principal=principal,
        action="w08_site_benchmark_view",
        resource_type="adoption_w08_benchmark",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "limit": limit,
            "count": len(limited),
        },
    )
    return {
        "generated_at": snapshot.get("generated_at"),
        "site": site,
        "window_days": snapshot.get("window_days"),
        "count": len(limited),
        "items": limited,
        "thresholds": snapshot.get("thresholds", {}),
    }


@app.get("/api/ops/adoption/w09/kpi-operation")
def get_ops_adoption_w09_kpi_operation(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w09_kpi_operation_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w09_kpi_operation_view",
        resource_type="adoption_w09_kpi_operation",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "kpi_count": metrics.get("kpi_count"),
            "owner_coverage_percent": metrics.get("owner_coverage_percent"),
            "red_count": metrics.get("red_count"),
        },
    )
    return snapshot


ADOPTION_POLICY_RESPONSE_SCHEMA = "adoption_policy_response"
ADOPTION_POLICY_RESPONSE_VERSION = "v1"


def _build_adoption_policy_response(
    *,
    phase: str,
    policy_kind: str,
    endpoint: str,
    policy: dict[str, Any],
    updated_at: datetime,
    policy_key: str,
    policy_site: str | None,
) -> dict[str, Any]:
    scope_type = "site" if policy_site else "global"
    return {
        "site": policy_site,
        "policy_key": policy_key,
        "updated_at": updated_at.isoformat(),
        "policy": policy,
        "version": ADOPTION_POLICY_RESPONSE_VERSION,
        "scope": {
            "type": scope_type,
            "site": policy_site,
            "policy_key": policy_key,
        },
        "meta": {
            "schema": ADOPTION_POLICY_RESPONSE_SCHEMA,
            "schema_version": ADOPTION_POLICY_RESPONSE_VERSION,
            "phase": phase,
            "policy_kind": policy_kind,
            "endpoint": endpoint,
            "scope_type": scope_type,
        },
    }


@app.get("/api/ops/adoption/w09/kpi-policy")
def get_ops_adoption_w09_kpi_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w09_kpi_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w09_kpi_policy_view",
        resource_type="adoption_w09_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
            "kpi_count": len(policy.get("kpis", []) if isinstance(policy.get("kpis"), list) else []),
            "escalation_rule_count": len(
                policy.get("escalation_map", []) if isinstance(policy.get("escalation_map"), list) else []
            ),
        },
    )
    return _build_adoption_policy_response(
        phase="w09",
        policy_kind="kpi-policy",
        endpoint="/api/ops/adoption/w09/kpi-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w09/kpi-policy")
def set_ops_adoption_w09_kpi_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w09:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W09 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w09_kpi_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w09_kpi_policy_update",
        resource_type="adoption_w09_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
            "kpi_count": len(policy.get("kpis", []) if isinstance(policy.get("kpis"), list) else []),
            "escalation_rule_count": len(
                policy.get("escalation_map", []) if isinstance(policy.get("escalation_map"), list) else []
            ),
        },
    )
    return _build_adoption_policy_response(
        phase="w09",
        policy_kind="kpi-policy",
        endpoint="/api/ops/adoption/w09/kpi-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.get("/api/ops/adoption/w10/self-serve")
def get_ops_adoption_w10_self_serve(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w10_self_serve_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w10_self_serve_view",
        resource_type="adoption_w10_self_serve",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "repeat_rate_percent": metrics.get("repeat_rate_percent"),
            "readiness_score": metrics.get("self_serve_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w10/support-policy")
def get_ops_adoption_w10_support_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w10_support_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w10_support_policy_view",
        resource_type="adoption_w10_support_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w10",
        policy_kind="support-policy",
        endpoint="/api/ops/adoption/w10/support-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w10/support-policy")
def set_ops_adoption_w10_support_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w10:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W10 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w10_support_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w10_support_policy_update",
        resource_type="adoption_w10_support_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w10",
        policy_kind="support-policy",
        endpoint="/api/ops/adoption/w10/support-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.get("/api/ops/adoption/w11/scale-readiness")
def get_ops_adoption_w11_scale_readiness(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w11_scale_readiness_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w11_scale_readiness_view",
        resource_type="adoption_w11_scale_readiness",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "repeat_rate_percent": metrics.get("repeat_rate_percent"),
            "readiness_score": metrics.get("scale_readiness_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w11/readiness-policy")
def get_ops_adoption_w11_readiness_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w11_readiness_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w11_readiness_policy_view",
        resource_type="adoption_w11_readiness_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w11",
        policy_kind="readiness-policy",
        endpoint="/api/ops/adoption/w11/readiness-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w11/readiness-policy")
def set_ops_adoption_w11_readiness_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w11:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W11 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w11_readiness_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w11_readiness_policy_update",
        resource_type="adoption_w11_readiness_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w11",
        policy_kind="readiness-policy",
        endpoint="/api/ops/adoption/w11/readiness-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.get("/api/ops/adoption/w12/closure-handoff")
def get_ops_adoption_w12_closure_handoff(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w12_closure_handoff_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w12_closure_handoff_view",
        resource_type="adoption_w12_closure_handoff",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "repeat_rate_percent": metrics.get("repeat_rate_percent"),
            "readiness_score": metrics.get("closure_handoff_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w12/handoff-policy")
def get_ops_adoption_w12_handoff_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w12_handoff_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w12_handoff_policy_view",
        resource_type="adoption_w12_handoff_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w12",
        policy_kind="handoff-policy",
        endpoint="/api/ops/adoption/w12/handoff-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w12/handoff-policy")
def set_ops_adoption_w12_handoff_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w12:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W12 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w12_handoff_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w12_handoff_policy_update",
        resource_type="adoption_w12_handoff_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w12",
        policy_kind="handoff-policy",
        endpoint="/api/ops/adoption/w12/handoff-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.get("/api/ops/adoption/w13/closure-handoff")
def get_ops_adoption_w13_closure_handoff(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w13_closure_handoff_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w13_closure_handoff_view",
        resource_type="adoption_w13_closure_handoff",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "repeat_rate_percent": metrics.get("repeat_rate_percent"),
            "readiness_score": metrics.get("closure_handoff_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w13/handoff-policy")
def get_ops_adoption_w13_handoff_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w13_handoff_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w13_handoff_policy_view",
        resource_type="adoption_w13_handoff_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w13",
        policy_kind="handoff-policy",
        endpoint="/api/ops/adoption/w13/handoff-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w13/handoff-policy")
def set_ops_adoption_w13_handoff_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w13:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W13 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w13_handoff_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w13_handoff_policy_update",
        resource_type="adoption_w13_handoff_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w13",
        policy_kind="handoff-policy",
        endpoint="/api/ops/adoption/w13/handoff-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )

@app.get("/api/ops/adoption/w14/stability-sprint")
def get_ops_adoption_w14_stability_sprint(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w14_stability_sprint_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w14_stability_sprint_view",
        resource_type="adoption_w14_stability_sprint",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "incident_repeat_rate_percent": metrics.get("incident_repeat_rate_percent"),
            "readiness_score": metrics.get("stability_sprint_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w14/stability-policy")
def get_ops_adoption_w14_stability_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w14_stability_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w14_stability_policy_view",
        resource_type="adoption_w14_stability_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w14",
        policy_kind="stability-policy",
        endpoint="/api/ops/adoption/w14/stability-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w14/stability-policy")
def set_ops_adoption_w14_stability_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w14:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W14 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w14_stability_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w14_stability_policy_update",
        resource_type="adoption_w14_stability_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w14",
        policy_kind="stability-policy",
        endpoint="/api/ops/adoption/w14/stability-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.get("/api/ops/adoption/w15/ops-efficiency")
def get_ops_adoption_w15_ops_efficiency(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=14, le=120)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w15_ops_efficiency_snapshot(site=normalized_site, days=days, allowed_sites=allowed_sites)
    metrics = snapshot.get("metrics", {}) if isinstance(snapshot.get("metrics"), dict) else {}
    _write_audit_log(
        principal=principal,
        action="w15_ops_efficiency_view",
        resource_type="adoption_w15_ops_efficiency",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "window_days": int(snapshot.get("window_days") or days),
            "overall_status": metrics.get("overall_status"),
            "incident_repeat_rate_percent": metrics.get("incident_repeat_rate_percent"),
            "readiness_score": metrics.get("ops_efficiency_readiness_score"),
            "target_met": metrics.get("target_met"),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w15/efficiency-policy")
def get_ops_adoption_w15_efficiency_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:read")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    policy, updated_at, policy_key, policy_site = _ensure_w15_efficiency_policy(normalized_site)
    _write_audit_log(
        principal=principal,
        action="w15_efficiency_policy_view",
        resource_type="adoption_w15_efficiency_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w15",
        policy_kind="efficiency-policy",
        endpoint="/api/ops/adoption/w15/efficiency-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )


@app.put("/api/ops/adoption/w15/efficiency-policy")
def set_ops_adoption_w15_efficiency_policy(
    payload: dict[str, Any],
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w15:write")),
) -> dict[str, Any]:
    normalized_site = _normalize_site_name(site)
    _require_site_access(principal, normalized_site)
    if normalized_site is None:
        _require_global_site_scope(principal)
        if not _has_permission(principal, "admins:manage"):
            raise HTTPException(status_code=403, detail="Global W15 policy update requires admins:manage")
    policy, updated_at, policy_key, policy_site = _upsert_w15_efficiency_policy(normalized_site, payload)
    _write_audit_log(
        principal=principal,
        action="w15_efficiency_policy_update",
        resource_type="adoption_w15_efficiency_policy",
        resource_id=policy_key,
        detail={
            "site": policy_site,
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
        },
    )
    return _build_adoption_policy_response(
        phase="w15",
        policy_kind="efficiency-policy",
        endpoint="/api/ops/adoption/w15/efficiency-policy",
        policy=policy,
        updated_at=updated_at,
        policy_key=policy_key,
        policy_site=policy_site,
    )



@app.get("/api/ops/adoption/w07/automation-readiness")
def get_ops_adoption_w07_automation_readiness(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    normalized_site = _normalize_site_name(site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    snapshot = _build_w07_automation_readiness_snapshot(site=normalized_site, allowed_sites=allowed_sites)
    _write_audit_log(
        principal=principal,
        action="w07_automation_readiness_view",
        resource_type="adoption_w07_automation",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "overall_status": snapshot.get("overall_status"),
            "webhook_target_count": snapshot.get("integration", {}).get("webhook_target_count"),
            "latest_run_status": snapshot.get("runtime", {}).get("latest_run_status"),
            "latest_run_recent": snapshot.get("runtime", {}).get("latest_run_recent"),
        },
    )
    return snapshot


@app.post("/api/ops/adoption/w07/sla-quality/run-weekly")
def run_ops_adoption_w07_sla_quality_weekly(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=7, le=90)] = 14,
    force_notify: Annotated[bool, Query()] = False,
    write_archive: Annotated[bool | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:write")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    normalized_site = _normalize_site_name(site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None

    result = run_w07_sla_quality_weekly_job(
        site=normalized_site,
        days=days,
        trigger="api",
        force_notify=force_notify,
        allowed_sites=allowed_sites,
    )

    archive_file: str | None = None
    archive_error: str | None = None
    archive_enabled = W07_WEEKLY_ARCHIVE_ENABLED if write_archive is None else bool(write_archive)
    if archive_enabled:
        try:
            trends = _build_w07_weekly_trends_payload(
                site=normalized_site,
                allowed_sites=allowed_sites,
                limit=104,
            )
            csv_text = _build_w07_weekly_archive_csv(trends.get("points", []))
            archive_dir = Path(W07_WEEKLY_ARCHIVE_PATH)
            archive_dir.mkdir(parents=True, exist_ok=True)
            stamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
            site_label = (normalized_site or "all").replace(" ", "_").replace("/", "_")
            file_path = archive_dir / f"w07-sla-quality-weekly-{site_label}-{stamp}.csv"
            file_path.write_text(csv_text, encoding="utf-8")
            archive_file = str(file_path)
        except Exception as exc:  # pragma: no cover - defensive filesystem path
            archive_error = str(exc)

    response = {
        **result,
        "write_archive": archive_enabled,
        "archive_file": archive_file,
        "archive_error": archive_error,
    }
    _write_audit_log(
        principal=principal,
        action="w07_sla_quality_weekly_run",
        resource_type="adoption_w07_sla_quality",
        resource_id=str(response.get("run_id") or "pending"),
        status=str(response.get("status") or "success"),
        detail={
            "site": normalized_site,
            "window_days": int(response.get("window_days") or days),
            "degraded": bool((response.get("degradation") or {}).get("degraded", False)),
            "reasons": (response.get("degradation") or {}).get("reasons", []),
            "cooldown_active": bool(response.get("cooldown_active", False)),
            "alert_attempted": bool(response.get("alert_attempted", False)),
            "alert_dispatched": bool(response.get("alert_dispatched", False)),
            "alert_error": response.get("alert_error"),
            "write_archive": archive_enabled,
            "archive_file": archive_file,
            "archive_error": archive_error,
        },
    )
    return response


@app.get("/api/ops/adoption/w07/sla-quality/latest-weekly")
def get_ops_adoption_w07_sla_quality_latest_weekly(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    normalized_site = _normalize_site_name(site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    runs = _read_w07_weekly_job_runs(site=normalized_site, allowed_sites=allowed_sites, limit=1)
    if not runs:
        raise HTTPException(status_code=404, detail="No W07 weekly run found")
    model, detail = runs[0]
    response = {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        "site": detail.get("site"),
        "window_days": detail.get("window_days"),
        "degradation": detail.get("degradation", {}),
        "alert_enabled": bool(detail.get("alert_enabled", W07_QUALITY_ALERT_ENABLED)),
        "cooldown_active": bool(detail.get("cooldown_active", False)),
        "cooldown_remaining_minutes": int(detail.get("cooldown_remaining_minutes") or 0),
        "last_alert_at": detail.get("last_alert_at"),
        "alert_attempted": bool(detail.get("alert_attempted", False)),
        "alert_dispatched": bool(detail.get("alert_dispatched", False)),
        "alert_error": detail.get("alert_error"),
        "alert_channels": detail.get("alert_channels", []),
        "snapshot": detail.get("snapshot", {}),
    }
    _write_audit_log(
        principal=principal,
        action="w07_sla_quality_weekly_latest_view",
        resource_type="adoption_w07_sla_quality",
        resource_id=str(model.id),
        detail={
            "site": normalized_site,
            "status": model.status,
            "degraded": bool((response.get("degradation") or {}).get("degraded", False)),
        },
    )
    return response


@app.get("/api/ops/adoption/w07/sla-quality/trends")
def get_ops_adoption_w07_sla_quality_trends(
    site: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=104)] = 26,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    normalized_site = _normalize_site_name(site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    payload = _build_w07_weekly_trends_payload(site=normalized_site, allowed_sites=allowed_sites, limit=limit)
    _write_audit_log(
        principal=principal,
        action="w07_sla_quality_trends_view",
        resource_type="adoption_w07_sla_quality",
        resource_id=normalized_site or "all",
        detail={
            "site": normalized_site,
            "point_count": int(payload.get("point_count") or 0),
        },
    )
    return payload


@app.get("/api/ops/adoption/w07/sla-quality/archive.csv")
def get_ops_adoption_w07_sla_quality_archive_csv(
    site: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=104)] = 52,
    principal: dict[str, Any] = Depends(require_permission("adoption_w07:read")),
) -> Response:
    _require_site_access(principal, site)
    normalized_site = _normalize_site_name(site)
    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    payload = _build_w07_weekly_trends_payload(site=normalized_site, allowed_sites=allowed_sites, limit=limit)
    csv_text = _build_w07_weekly_archive_csv(payload.get("points", []))
    stamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    site_label = (normalized_site or "all").replace(" ", "_")
    file_name = f"adoption-w07-sla-quality-weekly-{site_label}-{stamp}.csv"
    _write_audit_log(
        principal=principal,
        action="w07_sla_quality_archive_csv_export",
        resource_type="adoption_w07_sla_quality",
        resource_id=file_name,
        detail={
            "site": normalized_site,
            "point_count": int(payload.get("point_count") or 0),
        },
    )
    return Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )


@app.get("/api/ops/adoption/w04/funnel")
def get_ops_adoption_w04_funnel(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w04_funnel_snapshot(site=site, days=days, allowed_sites=allowed_sites)
    _write_audit_log(
        principal=principal,
        action="w04_funnel_view",
        resource_type="adoption_w04_funnel",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "total_users": int(snapshot.get("metrics", {}).get("total_users") or 0),
            "median_ttv_minutes": snapshot.get("metrics", {}).get("median_ttv_minutes"),
            "target_met": bool(snapshot.get("metrics", {}).get("target_met", False)),
        },
    )
    return snapshot


@app.get("/api/ops/adoption/w04/blockers")
def get_ops_adoption_w04_blockers(
    site: Annotated[str | None, Query()] = None,
    days: Annotated[int, Query(ge=1, le=90)] = 30,
    max_items: Annotated[int, Query(ge=1, le=10)] = 3,
    principal: dict[str, Any] = Depends(require_permission("adoption_w04:read")),
) -> dict[str, Any]:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    snapshot = _build_w04_blocker_snapshot(
        site=site,
        days=days,
        allowed_sites=allowed_sites,
        max_items=max_items,
    )
    _write_audit_log(
        principal=principal,
        action="w04_blockers_view",
        resource_type="adoption_w04_blockers",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_days": int(snapshot.get("window_days") or days),
            "max_items": max_items,
            "top_keys": [
                str(item.get("blocker_key") or "")
                for item in snapshot.get("top", [])
                if isinstance(item, dict)
            ],
        },
    )
    return snapshot


@app.get("/api/ops/handover/brief", response_model=OpsHandoverBriefRead)
def get_ops_handover_brief(
    site: Annotated[str | None, Query()] = None,
    window_hours: Annotated[int, Query(ge=1, le=168)] = 12,
    due_soon_hours: Annotated[int, Query(ge=1, le=72)] = 6,
    max_items: Annotated[int, Query(ge=1, le=50)] = 10,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> OpsHandoverBriefRead:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_ops_handover_brief(
        site=site,
        window_hours=window_hours,
        due_soon_hours=due_soon_hours,
        max_items=max_items,
        allowed_sites=allowed_sites,
    )
    _write_audit_log(
        principal=principal,
        action="ops_handover_brief_view",
        resource_type="report",
        resource_id=site or "all",
        detail={
            "site": site,
            "window_hours": window_hours,
            "due_soon_hours": due_soon_hours,
            "max_items": max_items,
            "open_work_orders": report.open_work_orders,
            "overdue_open_work_orders": report.overdue_open_work_orders,
            "due_soon_work_orders": report.due_soon_work_orders,
        },
    )
    return report


@app.get("/api/ops/handover/brief/csv")
def get_ops_handover_brief_csv(
    site: Annotated[str | None, Query()] = None,
    window_hours: Annotated[int, Query(ge=1, le=168)] = 12,
    due_soon_hours: Annotated[int, Query(ge=1, le=72)] = 6,
    max_items: Annotated[int, Query(ge=1, le=50)] = 10,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_ops_handover_brief(
        site=site,
        window_hours=window_hours,
        due_soon_hours=due_soon_hours,
        max_items=max_items,
        allowed_sites=allowed_sites,
    )
    csv_text = _build_handover_brief_csv(report)
    site_label = (report.site or "all").replace(" ", "_")
    ts = report.generated_at.strftime("%Y%m%dT%H%M%SZ")
    file_name = f"handover-brief-{site_label}-{ts}.csv"
    response = Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )
    _write_audit_log(
        principal=principal,
        action="report_handover_export_csv",
        resource_type="report",
        resource_id=f"{report.site or 'ALL'}:{ts}",
        detail={
            "site": site,
            "window_hours": window_hours,
            "due_soon_hours": due_soon_hours,
            "max_items": max_items,
        },
    )
    return response


@app.get("/api/ops/handover/brief/pdf")
def get_ops_handover_brief_pdf(
    site: Annotated[str | None, Query()] = None,
    window_hours: Annotated[int, Query(ge=1, le=168)] = 12,
    due_soon_hours: Annotated[int, Query(ge=1, le=72)] = 6,
    max_items: Annotated[int, Query(ge=1, le=50)] = 10,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> Response:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_ops_handover_brief(
        site=site,
        window_hours=window_hours,
        due_soon_hours=due_soon_hours,
        max_items=max_items,
        allowed_sites=allowed_sites,
    )
    pdf_bytes = _build_handover_brief_pdf(report)
    site_label = (report.site or "all").replace(" ", "_")
    ts = report.generated_at.strftime("%Y%m%dT%H%M%SZ")
    file_name = f"handover-brief-{site_label}-{ts}.pdf"
    response = Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )
    _write_audit_log(
        principal=principal,
        action="report_handover_export_pdf",
        resource_type="report",
        resource_id=f"{report.site or 'ALL'}:{ts}",
        detail={
            "site": site,
            "window_hours": window_hours,
            "due_soon_hours": due_soon_hours,
            "max_items": max_items,
        },
    )
    return response


def _build_alert_channel_kpi_snapshot(
    *,
    event_type: str | None = None,
    windows: list[int] | None = None,
    now: datetime | None = None,
) -> dict[str, Any]:
    generated_at = now or datetime.now(timezone.utc)
    normalized_windows = sorted({int(value) for value in (windows or [7, 30]) if int(value) > 0})
    if not normalized_windows:
        normalized_windows = [7, 30]

    max_days = max(normalized_windows)
    oldest_cutoff = generated_at - timedelta(days=max_days)
    stmt = (
        select(
            alert_deliveries.c.target,
            alert_deliveries.c.status,
            alert_deliveries.c.last_attempt_at,
        )
        .where(alert_deliveries.c.last_attempt_at >= oldest_cutoff)
        .order_by(alert_deliveries.c.last_attempt_at.desc(), alert_deliveries.c.id.desc())
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    parsed_rows: list[dict[str, Any]] = []
    for row in rows:
        attempted_at = _as_optional_datetime(row.get("last_attempt_at"))
        if attempted_at is None:
            continue
        parsed_rows.append(
            {
                "target": str(row.get("target") or "unknown"),
                "status": str(row.get("status") or "failed").lower(),
                "attempted_at": attempted_at,
            }
        )

    window_payloads: list[dict[str, Any]] = []
    for days in normalized_windows:
        cutoff = generated_at - timedelta(days=days)
        channel_counts: dict[str, dict[str, Any]] = {}
        total_deliveries = 0
        success_count = 0
        warning_count = 0
        failed_count = 0

        for row in parsed_rows:
            attempted_at = row["attempted_at"]
            if attempted_at < cutoff:
                continue

            total_deliveries += 1
            status = row["status"]
            if status == "success":
                success_count += 1
            elif status == "warning":
                warning_count += 1
            else:
                failed_count += 1

            target = row["target"]
            bucket = channel_counts.get(target)
            if bucket is None:
                bucket = {
                    "target": target,
                    "total_deliveries": 0,
                    "success_count": 0,
                    "warning_count": 0,
                    "failed_count": 0,
                    "last_attempt_at": None,
                }
                channel_counts[target] = bucket
            bucket["total_deliveries"] += 1
            if status == "success":
                bucket["success_count"] += 1
            elif status == "warning":
                bucket["warning_count"] += 1
            else:
                bucket["failed_count"] += 1
            last_attempt_at = bucket.get("last_attempt_at")
            if not isinstance(last_attempt_at, datetime) or attempted_at > last_attempt_at:
                bucket["last_attempt_at"] = attempted_at

        channels: list[dict[str, Any]] = []
        for bucket in channel_counts.values():
            channel_total = int(bucket["total_deliveries"])
            channel_success = int(bucket["success_count"])
            channel_rate = round((channel_success / channel_total * 100), 2) if channel_total > 0 else 0.0
            last_attempt_at = bucket.get("last_attempt_at")
            channels.append(
                {
                    "target": bucket["target"],
                    "total_deliveries": channel_total,
                    "success_count": channel_success,
                    "warning_count": int(bucket["warning_count"]),
                    "failed_count": int(bucket["failed_count"]),
                    "success_rate_percent": channel_rate,
                    "last_attempt_at": last_attempt_at.isoformat() if isinstance(last_attempt_at, datetime) else None,
                }
            )

        channels.sort(key=lambda item: (-int(item["total_deliveries"]), str(item["target"])))
        success_rate_percent = round((success_count / total_deliveries * 100), 2) if total_deliveries > 0 else 0.0
        window_payloads.append(
            {
                "days": days,
                "window_start": cutoff.isoformat(),
                "window_end": generated_at.isoformat(),
                "total_deliveries": total_deliveries,
                "success_count": success_count,
                "warning_count": warning_count,
                "failed_count": failed_count,
                "success_rate_percent": success_rate_percent,
                "channels": channels,
            }
        )

    return {
        "generated_at": generated_at.isoformat(),
        "event_type": event_type,
        "windows": window_payloads,
    }


def _compute_recovery_minutes_stats(recovery_minutes: list[float]) -> dict[str, float | None]:
    values: list[float] = []
    for item in recovery_minutes:
        try:
            parsed = float(item)
        except (TypeError, ValueError):
            continue
        if parsed < 0.0:
            continue
        values.append(parsed)
    if not values:
        return {
            "mttr_minutes": None,
            "median_recovery_minutes": None,
            "longest_recovery_minutes": None,
        }

    sorted_values = sorted(values)
    count = len(sorted_values)
    mid = count // 2
    if count % 2 == 1:
        median = sorted_values[mid]
    else:
        median = (sorted_values[mid - 1] + sorted_values[mid]) / 2.0

    return {
        "mttr_minutes": round(sum(sorted_values) / count, 2),
        "median_recovery_minutes": round(median, 2),
        "longest_recovery_minutes": round(sorted_values[-1], 2),
    }


def _build_alert_channel_mttr_snapshot(
    *,
    event_type: str | None = None,
    windows: list[int] | None = None,
    now: datetime | None = None,
) -> dict[str, Any]:
    generated_at = now or datetime.now(timezone.utc)
    normalized_windows = sorted({int(value) for value in (windows or [7, 30]) if int(value) > 0})
    if not normalized_windows:
        normalized_windows = [7, 30]

    max_days = max(normalized_windows)
    # Include pre-window history so incidents already open at window start can be tracked.
    history_start = generated_at - timedelta(days=max_days + 30)
    stmt = (
        select(
            alert_deliveries.c.target,
            alert_deliveries.c.status,
            alert_deliveries.c.last_attempt_at,
        )
        .where(alert_deliveries.c.last_attempt_at >= history_start)
        .order_by(alert_deliveries.c.target.asc(), alert_deliveries.c.last_attempt_at.asc(), alert_deliveries.c.id.asc())
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()

    history_by_target: dict[str, list[dict[str, Any]]] = {}
    for row in rows:
        attempted_at = _as_optional_datetime(row.get("last_attempt_at"))
        if attempted_at is None:
            continue
        target = str(row.get("target") or "unknown")
        history_by_target.setdefault(target, []).append(
            {
                "status": str(row.get("status") or "failed").strip().lower(),
                "attempted_at": attempted_at,
            }
        )

    window_payloads: list[dict[str, Any]] = []
    for days in normalized_windows:
        cutoff = generated_at - timedelta(days=days)
        channels: list[dict[str, Any]] = []
        overall_incidents = 0
        overall_recovered = 0
        overall_unresolved = 0
        overall_recovery_minutes: list[float] = []

        for target, history in history_by_target.items():
            in_incident = False
            for item in history:
                attempted_at = item["attempted_at"]
                if attempted_at >= cutoff:
                    break
                status = item["status"]
                if _is_alert_failure_status(status):
                    in_incident = True
                elif status == "success":
                    in_incident = False

            incident_start: datetime | None = cutoff if in_incident else None
            last_incident_start: datetime | None = cutoff if in_incident else None
            last_recovery_at: datetime | None = None
            incident_count = 1 if in_incident else 0
            recovered_incidents = 0
            unresolved_incidents = 0
            channel_recovery_minutes: list[float] = []

            for item in history:
                attempted_at = item["attempted_at"]
                if attempted_at < cutoff or attempted_at > generated_at:
                    continue
                status = item["status"]
                if _is_alert_failure_status(status):
                    if not in_incident:
                        in_incident = True
                        incident_start = attempted_at
                        last_incident_start = attempted_at
                        incident_count += 1
                    continue
                if status == "success" and in_incident:
                    effective_start = incident_start or cutoff
                    recovery_minutes = max((attempted_at - effective_start).total_seconds() / 60.0, 0.0)
                    channel_recovery_minutes.append(recovery_minutes)
                    recovered_incidents += 1
                    in_incident = False
                    incident_start = None
                    last_recovery_at = attempted_at

            if in_incident:
                unresolved_incidents = 1

            if incident_count == 0:
                continue

            stats = _compute_recovery_minutes_stats(channel_recovery_minutes)
            channels.append(
                {
                    "target": target,
                    "incident_count": incident_count,
                    "recovered_incidents": recovered_incidents,
                    "unresolved_incidents": unresolved_incidents,
                    "mttr_minutes": stats["mttr_minutes"],
                    "median_recovery_minutes": stats["median_recovery_minutes"],
                    "longest_recovery_minutes": stats["longest_recovery_minutes"],
                    "last_incident_start": last_incident_start.isoformat() if last_incident_start else None,
                    "last_recovery_at": last_recovery_at.isoformat() if last_recovery_at else None,
                }
            )

            overall_incidents += incident_count
            overall_recovered += recovered_incidents
            overall_unresolved += unresolved_incidents
            overall_recovery_minutes.extend(channel_recovery_minutes)

        channels.sort(
            key=lambda item: (
                -int(item.get("unresolved_incidents") or 0),
                -float(item.get("mttr_minutes") or -1.0),
                str(item.get("target") or ""),
            )
        )
        overall_stats = _compute_recovery_minutes_stats(overall_recovery_minutes)
        window_payloads.append(
            {
                "days": days,
                "window_start": cutoff.isoformat(),
                "window_end": generated_at.isoformat(),
                "incident_count": overall_incidents,
                "recovered_incidents": overall_recovered,
                "unresolved_incidents": overall_unresolved,
                "mttr_minutes": overall_stats["mttr_minutes"],
                "median_recovery_minutes": overall_stats["median_recovery_minutes"],
                "longest_recovery_minutes": overall_stats["longest_recovery_minutes"],
                "channels": channels,
            }
        )

    return {
        "generated_at": generated_at.isoformat(),
        "event_type": event_type,
        "windows": window_payloads,
    }


@app.get("/api/ops/alerts/deliveries", response_model=list[AlertDeliveryRead])
def list_alert_deliveries(
    event_type: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=300)] = 100,
    offset: Annotated[int, Query(ge=0)] = 0,
    _: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[AlertDeliveryRead]:
    stmt = select(alert_deliveries).order_by(
        alert_deliveries.c.last_attempt_at.desc(),
        alert_deliveries.c.id.desc(),
    )
    if event_type is not None:
        stmt = stmt.where(alert_deliveries.c.event_type == event_type)
    if status is not None:
        stmt = stmt.where(alert_deliveries.c.status == status)
    stmt = stmt.limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_alert_delivery_model(row) for row in rows]


@app.get("/api/ops/alerts/kpi/channels")
def get_alert_channel_kpi(
    event_type: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_alert_channel_kpi_snapshot(event_type=event_type, windows=[7, 30])
    summaries = [
        {
            "days": int(item.get("days") or 0),
            "total_deliveries": int(item.get("total_deliveries") or 0),
            "success_rate_percent": float(item.get("success_rate_percent") or 0.0),
        }
        for item in snapshot.get("windows", [])
        if isinstance(item, dict)
    ]
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_kpi_view",
        resource_type="alert_delivery",
        resource_id=event_type or "all",
        detail={
            "event_type": event_type,
            "windows": summaries,
        },
    )
    return snapshot


@app.get("/api/ops/alerts/kpi/mttr")
def get_alert_channel_mttr_kpi(
    event_type: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_alert_channel_mttr_snapshot(event_type=event_type, windows=[7, 30])
    summaries = [
        {
            "days": int(item.get("days") or 0),
            "incident_count": int(item.get("incident_count") or 0),
            "recovered_incidents": int(item.get("recovered_incidents") or 0),
            "unresolved_incidents": int(item.get("unresolved_incidents") or 0),
            "mttr_minutes": item.get("mttr_minutes"),
        }
        for item in snapshot.get("windows", [])
        if isinstance(item, dict)
    ]
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_mttr_kpi_view",
        resource_type="alert_delivery",
        resource_id=event_type or "all",
        detail={
            "event_type": event_type,
            "windows": summaries,
        },
    )
    return snapshot


@app.get("/api/ops/alerts/mttr-slo/policy")
def get_alert_mttr_slo_policy(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    policy, updated_at, policy_key = _ensure_mttr_slo_policy()
    _write_audit_log(
        principal=principal,
        action="ops_alert_mttr_slo_policy_view",
        resource_type="alert_policy",
        resource_id=policy_key,
        detail={
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
            "window_days": int(policy.get("window_days") or 0),
            "threshold_minutes": int(policy.get("threshold_minutes") or 0),
            "min_incidents": int(policy.get("min_incidents") or 0),
        },
    )
    return {
        "policy_key": policy_key,
        "updated_at": updated_at.isoformat(),
        "policy": policy,
    }


@app.put("/api/ops/alerts/mttr-slo/policy")
def set_alert_mttr_slo_policy(
    payload: dict[str, Any],
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    policy, updated_at, policy_key = _upsert_mttr_slo_policy(payload)
    _write_audit_log(
        principal=principal,
        action="ops_alert_mttr_slo_policy_update",
        resource_type="alert_policy",
        resource_id=policy_key,
        detail={
            "policy_key": policy_key,
            "enabled": bool(policy.get("enabled", True)),
            "window_days": int(policy.get("window_days") or 0),
            "threshold_minutes": int(policy.get("threshold_minutes") or 0),
            "min_incidents": int(policy.get("min_incidents") or 0),
            "auto_recover_enabled": bool(policy.get("auto_recover_enabled", True)),
            "recover_state": policy.get("recover_state"),
            "recover_max_targets": int(policy.get("recover_max_targets") or 0),
            "notify_enabled": bool(policy.get("notify_enabled", True)),
            "notify_event_type": policy.get("notify_event_type"),
            "notify_cooldown_minutes": int(policy.get("notify_cooldown_minutes") or 0),
        },
    )
    return {
        "policy_key": policy_key,
        "updated_at": updated_at.isoformat(),
        "policy": policy,
    }


@app.post("/api/ops/alerts/mttr-slo/check/run")
def run_alert_mttr_slo_check(
    event_type: Annotated[str | None, Query()] = None,
    force_notify: Annotated[bool, Query()] = False,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_alert_mttr_slo_check_job(
        event_type=event_type,
        force_notify=force_notify,
        trigger="api",
    )
    _write_audit_log(
        principal=principal,
        action="ops_alert_mttr_slo_check_run",
        resource_type="alert_delivery",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "success"),
        detail={
            "event_type": event_type,
            "force_notify": force_notify,
            "breach": bool(result.get("breach", False)),
            "window": result.get("window", {}),
            "actions": result.get("actions", {}),
        },
    )
    return result


@app.get("/api/ops/alerts/mttr-slo/check/latest")
def get_alert_mttr_slo_check_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "alert_mttr_slo_check")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No alert_mttr_slo_check run found")

    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    response = {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        "event_type": detail.get("event_type"),
        "policy_key": detail.get("policy_key"),
        "policy_updated_at": detail.get("policy_updated_at"),
        "policy": detail.get("policy", {}),
        "window": detail.get("window", {}),
        "breach": bool(detail.get("breach", False)),
        "top_channels": detail.get("top_channels", []),
        "actions": detail.get("actions", {}),
    }
    _write_audit_log(
        principal=principal,
        action="ops_alert_mttr_slo_check_latest_view",
        resource_type="alert_delivery",
        resource_id=str(model.id),
        detail={
            "run_id": model.id,
            "status": model.status,
            "breach": bool(response["breach"]),
        },
    )
    return response


@app.get("/api/ops/alerts/channels/guard")
def get_alert_channel_guard(
    event_type: Annotated[str | None, Query()] = None,
    lookback_days: Annotated[int, Query(ge=1, le=90)] = 30,
    max_targets: Annotated[int, Query(ge=1, le=200)] = 100,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    snapshot = _build_alert_channel_guard_snapshot(
        event_type=event_type,
        lookback_days=lookback_days,
        max_targets=max_targets,
    )
    summary = snapshot.get("summary", {})
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_guard_view",
        resource_type="alert_delivery",
        resource_id=event_type or "all",
        detail={
            "event_type": event_type,
            "lookback_days": lookback_days,
            "max_targets": max_targets,
            "status": summary.get("status"),
            "target_count": summary.get("target_count"),
            "warning_count": summary.get("warning_count"),
            "quarantined_count": summary.get("quarantined_count"),
        },
    )
    return snapshot


@app.post("/api/ops/alerts/channels/guard/recover")
def recover_alert_channel_guard(
    target: Annotated[str, Query(min_length=3, max_length=400)],
    event_type: Annotated[str | None, Query()] = None,
    note: Annotated[str | None, Query(max_length=300)] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    normalized_target = target.strip()
    if not normalized_target:
        raise HTTPException(status_code=400, detail="target is required")

    now = datetime.now(timezone.utc)
    before = _compute_alert_channel_guard_state(
        normalized_target,
        now=now,
        event_type=event_type,
    )
    probe_payload = {
        "event": "alert_channel_recovery_probe",
        "target": normalized_target,
        "event_type_scope": event_type,
        "checked_at": now.isoformat(),
        "requested_by": str(principal.get("username") or "unknown"),
        "note": note or "",
    }
    ok, err = _post_json_with_retries(
        url=normalized_target,
        payload=probe_payload,
        retries=ALERT_WEBHOOK_RETRIES,
        timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
    )
    probe_event_type = event_type or "alert_channel_recovery_probe"
    probe_status = "success" if ok and err is None else ("warning" if ok else "failed")
    delivery_id = _write_alert_delivery(
        event_type=probe_event_type,
        target=normalized_target,
        status=probe_status,
        error=err,
        payload={**probe_payload, "probe": True},
    )
    after = _compute_alert_channel_guard_state(
        normalized_target,
        now=datetime.now(timezone.utc),
        event_type=event_type,
    )
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_guard_recover",
        resource_type="alert_delivery",
        resource_id=normalized_target,
        status=probe_status,
        detail={
            "target": normalized_target,
            "event_type": event_type,
            "probe_delivery_id": delivery_id,
            "probe_status": probe_status,
            "probe_error": err,
            "before_state": before.get("state"),
            "after_state": after.get("state"),
            "before_consecutive_failures": before.get("consecutive_failures"),
            "after_consecutive_failures": after.get("consecutive_failures"),
        },
    )
    return {
        "target": normalized_target,
        "event_type": event_type,
        "probe_delivery_id": delivery_id,
        "probe_status": probe_status,
        "probe_error": err,
        "before": before,
        "after": after,
        "recommended_recovery_steps": [
            "1)  endpoint / .",
            "2) guard/recover probe  success .",
            "3) /api/ops/alerts/channels/guard state=healthy  .",
        ],
    }


@app.post("/api/ops/alerts/channels/guard/recover-batch")
def recover_alert_channel_guard_batch(
    event_type: Annotated[str | None, Query()] = None,
    state: Annotated[str, Query(pattern=r"^(quarantined|warning|all)$")] = "quarantined",
    max_targets: Annotated[int | None, Query(ge=1, le=500)] = None,
    dry_run: Annotated[bool, Query()] = False,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_alert_guard_recover_job(
        event_type=event_type,
        state_filter=state,
        max_targets=max_targets,
        dry_run=dry_run,
        trigger="api",
    )
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_guard_recover_batch",
        resource_type="alert_delivery",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "success"),
        detail={
            "event_type": event_type,
            "state_filter": state,
            "max_targets": result.get("max_targets"),
            "dry_run": dry_run,
            "selected_target_count": result.get("selected_target_count"),
            "processed_count": result.get("processed_count"),
            "success_count": result.get("success_count"),
            "warning_count": result.get("warning_count"),
            "failed_count": result.get("failed_count"),
            "skipped_count": result.get("skipped_count"),
        },
    )
    return result


@app.get("/api/ops/alerts/channels/guard/recover/latest")
def get_alert_channel_guard_recover_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "alert_guard_recover")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No alert_guard_recover run found")
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    response = {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        "event_type": detail.get("event_type"),
        "state_filter": detail.get("state_filter"),
        "max_targets": detail.get("max_targets"),
        "dry_run": bool(detail.get("dry_run", False)),
        "selected_target_count": int(detail.get("selected_target_count") or 0),
        "processed_count": int(detail.get("processed_count") or 0),
        "success_count": int(detail.get("success_count") or 0),
        "warning_count": int(detail.get("warning_count") or 0),
        "failed_count": int(detail.get("failed_count") or 0),
        "skipped_count": int(detail.get("skipped_count") or 0),
        "results": detail.get("results", []),
    }
    _write_audit_log(
        principal=principal,
        action="ops_alert_channel_guard_recover_latest_view",
        resource_type="alert_delivery",
        resource_id=str(model.id),
        detail={
            "run_id": model.id,
            "status": model.status,
            "processed_count": response["processed_count"],
            "failed_count": response["failed_count"],
        },
    )
    return response


@app.get("/api/ops/alerts/retention/policy")
def get_alert_retention_policy(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    _write_audit_log(
        principal=principal,
        action="ops_alert_retention_policy_view",
        resource_type="alert_delivery",
        resource_id="policy",
        detail={
            "retention_days": ALERT_RETENTION_DAYS,
            "max_delete": ALERT_RETENTION_MAX_DELETE,
            "archive_enabled": ALERT_RETENTION_ARCHIVE_ENABLED,
            "archive_path": ALERT_RETENTION_ARCHIVE_PATH,
        },
    )
    return {
        "retention_days": max(1, ALERT_RETENTION_DAYS),
        "max_delete": max(1, ALERT_RETENTION_MAX_DELETE),
        "archive_enabled": ALERT_RETENTION_ARCHIVE_ENABLED,
        "archive_path": ALERT_RETENTION_ARCHIVE_PATH,
    }


@app.get("/api/ops/alerts/retention/latest")
def get_alert_retention_latest(
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    with get_conn() as conn:
        row = conn.execute(
            select(job_runs)
            .where(job_runs.c.job_name == "alert_retention")
            .order_by(job_runs.c.finished_at.desc(), job_runs.c.id.desc())
            .limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="No alert_retention run found")
    model = _row_to_job_run_model(row)
    detail = model.detail if isinstance(model.detail, dict) else {}
    response = {
        "run_id": model.id,
        "job_name": model.job_name,
        "trigger": model.trigger,
        "status": model.status,
        "started_at": model.started_at.isoformat(),
        "finished_at": model.finished_at.isoformat(),
        "retention_days": detail.get("retention_days"),
        "max_delete": detail.get("max_delete"),
        "dry_run": bool(detail.get("dry_run", False)),
        "write_archive": bool(detail.get("write_archive", False)),
        "candidate_count": int(detail.get("candidate_count") or 0),
        "deleted_count": int(detail.get("deleted_count") or 0),
        "archive_file": detail.get("archive_file"),
        "archive_error": detail.get("archive_error"),
        "cutoff": detail.get("cutoff"),
    }
    _write_audit_log(
        principal=principal,
        action="ops_alert_retention_latest_view",
        resource_type="alert_delivery",
        resource_id=str(model.id),
        detail={
            "run_id": model.id,
            "status": model.status,
            "deleted_count": response["deleted_count"],
            "archive_error": response["archive_error"],
        },
    )
    return response


@app.post("/api/ops/alerts/retention/run")
def run_alert_retention(
    retention_days: Annotated[int | None, Query(ge=1, le=3650)] = None,
    max_delete: Annotated[int | None, Query(ge=1, le=50000)] = None,
    dry_run: Annotated[bool, Query()] = False,
    write_archive: Annotated[bool | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> dict[str, Any]:
    result = run_alert_retention_job(
        retention_days=retention_days,
        max_delete=max_delete,
        dry_run=dry_run,
        write_archive=write_archive,
        trigger="api",
    )
    _write_audit_log(
        principal=principal,
        action="ops_alert_retention_run",
        resource_type="alert_delivery",
        resource_id=str(result.get("run_id") or "pending"),
        status=str(result.get("status") or "success"),
        detail={
            "retention_days": result.get("retention_days"),
            "max_delete": result.get("max_delete"),
            "dry_run": result.get("dry_run"),
            "write_archive": result.get("write_archive"),
            "candidate_count": result.get("candidate_count"),
            "deleted_count": result.get("deleted_count"),
            "archive_file": result.get("archive_file"),
            "archive_error": result.get("archive_error"),
        },
    )
    return result


@app.post("/api/ops/sla/simulate", response_model=SlaWhatIfResponse)
def simulate_sla(
    payload: SlaWhatIfRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaWhatIfResponse:
    _require_site_access(principal, payload.site)
    allowed_sites = _allowed_sites_for_principal(principal) if payload.site is None else None
    result = simulate_sla_policy_change(
        policy=payload.policy,
        site=payload.site,
        limit=payload.limit,
        include_work_order_ids=payload.include_work_order_ids,
        sample_size=payload.sample_size,
        recompute_due_from_policy=payload.recompute_due_from_policy,
        allowed_sites=allowed_sites,
    )
    _write_audit_log(
        principal=principal,
        action="sla_policy_simulation_run",
        resource_type="sla_policy",
        resource_id=payload.site or "global",
        detail={
            "site": payload.site,
            "limit": payload.limit,
            "baseline_escalate_count": result.baseline_escalate_count,
            "simulated_escalate_count": result.simulated_escalate_count,
            "delta_escalate_count": result.delta_escalate_count,
        },
    )
    return result


@app.post("/api/ops/alerts/retries/run", response_model=AlertRetryRunResponse)
def run_alert_retries(
    payload: AlertRetryRunRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AlertRetryRunResponse:
    result = run_alert_retry_job(
        event_type=payload.event_type,
        only_status=payload.only_status,
        limit=payload.limit,
        max_attempt_count=payload.max_attempt_count,
        min_last_attempt_age_sec=payload.min_last_attempt_age_sec,
        trigger="api",
    )
    _write_audit_log(
        principal=principal,
        action="alert_retry_batch_run",
        resource_type="alert_delivery",
        resource_id="batch",
        detail={
            "event_type": payload.event_type,
            "statuses": payload.only_status,
            "limit": payload.limit,
            "processed_count": result.processed_count,
            "failed_count": result.failed_count,
        },
    )
    return result


@app.post("/api/admin/policies/sla/proposals", response_model=SlaPolicyProposalRead, status_code=201)
def create_sla_policy_proposal(
    payload: SlaPolicyProposalCreate,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyProposalRead:
    now = datetime.now(timezone.utc)
    normalized_site = _normalize_site_name(payload.site)
    if normalized_site is None:
        _require_global_site_scope(principal)
    else:
        _require_site_access(principal, normalized_site)

    allowed_sites = _allowed_sites_for_principal(principal) if normalized_site is None else None
    simulation = simulate_sla_policy_change(
        policy=payload.policy,
        site=normalized_site,
        limit=payload.simulation_limit,
        include_work_order_ids=payload.include_work_order_ids,
        sample_size=payload.sample_size,
        recompute_due_from_policy=payload.recompute_due_from_policy,
        allowed_sites=allowed_sites,
    )
    requested_by = str(principal.get("username") or "unknown")

    with get_conn() as conn:
        result = conn.execute(
            insert(sla_policy_proposals).values(
                site=normalized_site,
                policy_json=_to_json_text(_normalize_sla_policy(payload.policy.model_dump())),
                simulation_json=_to_json_text(simulation.model_dump()),
                note=payload.note or "",
                status=SLA_PROPOSAL_STATUS_PENDING,
                requested_by=requested_by,
                decided_by=None,
                decision_note=None,
                created_at=now,
                decided_at=None,
                applied_at=None,
            )
        )
        proposal_id = int(result.inserted_primary_key[0])
        row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()

    if row is None:
        raise HTTPException(status_code=500, detail="Failed to create SLA policy proposal")
    model = _row_to_sla_policy_proposal_model(row)
    _write_audit_log(
        principal=principal,
        action="sla_policy_proposal_create",
        resource_type="sla_policy_proposal",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "baseline_escalate_count": simulation.baseline_escalate_count,
            "simulated_escalate_count": simulation.simulated_escalate_count,
            "delta_escalate_count": simulation.delta_escalate_count,
        },
    )
    return model


@app.get("/api/admin/policies/sla/proposals", response_model=list[SlaPolicyProposalRead])
def list_sla_policy_proposals(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=300)] = 100,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[SlaPolicyProposalRead]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is not None:
        _require_site_access(principal, normalized_site)

    stmt = select(sla_policy_proposals).order_by(
        sla_policy_proposals.c.created_at.desc(),
        sla_policy_proposals.c.id.desc(),
    )
    if normalized_site is not None:
        stmt = stmt.where(sla_policy_proposals.c.site == normalized_site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(sla_policy_proposals.c.site.in_(allowed_sites))
    if status is not None:
        stmt = stmt.where(sla_policy_proposals.c.status == status)
    stmt = stmt.limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_sla_policy_proposal_model(row) for row in rows]


@app.get("/api/admin/policies/sla/proposals/{proposal_id}", response_model=SlaPolicyProposalRead)
def get_sla_policy_proposal(
    proposal_id: int,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyProposalRead:
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="SLA policy proposal not found")

    proposal_site = row["site"]
    if proposal_site is None:
        _require_global_site_scope(principal)
    else:
        _require_site_access(principal, str(proposal_site))
    return _row_to_sla_policy_proposal_model(row)


@app.post("/api/admin/policies/sla/proposals/{proposal_id}/approve", response_model=SlaPolicyProposalRead)
def approve_sla_policy_proposal(
    proposal_id: int,
    payload: SlaPolicyProposalDecision,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyProposalRead:
    now = datetime.now(timezone.utc)
    decided_by = str(principal.get("username") or "unknown")

    with get_conn() as conn:
        row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="SLA policy proposal not found")

        proposal_site = row["site"]
        if proposal_site is None:
            _require_global_site_scope(principal)
        else:
            _require_site_access(principal, str(proposal_site))

        if str(row["status"]) != SLA_PROPOSAL_STATUS_PENDING:
            raise HTTPException(status_code=409, detail="Only pending proposal can be approved")
        if str(row["requested_by"]) == decided_by:
            raise HTTPException(status_code=409, detail="Proposal cannot be self-approved")

    policy_raw = str(row["policy_json"] or "{}")
    try:
        policy_dict = json.loads(policy_raw)
    except json.JSONDecodeError as exc:
        raise HTTPException(status_code=500, detail="Invalid proposal policy payload") from exc
    if not isinstance(policy_dict, dict):
        raise HTTPException(status_code=500, detail="Invalid proposal policy payload")

    policy_model = SlaPolicyUpdate(**policy_dict)
    applied_policy = _upsert_sla_policy(
        policy_model,
        site=row["site"],
        source_action="proposal_approval",
        actor_username=decided_by,
        note=f"proposal_id={proposal_id}; {payload.note or ''}".strip(),
    )

    with get_conn() as conn:
        conn.execute(
            update(sla_policy_proposals)
            .where(sla_policy_proposals.c.id == proposal_id)
            .values(
                status=SLA_PROPOSAL_STATUS_APPROVED,
                decided_by=decided_by,
                decision_note=payload.note or "",
                decided_at=now,
                applied_at=now,
            )
        )
        updated_row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to approve SLA policy proposal")
    model = _row_to_sla_policy_proposal_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="sla_policy_proposal_approve",
        resource_type="sla_policy_proposal",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "status": model.status,
            "applied_policy_key": applied_policy.policy_key,
            "decision_note": payload.note,
        },
    )
    return model


@app.post("/api/admin/policies/sla/proposals/{proposal_id}/reject", response_model=SlaPolicyProposalRead)
def reject_sla_policy_proposal(
    proposal_id: int,
    payload: SlaPolicyProposalDecision,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyProposalRead:
    now = datetime.now(timezone.utc)
    decided_by = str(principal.get("username") or "unknown")

    with get_conn() as conn:
        row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="SLA policy proposal not found")

        proposal_site = row["site"]
        if proposal_site is None:
            _require_global_site_scope(principal)
        else:
            _require_site_access(principal, str(proposal_site))

        if str(row["status"]) != SLA_PROPOSAL_STATUS_PENDING:
            raise HTTPException(status_code=409, detail="Only pending proposal can be rejected")

        conn.execute(
            update(sla_policy_proposals)
            .where(sla_policy_proposals.c.id == proposal_id)
            .values(
                status=SLA_PROPOSAL_STATUS_REJECTED,
                decided_by=decided_by,
                decision_note=payload.note or "",
                decided_at=now,
                applied_at=None,
            )
        )
        updated_row = conn.execute(
            select(sla_policy_proposals).where(sla_policy_proposals.c.id == proposal_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to reject SLA policy proposal")
    model = _row_to_sla_policy_proposal_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="sla_policy_proposal_reject",
        resource_type="sla_policy_proposal",
        resource_id=str(model.id),
        detail={"site": model.site, "status": model.status, "decision_note": payload.note},
    )
    return model


@app.post("/api/ops/alerts/deliveries/{delivery_id}/retry", response_model=AlertDeliveryRead)
def retry_alert_delivery(
    delivery_id: int,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AlertDeliveryRead:
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(alert_deliveries).where(alert_deliveries.c.id == delivery_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Alert delivery not found")

        payload_raw = str(row["payload_json"] or "{}")
        try:
            payload = json.loads(payload_raw)
        except json.JSONDecodeError:
            payload = {}
        if not isinstance(payload, dict):
            payload = {}

        ok, err = _post_json_with_retries(
            url=str(row["target"]),
            payload=payload,
            retries=ALERT_WEBHOOK_RETRIES,
            timeout_sec=ALERT_WEBHOOK_TIMEOUT_SEC,
        )
        next_status = "success" if ok and err is None else ("warning" if ok else "failed")
        next_attempt_count = int(row["attempt_count"]) + 1
        conn.execute(
            update(alert_deliveries)
            .where(alert_deliveries.c.id == delivery_id)
            .values(
                status=next_status,
                error=err,
                attempt_count=next_attempt_count,
                last_attempt_at=now,
                updated_at=now,
            )
        )
        updated_row = conn.execute(
            select(alert_deliveries).where(alert_deliveries.c.id == delivery_id).limit(1)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to retry alert delivery")
    model = _row_to_alert_delivery_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="alert_delivery_retry",
        resource_type="alert_delivery",
        resource_id=str(model.id),
        status=model.status,
        detail={"target": model.target, "status": model.status, "attempt_count": model.attempt_count},
    )
    return model


@app.get("/api/admin/policies/sla", response_model=SlaPolicyRead)
def get_sla_policy(
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyRead:
    _require_site_access(principal, site)
    policy, updated_at, source, resolved_site, policy_key = _load_sla_policy(site=site)
    return _sla_policy_to_model(
        policy_key=policy_key,
        site=resolved_site,
        source=source,
        updated_at=updated_at,
        policy=policy,
    )


@app.put("/api/admin/policies/sla", response_model=SlaPolicyRead)
def set_sla_policy(
    payload: SlaPolicyUpdate,
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyRead:
    if site is None:
        _require_global_site_scope(principal)
    else:
        _require_site_access(principal, site)
    actor_username = str(principal.get("username") or "unknown")
    model = _upsert_sla_policy(
        payload,
        site=site,
        source_action="manual_update",
        actor_username=actor_username,
        note="direct policy update",
    )
    _write_audit_log(
        principal=principal,
        action="sla_policy_update",
        resource_type="sla_policy",
        resource_id=model.policy_key,
        detail={
            "site": model.site,
            "source": model.source,
            "default_due_hours": model.default_due_hours,
            "escalation_grace_minutes": model.escalation_grace_minutes,
        },
    )
    return model


@app.get("/api/admin/policies/sla/revisions", response_model=list[SlaPolicyRevisionRead])
def list_sla_policy_revisions(
    site: Annotated[str | None, Query()] = None,
    source_action: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=500)] = 100,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> list[SlaPolicyRevisionRead]:
    normalized_site = _normalize_site_name(site)
    if normalized_site is not None:
        _require_site_access(principal, normalized_site)

    stmt = select(sla_policy_revisions).order_by(
        sla_policy_revisions.c.created_at.desc(),
        sla_policy_revisions.c.id.desc(),
    )
    if normalized_site is not None:
        stmt = stmt.where(sla_policy_revisions.c.site == normalized_site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(sla_policy_revisions.c.site.in_(allowed_sites))
    if source_action is not None:
        stmt = stmt.where(sla_policy_revisions.c.source_action == source_action)
    stmt = stmt.limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_sla_policy_revision_model(row) for row in rows]


@app.post("/api/admin/policies/sla/revisions/{revision_id}/restore", response_model=SlaPolicyRead)
def restore_sla_policy_revision(
    revision_id: int,
    payload: SlaPolicyRestoreRequest,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> SlaPolicyRead:
    with get_conn() as conn:
        row = conn.execute(
            select(sla_policy_revisions).where(sla_policy_revisions.c.id == revision_id)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="SLA policy revision not found")

    revision_site = row["site"]
    if revision_site is None:
        _require_global_site_scope(principal)
    else:
        _require_site_access(principal, str(revision_site))

    raw_policy = str(row["policy_json"] or "{}")
    try:
        policy_dict = json.loads(raw_policy)
    except json.JSONDecodeError as exc:
        raise HTTPException(status_code=500, detail="Invalid revision policy payload") from exc
    if not isinstance(policy_dict, dict):
        raise HTTPException(status_code=500, detail="Invalid revision policy payload")

    policy_model = SlaPolicyUpdate(**policy_dict)
    actor_username = str(principal.get("username") or "unknown")
    model = _upsert_sla_policy(
        policy_model,
        site=revision_site,
        source_action="revision_restore",
        actor_username=actor_username,
        note=f"revision_id={revision_id}; {payload.note or ''}".strip(),
    )
    _write_audit_log(
        principal=principal,
        action="sla_policy_restore",
        resource_type="sla_policy_revision",
        resource_id=str(revision_id),
        detail={
            "site": revision_site,
            "policy_key": model.policy_key,
            "decision_note": payload.note,
        },
    )
    return model


@app.post("/api/admin/tokens/{token_id}/revoke", response_model=AdminTokenRead)
def revoke_admin_token(
    token_id: int,
    principal: dict[str, Any] = Depends(require_permission("admins:manage")),
) -> AdminTokenRead:
    now = datetime.now(timezone.utc)

    with get_conn() as conn:
        row = conn.execute(
            select(
                admin_tokens.c.id.label("token_id"),
                admin_tokens.c.user_id.label("user_id"),
                admin_users.c.username.label("username"),
                admin_tokens.c.label.label("label"),
                admin_tokens.c.is_active.label("is_active"),
                admin_tokens.c.site_scope.label("token_site_scope"),
                admin_users.c.site_scope.label("user_site_scope"),
                admin_tokens.c.expires_at.label("expires_at"),
                admin_tokens.c.last_used_at.label("last_used_at"),
                admin_tokens.c.created_at.label("created_at"),
            )
            .where(admin_tokens.c.id == token_id)
            .where(admin_users.c.id == admin_tokens.c.user_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Admin token not found")

        actor_user_id = principal.get("user_id")
        if actor_user_id is not None and int(actor_user_id) == int(row["user_id"]):
            raise HTTPException(status_code=409, detail="Cannot revoke token of current admin user")

        conn.execute(
            update(admin_tokens)
            .where(admin_tokens.c.id == token_id)
            .values(is_active=False, last_used_at=now)
        )
        updated = conn.execute(
            select(
                admin_tokens.c.id.label("token_id"),
                admin_tokens.c.user_id.label("user_id"),
                admin_users.c.username.label("username"),
                admin_tokens.c.label.label("label"),
                admin_tokens.c.is_active.label("is_active"),
                admin_tokens.c.site_scope.label("token_site_scope"),
                admin_users.c.site_scope.label("user_site_scope"),
                admin_tokens.c.expires_at.label("expires_at"),
                admin_tokens.c.last_used_at.label("last_used_at"),
                admin_tokens.c.created_at.label("created_at"),
            )
            .where(admin_tokens.c.id == token_id)
            .where(admin_users.c.id == admin_tokens.c.user_id)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to revoke admin token")
    model = _row_to_admin_token_model(updated)
    _write_audit_log(
        principal=principal,
        action="admin_token_revoke",
        resource_type="admin_token",
        resource_id=str(model.token_id),
        detail={"user_id": model.user_id, "label": model.label},
    )
    return model


@app.get("/api/workflow-locks", response_model=list[WorkflowLockRead])
def list_workflow_locks(
    site: Annotated[str | None, Query()] = None,
    status: Annotated[str | None, Query()] = None,
    workflow_key: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=200)] = 50,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> list[WorkflowLockRead]:
    _require_workflow_lock_action(principal, action="read")
    _require_site_access(principal, site)
    normalized_status = status.strip().lower() if status is not None else None
    if normalized_status is not None and normalized_status not in WORKFLOW_LOCK_STATUS_SET:
        raise HTTPException(status_code=400, detail="Invalid workflow lock status")

    stmt = select(workflow_locks)
    if site is not None:
        stmt = stmt.where(workflow_locks.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(workflow_locks.c.site.in_(allowed_sites))
    if normalized_status is not None:
        stmt = stmt.where(workflow_locks.c.status == normalized_status)
    if workflow_key is not None:
        stmt = stmt.where(workflow_locks.c.workflow_key == workflow_key)
    stmt = stmt.order_by(workflow_locks.c.created_at.desc(), workflow_locks.c.id.desc()).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_workflow_lock_model(row) for row in rows]


@app.post("/api/workflow-locks", response_model=WorkflowLockRead, status_code=201)
def create_workflow_lock(
    payload: WorkflowLockCreate,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    _require_site_access(principal, payload.site)
    _require_workflow_lock_action(principal, action="create", status=WORKFLOW_LOCK_STATUS_DRAFT)
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)

    with get_conn() as conn:
        result = conn.execute(
            insert(workflow_locks).values(
                site=payload.site,
                workflow_key=payload.workflow_key,
                status=WORKFLOW_LOCK_STATUS_DRAFT,
                content_json=_to_json_text(payload.content),
                requested_ticket=payload.requested_ticket,
                last_comment="",
                lock_reason=None,
                unlock_reason=None,
                created_by=actor_username,
                updated_by=actor_username,
                reviewed_by=None,
                approved_by=None,
                locked_by=None,
                unlocked_by=None,
                created_at=now,
                updated_at=now,
                reviewed_at=None,
                approved_at=None,
                locked_at=None,
                unlocked_at=None,
            )
        )
        workflow_lock_id = int(result.inserted_primary_key[0])
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if row is None:
        raise HTTPException(status_code=500, detail="Failed to create workflow lock")
    model = _row_to_workflow_lock_model(row)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_create",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "workflow_key": model.workflow_key,
            "status": model.status,
            "requested_ticket": model.requested_ticket,
        },
    )
    return model


@app.get("/api/workflow-locks/{workflow_lock_id}", response_model=WorkflowLockRead)
def get_workflow_lock(
    workflow_lock_id: int,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    _require_workflow_lock_action(principal, action="read")
    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="Workflow lock not found")
    _require_site_access(principal, str(row["site"]))
    return _row_to_workflow_lock_model(row)


@app.patch("/api/workflow-locks/{workflow_lock_id}/draft", response_model=WorkflowLockRead)
def update_workflow_lock_draft(
    workflow_lock_id: int,
    payload: WorkflowLockDraftUpdate,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)

    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="update_draft", status=str(row["status"]))

        next_content_json = row["content_json"]
        if payload.content is not None:
            next_content_json = _to_json_text(payload.content)
        next_ticket = row["requested_ticket"] if payload.requested_ticket is None else payload.requested_ticket
        next_comment = payload.comment or str(row.get("last_comment") or "")

        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                content_json=next_content_json,
                requested_ticket=next_ticket,
                last_comment=next_comment,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to update workflow lock draft")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_update_draft",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={"status": model.status, "requested_ticket": model.requested_ticket},
    )
    return model


@app.post("/api/workflow-locks/{workflow_lock_id}/submit", response_model=WorkflowLockRead)
def submit_workflow_lock_for_review(
    workflow_lock_id: int,
    payload: WorkflowLockTransitionRequest,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="submit", status=str(row["status"]))

        next_comment = payload.comment or str(row.get("last_comment") or "")
        next_ticket = row["requested_ticket"] if payload.requested_ticket is None else payload.requested_ticket
        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                status=WORKFLOW_LOCK_STATUS_REVIEW,
                requested_ticket=next_ticket,
                last_comment=next_comment,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to submit workflow lock")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_submit",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={"status": model.status, "requested_ticket": model.requested_ticket, "comment": payload.comment},
    )
    return model


@app.post("/api/workflow-locks/{workflow_lock_id}/approve", response_model=WorkflowLockRead)
def approve_workflow_lock(
    workflow_lock_id: int,
    payload: WorkflowLockTransitionRequest,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="approve", status=str(row["status"]))

        next_comment = payload.comment or str(row.get("last_comment") or "")
        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                status=WORKFLOW_LOCK_STATUS_APPROVED,
                last_comment=next_comment,
                reviewed_by=actor_username,
                reviewed_at=now,
                approved_by=actor_username,
                approved_at=now,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to approve workflow lock")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_approve",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={"status": model.status, "comment": payload.comment},
    )
    return model


@app.post("/api/workflow-locks/{workflow_lock_id}/reject", response_model=WorkflowLockRead)
def reject_workflow_lock(
    workflow_lock_id: int,
    payload: WorkflowLockTransitionRequest,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="reject", status=str(row["status"]))

        next_comment = payload.comment or "Rejected in review"
        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                status=WORKFLOW_LOCK_STATUS_DRAFT,
                last_comment=next_comment,
                reviewed_by=actor_username,
                reviewed_at=now,
                approved_by=None,
                approved_at=None,
                locked_by=None,
                locked_at=None,
                lock_reason=None,
                unlocked_by=None,
                unlocked_at=None,
                unlock_reason=None,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to reject workflow lock")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_reject",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={"status": model.status, "comment": payload.comment},
    )
    return model


@app.post("/api/workflow-locks/{workflow_lock_id}/lock", response_model=WorkflowLockRead)
def lock_workflow_lock(
    workflow_lock_id: int,
    payload: WorkflowLockTransitionRequest,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="lock", status=str(row["status"]))

        next_comment = payload.comment or str(row.get("last_comment") or "")
        next_ticket = row["requested_ticket"] if payload.requested_ticket is None else payload.requested_ticket
        lock_reason = payload.reason.strip() or "Approved workflow lock"
        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                status=WORKFLOW_LOCK_STATUS_LOCKED,
                requested_ticket=next_ticket,
                lock_reason=lock_reason,
                last_comment=next_comment,
                locked_by=actor_username,
                locked_at=now,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to lock workflow")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_lock",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={"status": model.status, "lock_reason": model.lock_reason, "requested_ticket": model.requested_ticket},
    )
    return model


@app.post("/api/workflow-locks/{workflow_lock_id}/unlock", response_model=WorkflowLockRead)
def unlock_workflow_lock(
    workflow_lock_id: int,
    payload: WorkflowLockTransitionRequest,
    principal: dict[str, Any] = Depends(get_current_admin),
) -> WorkflowLockRead:
    actor_username = str(principal.get("username") or "unknown")
    now = datetime.now(timezone.utc)
    reason = payload.reason.strip()
    ticket = (payload.requested_ticket or "").strip()
    if not reason:
        raise HTTPException(status_code=400, detail="Unlock reason is required")
    if not ticket:
        raise HTTPException(status_code=400, detail="Unlock request ticket is required")

    with get_conn() as conn:
        row = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Workflow lock not found")
        _require_site_access(principal, str(row["site"]))
        _require_workflow_lock_action(principal, action="unlock", status=str(row["status"]))

        next_comment = payload.comment or str(row.get("last_comment") or "")
        conn.execute(
            update(workflow_locks)
            .where(workflow_locks.c.id == workflow_lock_id)
            .values(
                status=WORKFLOW_LOCK_STATUS_APPROVED,
                requested_ticket=ticket,
                unlock_reason=reason,
                last_comment=next_comment,
                unlocked_by=actor_username,
                unlocked_at=now,
                updated_by=actor_username,
                updated_at=now,
            )
        )
        updated = conn.execute(
            select(workflow_locks).where(workflow_locks.c.id == workflow_lock_id).limit(1)
        ).mappings().first()

    if updated is None:
        raise HTTPException(status_code=500, detail="Failed to unlock workflow")
    model = _row_to_workflow_lock_model(updated)
    _write_audit_log(
        principal=principal,
        action="workflow_lock_unlock",
        resource_type="workflow_lock",
        resource_id=str(model.id),
        detail={
            "status": model.status,
            "unlock_reason": reason,
            "requested_ticket": ticket,
            "comment": payload.comment,
        },
    )
    return model


@app.post("/api/inspections", response_model=InspectionRead, status_code=201)
def create_inspection(
    payload: InspectionCreate,
    principal: dict[str, Any] = Depends(require_permission("inspections:write")),
) -> InspectionRead:
    _require_site_access(principal, payload.site)
    risk_level, flags = _calculate_risk(payload)
    now = datetime.now(timezone.utc)
    inspected_at = _to_utc(payload.inspected_at)

    with get_conn() as conn:
        result = conn.execute(
            insert(inspections).values(
                site=payload.site,
                location=payload.location,
                cycle=payload.cycle,
                inspector=payload.inspector,
                inspected_at=inspected_at,
                transformer_kva=payload.transformer_kva,
                voltage_r=payload.voltage_r,
                voltage_s=payload.voltage_s,
                voltage_t=payload.voltage_t,
                current_r=payload.current_r,
                current_s=payload.current_s,
                current_t=payload.current_t,
                winding_temp_c=payload.winding_temp_c,
                grounding_ohm=payload.grounding_ohm,
                insulation_mohm=payload.insulation_mohm,
                notes=payload.notes,
                risk_level=risk_level,
                risk_flags=",".join(flags),
                created_at=now,
            )
        )
        inspection_id = result.inserted_primary_key[0]
        if inspection_id is None:
            raise HTTPException(status_code=500, detail="Failed to create inspection")

        row = conn.execute(
            select(inspections).where(inspections.c.id == inspection_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=500, detail="Failed to load created inspection")

    model = _row_to_read_model(row)
    _write_audit_log(
        principal=principal,
        action="inspection_create",
        resource_type="inspection",
        resource_id=str(model.id),
        detail={"site": model.site, "location": model.location, "risk_level": model.risk_level},
    )
    return model


@app.get("/api/inspections", response_model=list[InspectionRead])
def list_inspections(
    site: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=100)] = 20,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("inspections:read")),
) -> list[InspectionRead]:
    _require_site_access(principal, site)
    stmt = select(inspections)
    if site is not None:
        stmt = stmt.where(inspections.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(inspections.c.site.in_(allowed_sites))

    with get_conn() as conn:
        rows = conn.execute(
            stmt.order_by(inspections.c.inspected_at.desc(), inspections.c.id.desc()).limit(limit).offset(offset)
        ).mappings().all()
    return [_row_to_read_model(r) for r in rows]


@app.get("/api/inspections/{inspection_id}", response_model=InspectionRead)
def get_inspection(
    inspection_id: int,
    principal: dict[str, Any] = Depends(require_permission("inspections:read")),
) -> InspectionRead:
    with get_conn() as conn:
        row = conn.execute(
            select(inspections).where(inspections.c.id == inspection_id)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="Inspection not found")
    _require_site_access(principal, str(row["site"]))
    return _row_to_read_model(row)


@app.get("/inspections/{inspection_id}/print", response_class=HTMLResponse)
def print_inspection(
    inspection_id: int,
    principal: dict[str, Any] = Depends(require_permission("inspections:read")),
) -> str:
    with get_conn() as conn:
        row = conn.execute(
            select(inspections).where(inspections.c.id == inspection_id)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="Inspection not found")
    _require_site_access(principal, str(row["site"]))

    data = _row_to_read_model(row)
    return f"""
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Inspection #{data.id}</title>
  <style>
    @page {{ size: A4; margin: 12mm; }}
    body {{ font-family: Arial, sans-serif; color: #111; }}
    h1 {{ margin-bottom: 10px; font-size: 20px; }}
    table {{ width: 100%; border-collapse: collapse; }}
    td {{ border: 1px solid #ddd; padding: 6px; font-size: 13px; }}
    .k {{ width: 30%; background: #f7f7f7; font-weight: 600; }}
  </style>
</head>
<body>
  <h1>Inspection Report #{data.id}</h1>
  <table>
    <tr><td class="k">Site</td><td>{data.site}</td></tr>
    <tr><td class="k">Location</td><td>{data.location}</td></tr>
    <tr><td class="k">Cycle</td><td>{data.cycle}</td></tr>
    <tr><td class="k">Inspector</td><td>{data.inspector}</td></tr>
    <tr><td class="k">Inspected At</td><td>{data.inspected_at.isoformat()}</td></tr>
    <tr><td class="k">Risk Level</td><td>{data.risk_level}</td></tr>
    <tr><td class="k">Risk Flags</td><td>{", ".join(data.risk_flags) or "-"}</td></tr>
    <tr><td class="k">Transformer (kVA)</td><td>{data.transformer_kva or "-"}</td></tr>
    <tr><td class="k">Voltage (R/S/T)</td><td>{data.voltage_r or "-"} / {data.voltage_s or "-"} / {data.voltage_t or "-"}</td></tr>
    <tr><td class="k">Current (R/S/T)</td><td>{data.current_r or "-"} / {data.current_s or "-"} / {data.current_t or "-"}</td></tr>
    <tr><td class="k">Winding Temp (C)</td><td>{data.winding_temp_c or "-"}</td></tr>
    <tr><td class="k">Grounding (ohm)</td><td>{data.grounding_ohm or "-"}</td></tr>
    <tr><td class="k">Insulation (Mohm)</td><td>{data.insulation_mohm or "-"}</td></tr>
    <tr><td class="k">Notes</td><td>{data.notes or "-"}</td></tr>
    <tr><td class="k">Created At</td><td>{data.created_at.isoformat()}</td></tr>
  </table>
</body>
</html>
"""


@app.post("/api/work-orders", response_model=WorkOrderRead, status_code=201)
def create_work_order(
    payload: WorkOrderCreate,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderRead:
    _require_site_access(principal, payload.site)
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "unknown")
    due_at = _as_optional_datetime(payload.due_at)
    auto_due_applied = False
    policy_source = "manual"
    if due_at is None:
        policy, _, source, _, _ = _load_sla_policy(site=payload.site)
        due_hours = int(policy["default_due_hours"].get(payload.priority, SLA_DEFAULT_DUE_HOURS["medium"]))
        due_at = now + timedelta(hours=due_hours)
        auto_due_applied = True
        policy_source = source

    with get_conn() as conn:
        result = conn.execute(
            insert(work_orders).values(
                title=payload.title,
                description=payload.description,
                site=payload.site,
                location=payload.location,
                priority=payload.priority,
                status="open",
                assignee=payload.assignee,
                reporter=payload.reporter,
                inspection_id=payload.inspection_id,
                due_at=due_at,
                acknowledged_at=None,
                completed_at=None,
                resolution_notes="",
                is_escalated=False,
                created_at=now,
                updated_at=now,
            )
        )
        work_order_id = result.inserted_primary_key[0]
        _append_work_order_event(
            conn,
            work_order_id=int(work_order_id),
            event_type="created",
            actor_username=actor_username,
            from_status=None,
            to_status="open",
            note=payload.description or "",
            detail={"priority": payload.priority, "assignee": payload.assignee, "reporter": payload.reporter},
        )
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()

    if row is None:
        raise HTTPException(status_code=500, detail="Failed to create work order")
    model = _row_to_work_order_model(row)
    _write_audit_log(
        principal=principal,
        action="work_order_create",
        resource_type="work_order",
        resource_id=str(model.id),
        detail={
            "site": model.site,
            "priority": model.priority,
            "due_at": model.due_at,
            "auto_due_applied": auto_due_applied,
            "policy_source": policy_source,
        },
    )
    return model


@app.get("/api/work-orders", response_model=list[WorkOrderRead])
def list_work_orders(
    status: Annotated[str | None, Query()] = None,
    site: Annotated[str | None, Query()] = None,
    limit: Annotated[int, Query(ge=1, le=100)] = 20,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("work_orders:read")),
) -> list[WorkOrderRead]:
    _require_site_access(principal, site)
    stmt = select(work_orders)
    if status is not None:
        stmt = stmt.where(work_orders.c.status == status)
    if site is not None:
        stmt = stmt.where(work_orders.c.site == site)
    else:
        allowed_sites = _allowed_sites_for_principal(principal)
        if allowed_sites is not None:
            if not allowed_sites:
                return []
            stmt = stmt.where(work_orders.c.site.in_(allowed_sites))

    stmt = stmt.order_by(work_orders.c.created_at.desc(), work_orders.c.id.desc()).limit(limit).offset(offset)

    with get_conn() as conn:
        rows = conn.execute(stmt).mappings().all()
    return [_row_to_work_order_model(r) for r in rows]


@app.get("/api/work-orders/{work_order_id}", response_model=WorkOrderRead)
def get_work_order(
    work_order_id: int,
    principal: dict[str, Any] = Depends(require_permission("work_orders:read")),
) -> WorkOrderRead:
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
    if row is None:
        raise HTTPException(status_code=404, detail="Work order not found")
    _require_site_access(principal, str(row["site"]))
    return _row_to_work_order_model(row)


@app.patch("/api/work-orders/{work_order_id}/ack", response_model=WorkOrderRead)
def ack_work_order(
    work_order_id: int,
    payload: WorkOrderAck,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "unknown")
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))
        _validate_work_order_transition(str(row["status"]), "acked")

        assignee = payload.assignee if payload.assignee is not None else row["assignee"]
        conn.execute(
            update(work_orders)
            .where(work_orders.c.id == work_order_id)
            .values(
                status="acked",
                assignee=assignee,
                acknowledged_at=now,
                updated_at=now,
            )
        )
        _append_work_order_event(
            conn,
            work_order_id=work_order_id,
            event_type="status_changed",
            actor_username=actor_username,
            from_status=str(row["status"]),
            to_status="acked",
            note="Acknowledged work order",
            detail={"assignee": assignee},
        )
        updated_row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to update work order")
    model = _row_to_work_order_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="work_order_ack",
        resource_type="work_order",
        resource_id=str(model.id),
        detail={"status": model.status, "assignee": model.assignee},
    )
    return model


@app.patch("/api/work-orders/{work_order_id}/complete", response_model=WorkOrderRead)
def complete_work_order(
    work_order_id: int,
    payload: WorkOrderComplete,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "unknown")
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))
        if row["status"] == "completed":
            return _row_to_work_order_model(row)
        _validate_work_order_transition(str(row["status"]), "completed")

        conn.execute(
            update(work_orders)
            .where(work_orders.c.id == work_order_id)
            .values(
                status="completed",
                completed_at=now,
                resolution_notes=payload.resolution_notes,
                updated_at=now,
            )
        )
        _append_work_order_event(
            conn,
            work_order_id=work_order_id,
            event_type="status_changed",
            actor_username=actor_username,
            from_status=str(row["status"]),
            to_status="completed",
            note=payload.resolution_notes,
            detail={"resolution_notes": payload.resolution_notes},
        )
        updated_row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to complete work order")
    model = _row_to_work_order_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="work_order_complete",
        resource_type="work_order",
        resource_id=str(model.id),
        detail={"status": model.status},
    )
    return model


@app.patch("/api/work-orders/{work_order_id}/cancel", response_model=WorkOrderRead)
def cancel_work_order(
    work_order_id: int,
    payload: WorkOrderCancel,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "unknown")
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))
        _validate_work_order_transition(str(row["status"]), "canceled")

        conn.execute(
            update(work_orders)
            .where(work_orders.c.id == work_order_id)
            .values(
                status="canceled",
                resolution_notes=payload.reason or row["resolution_notes"] or "",
                updated_at=now,
            )
        )
        _append_work_order_event(
            conn,
            work_order_id=work_order_id,
            event_type="status_changed",
            actor_username=actor_username,
            from_status=str(row["status"]),
            to_status="canceled",
            note=payload.reason or "Canceled work order",
            detail={"reason": payload.reason},
        )
        updated_row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to cancel work order")
    model = _row_to_work_order_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="work_order_cancel",
        resource_type="work_order",
        resource_id=str(model.id),
        detail={"status": model.status, "reason": payload.reason},
    )
    return model


@app.patch("/api/work-orders/{work_order_id}/reopen", response_model=WorkOrderRead)
def reopen_work_order(
    work_order_id: int,
    payload: WorkOrderReopen,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderRead:
    now = datetime.now(timezone.utc)
    actor_username = str(principal.get("username") or "unknown")
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))
        _validate_work_order_transition(str(row["status"]), "open")

        conn.execute(
            update(work_orders)
            .where(work_orders.c.id == work_order_id)
            .values(
                status="open",
                completed_at=None,
                acknowledged_at=None,
                is_escalated=False,
                updated_at=now,
            )
        )
        _append_work_order_event(
            conn,
            work_order_id=work_order_id,
            event_type="status_changed",
            actor_username=actor_username,
            from_status=str(row["status"]),
            to_status="open",
            note=payload.reason or "Reopened work order",
            detail={"reason": payload.reason},
        )
        updated_row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()

    if updated_row is None:
        raise HTTPException(status_code=500, detail="Failed to reopen work order")
    model = _row_to_work_order_model(updated_row)
    _write_audit_log(
        principal=principal,
        action="work_order_reopen",
        resource_type="work_order",
        resource_id=str(model.id),
        detail={"status": model.status, "reason": payload.reason},
    )
    return model


@app.post("/api/work-orders/{work_order_id}/comments", response_model=WorkOrderEventRead, status_code=201)
def add_work_order_comment(
    work_order_id: int,
    payload: WorkOrderCommentCreate,
    principal: dict[str, Any] = Depends(require_permission("work_orders:write")),
) -> WorkOrderEventRead:
    actor_username = str(principal.get("username") or "unknown")
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))

        result = conn.execute(
            insert(work_order_events).values(
                work_order_id=work_order_id,
                event_type="comment",
                actor_username=actor_username,
                from_status=row["status"],
                to_status=row["status"],
                note=payload.comment,
                detail_json=_to_json_text({"comment": payload.comment}),
                created_at=datetime.now(timezone.utc),
            )
        )
        event_id = int(result.inserted_primary_key[0])
        event_row = conn.execute(
            select(work_order_events).where(work_order_events.c.id == event_id)
        ).mappings().first()

    if event_row is None:
        raise HTTPException(status_code=500, detail="Failed to create work order comment")
    model = _row_to_work_order_event_model(event_row)
    _write_audit_log(
        principal=principal,
        action="work_order_comment_add",
        resource_type="work_order",
        resource_id=str(work_order_id),
        detail={"event_id": model.id},
    )
    return model


@app.get("/api/work-orders/{work_order_id}/events", response_model=list[WorkOrderEventRead])
def list_work_order_events(
    work_order_id: int,
    limit: Annotated[int, Query(ge=1, le=300)] = 100,
    offset: Annotated[int, Query(ge=0)] = 0,
    principal: dict[str, Any] = Depends(require_permission("work_orders:read")),
) -> list[WorkOrderEventRead]:
    with get_conn() as conn:
        row = conn.execute(
            select(work_orders).where(work_orders.c.id == work_order_id)
        ).mappings().first()
        if row is None:
            raise HTTPException(status_code=404, detail="Work order not found")
        _require_site_access(principal, str(row["site"]))

        rows = conn.execute(
            select(work_order_events)
            .where(work_order_events.c.work_order_id == work_order_id)
            .order_by(work_order_events.c.created_at.asc(), work_order_events.c.id.asc())
            .limit(limit)
            .offset(offset)
        ).mappings().all()
    return [_row_to_work_order_event_model(item) for item in rows]


@app.post("/api/work-orders/escalations/run", response_model=SlaEscalationRunResponse)
def run_sla_escalation(
    payload: SlaEscalationRunRequest,
    principal: dict[str, Any] = Depends(require_permission("work_orders:escalate")),
) -> SlaEscalationRunResponse:
    _require_site_access(principal, payload.site)
    allowed_sites = _allowed_sites_for_principal(principal) if payload.site is None else None
    result = run_sla_escalation_job(
        site=payload.site,
        dry_run=payload.dry_run,
        limit=payload.limit,
        allowed_sites=allowed_sites,
        trigger="api",
    )
    _write_audit_log(
        principal=principal,
        action="work_order_sla_escalation_run",
        resource_type="work_order",
        resource_id="batch",
        detail={
            "site": payload.site,
            "allowed_sites": allowed_sites,
            "dry_run": payload.dry_run,
            "limit": payload.limit,
            "candidate_count": result.candidate_count,
            "escalated_count": result.escalated_count,
            "alert_dispatched": result.alert_dispatched,
            "alert_error": result.alert_error,
        },
    )
    return result


@app.get("/api/reports/monthly", response_model=MonthlyReportRead)
def get_monthly_report(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("reports:read")),
) -> MonthlyReportRead:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    return build_monthly_report(month=month, site=site, allowed_sites=allowed_sites)


@app.get("/api/reports/monthly/csv")
def get_monthly_report_csv(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("reports:export")),
) -> Response:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_monthly_report(month=month, site=site, allowed_sites=allowed_sites)
    csv_text = _build_monthly_report_csv(report)
    site_label = (report.site or "all").replace(" ", "_")
    file_name = f"monthly-report-{report.month}-{site_label}.csv"
    response = Response(
        content=csv_text,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )
    _write_audit_log(
        principal=principal,
        action="report_monthly_export_csv",
        resource_type="report",
        resource_id=f"{report.month}:{report.site or 'ALL'}",
        detail={"month": report.month, "site": report.site},
    )
    return response


@app.get("/api/reports/monthly/pdf")
def get_monthly_report_pdf(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("reports:export")),
) -> Response:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_monthly_report(month=month, site=site, allowed_sites=allowed_sites)
    pdf_bytes = _build_monthly_report_pdf(report)
    site_label = (report.site or "all").replace(" ", "_")
    file_name = f"monthly-report-{report.month}-{site_label}.pdf"
    response = Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": f'attachment; filename="{file_name}"'},
    )
    _write_audit_log(
        principal=principal,
        action="report_monthly_export_pdf",
        resource_type="report",
        resource_id=f"{report.month}:{report.site or 'ALL'}",
        detail={"month": report.month, "site": report.site},
    )
    return response


@app.get("/reports/monthly/print", response_class=HTMLResponse)
def print_monthly_report(
    month: Annotated[str | None, Query(description="YYYY-MM", pattern=r"^\d{4}-\d{2}$")] = None,
    site: Annotated[str | None, Query()] = None,
    principal: dict[str, Any] = Depends(require_permission("reports:read")),
) -> str:
    _require_site_access(principal, site)
    allowed_sites = _allowed_sites_for_principal(principal) if site is None else None
    report = build_monthly_report(month=month, site=site, allowed_sites=allowed_sites)
    return f"""
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Monthly Audit Report {report.month}</title>
  <style>
    @page {{ size: A4; margin: 12mm; }}
    body {{ font-family: Arial, sans-serif; color: #111; }}
    h1 {{ margin-bottom: 8px; font-size: 20px; }}
    h2 {{ margin-top: 14px; margin-bottom: 6px; font-size: 16px; }}
    table {{ width: 100%; border-collapse: collapse; margin-bottom: 8px; }}
    td {{ border: 1px solid #ddd; padding: 6px; font-size: 13px; }}
    .k {{ width: 40%; background: #f7f7f7; font-weight: 600; }}
  </style>
</head>
<body>
  <h1>Monthly Audit Report ({report.month})</h1>
  <table>
    <tr><td class="k">Site</td><td>{report.site or "ALL"}</td></tr>
    <tr><td class="k">Generated At</td><td>{report.generated_at.isoformat()}</td></tr>
  </table>
  <h2>Inspection Summary</h2>
  <table>
    <tr><td class="k">Total</td><td>{report.inspections["total"]}</td></tr>
    <tr><td class="k">Risk Counts</td><td>{report.inspections["risk_counts"]}</td></tr>
    <tr><td class="k">Top Risk Flags</td><td>{report.inspections["top_risk_flags"]}</td></tr>
  </table>
  <h2>Work Order Summary</h2>
  <table>
    <tr><td class="k">Total</td><td>{report.work_orders["total"]}</td></tr>
    <tr><td class="k">Status Counts</td><td>{report.work_orders["status_counts"]}</td></tr>
    <tr><td class="k">Escalated Count</td><td>{report.work_orders["escalated_count"]}</td></tr>
    <tr><td class="k">Overdue Open Count</td><td>{report.work_orders["overdue_open_count"]}</td></tr>
    <tr><td class="k">Completion Rate (%)</td><td>{report.work_orders["completion_rate_percent"]}</td></tr>
    <tr><td class="k">Avg Resolution Hours</td><td>{report.work_orders["avg_resolution_hours"] or "-"}</td></tr>
  </table>
</body>
</html>
"""


app.include_router(ops_router)
app.include_router(admin_router)
app.include_router(adoption_router)
app.include_router(public_router)


